Parent process ID: 17159 node: 172.31.22.229
12 cutpoints
Stages 1
Micro-bs 32 Max mem: 8350516326.4
Predicted microbatch size for 1: 32
comm size 0
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 1 4 0 1019436.4886319825 0
End of simulation:  Mini-batch time (usec) = 1473410
Min send: 10000000, max send 0
Min long send: 10000000, max long send 0
Min fwd: 10000000, max fwd 0; min bwd 10000000, max bwd 0
Min long fwd: 32586, max long fwd 34870; min long bwd 78355, max long bwd 82859
Time taken by simulation: 43 microseconds

Stages 2
Micro-bs 32 Max mem: 5185528320.0
Predicted microbatch size for 2: 32
comm size 12845056
WARNING: no send time found, 2 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 2 8 0 12826.751708984375 541471.8854995001
End of simulation:  Mini-batch time (usec) = 2009897
Min send: 10000000, max send 0
Min long send: 541803, max long send 557166
Min fwd: 17296, max fwd 25575; min bwd 48866, max bwd 52899
Min long fwd: 8632, max long fwd 14339; min long bwd 27298, max long bwd 31270
Time taken by simulation: 164 microseconds

Stages 3
Micro-bs 32 Max mem: 4313669017.6
Predicted microbatch size for 3: 32
comm size 25690112
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 11 0 6699.138164520264 929913.8118823369
End of simulation:  Mini-batch time (usec) = 6713432
Min send: 10000000, max send 0
Min long send: 930245, max long send 952379
Min fwd: 8603, max fwd 19440; min bwd 23111, max bwd 41107
Min long fwd: 1397, max long fwd 9139; min long bwd 11354, max long bwd 19649
Time taken by simulation: 351 microseconds

Stages 4
Micro-bs 32 Max mem: 3762429747.2
Predicted microbatch size for 4: 32
comm size 25690112
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 16 0 2442.7969455718994 929913.8118823369
End of simulation:  Mini-batch time (usec) = 10570352
Min send: 10000000, max send 0
Min long send: 929995, max long send 956013
Min fwd: 4298, max fwd 15893; min bwd 12064, max bwd 32201
Min long fwd: 434, max long fwd 5410; min long bwd 7050, max long bwd 15280
Time taken by simulation: 718 microseconds

Stages 6
Micro-bs 32 Max mem: 3200148889.6
Predicted microbatch size for 6: 32
comm size 12845056
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 22 0 1199.0070343017578 541471.8854995001
End of simulation:  Mini-batch time (usec) = 10143004
Min send: 10000000, max send 0
Min long send: 541608, max long send 568633
Min fwd: 100, max fwd 13449; min bwd 5055, max bwd 25194
Min long fwd: 204, max long fwd 4354; min long bwd 636, max long bwd 8174
Time taken by simulation: 1582 microseconds

{1: 1.47341, 2: 2.009897, 3: 6.713432, 4: 10.570352, 6: 10.143004}
{1: 32, 2: 32, 3: 32, 4: 32, 6: 32}
best config is: 2 32
expected time is 2.009897
9 per stage
18 servers!
Config:
ranks: range(8, 9)
train batch size: 2048
partitions: 2
chunk_size: 32
data depth: 9
stage to rank map: 0,2,4,6,8,10,12,14,16;1,3,5,7,9,11,13,15,17;
World size is 18
/opt/conda/envs/varuna/bin/python -u main.py --rank=8 --chunk_size=32 --local_rank=0 --stage_to_rank_map=0,2,4,6,8,10,12,14,16;1,3,5,7,9,11,13,15,17; --batch-size=224 data -a vgg19 --varuna --lr 0.001 --epochs 1000 --resume s3://spot-checkpoints/vgg19
=> creating model 'vgg19'
[2, 4, 6, 8, 10, 12, 14, 16, 18, 21, 24]
Files already downloaded and verified
Num cutpoints is 11
dry run time 0.8745486736297607
SHARED WEIGHTS ARE
None
this rank  8 is part of pipeline replica  4
7 chunks
8 Overflow !!
8 : update_scale(): _has_overflow, dynamic. _loss_scale =  524288.0
[2022-11-30 13:58:40.213439] Finished iteration 1, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 9490.642
8 Overflow !!
8 : update_scale(): _has_overflow, dynamic. _loss_scale =  262144.0
[2022-11-30 13:58:42.606675] Finished iteration 2, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2392.996
[2022-11-30 13:58:45.071645] Finished iteration 3, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2464.942
8 Overflow !!
8 : update_scale(): _has_overflow, dynamic. _loss_scale =  131072.0
[2022-11-30 13:58:47.460052] Finished iteration 4, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2388.364
8 Overflow !!
8 : update_scale(): _has_overflow, dynamic. _loss_scale =  65536.0
[2022-11-30 13:58:48.806395] Finished iteration 5, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1346.251
8 Overflow !!
8 : update_scale(): _has_overflow, dynamic. _loss_scale =  32768.0
[2022-11-30 13:58:50.155629] Finished iteration 6, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1349.199
8 Overflow !!
8 : update_scale(): _has_overflow, dynamic. _loss_scale =  16384.0
[2022-11-30 13:58:51.508546] Finished iteration 7, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1352.889
8 : update_scale(): _has_overflow, dynamic. _loss_scale =  8192.0
[2022-11-30 13:58:52.996148] Finished iteration 8, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1487.565
[2022-11-30 13:58:54.432179] Finished iteration 9, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1436.005
[2022-11-30 13:58:30.704057] Epoch: [0][ 10/224]	Time  1.402 ( 2.510)	Data  0.008 ( 0.530)	Loss 6.8945e+00 (2.0419e+01)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
[2022-11-30 13:58:55.829597] Finished iteration 10, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1397.370
[2022-11-30 13:58:57.161579] Finished iteration 11, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1331.946
[2022-11-30 13:58:58.430108] Finished iteration 12, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1268.512
[2022-11-30 13:58:59.764755] Finished iteration 13, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1334.581
[2022-11-30 13:59:01.115125] Finished iteration 14, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1350.333
[2022-11-30 13:59:02.541393] Finished iteration 15, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1426.229
[2022-11-30 13:59:03.947683] Finished iteration 16, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1406.252
[2022-11-30 13:59:05.419872] Finished iteration 17, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1472.146
[2022-11-30 13:59:06.844834] Finished iteration 18, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1424.912
[2022-11-30 13:59:08.191053] Finished iteration 19, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1346.186
[2022-11-30 13:58:30.704057] Epoch: [0][ 20/224]	Time  1.396 ( 1.943)	Data  0.003 ( 0.267)	Loss 5.4035e+00 (1.3227e+01)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
[2022-11-30 13:59:09.588013] Finished iteration 20, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1396.927
[2022-11-30 13:59:10.998983] Finished iteration 21, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1410.930
[2022-11-30 13:59:12.466887] Finished iteration 22, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1467.869
[2022-11-30 13:59:13.852088] Finished iteration 23, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1385.174
[2022-11-30 13:59:15.297778] Finished iteration 24, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1445.664
[2022-11-30 13:59:16.702537] Finished iteration 25, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1404.729
[2022-11-30 13:59:18.187359] Finished iteration 26, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1484.745
[2022-11-30 13:59:19.560621] Finished iteration 27, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1373.227
[2022-11-30 13:59:21.046663] Finished iteration 28, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1486.002
[2022-11-30 13:59:22.883744] Finished iteration 29, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1837.049
[2022-11-30 13:58:30.704057] Epoch: [0][ 30/224]	Time  1.310 ( 1.782)	Data  0.006 ( 0.180)	Loss 4.6964e+00 (1.0441e+01)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
[2022-11-30 13:59:24.191640] Finished iteration 30, CKPT_AND_STOP: False, flag: tensor([1], dtype=torch.int32), speed: 1307.868
Opt ckpt time 1.465552568435669
Process done with return code 0
Parent process ID: 18751 node: 172.31.22.165
12 cutpoints
Stages 1
Micro-bs 32 Max mem: 8350516326.4
Predicted microbatch size for 1: 32
comm size 0
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 1 4 0 980927.4647721202 0
End of simulation:  Mini-batch time (usec) = 1434901
Min send: 10000000, max send 0
Min long send: 10000000, max long send 0
Min fwd: 10000000, max fwd 0; min bwd 10000000, max bwd 0
Min long fwd: 32586, max long fwd 34870; min long bwd 78355, max long bwd 82859
Time taken by simulation: 40 microseconds

Stages 2
Micro-bs 32 Max mem: 5185528320.0
Predicted microbatch size for 2: 32
comm size 12845056
WARNING: no send time found, 2 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 2 8 0 12136.97624206543 541471.8854995001
End of simulation:  Mini-batch time (usec) = 2009207
Min send: 10000000, max send 0
Min long send: 541803, max long send 557166
Min fwd: 17296, max fwd 25575; min bwd 48866, max bwd 52899
Min long fwd: 8632, max long fwd 14339; min long bwd 27298, max long bwd 31270
Time taken by simulation: 161 microseconds

Stages 3
Micro-bs 32 Max mem: 4313669017.6
Predicted microbatch size for 3: 32
comm size 25690112
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 13 0 5941.788673400879 929913.8118823369
End of simulation:  Mini-batch time (usec) = 7626781
Min send: 10000000, max send 0
Min long send: 930245, max long send 952379
Min fwd: 8603, max fwd 19440; min bwd 21579, max bwd 43006
Min long fwd: 1397, max long fwd 9139; min long bwd 11398, max long bwd 19649
Time taken by simulation: 416 microseconds

Stages 4
Micro-bs 32 Max mem: 3762429747.2
Predicted microbatch size for 4: 32
comm size 25690112
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 16 0 2442.7969455718994 929913.8118823369
End of simulation:  Mini-batch time (usec) = 10570352
Min send: 10000000, max send 0
Min long send: 929995, max long send 956013
Min fwd: 4298, max fwd 15893; min bwd 12064, max bwd 32201
Min long fwd: 434, max long fwd 5410; min long bwd 7050, max long bwd 15280
Time taken by simulation: 771 microseconds

Stages 6
Micro-bs 32 Max mem: 3200148889.6
Predicted microbatch size for 6: 32
comm size 12845056
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 32 0 726.5806198120117 541471.8854995001
End of simulation:  Mini-batch time (usec) = 12814276
Min send: 10000000, max send 0
Min long send: 541471, max long send 569692
Min fwd: 100, max fwd 12458; min bwd 5055, max bwd 25528
Min long fwd: 242, max long fwd 4365; min long bwd 988, max long bwd 7376
Time taken by simulation: 2310 microseconds

{1: 1.434901, 2: 2.009207, 3: 7.626781, 4: 10.570352, 6: 12.814276}
{1: 32, 2: 32, 3: 32, 4: 32, 6: 32}
best config is: 2 32
expected time is 2.009207
8 per stage
16 servers!
Config:
ranks: range(8, 9)
train batch size: 2048
partitions: 2
chunk_size: 32
data depth: 8
stage to rank map: 0,2,4,6,8,10,12,14;1,3,5,7,9,11,13,15;
World size is 16
/opt/conda/envs/varuna/bin/python -u main.py --rank=8 --chunk_size=32 --local_rank=0 --stage_to_rank_map=0,2,4,6,8,10,12,14;1,3,5,7,9,11,13,15; --batch-size=256 data -a vgg19 --varuna --lr 0.001 --epochs 1000 --resume s3://spot-checkpoints/vgg19 --resume_step 30
=> creating model 'vgg19'
[2, 4, 6, 8, 10, 12, 14, 16, 18, 21, 24]
Files already downloaded and verified
Num cutpoints is 11
dry run time 0.8077354431152344
SHARED WEIGHTS ARE
None
this rank  8 is part of pipeline replica  4
8 chunks
8 Overflow !!
8 : update_scale(): _has_overflow, dynamic. _loss_scale =  524288.0
[2022-11-30 14:01:02.435747] Finished iteration 31, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 9750.994
8 Overflow !!
8 : update_scale(): _has_overflow, dynamic. _loss_scale =  262144.0
[2022-11-30 14:01:04.948766] Finished iteration 32, CKPT_AND_STOP: False, flag: tensor([1], dtype=torch.int32), speed: 2512.775
Opt ckpt time 1.4360260963439941
Process done with return code 0
Parent process ID: 17736 node: 172.31.19.171
12 cutpoints
Stages 1
Micro-bs 32 Max mem: 8350516326.4
Predicted microbatch size for 1: 32
comm size 0
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 1 4 0 959937.744140625 0
End of simulation:  Mini-batch time (usec) = 1413911
Min send: 10000000, max send 0
Min long send: 10000000, max long send 0
Min fwd: 10000000, max fwd 0; min bwd 10000000, max bwd 0
Min long fwd: 32586, max long fwd 34870; min long bwd 78355, max long bwd 82859
Time taken by simulation: 44 microseconds

Stages 2
Micro-bs 32 Max mem: 5185528320.0
Predicted microbatch size for 2: 32
comm size 12845056
WARNING: no send time found, 2 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 2 8 0 12136.97624206543 541471.8854995001
End of simulation:  Mini-batch time (usec) = 2009207
Min send: 10000000, max send 0
Min long send: 541803, max long send 557166
Min fwd: 17296, max fwd 25575; min bwd 48866, max bwd 52899
Min long fwd: 8632, max long fwd 14339; min long bwd 27298, max long bwd 31270
Time taken by simulation: 166 microseconds

Stages 3
Micro-bs 32 Max mem: 4313669017.6
Predicted microbatch size for 3: 32
comm size 25690112
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 13 0 5941.788673400879 929913.8118823369
End of simulation:  Mini-batch time (usec) = 7626781
Min send: 10000000, max send 0
Min long send: 930245, max long send 952379
Min fwd: 8603, max fwd 19440; min bwd 21579, max bwd 43006
Min long fwd: 1397, max long fwd 9139; min long bwd 11398, max long bwd 19649
Time taken by simulation: 412 microseconds

Stages 4
Micro-bs 32 Max mem: 3762429747.2
Predicted microbatch size for 4: 32
comm size 25690112
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 16 0 2442.7969455718994 929913.8118823369
End of simulation:  Mini-batch time (usec) = 10570352
Min send: 10000000, max send 0
Min long send: 929995, max long send 956013
Min fwd: 4298, max fwd 15893; min bwd 12064, max bwd 32201
Min long fwd: 434, max long fwd 5410; min long bwd 7050, max long bwd 15280
Time taken by simulation: 748 microseconds

Stages 6
Micro-bs 32 Max mem: 3200148889.6
Predicted microbatch size for 6: 32
comm size 12845056
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 32 0 726.5806198120117 541471.8854995001
End of simulation:  Mini-batch time (usec) = 12814276
Min send: 10000000, max send 0
Min long send: 541471, max long send 569692
Min fwd: 100, max fwd 12458; min bwd 5055, max bwd 25528
Min long fwd: 242, max long fwd 4365; min long bwd 988, max long bwd 7376
Time taken by simulation: 2297 microseconds

{1: 1.413911, 2: 2.009207, 3: 7.626781, 4: 10.570352, 6: 12.814276}
{1: 32, 2: 32, 3: 32, 4: 32, 6: 32}
best config is: 2 32
expected time is 2.009207
8 per stage
16 servers!
Config:
ranks: range(8, 9)
train batch size: 2048
partitions: 2
chunk_size: 32
data depth: 8
stage to rank map: 0,2,4,6,8,10,12,14;1,3,5,7,9,11,13,15;
World size is 16
/opt/conda/envs/varuna/bin/python -u main.py --rank=8 --chunk_size=32 --local_rank=0 --stage_to_rank_map=0,2,4,6,8,10,12,14;1,3,5,7,9,11,13,15; --batch-size=256 data -a vgg19 --varuna --lr 0.001 --epochs 1000 --resume s3://spot-checkpoints/vgg19 --resume_step 32
=> creating model 'vgg19'
[2, 4, 6, 8, 10, 12, 14, 16, 18, 21, 24]
Files already downloaded and verified
Num cutpoints is 11
dry run time 0.7405126094818115
SHARED WEIGHTS ARE
None
this rank  8 is part of pipeline replica  4
8 chunks
8 Overflow !!
8 : update_scale(): _has_overflow, dynamic. _loss_scale =  524288.0
[2022-11-30 14:02:39.021254] Finished iteration 33, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 9856.284
8 Overflow !!
8 : update_scale(): _has_overflow, dynamic. _loss_scale =  262144.0
[2022-11-30 14:02:41.465794] Finished iteration 34, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2444.177
8 : update_scale(): _has_overflow, dynamic. _loss_scale =  131072.0
[2022-11-30 14:02:44.043890] Finished iteration 35, CKPT_AND_STOP: False, flag: tensor([1], dtype=torch.int32), speed: 2578.061
Opt ckpt time 1.7442269325256348
Process done with return code 0
Parent process ID: 16935 node: 172.31.17.44
12 cutpoints
Stages 1
Micro-bs 32 Max mem: 8350516326.4
Predicted microbatch size for 1: 32
comm size 0
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 1 5 0 469314.3005371094 0
End of simulation:  Mini-batch time (usec) = 1031482
Min send: 10000000, max send 0
Min long send: 10000000, max long send 0
Min fwd: 10000000, max fwd 0; min bwd 10000000, max bwd 0
Min long fwd: 31455, max long fwd 34870; min long bwd 76739, max long bwd 82859
Time taken by simulation: 49 microseconds

Stages 2
Micro-bs 32 Max mem: 5185528320.0
Predicted microbatch size for 2: 32
comm size 12845056
WARNING: no send time found, 2 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 2 10 0 14465.604782104492 541471.8854995001
End of simulation:  Mini-batch time (usec) = 2417640
Min send: 10000000, max send 0
Min long send: 541659, max long send 557502
Min fwd: 17296, max fwd 25575; min bwd 47081, max bwd 56289
Min long fwd: 10095, max long fwd 15512; min long bwd 26495, max long bwd 30607
Time taken by simulation: 202 microseconds

Stages 3
Micro-bs 32 Max mem: 4313669017.6
Predicted microbatch size for 3: 32
comm size 25690112
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 13 0 5941.788673400879 929913.8118823369
End of simulation:  Mini-batch time (usec) = 7626781
Min send: 10000000, max send 0
Min long send: 930245, max long send 952379
Min fwd: 8603, max fwd 19440; min bwd 21579, max bwd 43006
Min long fwd: 1397, max long fwd 9139; min long bwd 11398, max long bwd 19649
Time taken by simulation: 412 microseconds

Stages 4
Micro-bs 32 Max mem: 3762429747.2
Predicted microbatch size for 4: 32
comm size 25690112
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 22 0 1736.614465713501 929913.8118823369
End of simulation:  Mini-batch time (usec) = 13349003
Min send: 10000000, max send 0
Min long send: 929995, max long send 952379
Min fwd: 3254, max fwd 16685; min bwd 13456, max bwd 30930
Min long fwd: 65, max long fwd 8369; min long bwd 8615, max long bwd 14208
Time taken by simulation: 986 microseconds

Stages 6
Micro-bs 32 Max mem: 3200148889.6
Predicted microbatch size for 6: 32
comm size 12845056
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 32 0 726.5806198120117 541471.8854995001
End of simulation:  Mini-batch time (usec) = 12814276
Min send: 10000000, max send 0
Min long send: 541471, max long send 569692
Min fwd: 100, max fwd 12458; min bwd 5055, max bwd 25528
Min long fwd: 242, max long fwd 4365; min long bwd 988, max long bwd 7376
Time taken by simulation: 2355 microseconds

{1: 1.031482, 2: 2.41764, 3: 7.626781, 4: 13.349003, 6: 12.814276}
{1: 32, 2: 32, 3: 32, 4: 32, 6: 32}
best config is: 2 32
expected time is 2.41764
7 per stage
14 servers!
Config:
ranks: range(8, 9)
train batch size: 2048
partitions: 2
chunk_size: 32
data depth: 7
stage to rank map: 0,2,4,6,8,10,12;1,3,5,7,9,11,13;
World size is 14
/opt/conda/envs/varuna/bin/python -u main.py --rank=8 --chunk_size=32 --local_rank=0 --stage_to_rank_map=0,2,4,6,8,10,12;1,3,5,7,9,11,13; --batch-size=288 data -a vgg19 --varuna --lr 0.001 --epochs 1000 --resume s3://spot-checkpoints/vgg19 --resume_step 35
=> creating model 'vgg19'
[2, 4, 6, 8, 10, 12, 14, 16, 18, 21, 24]
Files already downloaded and verified
Num cutpoints is 11
dry run time 0.8303418159484863
SHARED WEIGHTS ARE
None
this rank  8 is part of pipeline replica  4
9 chunks
8 Overflow !!
8 : update_scale(): _has_overflow, dynamic. _loss_scale =  524288.0
[2022-11-30 14:04:17.275972] Finished iteration 36, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 9019.596
8 : update_scale(): _has_overflow, dynamic. _loss_scale =  262144.0
[2022-11-30 14:04:19.778259] Finished iteration 37, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2502.088
8 : update_scale(): _has_overflow, dynamic. _loss_scale =  131072.0
[2022-11-30 14:04:22.335826] Finished iteration 38, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2557.533
8 : update_scale(): _has_overflow, dynamic. _loss_scale =  65536.0
[2022-11-30 14:04:24.838472] Finished iteration 39, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2502.590
8 : update_scale(): _has_overflow, dynamic. _loss_scale =  32768.0
[2022-11-30 14:04:08.254159] Epoch: [0][ 40/174]	Time  3.524 ( 3.819)	Data  1.010 ( 0.863)	Loss 4.7027e+00 (4.6957e+00)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
[2022-11-30 14:04:27.356397] Finished iteration 40, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2517.827
[2022-11-30 14:04:28.840589] Finished iteration 41, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1484.186
[2022-11-30 14:04:30.291327] Finished iteration 42, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1450.613
[2022-11-30 14:04:31.828909] Finished iteration 43, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1537.527
[2022-11-30 14:04:33.379258] Finished iteration 44, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1550.306
[2022-11-30 14:04:34.849911] Finished iteration 45, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1470.705
[2022-11-30 14:04:36.387035] Finished iteration 46, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1536.999
[2022-11-30 14:04:37.893140] Finished iteration 47, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1506.066
[2022-11-30 14:04:39.400324] Finished iteration 48, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1507.128
[2022-11-30 14:04:40.893009] Finished iteration 49, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1492.645
[2022-11-30 14:04:08.254159] Epoch: [0][ 50/174]	Time  1.505 ( 2.276)	Data  0.004 ( 0.291)	Loss 4.6341e+00 (4.6751e+00)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
[2022-11-30 14:04:42.403111] Finished iteration 50, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1510.034
[2022-11-30 14:04:43.893636] Finished iteration 51, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1490.513
[2022-11-30 14:04:45.376246] Finished iteration 52, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1482.571
[2022-11-30 14:04:46.887393] Finished iteration 53, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1511.093
[2022-11-30 14:04:48.426639] Finished iteration 54, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1539.228
[2022-11-30 14:04:49.934014] Finished iteration 55, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1507.335
[2022-11-30 14:04:51.412037] Finished iteration 56, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1477.977
[2022-11-30 14:04:52.893907] Finished iteration 57, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1481.914
