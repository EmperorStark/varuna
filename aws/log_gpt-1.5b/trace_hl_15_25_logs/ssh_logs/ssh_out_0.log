Parent process ID: 31660 node: 172.31.28.108
48 cutpoints
Stages 1
13 179408597504.00003
7 107169514393.59993
4 71132724223.99994
2 45211359129.60004
Predicted microbatch size for 1: 1
comm size 0
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 1 5 0 5970528.80859375 0
End of simulation:  Mini-batch time (usec) = 8296641
Min send: 10000000, max send 0
Min long send: 10000000, max long send 0
Min fwd: 10000000, max fwd 0; min bwd 10000000, max bwd 0
Min long fwd: 164718, max long fwd 168133; min long bwd 296265, max long bwd 302385
Time taken by simulation: 47 microseconds

Stages 2
13 91326429286.39996
7 54442902425.59998
4 36011032883.20001
2 22710326886.4
Predicted microbatch size for 2: 1
comm size 1638400
WARNING: no send time found, 2 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 2 11 0 2767979.736328125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6203240
Min send: 10000000, max send 0
Min long send: 38387, max long send 62760
Min fwd: 76538, max fwd 83279; min bwd 142710, max bwd 147733
Min long fwd: 81915, max long fwd 89657; min long bwd 148530, max long bwd 156110
Time taken by simulation: 216 microseconds

Stages 3
13 62378072166.39999
7 37276345241.600006
4 24698690662.400005
2 15681540915.199997
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 18 0 1846814.0869140625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5987018
Min send: 10000000, max send 0
Min long send: 38387, max long send 60521
Min fwd: 45773, max fwd 59834; min bwd 93871, max bwd 104244
Min long fwd: 57033, max long fwd 64913; min long bwd 98140, max long bwd 103204
Time taken by simulation: 524 microseconds

Stages 4
13 47854723993.6
7 28643536588.800003
4 19017705369.600002
2 12167147929.599998
3 15282454937.599998
Predicted microbatch size for 4: 2
comm size 3276800
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 13 0 1338646.484375 80871.45884831746
End of simulation:  Mini-batch time (usec) = 5132496
Min send: 10000000, max send 0
Min long send: 80953, max long send 103337
Min fwd: 48269, max fwd 59401; min bwd 107938, max bwd 126574
Min long fwd: 53770, max long fwd 60383; min long bwd 118672, max long bwd 125606
Time taken by simulation: 623 microseconds

Stages 6
13 33331375820.800003
7 20010727936.0
4 13336720076.8
5 15504158822.400002
Predicted microbatch size for 6: 4
comm size 6553600
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 11 0 770127.8076171875 159635.3450129109
End of simulation:  Mini-batch time (usec) = 6157105
Min send: 10000000, max send 0
Min long send: 159689, max long send 184340
Min fwd: 52659, max fwd 63832; min bwd 123243, max bwd 140240
Min long fwd: 72998, max long fwd 78841; min long bwd 148211, max long bwd 154022
Time taken by simulation: 770 microseconds

Stages 8
13 26069701734.4
7 15694323609.6
4 10496227430.4
5 12173858304.0
6 13758925312.0
Predicted microbatch size for 8: 6
comm size 9830400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 11 0 442992.24853515625 230166.85465330718
End of simulation:  Mini-batch time (usec) = 8313990
Min send: 10000000, max send 0
Min long send: 230166, max long send 255370
Min fwd: 54051, max fwd 66033; min bwd 132265, max bwd 140978
Min long fwd: 81808, max long fwd 89347; min long bwd 157650, max long bwd 164467
Time taken by simulation: 1039 microseconds

Stages 12
13 18808027648.0
7 11377919283.2
10 15096853196.8
11 16232151142.4
Predicted microbatch size for 12: 10
comm size 16384000
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 13 0 0 361377.8571928701
End of simulation:  Mini-batch time (usec) = 15020502
Min send: 10000000, max send 0
Min long send: 361431, max long send 386584
Min fwd: 61398, max fwd 73009; min bwd 138510, max bwd 150849
Min long fwd: 109818, max long fwd 116156; min long bwd 179680, max long bwd 186710
Time taken by simulation: 1899 microseconds

Stages 16
13 15177190604.8
19 21144245452.8
16 18160685260.8
14 16174148608.0
Predicted microbatch size for 16: 13
comm size 21299200
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 10 0 0 425876.58448885847
End of simulation:  Mini-batch time (usec) = 20148929
Min send: 10000000, max send 0
Min long send: 425930, max long send 455880
Min fwd: 58146, max fwd 69239; min bwd 134282, max bwd 149519
Min long fwd: 116097, max long fwd 122130; min long bwd 192822, max long bwd 197216
Time taken by simulation: 2378 microseconds

can't have 24 stages!
{1: 8.296641, 2: 6.20324, 3: 5.987018, 4: 5.132496, 6: 6.157105, 8: 8.31399, 12: 15.020502, 16: 20.148929}
{1: 1, 2: 1, 3: 1, 4: 2, 6: 4, 8: 6, 12: 10, 16: 13}
best config is: 4 2
expected time is 5.132496
5 per stage
20 servers!
Config:
ranks: range(0, 1)
train batch size: 128
partitions: 4
chunk_size: 2
data depth: 5
stage to rank map: 0,4,8,12,16;1,5,9,13,17;2,6,10,14,18;3,7,11,15,19;
World size is 20
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=0 --chunk_size=2 --local_rank=0 --stage_to_rank_map=0,4,8,12,16;1,5,9,13,17;2,6,10,14,18;3,7,11,15,19; --batch-size=25 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 232
using world size: 20 and model-parallel size: 1 
using torch.float32 for parameters ...
-------------------- arguments --------------------
  adam_beta1 ...................... 0.9
  adam_beta2 ...................... 0.999
  adam_eps ........................ 1e-08
  adlr_autoresume ................. False
  adlr_autoresume_interval ........ 1000
  apply_query_key_layer_scaling ... False
  apply_residual_connection_post_layernorm  False
  attention_dropout ............... 0.1
  attention_softmax_in_fp32 ....... False
  batch_size ...................... 25
  bert_load ....................... None
  bias_dropout_fusion ............. False
  bias_gelu_fusion ................ False
  block_data_path ................. None
  checkpoint_activations .......... False
  checkpoint_num_layers ........... 1
  chunk_size ...................... 2
  clip_grad ....................... 1.0
  data_impl ....................... mmap
  data_path ....................... None
  DDP_impl ........................ local
  distribute_checkpointed_activations  False
  distributed_backend ............. gloo
  dynamic_loss_scale .............. True
  eod_mask_loss ................... False
  eval_interval ................... 10000
  eval_iters ...................... 10
  exit_interval ................... 10000
  faiss_use_gpu ................... False
  finetune ........................ False
  fp16 ............................ True
  fp16_lm_cross_entropy ........... False
  fp32_allreduce .................. False
  hidden_dropout .................. 0.1
  hidden_size ..................... 1600
  hysteresis ...................... 2
  ict_head_size ................... None
  ict_load ........................ None
  indexer_batch_size .............. 128
  indexer_log_interval ............ 1000
  init_method_std ................. 0.02
  layernorm_epsilon ............... 1e-05
  lazy_mpu_init ................... None
  load ............................ s3://spot-checkpoints/gpt
  local_rank ...................... 0
  log_interval .................... 1
  loss_scale ...................... None
  loss_scale_window ............... 1000
  lr .............................. 0.00015
  lr_decay_iters .................. 18750
  lr_decay_style .................. cosine
  make_vocab_size_divisible_by .... 128
  mask_prob ....................... 0.15
  max_position_embeddings ......... 1024
  merge_file ...................... /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt
  min_lr .......................... 1e-05
  min_scale ....................... 1
  mmap_warmup ..................... False
  model_parallel_size ............. 1
  no_load_optim ................... False
  no_load_rng ..................... False
  no_save_optim ................... False
  no_save_rng ..................... False
  num_attention_heads ............. 25
  num_layers ...................... 48
  num_unique_layers ............... None
  num_workers ..................... 2
  onnx_safe ....................... None
  openai_gelu ..................... False
  override_lr_scheduler ........... False
  param_sharing_style ............. grouped
  params_dtype .................... torch.float32
  profiling ....................... False
  query_in_block_prob ............. 0.1
  rank ............................ 0
  report_topk_accuracies .......... []
  reset_attention_mask ............ False
  reset_position_ids .............. False
  resume_step ..................... 232
  save ............................ s3://spot-checkpoints/gpt
  save_interval ................... 500
  scaled_masked_softmax_fusion .... False
  scaled_upper_triang_masked_softmax_fusion  False
  seed ............................ 1234
  seq_length ...................... 1024
  short_seq_prob .................. 0.1
  split ........................... 949,50,1
  stage_to_rank_map ............... 0,4,8,12,16;1,5,9,13,17;2,6,10,14,18;3,7,11,15,19;
  synthetic ....................... True
  tensorboard_dir ................. None
  titles_data_path ................ None
  tokenizer_type .................. GPT2BPETokenizer
  train_iters ..................... 18750
  use_checkpoint_lr_scheduler ..... False
  use_cpu_initialization .......... True
  use_one_sent_docs ............... False
  varuna .......................... True
  vocab_file ...................... /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json
  vocab_size ...................... 40478
  warmup .......................... 0.01
  weight_decay .................... 0.01
  world_size ...................... 20
---------------- end of arguments ----------------
> building GPT2BPETokenizer tokenizer ...
 > padded vocab (size: 50257) with 47 dummy tokens (new size: 50304)
> initializing torch distributed ...
> initializing model parallel with size 1
> setting random seeds to 1234 ...
> initializing model parallel cuda seeds on global rank 0, model parallel rank 0, and data parallel rank 0 with model parallel seed: 3952 and data parallel seed: 1234
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      2343750
    validation: 2500
    test:       1250
> building train, validation, and test datasets for GPT2 ...
> finished creating GPT2 datasets ...
building GPT2 model ...
dry run time 0.683372974395752
SHARED WEIGHTS ARE
[(0, 3)]
this rank  0 is part of pipeline replica  0
13 chunks
 > number of parameters on model parallel rank 0: 451014400
Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.

Defaults for this optimization level are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
> learning rate decay style: cosine
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
global rank 0 is loading checkpoint s3://spot-checkpoints/gpt/iter_0000232/mp_rank_00/model_optim_rng.pt
 > using checkpoint value 0.00015 for learning rate
 > using checkpoint value 1e-05 for minimum learning rate
 > using checkpoint value 187.5 for warmup iterations
 > using checkpoint value 18750 for total number of iterations
 > using checkpoint value cosine for decay style
  successfully loaded s3://spot-checkpoints/gpt/iter_0000232/mp_rank_00/model_optim_rng.pt
 > finished loading checkpoint in 52.328 seconds
setting training data start iteration to 232
setting validation data start iteration to 0
done with setups ...
time (ms) | model and optimizer: 69481.61 | train/valid/test data iterators: 287.56
training ...
START iteration 232, CKPT_AND_STOP: False
Finished iteration 233, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
 iteration      233/   18750 | elapsed time per iteration (ms): 8116.8 | learning rate: 1.500E-04 | lm loss: 1.060528E+01 | loss scale: 131072.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
after 233 iterations memory (MB) | allocated: 6137.60009765625 | max allocated: 13061.97802734375 | reserved: 14082.0 | max reserved: 14082.0
time (ms) | optimizer: 24.14 | batch generator: 14.33
START iteration 233, CKPT_AND_STOP: False
Finished iteration 234, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
 iteration      234/   18750 | elapsed time per iteration (ms): 6836.8 | learning rate: 1.500E-04 | lm loss: 1.060623E+01 | loss scale: 131072.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | optimizer: 23.73 | batch generator: 1.99
START iteration 234, CKPT_AND_STOP: False
Finished iteration 235, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
 iteration      235/   18750 | elapsed time per iteration (ms): 5710.7 | learning rate: 1.500E-04 | lm loss: 1.063215E+01 | loss scale: 131072.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | optimizer: 23.75 | batch generator: 2.81
START iteration 235, CKPT_AND_STOP: False
Finished iteration 236, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
 iteration      236/   18750 | elapsed time per iteration (ms): 5692.2 | learning rate: 1.500E-04 | lm loss: 1.063104E+01 | loss scale: 131072.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | optimizer: 23.66 | batch generator: 1.86
START iteration 236, CKPT_AND_STOP: False
Finished iteration 237, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
 iteration      237/   18750 | elapsed time per iteration (ms): 5695.8 | learning rate: 1.500E-04 | lm loss: 1.063549E+01 | loss scale: 131072.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | optimizer: 23.78 | batch generator: 1.80
START iteration 237, CKPT_AND_STOP: False
Finished iteration 238, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
 iteration      238/   18750 | elapsed time per iteration (ms): 4616.0 | learning rate: 1.500E-04 | lm loss: 1.063356E+01 | loss scale: 131072.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | optimizer: 23.69 | batch generator: 1.47
START iteration 238, CKPT_AND_STOP: False
Finished iteration 239, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
 iteration      239/   18750 | elapsed time per iteration (ms): 4726.9 | learning rate: 1.500E-04 | lm loss: 1.063383E+01 | loss scale: 131072.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | optimizer: 23.71 | batch generator: 2.55
START iteration 239, CKPT_AND_STOP: False
Finished iteration 240, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
 iteration      240/   18750 | elapsed time per iteration (ms): 4650.5 | learning rate: 1.500E-04 | lm loss: 1.063597E+01 | loss scale: 131072.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | optimizer: 23.73 | batch generator: 1.48
START iteration 240, CKPT_AND_STOP: False
Finished iteration 241, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
 iteration      241/   18750 | elapsed time per iteration (ms): 4635.5 | learning rate: 1.500E-04 | lm loss: 1.063368E+01 | loss scale: 131072.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | optimizer: 23.67 | batch generator: 2.17
START iteration 241, CKPT_AND_STOP: False
Finished iteration 242, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
 iteration      242/   18750 | elapsed time per iteration (ms): 4631.2 | learning rate: 1.500E-04 | lm loss: 1.063199E+01 | loss scale: 131072.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | optimizer: 23.67 | batch generator: 1.41
START iteration 242, CKPT_AND_STOP: False
Finished iteration 243, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
 iteration      243/   18750 | elapsed time per iteration (ms): 4671.3 | learning rate: 1.500E-04 | lm loss: 1.063205E+01 | loss scale: 131072.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | optimizer: 23.67 | batch generator: 2.16
START iteration 243, CKPT_AND_STOP: False
Finished iteration 244, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
 iteration      244/   18750 | elapsed time per iteration (ms): 4690.8 | learning rate: 1.500E-04 | lm loss: 1.063259E+01 | loss scale: 131072.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | optimizer: 23.69 | batch generator: 1.66
START iteration 244, CKPT_AND_STOP: False
Finished iteration 245, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
 iteration      245/   18750 | elapsed time per iteration (ms): 4648.7 | learning rate: 1.500E-04 | lm loss: 1.063017E+01 | loss scale: 131072.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | optimizer: 23.73 | batch generator: 2.37
START iteration 245, CKPT_AND_STOP: False
Finished iteration 246, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
 iteration      246/   18750 | elapsed time per iteration (ms): 4696.5 | learning rate: 1.500E-04 | lm loss: 1.063102E+01 | loss scale: 131072.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | optimizer: 23.65 | batch generator: 1.64
START iteration 246, CKPT_AND_STOP: False
Finished iteration 247, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
 iteration      247/   18750 | elapsed time per iteration (ms): 4700.6 | learning rate: 1.500E-04 | lm loss: 1.062975E+01 | loss scale: 131072.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | optimizer: 23.68 | batch generator: 2.37
START iteration 247, CKPT_AND_STOP: False
Finished iteration 248, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
 iteration      248/   18750 | elapsed time per iteration (ms): 4669.8 | learning rate: 1.500E-04 | lm loss: 1.062987E+01 | loss scale: 131072.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | optimizer: 23.78 | batch generator: 1.75
START iteration 248, CKPT_AND_STOP: False
Finished iteration 249, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
 iteration      249/   18750 | elapsed time per iteration (ms): 4660.4 | learning rate: 1.500E-04 | lm loss: 1.062002E+01 | loss scale: 131072.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | optimizer: 23.70 | batch generator: 2.10
START iteration 249, CKPT_AND_STOP: False
Finished iteration 250, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
 iteration      250/   18750 | elapsed time per iteration (ms): 4680.8 | learning rate: 1.500E-04 | lm loss: 1.061862E+01 | loss scale: 131072.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | optimizer: 23.67 | batch generator: 1.45
START iteration 250, CKPT_AND_STOP: False
Finished iteration 251, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
 iteration      251/   18750 | elapsed time per iteration (ms): 4701.9 | learning rate: 1.500E-04 | lm loss: 1.061909E+01 | loss scale: 131072.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | optimizer: 23.70 | batch generator: 2.01
START iteration 251, CKPT_AND_STOP: False
Finished iteration 252, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
 iteration      252/   18750 | elapsed time per iteration (ms): 4658.9 | learning rate: 1.500E-04 | lm loss: 1.061655E+01 | loss scale: 131072.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | optimizer: 23.67 | batch generator: 1.54
START iteration 252, CKPT_AND_STOP: False
Finished iteration 253, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
 iteration      253/   18750 | elapsed time per iteration (ms): 4618.7 | learning rate: 1.500E-04 | lm loss: 1.061717E+01 | loss scale: 131072.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | optimizer: 23.72 | batch generator: 2.11
START iteration 253, CKPT_AND_STOP: False
Finished iteration 254, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
 iteration      254/   18750 | elapsed time per iteration (ms): 4648.6 | learning rate: 1.500E-04 | lm loss: 1.061647E+01 | loss scale: 131072.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | optimizer: 23.65 | batch generator: 1.67
START iteration 254, CKPT_AND_STOP: False
Finished iteration 255, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
 iteration      255/   18750 | elapsed time per iteration (ms): 4667.2 | learning rate: 1.500E-04 | lm loss: 1.061624E+01 | loss scale: 131072.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | optimizer: 23.70 | batch generator: 1.99
START iteration 255, CKPT_AND_STOP: False
Finished iteration 256, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
 iteration      256/   18750 | elapsed time per iteration (ms): 4654.7 | learning rate: 1.500E-04 | lm loss: 1.061688E+01 | loss scale: 131072.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | optimizer: 23.68 | batch generator: 1.48
START iteration 256, CKPT_AND_STOP: False
Finished iteration 257, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
 iteration      257/   18750 | elapsed time per iteration (ms): 4742.0 | learning rate: 1.500E-04 | lm loss: 1.061675E+01 | loss scale: 131072.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | optimizer: 23.65 | batch generator: 2.12
START iteration 257, CKPT_AND_STOP: False
Finished iteration 258, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
 iteration      258/   18750 | elapsed time per iteration (ms): 4613.3 | learning rate: 1.500E-04 | lm loss: 1.061659E+01 | loss scale: 131072.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | optimizer: 23.68 | batch generator: 1.96
START iteration 258, CKPT_AND_STOP: False
Finished iteration 259, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
 iteration      259/   18750 | elapsed time per iteration (ms): 4633.3 | learning rate: 1.500E-04 | lm loss: 1.061569E+01 | loss scale: 131072.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | optimizer: 23.68 | batch generator: 1.86
START iteration 259, CKPT_AND_STOP: False
Finished iteration 260, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
 iteration      260/   18750 | elapsed time per iteration (ms): 4655.0 | learning rate: 1.500E-04 | lm loss: 1.061808E+01 | loss scale: 131072.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | optimizer: 23.84 | batch generator: 1.77
START iteration 260, CKPT_AND_STOP: False
Finished iteration 261, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
 iteration      261/   18750 | elapsed time per iteration (ms): 4653.4 | learning rate: 1.500E-04 | lm loss: 1.061653E+01 | loss scale: 131072.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | optimizer: 23.70 | batch generator: 2.40
START iteration 261, CKPT_AND_STOP: False
Finished iteration 262, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
 iteration      262/   18750 | elapsed time per iteration (ms): 4678.0 | learning rate: 1.500E-04 | lm loss: 1.061805E+01 | loss scale: 131072.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | optimizer: 23.68 | batch generator: 1.81
START iteration 262, CKPT_AND_STOP: False
Finished iteration 263, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
 iteration      263/   18750 | elapsed time per iteration (ms): 4636.9 | learning rate: 1.500E-04 | lm loss: 1.061738E+01 | loss scale: 131072.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | optimizer: 23.71 | batch generator: 1.93
START iteration 263, CKPT_AND_STOP: False
Finished iteration 264, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
 iteration      264/   18750 | elapsed time per iteration (ms): 4652.9 | learning rate: 1.500E-04 | lm loss: 1.061713E+01 | loss scale: 131072.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | optimizer: 23.66 | batch generator: 1.56
START iteration 264, CKPT_AND_STOP: False
Finished iteration 265, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
 iteration      265/   18750 | elapsed time per iteration (ms): 4677.0 | learning rate: 1.500E-04 | lm loss: 1.061911E+01 | loss scale: 131072.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | optimizer: 23.86 | batch generator: 2.21
START iteration 265, CKPT_AND_STOP: False
Finished iteration 266, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
 iteration      266/   18750 | elapsed time per iteration (ms): 4636.1 | learning rate: 1.500E-04 | lm loss: 1.062029E+01 | loss scale: 131072.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | optimizer: 23.69 | batch generator: 1.55
START iteration 266, CKPT_AND_STOP: False
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  65536.0
Finished iteration 267, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
 iteration      267/   18750 | elapsed time per iteration (ms): 4626.9 | learning rate: 1.500E-04 | loss scale: 65536.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | optimizer: 5.08 | batch generator: 2.00
START iteration 267, CKPT_AND_STOP: False
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  32768.0
Finished iteration 268, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
 iteration      268/   18750 | elapsed time per iteration (ms): 4627.8 | learning rate: 1.500E-04 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | optimizer: 4.49 | batch generator: 1.41
START iteration 268, CKPT_AND_STOP: False
Finished iteration 269, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
 iteration      269/   18750 | elapsed time per iteration (ms): 4638.9 | learning rate: 1.500E-04 | lm loss: 1.342969E+01 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | optimizer: 23.68 | batch generator: 2.21
START iteration 269, CKPT_AND_STOP: False
Finished iteration 270, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
 iteration      270/   18750 | elapsed time per iteration (ms): 4663.5 | learning rate: 1.500E-04 | lm loss: 1.063340E+01 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | optimizer: 23.76 | batch generator: 1.47
START iteration 270, CKPT_AND_STOP: False
Finished iteration 271, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
 iteration      271/   18750 | elapsed time per iteration (ms): 4624.7 | learning rate: 1.500E-04 | lm loss: 1.065131E+01 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | optimizer: 23.67 | batch generator: 2.18
START iteration 271, CKPT_AND_STOP: False
Finished iteration 272, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
 iteration      272/   18750 | elapsed time per iteration (ms): 4680.7 | learning rate: 1.500E-04 | lm loss: 1.065192E+01 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | optimizer: 23.72 | batch generator: 1.57
START iteration 272, CKPT_AND_STOP: False
Finished iteration 273, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
 iteration      273/   18750 | elapsed time per iteration (ms): 4602.7 | learning rate: 1.500E-04 | lm loss: 1.061963E+01 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | optimizer: 23.74 | batch generator: 2.05
START iteration 273, CKPT_AND_STOP: False
Finished iteration 274, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
 iteration      274/   18750 | elapsed time per iteration (ms): 4627.6 | learning rate: 1.500E-04 | lm loss: 1.062558E+01 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | optimizer: 23.67 | batch generator: 1.50
START iteration 274, CKPT_AND_STOP: False
Finished iteration 275, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
 iteration      275/   18750 | elapsed time per iteration (ms): 4637.3 | learning rate: 1.500E-04 | lm loss: 1.063031E+01 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | optimizer: 23.74 | batch generator: 2.04
START iteration 275, CKPT_AND_STOP: False
Finished iteration 276, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
 iteration      276/   18750 | elapsed time per iteration (ms): 4688.4 | learning rate: 1.500E-04 | lm loss: 1.063882E+01 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | optimizer: 23.66 | batch generator: 1.49
START iteration 276, CKPT_AND_STOP: False
Finished iteration 277, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
 iteration      277/   18750 | elapsed time per iteration (ms): 4670.0 | learning rate: 1.500E-04 | lm loss: 1.063686E+01 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | optimizer: 23.70 | batch generator: 2.23
START iteration 277, CKPT_AND_STOP: False
Finished iteration 278, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
 iteration      278/   18750 | elapsed time per iteration (ms): 4646.0 | learning rate: 1.500E-04 | lm loss: 1.063473E+01 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | optimizer: 23.87 | batch generator: 1.57
START iteration 278, CKPT_AND_STOP: False
Finished iteration 279, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
 iteration      279/   18750 | elapsed time per iteration (ms): 4664.9 | learning rate: 1.500E-04 | lm loss: 1.062994E+01 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | optimizer: 23.73 | batch generator: 2.21
START iteration 279, CKPT_AND_STOP: False
Finished iteration 280, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
 iteration      280/   18750 | elapsed time per iteration (ms): 4694.6 | learning rate: 1.500E-04 | lm loss: 1.063086E+01 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | optimizer: 23.74 | batch generator: 1.52
START iteration 280, CKPT_AND_STOP: False
Finished iteration 281, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
 iteration      281/   18750 | elapsed time per iteration (ms): 4585.6 | learning rate: 1.500E-04 | lm loss: 1.062321E+01 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | optimizer: 23.70 | batch generator: 2.00
START iteration 281, CKPT_AND_STOP: False
Finished iteration 282, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
 iteration      282/   18750 | elapsed time per iteration (ms): 4644.7 | learning rate: 1.500E-04 | lm loss: 1.062031E+01 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | optimizer: 23.66 | batch generator: 1.58
START iteration 282, CKPT_AND_STOP: False
Finished iteration 283, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
 iteration      283/   18750 | elapsed time per iteration (ms): 4607.7 | learning rate: 1.500E-04 | lm loss: 1.064549E+01 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | optimizer: 23.67 | batch generator: 2.10
START iteration 283, CKPT_AND_STOP: False
Finished iteration 284, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
 iteration      284/   18750 | elapsed time per iteration (ms): 4650.3 | learning rate: 1.500E-04 | lm loss: 1.064126E+01 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | optimizer: 23.68 | batch generator: 1.61
START iteration 284, CKPT_AND_STOP: False
Finished iteration 285, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
 iteration      285/   18750 | elapsed time per iteration (ms): 4601.8 | learning rate: 1.500E-04 | lm loss: 1.064638E+01 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | optimizer: 23.80 | batch generator: 2.19
START iteration 285, CKPT_AND_STOP: False
Finished iteration 286, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
 iteration      286/   18750 | elapsed time per iteration (ms): 4618.8 | learning rate: 1.500E-04 | lm loss: 1.062767E+01 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | optimizer: 23.69 | batch generator: 1.50
START iteration 286, CKPT_AND_STOP: False
Finished iteration 287, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
 iteration      287/   18750 | elapsed time per iteration (ms): 4654.7 | learning rate: 1.500E-04 | lm loss: 1.062793E+01 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | optimizer: 23.69 | batch generator: 2.09
START iteration 287, CKPT_AND_STOP: False
Finished iteration 288, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
 iteration      288/   18750 | elapsed time per iteration (ms): 4635.2 | learning rate: 1.500E-04 | lm loss: 1.063149E+01 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | optimizer: 23.65 | batch generator: 1.55
START iteration 288, CKPT_AND_STOP: False
Finished iteration 289, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
 iteration      289/   18750 | elapsed time per iteration (ms): 4644.8 | learning rate: 1.500E-04 | lm loss: 1.063374E+01 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | optimizer: 23.67 | batch generator: 2.05
START iteration 289, CKPT_AND_STOP: False
Finished iteration 290, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
 iteration      290/   18750 | elapsed time per iteration (ms): 4641.6 | learning rate: 1.500E-04 | lm loss: 1.063548E+01 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | optimizer: 23.74 | batch generator: 1.83
START iteration 290, CKPT_AND_STOP: False
Finished iteration 291, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
 iteration      291/   18750 | elapsed time per iteration (ms): 4663.7 | learning rate: 1.500E-04 | lm loss: 1.063350E+01 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | optimizer: 23.72 | batch generator: 2.03
START iteration 291, CKPT_AND_STOP: False
Finished iteration 292, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
 iteration      292/   18750 | elapsed time per iteration (ms): 4663.9 | learning rate: 1.500E-04 | lm loss: 1.063638E+01 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | optimizer: 23.67 | batch generator: 1.81
START iteration 292, CKPT_AND_STOP: False
Finished iteration 293, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
 iteration      293/   18750 | elapsed time per iteration (ms): 4683.2 | learning rate: 1.500E-04 | lm loss: 1.063489E+01 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | optimizer: 23.70 | batch generator: 1.95
START iteration 293, CKPT_AND_STOP: False
Finished iteration 294, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
 iteration      294/   18750 | elapsed time per iteration (ms): 4617.8 | learning rate: 1.500E-04 | lm loss: 1.063429E+01 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | optimizer: 23.66 | batch generator: 1.53
START iteration 294, CKPT_AND_STOP: False
Finished iteration 295, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
 iteration      295/   18750 | elapsed time per iteration (ms): 4685.2 | learning rate: 1.500E-04 | lm loss: 1.063104E+01 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | optimizer: 23.73 | batch generator: 2.21
START iteration 295, CKPT_AND_STOP: False
Finished iteration 296, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
 iteration      296/   18750 | elapsed time per iteration (ms): 4667.7 | learning rate: 1.500E-04 | lm loss: 1.063064E+01 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | optimizer: 23.68 | batch generator: 1.44
START iteration 296, CKPT_AND_STOP: False
Finished iteration 297, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
 iteration      297/   18750 | elapsed time per iteration (ms): 4669.4 | learning rate: 1.500E-04 | lm loss: 1.062773E+01 | loss scale: 32768.0 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | optimizer: 23.66 | batch generator: 2.12
START iteration 297, CKPT_AND_STOP: False
