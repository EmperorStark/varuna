Parent process ID: 18528 node: 172.31.18.152
48 cutpoints
Stages 1
13 179408597504.00003
7 107169514393.59993
4 71132724223.99994
2 45211359129.60004
Predicted microbatch size for 1: 1
comm size 0
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 1 5 0 5970528.80859375 0
End of simulation:  Mini-batch time (usec) = 8296641
Min send: 10000000, max send 0
Min long send: 10000000, max long send 0
Min fwd: 10000000, max fwd 0; min bwd 10000000, max bwd 0
Min long fwd: 164718, max long fwd 168133; min long bwd 296265, max long bwd 302385
Time taken by simulation: 50 microseconds

Stages 2
13 91326429286.39996
7 54442902425.59998
4 36011032883.20001
2 22710326886.4
Predicted microbatch size for 2: 1
comm size 1638400
WARNING: no send time found, 2 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 2 11 0 2767979.736328125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6203240
Min send: 10000000, max send 0
Min long send: 38387, max long send 62760
Min fwd: 76538, max fwd 83279; min bwd 142710, max bwd 147733
Min long fwd: 81915, max long fwd 89657; min long bwd 148530, max long bwd 156110
Time taken by simulation: 192 microseconds

Stages 3
13 62378072166.39999
7 37276345241.600006
4 24698690662.400005
2 15681540915.199997
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 18 0 1846814.0869140625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5987018
Min send: 10000000, max send 0
Min long send: 38387, max long send 60521
Min fwd: 45773, max fwd 59834; min bwd 93871, max bwd 104244
Min long fwd: 57033, max long fwd 64913; min long bwd 98140, max long bwd 103204
Time taken by simulation: 527 microseconds

Stages 4
13 47854723993.6
7 28643536588.800003
4 19017705369.600002
2 12167147929.599998
3 15282454937.599998
Predicted microbatch size for 4: 2
comm size 3276800
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 13 0 1338646.484375 80871.45884831746
End of simulation:  Mini-batch time (usec) = 5132496
Min send: 10000000, max send 0
Min long send: 80953, max long send 103337
Min fwd: 48269, max fwd 59401; min bwd 107938, max bwd 126574
Min long fwd: 53770, max long fwd 60383; min long bwd 118672, max long bwd 125606
Time taken by simulation: 572 microseconds

Stages 6
13 33331375820.800003
7 20010727936.0
4 13336720076.8
5 15504158822.400002
Predicted microbatch size for 6: 4
comm size 6553600
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 11 0 770127.8076171875 159635.3450129109
End of simulation:  Mini-batch time (usec) = 6157105
Min send: 10000000, max send 0
Min long send: 159689, max long send 184340
Min fwd: 52659, max fwd 63832; min bwd 123243, max bwd 140240
Min long fwd: 72998, max long fwd 78841; min long bwd 148211, max long bwd 154022
Time taken by simulation: 768 microseconds

Stages 8
13 26069701734.4
7 15694323609.6
4 10496227430.4
5 12173858304.0
6 13758925312.0
Predicted microbatch size for 8: 6
comm size 9830400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 11 0 442992.24853515625 230166.85465330718
End of simulation:  Mini-batch time (usec) = 8313990
Min send: 10000000, max send 0
Min long send: 230166, max long send 255370
Min fwd: 54051, max fwd 66033; min bwd 132265, max bwd 140978
Min long fwd: 81808, max long fwd 89347; min long bwd 157650, max long bwd 164467
Time taken by simulation: 1038 microseconds

Stages 12
13 18808027648.0
7 11377919283.2
10 15096853196.8
11 16232151142.4
Predicted microbatch size for 12: 10
comm size 16384000
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 13 0 0 361377.8571928701
End of simulation:  Mini-batch time (usec) = 15020502
Min send: 10000000, max send 0
Min long send: 361431, max long send 386584
Min fwd: 61398, max fwd 73009; min bwd 138510, max bwd 150849
Min long fwd: 109818, max long fwd 116156; min long bwd 179680, max long bwd 186710
Time taken by simulation: 1936 microseconds

Stages 16
13 15177190604.8
19 21144245452.8
16 18160685260.8
14 16174148608.0
Predicted microbatch size for 16: 13
comm size 21299200
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 10 0 0 425876.58448885847
End of simulation:  Mini-batch time (usec) = 20148929
Min send: 10000000, max send 0
Min long send: 425930, max long send 455880
Min fwd: 58146, max fwd 69239; min bwd 134282, max bwd 149519
Min long fwd: 116097, max long fwd 122130; min long bwd 192822, max long bwd 197216
Time taken by simulation: 1931 microseconds

can't have 24 stages!
{1: 8.296641, 2: 6.20324, 3: 5.987018, 4: 5.132496, 6: 6.157105, 8: 8.31399, 12: 15.020502, 16: 20.148929}
{1: 1, 2: 1, 3: 1, 4: 2, 6: 4, 8: 6, 12: 10, 16: 13}
best config is: 4 2
expected time is 5.132496
5 per stage
20 servers!
Config:
ranks: range(2, 3)
train batch size: 128
partitions: 4
chunk_size: 2
data depth: 5
stage to rank map: 0,4,8,12,16;1,5,9,13,17;2,6,10,14,18;3,7,11,15,19;
World size is 20
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=2 --chunk_size=2 --local_rank=0 --stage_to_rank_map=0,4,8,12,16;1,5,9,13,17;2,6,10,14,18;3,7,11,15,19; --batch-size=25 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 232
dry run time 0.7731375694274902
SHARED WEIGHTS ARE
[(0, 3)]
this rank  2 is part of pipeline replica  0
13 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
 > finished loading checkpoint in 52.317 seconds
START iteration 232, CKPT_AND_STOP: False
Finished iteration 233, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 233, CKPT_AND_STOP: False
Finished iteration 234, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 234, CKPT_AND_STOP: False
Finished iteration 235, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 235, CKPT_AND_STOP: False
Finished iteration 236, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 236, CKPT_AND_STOP: False
Finished iteration 237, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 237, CKPT_AND_STOP: False
Finished iteration 238, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 238, CKPT_AND_STOP: False
Finished iteration 239, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 239, CKPT_AND_STOP: False
Finished iteration 240, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 240, CKPT_AND_STOP: False
Finished iteration 241, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 241, CKPT_AND_STOP: False
Finished iteration 242, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 242, CKPT_AND_STOP: False
Finished iteration 243, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 243, CKPT_AND_STOP: False
Finished iteration 244, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 244, CKPT_AND_STOP: False
Finished iteration 245, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 245, CKPT_AND_STOP: False
Finished iteration 246, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 246, CKPT_AND_STOP: False
Finished iteration 247, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 247, CKPT_AND_STOP: False
Finished iteration 248, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 248, CKPT_AND_STOP: False
Finished iteration 249, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 249, CKPT_AND_STOP: False
Finished iteration 250, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 250, CKPT_AND_STOP: False
Finished iteration 251, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 251, CKPT_AND_STOP: False
Finished iteration 252, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 252, CKPT_AND_STOP: False
Finished iteration 253, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 253, CKPT_AND_STOP: False
Finished iteration 254, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 254, CKPT_AND_STOP: False
Finished iteration 255, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 255, CKPT_AND_STOP: False
Finished iteration 256, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 256, CKPT_AND_STOP: False
Finished iteration 257, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 257, CKPT_AND_STOP: False
Finished iteration 258, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 258, CKPT_AND_STOP: False
Finished iteration 259, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 259, CKPT_AND_STOP: False
Finished iteration 260, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 260, CKPT_AND_STOP: False
Finished iteration 261, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 261, CKPT_AND_STOP: False
Finished iteration 262, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 262, CKPT_AND_STOP: False
Finished iteration 263, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 263, CKPT_AND_STOP: False
Finished iteration 264, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 264, CKPT_AND_STOP: False
Finished iteration 265, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 265, CKPT_AND_STOP: False
Finished iteration 266, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 266, CKPT_AND_STOP: False
2 : update_scale(): _has_overflow, dynamic. _loss_scale =  65536.0
Finished iteration 267, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 267, CKPT_AND_STOP: False
2 : update_scale(): _has_overflow, dynamic. _loss_scale =  32768.0
Finished iteration 268, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 268, CKPT_AND_STOP: False
Finished iteration 269, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 269, CKPT_AND_STOP: False
Finished iteration 270, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 270, CKPT_AND_STOP: False
Finished iteration 271, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 271, CKPT_AND_STOP: False
Finished iteration 272, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 272, CKPT_AND_STOP: False
Finished iteration 273, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 273, CKPT_AND_STOP: False
Finished iteration 274, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 274, CKPT_AND_STOP: False
Finished iteration 275, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 275, CKPT_AND_STOP: False
Finished iteration 276, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 276, CKPT_AND_STOP: False
Finished iteration 277, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 277, CKPT_AND_STOP: False
Finished iteration 278, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 278, CKPT_AND_STOP: False
Finished iteration 279, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 279, CKPT_AND_STOP: False
Finished iteration 280, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 280, CKPT_AND_STOP: False
Finished iteration 281, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 281, CKPT_AND_STOP: False
Finished iteration 282, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 282, CKPT_AND_STOP: False
Finished iteration 283, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 283, CKPT_AND_STOP: False
Finished iteration 284, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 284, CKPT_AND_STOP: False
Finished iteration 285, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 285, CKPT_AND_STOP: False
Finished iteration 286, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 286, CKPT_AND_STOP: False
Finished iteration 287, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 287, CKPT_AND_STOP: False
Finished iteration 288, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 288, CKPT_AND_STOP: False
Finished iteration 289, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 289, CKPT_AND_STOP: False
Finished iteration 290, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 290, CKPT_AND_STOP: False
Finished iteration 291, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 291, CKPT_AND_STOP: False
Finished iteration 292, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 292, CKPT_AND_STOP: False
Finished iteration 293, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 293, CKPT_AND_STOP: False
Finished iteration 294, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 294, CKPT_AND_STOP: False
Finished iteration 295, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 295, CKPT_AND_STOP: False
Finished iteration 296, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 296, CKPT_AND_STOP: False
Finished iteration 297, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 297, CKPT_AND_STOP: False
