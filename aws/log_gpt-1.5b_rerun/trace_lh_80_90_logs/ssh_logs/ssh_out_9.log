Parent process ID: 6081 node: 172.31.22.165
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 21 0 1916562.744140625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6803052
Min send: 10000000, max send 0
Min long send: 38109, max long send 62549
Min fwd: 45773, max fwd 59456; min bwd 92874, max bwd 103910
Min long fwd: 57033, max long fwd 64913; min long bwd 96930, max long bwd 106927
Time taken by simulation: 621 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 32 0 1199719.8486328125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6885286
Min send: 10000000, max send 0
Min long send: 38109, max long send 65217
Min fwd: 31551, max fwd 49103; min bwd 67585, max bwd 79482
Min long fwd: 42800, max long fwd 50971; min long bwd 74672, max long bwd 82652
Time taken by simulation: 1397 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 42 0 770127.8076171875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5988334
Min send: 10000000, max send 0
Min long send: 38055, max long send 68059
Min fwd: 18837, max fwd 35859; min bwd 42358, max bwd 55388
Min long fwd: 27768, max long fwd 35092; min long bwd 51025, max long bwd 59414
Time taken by simulation: 2994 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 64 0 442992.24853515625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6489103
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 9901, max fwd 27419; min bwd 27605, max bwd 45180
Min long fwd: 21186, max long fwd 32479; min long bwd 41203, max long bwd 48557
Time taken by simulation: 6496 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8759578
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 5999, max fwd 22973; min bwd 17039, max bwd 34800
Min long fwd: 12470, max long fwd 25017; min long bwd 25566, max long bwd 36212
Time taken by simulation: 21360 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29671 microseconds

can't have 24 stages!
{1: inf, 2: inf, 3: 6.803052, 4: 6.885286, 6: 5.988334, 8: 6.489103, 12: 8.759578, 16: 7.580423}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1}
best config is: 6 1
expected time is 5.988334
3 per stage
18 servers!
Config:
ranks: range(9, 10)
train batch size: 128
partitions: 6
chunk_size: 1
data depth: 3
stage to rank map: 0,6,12;1,7,13;2,8,14;3,9,15;4,10,16;5,11,17;
World size is 18
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=9 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,6,12;1,7,13;2,8,14;3,9,15;4,10,16;5,11,17; --batch-size=42 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16
dry run time 10.14490532875061
SHARED WEIGHTS ARE
[(0, 5)]
this rank  9 is part of pipeline replica  1
42 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
 > finished loading checkpoint in 0.223 seconds
START iteration 0, CKPT_AND_STOP: False
[2022-12-08 14:50:52.624612] Finished iteration 1, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 11102.071
START iteration 1, CKPT_AND_STOP: False
[2022-12-08 14:50:58.742667] Finished iteration 2, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6118.082
START iteration 2, CKPT_AND_STOP: False
[2022-12-08 14:51:04.770982] Finished iteration 3, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6028.315
START iteration 3, CKPT_AND_STOP: False
[2022-12-08 14:51:10.874609] Finished iteration 4, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6103.627
START iteration 4, CKPT_AND_STOP: False
[2022-12-08 14:51:17.225699] Finished iteration 5, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6351.089
START iteration 5, CKPT_AND_STOP: False
[2022-12-08 14:51:22.270128] Finished iteration 6, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5044.430
START iteration 6, CKPT_AND_STOP: False
[2022-12-08 14:51:27.275715] Finished iteration 7, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5005.587
START iteration 7, CKPT_AND_STOP: False
[2022-12-08 14:51:32.341340] Finished iteration 8, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5065.625
START iteration 8, CKPT_AND_STOP: False
[2022-12-08 14:51:37.456150] Finished iteration 9, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5114.810
START iteration 9, CKPT_AND_STOP: False
[2022-12-08 14:51:42.473472] Finished iteration 10, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5017.322
START iteration 10, CKPT_AND_STOP: False
[2022-12-08 14:51:47.529102] Finished iteration 11, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5055.631
START iteration 11, CKPT_AND_STOP: False
[2022-12-08 14:51:52.562546] Finished iteration 12, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5033.444
START iteration 12, CKPT_AND_STOP: False
[2022-12-08 14:51:57.633524] Finished iteration 13, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5070.978
START iteration 13, CKPT_AND_STOP: False
[2022-12-08 14:52:02.662848] Finished iteration 14, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5029.324
START iteration 14, CKPT_AND_STOP: False
[2022-12-08 14:52:07.740366] Finished iteration 15, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5077.518
START iteration 15, CKPT_AND_STOP: False
[2022-12-08 14:52:13.484891] Finished iteration 16, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5744.525
START iteration 16, CKPT_AND_STOP: False
[2022-12-08 14:52:18.466118] Finished iteration 17, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4981.227
START iteration 17, CKPT_AND_STOP: False
[2022-12-08 14:52:23.515686] Finished iteration 18, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5049.568
START iteration 18, CKPT_AND_STOP: False
[2022-12-08 14:52:28.518182] Finished iteration 19, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5002.494
START iteration 19, CKPT_AND_STOP: False
[2022-12-08 14:52:33.553625] Finished iteration 20, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5035.444
START iteration 20, CKPT_AND_STOP: False
[2022-12-08 14:52:38.581642] Finished iteration 21, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5028.017
START iteration 21, CKPT_AND_STOP: False
[2022-12-08 14:52:43.692166] Finished iteration 22, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5110.525
START iteration 22, CKPT_AND_STOP: False
[2022-12-08 14:52:48.798338] Finished iteration 23, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5106.171
START iteration 23, CKPT_AND_STOP: False
[2022-12-08 14:52:53.891905] Finished iteration 24, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5093.568
START iteration 24, CKPT_AND_STOP: False
[2022-12-08 14:52:58.904660] Finished iteration 25, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5012.754
START iteration 25, CKPT_AND_STOP: False
[2022-12-08 14:53:03.944110] Finished iteration 26, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5039.449
START iteration 26, CKPT_AND_STOP: False
[2022-12-08 14:53:09.042879] Finished iteration 27, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5098.769
START iteration 27, CKPT_AND_STOP: False
[2022-12-08 14:53:14.043418] Finished iteration 28, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5000.540
START iteration 28, CKPT_AND_STOP: False
[2022-12-08 14:53:19.087206] Finished iteration 29, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5043.788
START iteration 29, CKPT_AND_STOP: False
[2022-12-08 14:53:24.193590] Finished iteration 30, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5106.385
START iteration 30, CKPT_AND_STOP: False
[2022-12-08 14:53:29.244892] Finished iteration 31, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5051.301
START iteration 31, CKPT_AND_STOP: False
[2022-12-08 14:53:34.289517] Finished iteration 32, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5044.626
START iteration 32, CKPT_AND_STOP: False
[2022-12-08 14:53:39.366372] Finished iteration 33, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5076.854
START iteration 33, CKPT_AND_STOP: False
[2022-12-08 14:53:44.484414] Finished iteration 34, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5118.046
START iteration 34, CKPT_AND_STOP: False
[2022-12-08 14:53:49.503091] Finished iteration 35, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5018.673
START iteration 35, CKPT_AND_STOP: False
[2022-12-08 14:53:54.548114] Finished iteration 36, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5045.023
START iteration 36, CKPT_AND_STOP: False
[2022-12-08 14:53:59.589885] Finished iteration 37, CKPT_AND_STOP: False, flag: tensor([2], dtype=torch.int32), speed: 5041.771
Begin to save checkpont and exit
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 9 signal handler called with signal 10
Opt ckpt time 12.096360921859741
Process done with return code 0
Parent process ID: 6683 node: 172.31.22.165
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 21 0 1916562.744140625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6803052
Min send: 10000000, max send 0
Min long send: 38109, max long send 62549
Min fwd: 45773, max fwd 59456; min bwd 92874, max bwd 103910
Min long fwd: 57033, max long fwd 64913; min long bwd 96930, max long bwd 106927
Time taken by simulation: 617 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 25 0 1338646.484375 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5804683
Min send: 10000000, max send 0
Min long send: 38055, max long send 64155
Min fwd: 30866, max fwd 48132; min bwd 66753, max bwd 79482
Min long fwd: 43307, max long fwd 50971; min long bwd 73461, max long bwd 80147
Time taken by simulation: 1062 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 42 0 770127.8076171875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5988334
Min send: 10000000, max send 0
Min long send: 38055, max long send 68059
Min fwd: 18837, max fwd 35859; min bwd 42358, max bwd 55388
Min long fwd: 27768, max long fwd 35092; min long bwd 51025, max long bwd 59414
Time taken by simulation: 2945 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 64 0 442992.24853515625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6489103
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 9901, max fwd 27419; min bwd 27605, max bwd 45180
Min long fwd: 21186, max long fwd 32479; min long bwd 41203, max long bwd 48557
Time taken by simulation: 6470 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8759578
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 5999, max fwd 22973; min bwd 17039, max bwd 34800
Min long fwd: 12470, max long fwd 25017; min long bwd 25566, max long bwd 36212
Time taken by simulation: 21357 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29590 microseconds

can't have 24 stages!
{1: inf, 2: inf, 3: 6.803052, 4: 5.804683, 6: 5.988334, 8: 6.489103, 12: 8.759578, 16: 7.580423}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1}
best config is: 4 1
expected time is 5.804683
5 per stage
20 servers!
Config:
ranks: range(9, 10)
train batch size: 128
partitions: 4
chunk_size: 1
data depth: 5
stage to rank map: 0,4,8,12,16;1,5,9,13,17;2,6,10,14,18;3,7,11,15,19;
World size is 20
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=9 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,4,8,12,16;1,5,9,13,17;2,6,10,14,18;3,7,11,15,19; --batch-size=25 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 37
dry run time 10.048177480697632
SHARED WEIGHTS ARE
[(0, 3)]
this rank  9 is part of pipeline replica  2
25 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 9 signal handler called with signal 10
 > finished loading checkpoint in 75.162 seconds
Process done with return code 0
Parent process ID: 7705 node: 172.31.22.165
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 18 0 1846814.0869140625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5987018
Min send: 10000000, max send 0
Min long send: 38387, max long send 60521
Min fwd: 45773, max fwd 59834; min bwd 93871, max bwd 104244
Min long fwd: 57033, max long fwd 64913; min long bwd 98140, max long bwd 103204
Time taken by simulation: 537 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 25 0 1338646.484375 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5804683
Min send: 10000000, max send 0
Min long send: 38055, max long send 64155
Min fwd: 30866, max fwd 48132; min bwd 66753, max bwd 79482
Min long fwd: 43307, max long fwd 50971; min long bwd 73461, max long bwd 80147
Time taken by simulation: 1098 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 42 0 770127.8076171875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5988334
Min send: 10000000, max send 0
Min long send: 38055, max long send 68059
Min fwd: 18837, max fwd 35859; min bwd 42358, max bwd 55388
Min long fwd: 27768, max long fwd 35092; min long bwd 51025, max long bwd 59414
Time taken by simulation: 2952 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 64 0 442992.24853515625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6489103
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 9901, max fwd 27419; min bwd 27605, max bwd 45180
Min long fwd: 21186, max long fwd 32479; min long bwd 41203, max long bwd 48557
Time taken by simulation: 6456 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8759578
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 5999, max fwd 22973; min bwd 17039, max bwd 34800
Min long fwd: 12470, max long fwd 25017; min long bwd 25566, max long bwd 36212
Time taken by simulation: 21329 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29588 microseconds

can't have 24 stages!
{1: inf, 2: inf, 3: 5.987018, 4: 5.804683, 6: 5.988334, 8: 6.489103, 12: 8.759578, 16: 7.580423}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1}
best config is: 4 1
expected time is 5.804683
5 per stage
20 servers!
Config:
ranks: range(9, 10)
train batch size: 128
partitions: 4
chunk_size: 1
data depth: 5
stage to rank map: 0,4,8,12,16;1,5,9,13,17;2,6,10,14,18;3,7,11,15,19;
World size is 20
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=9 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,4,8,12,16;1,5,9,13,17;2,6,10,14,18;3,7,11,15,19; --batch-size=25 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 37
dry run time 10.081311464309692
SHARED WEIGHTS ARE
[(0, 3)]
this rank  9 is part of pipeline replica  2
25 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 9 signal handler called with signal 10
 > finished loading checkpoint in 61.706 seconds
Process done with return code 0
Parent process ID: 8727 node: 172.31.22.165
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 18 0 1846814.0869140625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5987018
Min send: 10000000, max send 0
Min long send: 38387, max long send 60521
Min fwd: 45773, max fwd 59834; min bwd 93871, max bwd 104244
Min long fwd: 57033, max long fwd 64913; min long bwd 98140, max long bwd 103204
Time taken by simulation: 541 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 25 0 1338646.484375 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5804683
Min send: 10000000, max send 0
Min long send: 38055, max long send 64155
Min fwd: 30866, max fwd 48132; min bwd 66753, max bwd 79482
Min long fwd: 43307, max long fwd 50971; min long bwd 73461, max long bwd 80147
Time taken by simulation: 1098 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 42 0 770127.8076171875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5988334
Min send: 10000000, max send 0
Min long send: 38055, max long send 68059
Min fwd: 18837, max fwd 35859; min bwd 42358, max bwd 55388
Min long fwd: 27768, max long fwd 35092; min long bwd 51025, max long bwd 59414
Time taken by simulation: 2976 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 64 0 442992.24853515625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6489103
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 9901, max fwd 27419; min bwd 27605, max bwd 45180
Min long fwd: 21186, max long fwd 32479; min long bwd 41203, max long bwd 48557
Time taken by simulation: 6467 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8759578
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 5999, max fwd 22973; min bwd 17039, max bwd 34800
Min long fwd: 12470, max long fwd 25017; min long bwd 25566, max long bwd 36212
Time taken by simulation: 21361 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29768 microseconds

can't have 24 stages!
{1: inf, 2: inf, 3: 5.987018, 4: 5.804683, 6: 5.988334, 8: 6.489103, 12: 8.759578, 16: 7.580423}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1}
best config is: 4 1
expected time is 5.804683
5 per stage
20 servers!
Config:
ranks: range(9, 10)
train batch size: 128
partitions: 4
chunk_size: 1
data depth: 5
stage to rank map: 0,4,8,12,16;1,5,9,13,17;2,6,10,14,18;3,7,11,15,19;
World size is 20
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=9 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,4,8,12,16;1,5,9,13,17;2,6,10,14,18;3,7,11,15,19; --batch-size=25 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 37
dry run time 9.917907238006592
SHARED WEIGHTS ARE
[(0, 3)]
this rank  9 is part of pipeline replica  2
25 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
 > finished loading checkpoint in 74.786 seconds
Process done with return code 0
Parent process ID: 9752 node: 172.31.22.165
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 18 0 1846814.0869140625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5987018
Min send: 10000000, max send 0
Min long send: 38387, max long send 60521
Min fwd: 45773, max fwd 59834; min bwd 93871, max bwd 104244
Min long fwd: 57033, max long fwd 64913; min long bwd 98140, max long bwd 103204
Time taken by simulation: 530 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 25 0 1338646.484375 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5804683
Min send: 10000000, max send 0
Min long send: 38055, max long send 64155
Min fwd: 30866, max fwd 48132; min bwd 66753, max bwd 79482
Min long fwd: 43307, max long fwd 50971; min long bwd 73461, max long bwd 80147
Time taken by simulation: 1064 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 42 0 770127.8076171875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5988334
Min send: 10000000, max send 0
Min long send: 38055, max long send 68059
Min fwd: 18837, max fwd 35859; min bwd 42358, max bwd 55388
Min long fwd: 27768, max long fwd 35092; min long bwd 51025, max long bwd 59414
Time taken by simulation: 2978 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 64 0 442992.24853515625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6489103
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 9901, max fwd 27419; min bwd 27605, max bwd 45180
Min long fwd: 21186, max long fwd 32479; min long bwd 41203, max long bwd 48557
Time taken by simulation: 6523 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8759578
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 5999, max fwd 22973; min bwd 17039, max bwd 34800
Min long fwd: 12470, max long fwd 25017; min long bwd 25566, max long bwd 36212
Time taken by simulation: 21346 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29650 microseconds

can't have 24 stages!
{1: inf, 2: inf, 3: 5.987018, 4: 5.804683, 6: 5.988334, 8: 6.489103, 12: 8.759578, 16: 7.580423}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1}
best config is: 4 1
expected time is 5.804683
5 per stage
20 servers!
Config:
ranks: range(9, 10)
train batch size: 128
partitions: 4
chunk_size: 1
data depth: 5
stage to rank map: 0,4,8,12,16;1,5,9,13,17;2,6,10,14,18;3,7,11,15,19;
World size is 20
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=9 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,4,8,12,16;1,5,9,13,17;2,6,10,14,18;3,7,11,15,19; --batch-size=25 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 37
dry run time 9.998443603515625
SHARED WEIGHTS ARE
[(0, 3)]
this rank  9 is part of pipeline replica  2
25 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 9 signal handler called with signal 10
 > finished loading checkpoint in 72.061 seconds
Process done with return code 0
Parent process ID: 10782 node: 172.31.22.165
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 16 0 2198285.64453125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5986016
Min send: 10000000, max send 0
Min long send: 38293, max long send 60521
Min fwd: 45773, max fwd 59456; min bwd 93556, max bwd 103910
Min long fwd: 57033, max long fwd 64913; min long bwd 97741, max long bwd 104518
Time taken by simulation: 512 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 21 0 1478731.4453125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5493991
Min send: 10000000, max send 0
Min long send: 38109, max long send 64155
Min fwd: 32128, max fwd 48180; min bwd 67776, max bwd 77208
Min long fwd: 43175, max long fwd 51496; min long bwd 74514, max long bwd 81205
Time taken by simulation: 892 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 32 0 876895.5078125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5017062
Min send: 10000000, max send 0
Min long send: 38071, max long send 66276
Min fwd: 18837, max fwd 35859; min bwd 42514, max bwd 56347
Min long fwd: 27753, max long fwd 35222; min long bwd 51765, max long bwd 59571
Time taken by simulation: 2308 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 42 0 610855.46875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4799842
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 10665, max fwd 27276; min bwd 28791, max bwd 43945
Min long fwd: 21459, max long fwd 30507; min long bwd 38642, max long bwd 48142
Time taken by simulation: 4229 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 64 0 343797.36328125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5360725
Min send: 10000000, max send 0
Min long send: 38056, max long send 68144
Min fwd: 5149, max fwd 20736; min bwd 17314, max bwd 33457
Min long fwd: 11639, max long fwd 22378; min long bwd 26559, max long bwd 34539
Time taken by simulation: 10386 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29789 microseconds

Stages 24
Micro-bs 1 Max mem: 2949765734.4
Predicted microbatch size for 24: 1
comm size 1638400
WARNING: no send time found, 24 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 24 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6789982
Min send: 10000000, max send 0
Min long send: 38055, max long send 74455
Min fwd: 26, max fwd 15549; min bwd 3842, max bwd 20573
Min long fwd: 7764, max long fwd 18097; min long bwd 11316, max long bwd 21840
Time taken by simulation: 45833 microseconds

{1: inf, 2: inf, 3: 5.986016, 4: 5.493991, 6: 5.017062, 8: 4.799842, 12: 5.360725, 16: 7.580423, 24: 6.789982}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1, 24: 1}
best config is: 8 1
expected time is 4.799842
3 per stage
24 servers!
Config:
ranks: range(9, 10)
train batch size: 128
partitions: 8
chunk_size: 1
data depth: 3
stage to rank map: 0,8,16;1,9,17;2,10,18;3,11,19;4,12,20;5,13,21;6,14,22;7,15,23;
World size is 24
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=9 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,8,16;1,9,17;2,10,18;3,11,19;4,12,20;5,13,21;6,14,22;7,15,23; --batch-size=42 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 37
dry run time 10.081636905670166
SHARED WEIGHTS ARE
[(0, 7)]
this rank  9 is part of pipeline replica  1
42 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
 > finished loading checkpoint in 43.971 seconds
START iteration 37, CKPT_AND_STOP: False
[2022-12-08 15:03:45.363898] Finished iteration 38, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 12377.365
START iteration 38, CKPT_AND_STOP: False
[2022-12-08 15:03:50.794752] Finished iteration 39, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5430.879
START iteration 39, CKPT_AND_STOP: False
[2022-12-08 15:03:56.240760] Finished iteration 40, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5446.009
START iteration 40, CKPT_AND_STOP: False
[2022-12-08 15:04:01.693788] Finished iteration 41, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5453.026
START iteration 41, CKPT_AND_STOP: False
[2022-12-08 15:04:07.177684] Finished iteration 42, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5483.898
START iteration 42, CKPT_AND_STOP: False
[2022-12-08 15:04:11.624150] Finished iteration 43, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4446.466
START iteration 43, CKPT_AND_STOP: False
[2022-12-08 15:04:15.963401] Finished iteration 44, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4339.251
START iteration 44, CKPT_AND_STOP: False
[2022-12-08 15:04:21.535752] Finished iteration 45, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5572.351
START iteration 45, CKPT_AND_STOP: False
[2022-12-08 15:04:25.861854] Finished iteration 46, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4326.102
START iteration 46, CKPT_AND_STOP: False
[2022-12-08 15:04:30.266215] Finished iteration 47, CKPT_AND_STOP: False, flag: tensor([3], dtype=torch.int32), speed: 4404.361
Begin to save checkpont and exit
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 9 signal handler called with signal 10
Opt ckpt time 8.412890672683716
Process done with return code 0
Parent process ID: 11935 node: 172.31.28.236
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 21 0 1916562.744140625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6803052
Min send: 10000000, max send 0
Min long send: 38109, max long send 62549
Min fwd: 45773, max fwd 59456; min bwd 92874, max bwd 103910
Min long fwd: 57033, max long fwd 64913; min long bwd 96930, max long bwd 106927
Time taken by simulation: 623 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 25 0 1338646.484375 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5804683
Min send: 10000000, max send 0
Min long send: 38055, max long send 64155
Min fwd: 30866, max fwd 48132; min bwd 66753, max bwd 79482
Min long fwd: 43307, max long fwd 50971; min long bwd 73461, max long bwd 80147
Time taken by simulation: 1073 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 42 0 770127.8076171875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5988334
Min send: 10000000, max send 0
Min long send: 38055, max long send 68059
Min fwd: 18837, max fwd 35859; min bwd 42358, max bwd 55388
Min long fwd: 27768, max long fwd 35092; min long bwd 51025, max long bwd 59414
Time taken by simulation: 2998 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 64 0 442992.24853515625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6489103
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 9901, max fwd 27419; min bwd 27605, max bwd 45180
Min long fwd: 21186, max long fwd 32479; min long bwd 41203, max long bwd 48557
Time taken by simulation: 6612 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8759578
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 5999, max fwd 22973; min bwd 17039, max bwd 34800
Min long fwd: 12470, max long fwd 25017; min long bwd 25566, max long bwd 36212
Time taken by simulation: 21610 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29704 microseconds

can't have 24 stages!
{1: inf, 2: inf, 3: 6.803052, 4: 5.804683, 6: 5.988334, 8: 6.489103, 12: 8.759578, 16: 7.580423}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1}
best config is: 4 1
expected time is 5.804683
5 per stage
20 servers!
Config:
ranks: range(9, 10)
train batch size: 128
partitions: 4
chunk_size: 1
data depth: 5
stage to rank map: 0,4,8,12,16;1,5,9,13,17;2,6,10,14,18;3,7,11,15,19;
World size is 20
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=9 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,4,8,12,16;1,5,9,13,17;2,6,10,14,18;3,7,11,15,19; --batch-size=25 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 47
dry run time 9.155370950698853
SHARED WEIGHTS ARE
[(0, 3)]
this rank  9 is part of pipeline replica  2
25 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 9 signal handler called with signal 10
Process done with return code 1
Parent process ID: 12904 node: 172.31.28.236
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 25 0 1731851.1962890625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7585451
Min send: 10000000, max send 0
Min long send: 38055, max long send 64155
Min fwd: 45773, max fwd 59456; min bwd 92460, max bwd 103910
Min long fwd: 56519, max long fwd 64913; min long bwd 96930, max long bwd 104722
Time taken by simulation: 728 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 32 0 1199719.8486328125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6885286
Min send: 10000000, max send 0
Min long send: 38109, max long send 65217
Min fwd: 31551, max fwd 49103; min bwd 67585, max bwd 79482
Min long fwd: 42800, max long fwd 50971; min long bwd 74672, max long bwd 82652
Time taken by simulation: 1414 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 64 0 548680.6640625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8215819
Min send: 10000000, max send 0
Min long send: 38055, max long send 68059
Min fwd: 17630, max fwd 35943; min bwd 42061, max bwd 55179
Min long fwd: 28151, max long fwd 36355; min long bwd 50517, max long bwd 61082
Time taken by simulation: 4578 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 64 0 442992.24853515625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6489103
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 9901, max fwd 27419; min bwd 27605, max bwd 45180
Min long fwd: 21186, max long fwd 32479; min long bwd 41203, max long bwd 48557
Time taken by simulation: 6630 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8759578
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 5999, max fwd 22973; min bwd 17039, max bwd 34800
Min long fwd: 12470, max long fwd 25017; min long bwd 25566, max long bwd 36212
Time taken by simulation: 21507 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29752 microseconds

can't have 24 stages!
{1: inf, 2: inf, 3: 7.585451, 4: 6.885286, 6: 8.215819, 8: 6.489103, 12: 8.759578, 16: 7.580423}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1}
best config is: 8 1
expected time is 6.489103
2 per stage
16 servers!
Config:
ranks: range(9, 10)
train batch size: 128
partitions: 8
chunk_size: 1
data depth: 2
stage to rank map: 0,8;1,9;2,10;3,11;4,12;5,13;6,14;7,15;
World size is 16
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=9 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,8;1,9;2,10;3,11;4,12;5,13;6,14;7,15; --batch-size=64 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 47
dry run time 11.683360576629639
SHARED WEIGHTS ARE
[(0, 7)]
this rank  9 is part of pipeline replica  1
64 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 9 signal handler called with signal 10
Process done with return code 1
Parent process ID: 13618 node: 172.31.21.45
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 32 0 1527054.19921875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8830859
Min send: 10000000, max send 0
Min long send: 38055, max long send 61744
Min fwd: 45773, max fwd 61214; min bwd 93190, max bwd 104086
Min long fwd: 56519, max long fwd 64913; min long bwd 96534, max long bwd 106927
Time taken by simulation: 926 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 42 0 1050667.96875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8392460
Min send: 10000000, max send 0
Min long send: 38071, max long send 65217
Min fwd: 32292, max fwd 49103; min bwd 66753, max bwd 79482
Min long fwd: 42823, max long fwd 51268; min long bwd 73813, max long bwd 81750
Time taken by simulation: 1799 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 64 0 548680.6640625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8215819
Min send: 10000000, max send 0
Min long send: 38055, max long send 68059
Min fwd: 17630, max fwd 35943; min bwd 42061, max bwd 55179
Min long fwd: 28151, max long fwd 36355; min long bwd 50517, max long bwd 61082
Time taken by simulation: 4558 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 11360042
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 11033, max fwd 28476; min bwd 28114, max bwd 44951
Min long fwd: 21153, max long fwd 31234; min long bwd 40297, max long bwd 49256
Time taken by simulation: 13070 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8759578
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 5999, max fwd 22973; min bwd 17039, max bwd 34800
Min long fwd: 12470, max long fwd 25017; min long bwd 25566, max long bwd 36212
Time taken by simulation: 21439 microseconds

can't have 16 stages!
can't have 24 stages!
{1: inf, 2: inf, 3: 8.830859, 4: 8.39246, 6: 8.215819, 8: 11.360042, 12: 8.759578}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1}
best config is: 6 1
expected time is 8.215819
2 per stage
12 servers!
Config:
ranks: range(9, 10)
train batch size: 128
partitions: 6
chunk_size: 1
data depth: 2
stage to rank map: 0,6;1,7;2,8;3,9;4,10;5,11;
World size is 12
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=9 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,6;1,7;2,8;3,9;4,10;5,11; --batch-size=64 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 47
dry run time 0.2761952877044678
SHARED WEIGHTS ARE
[(0, 5)]
this rank  9 is part of pipeline replica  1
64 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 9 signal handler called with signal 10
 > finished loading checkpoint in 44.881 seconds
Process done with return code 0
Parent process ID: 9933 node: 172.31.23.137
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 32 0 1527054.19921875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8830859
Min send: 10000000, max send 0
Min long send: 38055, max long send 61744
Min fwd: 45773, max fwd 61214; min bwd 93190, max bwd 104086
Min long fwd: 56519, max long fwd 64913; min long bwd 96534, max long bwd 106927
Time taken by simulation: 928 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 42 0 1050667.96875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8392460
Min send: 10000000, max send 0
Min long send: 38071, max long send 65217
Min fwd: 32292, max fwd 49103; min bwd 66753, max bwd 79482
Min long fwd: 42823, max long fwd 51268; min long bwd 73813, max long bwd 81750
Time taken by simulation: 1821 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 64 0 548680.6640625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8215819
Min send: 10000000, max send 0
Min long send: 38055, max long send 68059
Min fwd: 17630, max fwd 35943; min bwd 42061, max bwd 55179
Min long fwd: 28151, max long fwd 36355; min long bwd 50517, max long bwd 61082
Time taken by simulation: 4596 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 11360042
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 11033, max fwd 28476; min bwd 28114, max bwd 44951
Min long fwd: 21153, max long fwd 31234; min long bwd 40297, max long bwd 49256
Time taken by simulation: 13057 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8759578
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 5999, max fwd 22973; min bwd 17039, max bwd 34800
Min long fwd: 12470, max long fwd 25017; min long bwd 25566, max long bwd 36212
Time taken by simulation: 21266 microseconds

can't have 16 stages!
can't have 24 stages!
{1: inf, 2: inf, 3: 8.830859, 4: 8.39246, 6: 8.215819, 8: 11.360042, 12: 8.759578}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1}
best config is: 6 1
expected time is 8.215819
2 per stage
12 servers!
Config:
ranks: range(9, 10)
train batch size: 128
partitions: 6
chunk_size: 1
data depth: 2
stage to rank map: 0,6;1,7;2,8;3,9;4,10;5,11;
World size is 12
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=9 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,6;1,7;2,8;3,9;4,10;5,11; --batch-size=64 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 47
dry run time 9.777556896209717
SHARED WEIGHTS ARE
[(0, 5)]
this rank  9 is part of pipeline replica  1
64 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 9 signal handler called with signal 10
 > finished loading checkpoint in 41.381 seconds
Process done with return code 0
Parent process ID: 10796 node: 172.31.23.137
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 42 0 1334285.400390625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 10543558
Min send: 10000000, max send 0
Min long send: 38287, max long send 65217
Min fwd: 45773, max fwd 61214; min bwd 92331, max bwd 103910
Min long fwd: 52474, max long fwd 64913; min long bwd 98140, max long bwd 106927
Time taken by simulation: 1205 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 64 0 748630.126953125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 11457418
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 31994, max fwd 49123; min bwd 66753, max bwd 80221
Min long fwd: 40995, max long fwd 51310; min long bwd 72999, max long bwd 81750
Time taken by simulation: 2689 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 14725210
Min send: 10000000, max send 0
Min long send: 38055, max long send 70233
Min fwd: 16996, max fwd 37054; min bwd 39871, max bwd 55692
Min long fwd: 24877, max long fwd 36805; min long bwd 48154, max long bwd 62088
Time taken by simulation: 9194 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 11360042
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 11033, max fwd 28476; min bwd 28114, max bwd 44951
Min long fwd: 21153, max long fwd 31234; min long bwd 40297, max long bwd 49256
Time taken by simulation: 13257 microseconds

can't have 12 stages!
can't have 16 stages!
can't have 24 stages!
{1: inf, 2: inf, 3: 10.543558, 4: 11.457418, 6: 14.72521, 8: 11.360042}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1}
best config is: 3 1
expected time is 10.543558
3 per stage
9 servers!
9 9 I am of no use!
Parent process ID: 11049 node: 172.31.23.137
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 42 0 1334285.400390625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 10543558
Min send: 10000000, max send 0
Min long send: 38287, max long send 65217
Min fwd: 45773, max fwd 61214; min bwd 92331, max bwd 103910
Min long fwd: 52474, max long fwd 64913; min long bwd 98140, max long bwd 106927
Time taken by simulation: 1196 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 64 0 748630.126953125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 11457418
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 31994, max fwd 49123; min bwd 66753, max bwd 80221
Min long fwd: 40995, max long fwd 51310; min long bwd 72999, max long bwd 81750
Time taken by simulation: 2727 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 14725210
Min send: 10000000, max send 0
Min long send: 38055, max long send 70233
Min fwd: 16996, max fwd 37054; min bwd 39871, max bwd 55692
Min long fwd: 24877, max long fwd 36805; min long bwd 48154, max long bwd 62088
Time taken by simulation: 9217 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 11360042
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 11033, max fwd 28476; min bwd 28114, max bwd 44951
Min long fwd: 21153, max long fwd 31234; min long bwd 40297, max long bwd 49256
Time taken by simulation: 13037 microseconds

can't have 12 stages!
can't have 16 stages!
can't have 24 stages!
{1: inf, 2: inf, 3: 10.543558, 4: 11.457418, 6: 14.72521, 8: 11.360042}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1}
best config is: 3 1
expected time is 10.543558
3 per stage
9 servers!
9 9 I am of no use!
Parent process ID: 11383 node: 172.31.23.137
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 32 0 1527054.19921875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8830859
Min send: 10000000, max send 0
Min long send: 38055, max long send 61744
Min fwd: 45773, max fwd 61214; min bwd 93190, max bwd 104086
Min long fwd: 56519, max long fwd 64913; min long bwd 96534, max long bwd 106927
Time taken by simulation: 919 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 42 0 1050667.96875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8392460
Min send: 10000000, max send 0
Min long send: 38071, max long send 65217
Min fwd: 32292, max fwd 49103; min bwd 66753, max bwd 79482
Min long fwd: 42823, max long fwd 51268; min long bwd 73813, max long bwd 81750
Time taken by simulation: 1802 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 64 0 548680.6640625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8215819
Min send: 10000000, max send 0
Min long send: 38055, max long send 68059
Min fwd: 17630, max fwd 35943; min bwd 42061, max bwd 55179
Min long fwd: 28151, max long fwd 36355; min long bwd 50517, max long bwd 61082
Time taken by simulation: 4595 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 11360042
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 11033, max fwd 28476; min bwd 28114, max bwd 44951
Min long fwd: 21153, max long fwd 31234; min long bwd 40297, max long bwd 49256
Time taken by simulation: 13074 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8759578
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 5999, max fwd 22973; min bwd 17039, max bwd 34800
Min long fwd: 12470, max long fwd 25017; min long bwd 25566, max long bwd 36212
Time taken by simulation: 21387 microseconds

can't have 16 stages!
can't have 24 stages!
{1: inf, 2: inf, 3: 8.830859, 4: 8.39246, 6: 8.215819, 8: 11.360042, 12: 8.759578}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1}
best config is: 6 1
expected time is 8.215819
2 per stage
12 servers!
Config:
ranks: range(9, 10)
train batch size: 128
partitions: 6
chunk_size: 1
data depth: 2
stage to rank map: 0,6;1,7;2,8;3,9;4,10;5,11;
World size is 12
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=9 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,6;1,7;2,8;3,9;4,10;5,11; --batch-size=64 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 47
dry run time 9.620829582214355
SHARED WEIGHTS ARE
[(0, 5)]
this rank  9 is part of pipeline replica  1
64 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 9 signal handler called with signal 10
 > finished loading checkpoint in 48.954 seconds
Process done with return code 0
Parent process ID: 12201 node: 172.31.23.137
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 32 0 1527054.19921875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8830859
Min send: 10000000, max send 0
Min long send: 38055, max long send 61744
Min fwd: 45773, max fwd 61214; min bwd 93190, max bwd 104086
Min long fwd: 56519, max long fwd 64913; min long bwd 96534, max long bwd 106927
Time taken by simulation: 918 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 42 0 1050667.96875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8392460
Min send: 10000000, max send 0
Min long send: 38071, max long send 65217
Min fwd: 32292, max fwd 49103; min bwd 66753, max bwd 79482
Min long fwd: 42823, max long fwd 51268; min long bwd 73813, max long bwd 81750
Time taken by simulation: 1774 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 64 0 548680.6640625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8215819
Min send: 10000000, max send 0
Min long send: 38055, max long send 68059
Min fwd: 17630, max fwd 35943; min bwd 42061, max bwd 55179
Min long fwd: 28151, max long fwd 36355; min long bwd 50517, max long bwd 61082
Time taken by simulation: 4536 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 11360042
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 11033, max fwd 28476; min bwd 28114, max bwd 44951
Min long fwd: 21153, max long fwd 31234; min long bwd 40297, max long bwd 49256
Time taken by simulation: 13102 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8759578
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 5999, max fwd 22973; min bwd 17039, max bwd 34800
Min long fwd: 12470, max long fwd 25017; min long bwd 25566, max long bwd 36212
Time taken by simulation: 21421 microseconds

can't have 16 stages!
can't have 24 stages!
{1: inf, 2: inf, 3: 8.830859, 4: 8.39246, 6: 8.215819, 8: 11.360042, 12: 8.759578}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1}
best config is: 6 1
expected time is 8.215819
2 per stage
12 servers!
Config:
ranks: range(9, 10)
train batch size: 128
partitions: 6
chunk_size: 1
data depth: 2
stage to rank map: 0,6;1,7;2,8;3,9;4,10;5,11;
World size is 12
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=9 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,6;1,7;2,8;3,9;4,10;5,11; --batch-size=64 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 47
dry run time 9.734981298446655
SHARED WEIGHTS ARE
[(0, 5)]
this rank  9 is part of pipeline replica  1
64 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 9 signal handler called with signal 10
Process done with return code 1
Parent process ID: 11410 node: 172.31.28.143
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 32 0 1527054.19921875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8830859
Min send: 10000000, max send 0
Min long send: 38055, max long send 61744
Min fwd: 45773, max fwd 61214; min bwd 93190, max bwd 104086
Min long fwd: 56519, max long fwd 64913; min long bwd 96534, max long bwd 106927
Time taken by simulation: 920 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 42 0 1050667.96875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8392460
Min send: 10000000, max send 0
Min long send: 38071, max long send 65217
Min fwd: 32292, max fwd 49103; min bwd 66753, max bwd 79482
Min long fwd: 42823, max long fwd 51268; min long bwd 73813, max long bwd 81750
Time taken by simulation: 1771 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 64 0 548680.6640625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8215819
Min send: 10000000, max send 0
Min long send: 38055, max long send 68059
Min fwd: 17630, max fwd 35943; min bwd 42061, max bwd 55179
Min long fwd: 28151, max long fwd 36355; min long bwd 50517, max long bwd 61082
Time taken by simulation: 4549 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 11360042
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 11033, max fwd 28476; min bwd 28114, max bwd 44951
Min long fwd: 21153, max long fwd 31234; min long bwd 40297, max long bwd 49256
Time taken by simulation: 13099 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8759578
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 5999, max fwd 22973; min bwd 17039, max bwd 34800
Min long fwd: 12470, max long fwd 25017; min long bwd 25566, max long bwd 36212
Time taken by simulation: 21387 microseconds

can't have 16 stages!
can't have 24 stages!
{1: inf, 2: inf, 3: 8.830859, 4: 8.39246, 6: 8.215819, 8: 11.360042, 12: 8.759578}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1}
best config is: 6 1
expected time is 8.215819
2 per stage
12 servers!
Config:
ranks: range(9, 10)
train batch size: 128
partitions: 6
chunk_size: 1
data depth: 2
stage to rank map: 0,6;1,7;2,8;3,9;4,10;5,11;
World size is 12
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=9 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,6;1,7;2,8;3,9;4,10;5,11; --batch-size=64 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 47
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 9 signal handler called with signal 10
dry run time 8.549565315246582
SHARED WEIGHTS ARE
[(0, 5)]
this rank  9 is part of pipeline replica  1
64 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
 > finished loading checkpoint in 48.076 seconds
Process done with return code 0
Parent process ID: 12227 node: 172.31.28.143
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 32 0 1527054.19921875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8830859
Min send: 10000000, max send 0
Min long send: 38055, max long send 61744
Min fwd: 45773, max fwd 61214; min bwd 93190, max bwd 104086
Min long fwd: 56519, max long fwd 64913; min long bwd 96534, max long bwd 106927
Time taken by simulation: 961 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 42 0 1050667.96875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8392460
Min send: 10000000, max send 0
Min long send: 38071, max long send 65217
Min fwd: 32292, max fwd 49103; min bwd 66753, max bwd 79482
Min long fwd: 42823, max long fwd 51268; min long bwd 73813, max long bwd 81750
Time taken by simulation: 1883 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 64 0 548680.6640625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8215819
Min send: 10000000, max send 0
Min long send: 38055, max long send 68059
Min fwd: 17630, max fwd 35943; min bwd 42061, max bwd 55179
Min long fwd: 28151, max long fwd 36355; min long bwd 50517, max long bwd 61082
Time taken by simulation: 4600 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 11360042
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 11033, max fwd 28476; min bwd 28114, max bwd 44951
Min long fwd: 21153, max long fwd 31234; min long bwd 40297, max long bwd 49256
Time taken by simulation: 13104 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8759578
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 5999, max fwd 22973; min bwd 17039, max bwd 34800
Min long fwd: 12470, max long fwd 25017; min long bwd 25566, max long bwd 36212
Time taken by simulation: 21365 microseconds

can't have 16 stages!
can't have 24 stages!
{1: inf, 2: inf, 3: 8.830859, 4: 8.39246, 6: 8.215819, 8: 11.360042, 12: 8.759578}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1}
best config is: 6 1
expected time is 8.215819
2 per stage
12 servers!
Config:
ranks: range(9, 10)
train batch size: 128
partitions: 6
chunk_size: 1
data depth: 2
stage to rank map: 0,6;1,7;2,8;3,9;4,10;5,11;
World size is 12
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=9 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,6;1,7;2,8;3,9;4,10;5,11; --batch-size=64 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 47
dry run time 9.760724306106567
SHARED WEIGHTS ARE
[(0, 5)]
this rank  9 is part of pipeline replica  1
64 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
 > finished loading checkpoint in 44.786 seconds
START iteration 47, CKPT_AND_STOP: False
[2022-12-08 15:22:35.062474] Finished iteration 48, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 11085.199
START iteration 48, CKPT_AND_STOP: False
[2022-12-08 15:22:42.569457] Finished iteration 49, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 7506.998
START iteration 49, CKPT_AND_STOP: False
[2022-12-08 15:22:50.100510] Finished iteration 50, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 7531.054
START iteration 50, CKPT_AND_STOP: False
[2022-12-08 15:22:57.780666] Finished iteration 51, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 7680.157
START iteration 51, CKPT_AND_STOP: False
[2022-12-08 15:23:05.437376] Finished iteration 52, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 7656.709
START iteration 52, CKPT_AND_STOP: False
[2022-12-08 15:23:12.057520] Finished iteration 53, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6620.145
START iteration 53, CKPT_AND_STOP: False
[2022-12-08 15:23:18.611813] Finished iteration 54, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6554.293
START iteration 54, CKPT_AND_STOP: False
[2022-12-08 15:23:25.341788] Finished iteration 55, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6729.974
START iteration 55, CKPT_AND_STOP: False
[2022-12-08 15:23:31.895156] Finished iteration 56, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6553.370
START iteration 56, CKPT_AND_STOP: False
[2022-12-08 15:23:38.532410] Finished iteration 57, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6637.254
START iteration 57, CKPT_AND_STOP: False
[2022-12-08 15:23:45.221455] Finished iteration 58, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6689.045
START iteration 58, CKPT_AND_STOP: False
[2022-12-08 15:23:51.794112] Finished iteration 59, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6572.655
START iteration 59, CKPT_AND_STOP: False
[2022-12-08 15:23:58.833174] Finished iteration 60, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 7039.064
START iteration 60, CKPT_AND_STOP: False
[2022-12-08 15:24:05.571030] Finished iteration 61, CKPT_AND_STOP: False, flag: tensor([8], dtype=torch.int32), speed: 6737.856
Begin to save checkpont and exit
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 9 signal handler called with signal 10
Opt ckpt time 14.607756853103638
Process done with return code 0
Parent process ID: 13176 node: 172.31.28.143
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 32 0 1527054.19921875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8830859
Min send: 10000000, max send 0
Min long send: 38055, max long send 61744
Min fwd: 45773, max fwd 61214; min bwd 93190, max bwd 104086
Min long fwd: 56519, max long fwd 64913; min long bwd 96534, max long bwd 106927
Time taken by simulation: 921 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 42 0 1050667.96875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8392460
Min send: 10000000, max send 0
Min long send: 38071, max long send 65217
Min fwd: 32292, max fwd 49103; min bwd 66753, max bwd 79482
Min long fwd: 42823, max long fwd 51268; min long bwd 73813, max long bwd 81750
Time taken by simulation: 1803 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 64 0 548680.6640625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8215819
Min send: 10000000, max send 0
Min long send: 38055, max long send 68059
Min fwd: 17630, max fwd 35943; min bwd 42061, max bwd 55179
Min long fwd: 28151, max long fwd 36355; min long bwd 50517, max long bwd 61082
Time taken by simulation: 4542 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 11360042
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 11033, max fwd 28476; min bwd 28114, max bwd 44951
Min long fwd: 21153, max long fwd 31234; min long bwd 40297, max long bwd 49256
Time taken by simulation: 13072 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8759578
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 5999, max fwd 22973; min bwd 17039, max bwd 34800
Min long fwd: 12470, max long fwd 25017; min long bwd 25566, max long bwd 36212
Time taken by simulation: 21349 microseconds

can't have 16 stages!
can't have 24 stages!
{1: inf, 2: inf, 3: 8.830859, 4: 8.39246, 6: 8.215819, 8: 11.360042, 12: 8.759578}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1}
best config is: 6 1
expected time is 8.215819
2 per stage
12 servers!
Config:
ranks: range(9, 10)
train batch size: 128
partitions: 6
chunk_size: 1
data depth: 2
stage to rank map: 0,6;1,7;2,8;3,9;4,10;5,11;
World size is 12
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=9 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,6;1,7;2,8;3,9;4,10;5,11; --batch-size=64 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 61
dry run time 9.73808240890503
SHARED WEIGHTS ARE
[(0, 5)]
this rank  9 is part of pipeline replica  1
64 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 9 signal handler called with signal 10
 > finished loading checkpoint in 72.497 seconds
Process done with return code 0
Parent process ID: 14247 node: 172.31.28.143
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 21 0 1916562.744140625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6803052
Min send: 10000000, max send 0
Min long send: 38109, max long send 62549
Min fwd: 45773, max fwd 59456; min bwd 92874, max bwd 103910
Min long fwd: 57033, max long fwd 64913; min long bwd 96930, max long bwd 106927
Time taken by simulation: 629 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 32 0 1199719.8486328125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6885286
Min send: 10000000, max send 0
Min long send: 38109, max long send 65217
Min fwd: 31551, max fwd 49103; min bwd 67585, max bwd 79482
Min long fwd: 42800, max long fwd 50971; min long bwd 74672, max long bwd 82652
Time taken by simulation: 1415 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 42 0 770127.8076171875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5988334
Min send: 10000000, max send 0
Min long send: 38055, max long send 68059
Min fwd: 18837, max fwd 35859; min bwd 42358, max bwd 55388
Min long fwd: 27768, max long fwd 35092; min long bwd 51025, max long bwd 59414
Time taken by simulation: 3007 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 64 0 442992.24853515625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6489103
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 9901, max fwd 27419; min bwd 27605, max bwd 45180
Min long fwd: 21186, max long fwd 32479; min long bwd 41203, max long bwd 48557
Time taken by simulation: 6562 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8759578
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 5999, max fwd 22973; min bwd 17039, max bwd 34800
Min long fwd: 12470, max long fwd 25017; min long bwd 25566, max long bwd 36212
Time taken by simulation: 21356 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29672 microseconds

can't have 24 stages!
{1: inf, 2: inf, 3: 6.803052, 4: 6.885286, 6: 5.988334, 8: 6.489103, 12: 8.759578, 16: 7.580423}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1}
best config is: 6 1
expected time is 5.988334
3 per stage
18 servers!
Config:
ranks: range(9, 10)
train batch size: 128
partitions: 6
chunk_size: 1
data depth: 3
stage to rank map: 0,6,12;1,7,13;2,8,14;3,9,15;4,10,16;5,11,17;
World size is 18
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=9 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,6,12;1,7,13;2,8,14;3,9,15;4,10,16;5,11,17; --batch-size=42 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 61
dry run time 10.347623825073242
SHARED WEIGHTS ARE
[(0, 5)]
this rank  9 is part of pipeline replica  1
42 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
 > finished loading checkpoint in 69.574 seconds
START iteration 61, CKPT_AND_STOP: False
[2022-12-08 15:28:32.618610] Finished iteration 62, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 11423.508
START iteration 62, CKPT_AND_STOP: False
[2022-12-08 15:28:38.738571] Finished iteration 63, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6120.015
START iteration 63, CKPT_AND_STOP: False
[2022-12-08 15:28:44.880508] Finished iteration 64, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6141.934
START iteration 64, CKPT_AND_STOP: False
[2022-12-08 15:28:51.054629] Finished iteration 65, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6174.123
START iteration 65, CKPT_AND_STOP: False
[2022-12-08 15:28:57.874520] Finished iteration 66, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6819.892
START iteration 66, CKPT_AND_STOP: False
[2022-12-08 15:29:02.948225] Finished iteration 67, CKPT_AND_STOP: False, flag: tensor([4], dtype=torch.int32), speed: 5073.704
Begin to save checkpont and exit
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 9 signal handler called with signal 10
Opt ckpt time 11.594224452972412
Process done with return code 0
Parent process ID: 15359 node: 172.31.28.143
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 21 0 1916562.744140625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6803052
Min send: 10000000, max send 0
Min long send: 38109, max long send 62549
Min fwd: 45773, max fwd 59456; min bwd 92874, max bwd 103910
Min long fwd: 57033, max long fwd 64913; min long bwd 96930, max long bwd 106927
Time taken by simulation: 612 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 32 0 1199719.8486328125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6885286
Min send: 10000000, max send 0
Min long send: 38109, max long send 65217
Min fwd: 31551, max fwd 49103; min bwd 67585, max bwd 79482
Min long fwd: 42800, max long fwd 50971; min long bwd 74672, max long bwd 82652
Time taken by simulation: 1360 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 42 0 770127.8076171875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5988334
Min send: 10000000, max send 0
Min long send: 38055, max long send 68059
Min fwd: 18837, max fwd 35859; min bwd 42358, max bwd 55388
Min long fwd: 27768, max long fwd 35092; min long bwd 51025, max long bwd 59414
Time taken by simulation: 2974 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 64 0 442992.24853515625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6489103
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 9901, max fwd 27419; min bwd 27605, max bwd 45180
Min long fwd: 21186, max long fwd 32479; min long bwd 41203, max long bwd 48557
Time taken by simulation: 6586 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8759578
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 5999, max fwd 22973; min bwd 17039, max bwd 34800
Min long fwd: 12470, max long fwd 25017; min long bwd 25566, max long bwd 36212
Time taken by simulation: 21330 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29561 microseconds

can't have 24 stages!
{1: inf, 2: inf, 3: 6.803052, 4: 6.885286, 6: 5.988334, 8: 6.489103, 12: 8.759578, 16: 7.580423}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1}
best config is: 6 1
expected time is 5.988334
3 per stage
18 servers!
Config:
ranks: range(9, 10)
train batch size: 128
partitions: 6
chunk_size: 1
data depth: 3
stage to rank map: 0,6,12;1,7,13;2,8,14;3,9,15;4,10,16;5,11,17;
World size is 18
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=9 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,6,12;1,7,13;2,8,14;3,9,15;4,10,16;5,11,17; --batch-size=42 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 67
dry run time 10.196401357650757
SHARED WEIGHTS ARE
[(0, 5)]
this rank  9 is part of pipeline replica  1
42 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
 > finished loading checkpoint in 50.047 seconds
START iteration 67, CKPT_AND_STOP: False
[2022-12-08 15:31:12.614627] Finished iteration 68, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 11363.989
START iteration 68, CKPT_AND_STOP: False
[2022-12-08 15:31:18.733931] Finished iteration 69, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6119.323
START iteration 69, CKPT_AND_STOP: False
[2022-12-08 15:31:24.749709] Finished iteration 70, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6015.777
START iteration 70, CKPT_AND_STOP: False
[2022-12-08 15:31:30.908707] Finished iteration 71, CKPT_AND_STOP: False, flag: tensor([4], dtype=torch.int32), speed: 6159.000
Begin to save checkpont and exit
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 9 signal handler called with signal 10
Opt ckpt time 17.86670231819153
Process done with return code 0
Parent process ID: 16725 node: 172.31.16.5
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 25 0 1731851.1962890625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7585451
Min send: 10000000, max send 0
Min long send: 38055, max long send 64155
Min fwd: 45773, max fwd 59456; min bwd 92460, max bwd 103910
Min long fwd: 56519, max long fwd 64913; min long bwd 96930, max long bwd 104722
Time taken by simulation: 728 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 32 0 1199719.8486328125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6885286
Min send: 10000000, max send 0
Min long send: 38109, max long send 65217
Min fwd: 31551, max fwd 49103; min bwd 67585, max bwd 79482
Min long fwd: 42800, max long fwd 50971; min long bwd 74672, max long bwd 82652
Time taken by simulation: 1404 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 64 0 548680.6640625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8215819
Min send: 10000000, max send 0
Min long send: 38055, max long send 68059
Min fwd: 17630, max fwd 35943; min bwd 42061, max bwd 55179
Min long fwd: 28151, max long fwd 36355; min long bwd 50517, max long bwd 61082
Time taken by simulation: 4542 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 64 0 442992.24853515625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6489103
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 9901, max fwd 27419; min bwd 27605, max bwd 45180
Min long fwd: 21186, max long fwd 32479; min long bwd 41203, max long bwd 48557
Time taken by simulation: 6546 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8759578
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 5999, max fwd 22973; min bwd 17039, max bwd 34800
Min long fwd: 12470, max long fwd 25017; min long bwd 25566, max long bwd 36212
Time taken by simulation: 21302 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29605 microseconds

can't have 24 stages!
{1: inf, 2: inf, 3: 7.585451, 4: 6.885286, 6: 8.215819, 8: 6.489103, 12: 8.759578, 16: 7.580423}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1}
best config is: 8 1
expected time is 6.489103
2 per stage
16 servers!
Config:
ranks: range(9, 10)
train batch size: 128
partitions: 8
chunk_size: 1
data depth: 2
stage to rank map: 0,8;1,9;2,10;3,11;4,12;5,13;6,14;7,15;
World size is 16
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=9 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,8;1,9;2,10;3,11;4,12;5,13;6,14;7,15; --batch-size=64 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 71
dry run time 9.667335510253906
SHARED WEIGHTS ARE
[(0, 7)]
this rank  9 is part of pipeline replica  1
64 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 9 signal handler called with signal 10
 > finished loading checkpoint in 38.731 seconds
Process done with return code 0
Parent process ID: 15143 node: 172.31.31.40
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 25 0 1731851.1962890625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7585451
Min send: 10000000, max send 0
Min long send: 38055, max long send 64155
Min fwd: 45773, max fwd 59456; min bwd 92460, max bwd 103910
Min long fwd: 56519, max long fwd 64913; min long bwd 96930, max long bwd 104722
Time taken by simulation: 727 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 42 0 1050667.96875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8392460
Min send: 10000000, max send 0
Min long send: 38071, max long send 65217
Min fwd: 32292, max fwd 49103; min bwd 66753, max bwd 79482
Min long fwd: 42823, max long fwd 51268; min long bwd 73813, max long bwd 81750
Time taken by simulation: 1769 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 64 0 548680.6640625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8215819
Min send: 10000000, max send 0
Min long send: 38055, max long send 68059
Min fwd: 17630, max fwd 35943; min bwd 42061, max bwd 55179
Min long fwd: 28151, max long fwd 36355; min long bwd 50517, max long bwd 61082
Time taken by simulation: 4541 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 11360042
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 11033, max fwd 28476; min bwd 28114, max bwd 44951
Min long fwd: 21153, max long fwd 31234; min long bwd 40297, max long bwd 49256
Time taken by simulation: 13069 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8759578
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 5999, max fwd 22973; min bwd 17039, max bwd 34800
Min long fwd: 12470, max long fwd 25017; min long bwd 25566, max long bwd 36212
Time taken by simulation: 21386 microseconds

can't have 16 stages!
can't have 24 stages!
{1: inf, 2: inf, 3: 7.585451, 4: 8.39246, 6: 8.215819, 8: 11.360042, 12: 8.759578}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1}
best config is: 3 1
expected time is 7.585451
5 per stage
15 servers!
Config:
ranks: range(9, 10)
train batch size: 128
partitions: 3
chunk_size: 1
data depth: 5
stage to rank map: 0,3,6,9,12;1,4,7,10,13;2,5,8,11,14;
World size is 15
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=9 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,3,6,9,12;1,4,7,10,13;2,5,8,11,14; --batch-size=25 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 71
dry run time 9.841490268707275
SHARED WEIGHTS ARE
[(0, 2)]
this rank  9 is part of pipeline replica  3
25 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
 > finished loading checkpoint in 81.092 seconds
START iteration 71, CKPT_AND_STOP: False
[2022-12-08 15:36:27.987531] Finished iteration 72, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 9569.998
START iteration 72, CKPT_AND_STOP: False
[2022-12-08 15:36:35.317150] Finished iteration 73, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 7329.641
START iteration 73, CKPT_AND_STOP: False
[2022-12-08 15:36:42.668817] Finished iteration 74, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 7351.669
START iteration 74, CKPT_AND_STOP: False
[2022-12-08 15:36:49.793562] Finished iteration 75, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 7124.743
START iteration 75, CKPT_AND_STOP: False
[2022-12-08 15:36:57.121597] Finished iteration 76, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 7328.036
START iteration 76, CKPT_AND_STOP: False
[2022-12-08 15:37:03.149924] Finished iteration 77, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6028.328
START iteration 77, CKPT_AND_STOP: False
[2022-12-08 15:37:09.456768] Finished iteration 78, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6306.845
START iteration 78, CKPT_AND_STOP: False
[2022-12-08 15:37:15.414829] Finished iteration 79, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5958.062
START iteration 79, CKPT_AND_STOP: False
[2022-12-08 15:37:21.695833] Finished iteration 80, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6281.004
START iteration 80, CKPT_AND_STOP: False
[2022-12-08 15:37:27.953128] Finished iteration 81, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6257.294
START iteration 81, CKPT_AND_STOP: False
[2022-12-08 15:37:34.312092] Finished iteration 82, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6358.964
START iteration 82, CKPT_AND_STOP: False
[2022-12-08 15:37:40.513789] Finished iteration 83, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6201.697
START iteration 83, CKPT_AND_STOP: False
[2022-12-08 15:37:46.715097] Finished iteration 84, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6201.307
START iteration 84, CKPT_AND_STOP: False
[2022-12-08 15:37:52.890713] Finished iteration 85, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6175.617
START iteration 85, CKPT_AND_STOP: False
[2022-12-08 15:37:59.004906] Finished iteration 86, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6114.192
START iteration 86, CKPT_AND_STOP: False
[2022-12-08 15:38:05.175019] Finished iteration 87, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6170.114
START iteration 87, CKPT_AND_STOP: False
[2022-12-08 15:38:11.456080] Finished iteration 88, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6281.060
START iteration 88, CKPT_AND_STOP: False
[2022-12-08 15:38:17.667999] Finished iteration 89, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6211.920
START iteration 89, CKPT_AND_STOP: False
[2022-12-08 15:38:23.986567] Finished iteration 90, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6318.568
START iteration 90, CKPT_AND_STOP: False
[2022-12-08 15:38:30.262225] Finished iteration 91, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6275.658
START iteration 91, CKPT_AND_STOP: False
[2022-12-08 15:38:36.524610] Finished iteration 92, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6262.384
START iteration 92, CKPT_AND_STOP: False
[2022-12-08 15:38:42.928237] Finished iteration 93, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6403.627
START iteration 93, CKPT_AND_STOP: False
[2022-12-08 15:38:49.444379] Finished iteration 94, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6516.143
START iteration 94, CKPT_AND_STOP: False
[2022-12-08 15:38:55.763316] Finished iteration 95, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6318.936
START iteration 95, CKPT_AND_STOP: False
[2022-12-08 15:39:02.029623] Finished iteration 96, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6266.308
START iteration 96, CKPT_AND_STOP: False
[2022-12-08 15:39:08.255212] Finished iteration 97, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6225.588
START iteration 97, CKPT_AND_STOP: False
[2022-12-08 15:39:14.475920] Finished iteration 98, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6220.709
START iteration 98, CKPT_AND_STOP: False
[2022-12-08 15:39:20.580996] Finished iteration 99, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6105.078
START iteration 99, CKPT_AND_STOP: False
[2022-12-08 15:39:26.740630] Finished iteration 100, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6159.632
START iteration 100, CKPT_AND_STOP: False
[2022-12-08 15:39:32.954943] Finished iteration 101, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6214.313
START iteration 101, CKPT_AND_STOP: False
[2022-12-08 15:39:38.985544] Finished iteration 102, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6030.602
START iteration 102, CKPT_AND_STOP: False
[2022-12-08 15:39:45.191320] Finished iteration 103, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6205.776
START iteration 103, CKPT_AND_STOP: False
[2022-12-08 15:39:51.397639] Finished iteration 104, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6206.319
START iteration 104, CKPT_AND_STOP: False
[2022-12-08 15:39:57.632735] Finished iteration 105, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6235.096
START iteration 105, CKPT_AND_STOP: False
[2022-12-08 15:40:03.885058] Finished iteration 106, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6252.323
START iteration 106, CKPT_AND_STOP: False
[2022-12-08 15:40:10.138563] Finished iteration 107, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6253.505
START iteration 107, CKPT_AND_STOP: False
[2022-12-08 15:40:16.394675] Finished iteration 108, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6256.113
START iteration 108, CKPT_AND_STOP: False
[2022-12-08 15:40:22.711177] Finished iteration 109, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6316.501
START iteration 109, CKPT_AND_STOP: False
[2022-12-08 15:40:29.204028] Finished iteration 110, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6492.851
START iteration 110, CKPT_AND_STOP: False
[2022-12-08 15:40:35.368180] Finished iteration 111, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6164.152
START iteration 111, CKPT_AND_STOP: False
[2022-12-08 15:40:41.612075] Finished iteration 112, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6243.896
START iteration 112, CKPT_AND_STOP: False
[2022-12-08 15:40:47.891186] Finished iteration 113, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6279.111
START iteration 113, CKPT_AND_STOP: False
[2022-12-08 15:40:54.167635] Finished iteration 114, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6276.449
START iteration 114, CKPT_AND_STOP: False
[2022-12-08 15:41:00.265134] Finished iteration 115, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6097.499
START iteration 115, CKPT_AND_STOP: False
[2022-12-08 15:41:06.805791] Finished iteration 116, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6540.656
START iteration 116, CKPT_AND_STOP: False
[2022-12-08 15:41:13.630612] Finished iteration 117, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6824.820
START iteration 117, CKPT_AND_STOP: False
[2022-12-08 15:41:20.753643] Finished iteration 118, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 7123.032
START iteration 118, CKPT_AND_STOP: False
[2022-12-08 15:41:27.093279] Finished iteration 119, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6339.636
START iteration 119, CKPT_AND_STOP: False
[2022-12-08 15:41:33.799012] Finished iteration 120, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6705.733
START iteration 120, CKPT_AND_STOP: False
[2022-12-08 15:41:40.058468] Finished iteration 121, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6259.456
START iteration 121, CKPT_AND_STOP: False
[2022-12-08 15:41:46.295885] Finished iteration 122, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6237.416
START iteration 122, CKPT_AND_STOP: False
[2022-12-08 15:41:52.433789] Finished iteration 123, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6137.903
START iteration 123, CKPT_AND_STOP: False
[2022-12-08 15:41:58.804781] Finished iteration 124, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6370.994
START iteration 124, CKPT_AND_STOP: False
[2022-12-08 15:42:04.966930] Finished iteration 125, CKPT_AND_STOP: False, flag: tensor([7], dtype=torch.int32), speed: 6162.148
Begin to save checkpont and exit
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 9 signal handler called with signal 10
Opt ckpt time 16.2957923412323
Parent process ID: 16516 node: 172.31.31.40
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 25 0 1731851.1962890625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7585451
Min send: 10000000, max send 0
Min long send: 38055, max long send 64155
Min fwd: 45773, max fwd 59456; min bwd 92460, max bwd 103910
Min long fwd: 56519, max long fwd 64913; min long bwd 96930, max long bwd 104722
Time taken by simulation: 729 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 32 0 1199719.8486328125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6885286
Min send: 10000000, max send 0
Min long send: 38109, max long send 65217
Min fwd: 31551, max fwd 49103; min bwd 67585, max bwd 79482
Min long fwd: 42800, max long fwd 50971; min long bwd 74672, max long bwd 82652
Time taken by simulation: 1377 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 64 0 548680.6640625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8215819
Min send: 10000000, max send 0
Min long send: 38055, max long send 68059
Min fwd: 17630, max fwd 35943; min bwd 42061, max bwd 55179
Min long fwd: 28151, max long fwd 36355; min long bwd 50517, max long bwd 61082
Time taken by simulation: 4571 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 64 0 442992.24853515625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6489103
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 9901, max fwd 27419; min bwd 27605, max bwd 45180
Min long fwd: 21186, max long fwd 32479; min long bwd 41203, max long bwd 48557
Time taken by simulation: 6538 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8759578
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 5999, max fwd 22973; min bwd 17039, max bwd 34800
Min long fwd: 12470, max long fwd 25017; min long bwd 25566, max long bwd 36212
Time taken by simulation: 21314 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29625 microseconds

can't have 24 stages!
{1: inf, 2: inf, 3: 7.585451, 4: 6.885286, 6: 8.215819, 8: 6.489103, 12: 8.759578, 16: 7.580423}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1}
best config is: 8 1
expected time is 6.489103
2 per stage
16 servers!
Config:
ranks: range(9, 10)
train batch size: 128
partitions: 8
chunk_size: 1
data depth: 2
stage to rank map: 0,8;1,9;2,10;3,11;4,12;5,13;6,14;7,15;
World size is 16
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=9 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,8;1,9;2,10;3,11;4,12;5,13;6,14;7,15; --batch-size=64 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 125
dry run time 9.864950895309448
SHARED WEIGHTS ARE
[(0, 7)]
this rank  9 is part of pipeline replica  1
64 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
 > finished loading checkpoint in 44.450 seconds
START iteration 125, CKPT_AND_STOP: False
[2022-12-08 15:44:15.419631] Finished iteration 126, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 13654.983
START iteration 126, CKPT_AND_STOP: False
[2022-12-08 15:44:23.216886] Finished iteration 127, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 7797.284
START iteration 127, CKPT_AND_STOP: False
[2022-12-08 15:44:30.257536] Finished iteration 128, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 7040.649
START iteration 128, CKPT_AND_STOP: False
[2022-12-08 15:44:36.795695] Finished iteration 129, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6538.161
START iteration 129, CKPT_AND_STOP: False
[2022-12-08 15:44:43.211391] Finished iteration 130, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6415.694
START iteration 130, CKPT_AND_STOP: False
[2022-12-08 15:44:48.566400] Finished iteration 131, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5355.010
START iteration 131, CKPT_AND_STOP: False
[2022-12-08 15:44:54.648118] Finished iteration 132, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6081.719
START iteration 132, CKPT_AND_STOP: False
