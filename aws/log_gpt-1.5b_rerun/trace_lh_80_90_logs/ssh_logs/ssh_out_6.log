Parent process ID: 4877 node: 172.31.16.5
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 21 0 1916562.744140625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6803052
Min send: 10000000, max send 0
Min long send: 38109, max long send 62549
Min fwd: 45773, max fwd 59456; min bwd 92874, max bwd 103910
Min long fwd: 57033, max long fwd 64913; min long bwd 96930, max long bwd 106927
Time taken by simulation: 621 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 32 0 1199719.8486328125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6885286
Min send: 10000000, max send 0
Min long send: 38109, max long send 65217
Min fwd: 31551, max fwd 49103; min bwd 67585, max bwd 79482
Min long fwd: 42800, max long fwd 50971; min long bwd 74672, max long bwd 82652
Time taken by simulation: 1408 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 42 0 770127.8076171875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5988334
Min send: 10000000, max send 0
Min long send: 38055, max long send 68059
Min fwd: 18837, max fwd 35859; min bwd 42358, max bwd 55388
Min long fwd: 27768, max long fwd 35092; min long bwd 51025, max long bwd 59414
Time taken by simulation: 3002 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 64 0 442992.24853515625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6489103
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 9901, max fwd 27419; min bwd 27605, max bwd 45180
Min long fwd: 21186, max long fwd 32479; min long bwd 41203, max long bwd 48557
Time taken by simulation: 6553 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8759578
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 5999, max fwd 22973; min bwd 17039, max bwd 34800
Min long fwd: 12470, max long fwd 25017; min long bwd 25566, max long bwd 36212
Time taken by simulation: 21326 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29624 microseconds

can't have 24 stages!
{1: inf, 2: inf, 3: 6.803052, 4: 6.885286, 6: 5.988334, 8: 6.489103, 12: 8.759578, 16: 7.580423}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1}
best config is: 6 1
expected time is 5.988334
3 per stage
18 servers!
Config:
ranks: range(6, 7)
train batch size: 128
partitions: 6
chunk_size: 1
data depth: 3
stage to rank map: 0,6,12;1,7,13;2,8,14;3,9,15;4,10,16;5,11,17;
World size is 18
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=6 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,6,12;1,7,13;2,8,14;3,9,15;4,10,16;5,11,17; --batch-size=42 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16
dry run time 9.975606918334961
SHARED WEIGHTS ARE
[(0, 5)]
this rank  6 is part of pipeline replica  1
42 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
 > finished loading checkpoint in 0.209 seconds
START iteration 0, CKPT_AND_STOP: False
[2022-12-08 14:50:52.623743] Finished iteration 1, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 11101.987
START iteration 1, CKPT_AND_STOP: False
[2022-12-08 14:50:58.741840] Finished iteration 2, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6118.125
START iteration 2, CKPT_AND_STOP: False
[2022-12-08 14:51:04.770116] Finished iteration 3, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6028.278
START iteration 3, CKPT_AND_STOP: False
[2022-12-08 14:51:10.877841] Finished iteration 4, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6107.723
START iteration 4, CKPT_AND_STOP: False
[2022-12-08 14:51:17.224872] Finished iteration 5, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6347.031
START iteration 5, CKPT_AND_STOP: False
[2022-12-08 14:51:22.269259] Finished iteration 6, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5044.390
START iteration 6, CKPT_AND_STOP: False
[2022-12-08 14:51:27.274823] Finished iteration 7, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5005.564
START iteration 7, CKPT_AND_STOP: False
[2022-12-08 14:51:32.340536] Finished iteration 8, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5065.713
START iteration 8, CKPT_AND_STOP: False
[2022-12-08 14:51:37.455262] Finished iteration 9, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5114.726
START iteration 9, CKPT_AND_STOP: False
[2022-12-08 14:51:42.472620] Finished iteration 10, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5017.358
START iteration 10, CKPT_AND_STOP: False
[2022-12-08 14:51:47.528253] Finished iteration 11, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5055.632
START iteration 11, CKPT_AND_STOP: False
[2022-12-08 14:51:52.561658] Finished iteration 12, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5033.406
START iteration 12, CKPT_AND_STOP: False
[2022-12-08 14:51:57.632638] Finished iteration 13, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5070.980
START iteration 13, CKPT_AND_STOP: False
[2022-12-08 14:52:02.662110] Finished iteration 14, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5029.472
START iteration 14, CKPT_AND_STOP: False
[2022-12-08 14:52:07.739575] Finished iteration 15, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5077.465
START iteration 15, CKPT_AND_STOP: False
[2022-12-08 14:52:13.484120] Finished iteration 16, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5744.545
START iteration 16, CKPT_AND_STOP: False
[2022-12-08 14:52:18.465250] Finished iteration 17, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4981.131
START iteration 17, CKPT_AND_STOP: False
[2022-12-08 14:52:23.514783] Finished iteration 18, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5049.533
START iteration 18, CKPT_AND_STOP: False
[2022-12-08 14:52:28.517313] Finished iteration 19, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5002.529
START iteration 19, CKPT_AND_STOP: False
[2022-12-08 14:52:33.552743] Finished iteration 20, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5035.430
START iteration 20, CKPT_AND_STOP: False
[2022-12-08 14:52:38.580733] Finished iteration 21, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5027.991
START iteration 21, CKPT_AND_STOP: False
[2022-12-08 14:52:43.691288] Finished iteration 22, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5110.554
START iteration 22, CKPT_AND_STOP: False
[2022-12-08 14:52:48.797457] Finished iteration 23, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5106.169
START iteration 23, CKPT_AND_STOP: False
[2022-12-08 14:52:53.891022] Finished iteration 24, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5093.565
START iteration 24, CKPT_AND_STOP: False
[2022-12-08 14:52:58.903742] Finished iteration 25, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5012.719
START iteration 25, CKPT_AND_STOP: False
[2022-12-08 14:53:03.943201] Finished iteration 26, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5039.459
START iteration 26, CKPT_AND_STOP: False
[2022-12-08 14:53:09.041993] Finished iteration 27, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5098.792
START iteration 27, CKPT_AND_STOP: False
[2022-12-08 14:53:14.042529] Finished iteration 28, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5000.537
START iteration 28, CKPT_AND_STOP: False
[2022-12-08 14:53:19.086333] Finished iteration 29, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5043.803
START iteration 29, CKPT_AND_STOP: False
[2022-12-08 14:53:24.192830] Finished iteration 30, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5106.497
START iteration 30, CKPT_AND_STOP: False
[2022-12-08 14:53:29.243989] Finished iteration 31, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5051.160
START iteration 31, CKPT_AND_STOP: False
[2022-12-08 14:53:34.288607] Finished iteration 32, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5044.617
START iteration 32, CKPT_AND_STOP: False
[2022-12-08 14:53:39.365465] Finished iteration 33, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5076.858
START iteration 33, CKPT_AND_STOP: False
[2022-12-08 14:53:44.483495] Finished iteration 34, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5118.030
START iteration 34, CKPT_AND_STOP: False
[2022-12-08 14:53:49.502219] Finished iteration 35, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5018.723
START iteration 35, CKPT_AND_STOP: False
[2022-12-08 14:53:54.547211] Finished iteration 36, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5044.992
START iteration 36, CKPT_AND_STOP: False
[2022-12-08 14:53:59.588981] Finished iteration 37, CKPT_AND_STOP: False, flag: tensor([2], dtype=torch.int32), speed: 5041.769
Begin to save checkpont and exit
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 6 signal handler called with signal 10
Opt ckpt time 12.923529386520386
Process done with return code 0
Parent process ID: 5410 node: 172.31.16.5
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 21 0 1916562.744140625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6803052
Min send: 10000000, max send 0
Min long send: 38109, max long send 62549
Min fwd: 45773, max fwd 59456; min bwd 92874, max bwd 103910
Min long fwd: 57033, max long fwd 64913; min long bwd 96930, max long bwd 106927
Time taken by simulation: 615 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 25 0 1338646.484375 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5804683
Min send: 10000000, max send 0
Min long send: 38055, max long send 64155
Min fwd: 30866, max fwd 48132; min bwd 66753, max bwd 79482
Min long fwd: 43307, max long fwd 50971; min long bwd 73461, max long bwd 80147
Time taken by simulation: 1063 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 42 0 770127.8076171875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5988334
Min send: 10000000, max send 0
Min long send: 38055, max long send 68059
Min fwd: 18837, max fwd 35859; min bwd 42358, max bwd 55388
Min long fwd: 27768, max long fwd 35092; min long bwd 51025, max long bwd 59414
Time taken by simulation: 3010 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 64 0 442992.24853515625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6489103
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 9901, max fwd 27419; min bwd 27605, max bwd 45180
Min long fwd: 21186, max long fwd 32479; min long bwd 41203, max long bwd 48557
Time taken by simulation: 6536 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8759578
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 5999, max fwd 22973; min bwd 17039, max bwd 34800
Min long fwd: 12470, max long fwd 25017; min long bwd 25566, max long bwd 36212
Time taken by simulation: 21361 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29770 microseconds

can't have 24 stages!
{1: inf, 2: inf, 3: 6.803052, 4: 5.804683, 6: 5.988334, 8: 6.489103, 12: 8.759578, 16: 7.580423}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1}
best config is: 4 1
expected time is 5.804683
5 per stage
20 servers!
Config:
ranks: range(6, 7)
train batch size: 128
partitions: 4
chunk_size: 1
data depth: 5
stage to rank map: 0,4,8,12,16;1,5,9,13,17;2,6,10,14,18;3,7,11,15,19;
World size is 20
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=6 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,4,8,12,16;1,5,9,13,17;2,6,10,14,18;3,7,11,15,19; --batch-size=25 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 37
dry run time 9.980435132980347
SHARED WEIGHTS ARE
[(0, 3)]
this rank  6 is part of pipeline replica  1
25 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 6 signal handler called with signal 10
 > finished loading checkpoint in 75.156 seconds
Process done with return code 0
Parent process ID: 6432 node: 172.31.16.5
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 18 0 1846814.0869140625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5987018
Min send: 10000000, max send 0
Min long send: 38387, max long send 60521
Min fwd: 45773, max fwd 59834; min bwd 93871, max bwd 104244
Min long fwd: 57033, max long fwd 64913; min long bwd 98140, max long bwd 103204
Time taken by simulation: 535 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 25 0 1338646.484375 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5804683
Min send: 10000000, max send 0
Min long send: 38055, max long send 64155
Min fwd: 30866, max fwd 48132; min bwd 66753, max bwd 79482
Min long fwd: 43307, max long fwd 50971; min long bwd 73461, max long bwd 80147
Time taken by simulation: 1070 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 42 0 770127.8076171875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5988334
Min send: 10000000, max send 0
Min long send: 38055, max long send 68059
Min fwd: 18837, max fwd 35859; min bwd 42358, max bwd 55388
Min long fwd: 27768, max long fwd 35092; min long bwd 51025, max long bwd 59414
Time taken by simulation: 2994 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 64 0 442992.24853515625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6489103
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 9901, max fwd 27419; min bwd 27605, max bwd 45180
Min long fwd: 21186, max long fwd 32479; min long bwd 41203, max long bwd 48557
Time taken by simulation: 6620 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8759578
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 5999, max fwd 22973; min bwd 17039, max bwd 34800
Min long fwd: 12470, max long fwd 25017; min long bwd 25566, max long bwd 36212
Time taken by simulation: 21339 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29564 microseconds

can't have 24 stages!
{1: inf, 2: inf, 3: 5.987018, 4: 5.804683, 6: 5.988334, 8: 6.489103, 12: 8.759578, 16: 7.580423}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1}
best config is: 4 1
expected time is 5.804683
5 per stage
20 servers!
Config:
ranks: range(6, 7)
train batch size: 128
partitions: 4
chunk_size: 1
data depth: 5
stage to rank map: 0,4,8,12,16;1,5,9,13,17;2,6,10,14,18;3,7,11,15,19;
World size is 20
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=6 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,4,8,12,16;1,5,9,13,17;2,6,10,14,18;3,7,11,15,19; --batch-size=25 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 37
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 6 signal handler called with signal 10
dry run time 9.859578371047974
SHARED WEIGHTS ARE
[(0, 3)]
this rank  6 is part of pipeline replica  1
25 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
 > finished loading checkpoint in 61.696 seconds
Process done with return code 0
Parent process ID: 7455 node: 172.31.16.5
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 18 0 1846814.0869140625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5987018
Min send: 10000000, max send 0
Min long send: 38387, max long send 60521
Min fwd: 45773, max fwd 59834; min bwd 93871, max bwd 104244
Min long fwd: 57033, max long fwd 64913; min long bwd 98140, max long bwd 103204
Time taken by simulation: 543 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 25 0 1338646.484375 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5804683
Min send: 10000000, max send 0
Min long send: 38055, max long send 64155
Min fwd: 30866, max fwd 48132; min bwd 66753, max bwd 79482
Min long fwd: 43307, max long fwd 50971; min long bwd 73461, max long bwd 80147
Time taken by simulation: 1063 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 42 0 770127.8076171875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5988334
Min send: 10000000, max send 0
Min long send: 38055, max long send 68059
Min fwd: 18837, max fwd 35859; min bwd 42358, max bwd 55388
Min long fwd: 27768, max long fwd 35092; min long bwd 51025, max long bwd 59414
Time taken by simulation: 3023 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 64 0 442992.24853515625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6489103
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 9901, max fwd 27419; min bwd 27605, max bwd 45180
Min long fwd: 21186, max long fwd 32479; min long bwd 41203, max long bwd 48557
Time taken by simulation: 6527 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8759578
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 5999, max fwd 22973; min bwd 17039, max bwd 34800
Min long fwd: 12470, max long fwd 25017; min long bwd 25566, max long bwd 36212
Time taken by simulation: 21331 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29584 microseconds

can't have 24 stages!
{1: inf, 2: inf, 3: 5.987018, 4: 5.804683, 6: 5.988334, 8: 6.489103, 12: 8.759578, 16: 7.580423}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1}
best config is: 4 1
expected time is 5.804683
5 per stage
20 servers!
Config:
ranks: range(6, 7)
train batch size: 128
partitions: 4
chunk_size: 1
data depth: 5
stage to rank map: 0,4,8,12,16;1,5,9,13,17;2,6,10,14,18;3,7,11,15,19;
World size is 20
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=6 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,4,8,12,16;1,5,9,13,17;2,6,10,14,18;3,7,11,15,19; --batch-size=25 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 37
dry run time 9.682279348373413
SHARED WEIGHTS ARE
[(0, 3)]
this rank  6 is part of pipeline replica  1
25 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 6 signal handler called with signal 10
 > finished loading checkpoint in 74.777 seconds
Process done with return code 0
Parent process ID: 8478 node: 172.31.16.5
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 18 0 1846814.0869140625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5987018
Min send: 10000000, max send 0
Min long send: 38387, max long send 60521
Min fwd: 45773, max fwd 59834; min bwd 93871, max bwd 104244
Min long fwd: 57033, max long fwd 64913; min long bwd 98140, max long bwd 103204
Time taken by simulation: 538 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 25 0 1338646.484375 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5804683
Min send: 10000000, max send 0
Min long send: 38055, max long send 64155
Min fwd: 30866, max fwd 48132; min bwd 66753, max bwd 79482
Min long fwd: 43307, max long fwd 50971; min long bwd 73461, max long bwd 80147
Time taken by simulation: 1068 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 42 0 770127.8076171875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5988334
Min send: 10000000, max send 0
Min long send: 38055, max long send 68059
Min fwd: 18837, max fwd 35859; min bwd 42358, max bwd 55388
Min long fwd: 27768, max long fwd 35092; min long bwd 51025, max long bwd 59414
Time taken by simulation: 2988 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 64 0 442992.24853515625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6489103
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 9901, max fwd 27419; min bwd 27605, max bwd 45180
Min long fwd: 21186, max long fwd 32479; min long bwd 41203, max long bwd 48557
Time taken by simulation: 6507 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8759578
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 5999, max fwd 22973; min bwd 17039, max bwd 34800
Min long fwd: 12470, max long fwd 25017; min long bwd 25566, max long bwd 36212
Time taken by simulation: 21473 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29707 microseconds

can't have 24 stages!
{1: inf, 2: inf, 3: 5.987018, 4: 5.804683, 6: 5.988334, 8: 6.489103, 12: 8.759578, 16: 7.580423}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1}
best config is: 4 1
expected time is 5.804683
5 per stage
20 servers!
Config:
ranks: range(6, 7)
train batch size: 128
partitions: 4
chunk_size: 1
data depth: 5
stage to rank map: 0,4,8,12,16;1,5,9,13,17;2,6,10,14,18;3,7,11,15,19;
World size is 20
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=6 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,4,8,12,16;1,5,9,13,17;2,6,10,14,18;3,7,11,15,19; --batch-size=25 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 37
dry run time 9.776610851287842
SHARED WEIGHTS ARE
[(0, 3)]
this rank  6 is part of pipeline replica  1
25 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 6 signal handler called with signal 10
 > finished loading checkpoint in 72.048 seconds
Process done with return code 0
Parent process ID: 9501 node: 172.31.16.5
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 16 0 2198285.64453125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5986016
Min send: 10000000, max send 0
Min long send: 38293, max long send 60521
Min fwd: 45773, max fwd 59456; min bwd 93556, max bwd 103910
Min long fwd: 57033, max long fwd 64913; min long bwd 97741, max long bwd 104518
Time taken by simulation: 484 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 21 0 1478731.4453125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5493991
Min send: 10000000, max send 0
Min long send: 38109, max long send 64155
Min fwd: 32128, max fwd 48180; min bwd 67776, max bwd 77208
Min long fwd: 43175, max long fwd 51496; min long bwd 74514, max long bwd 81205
Time taken by simulation: 900 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 32 0 876895.5078125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5017062
Min send: 10000000, max send 0
Min long send: 38071, max long send 66276
Min fwd: 18837, max fwd 35859; min bwd 42514, max bwd 56347
Min long fwd: 27753, max long fwd 35222; min long bwd 51765, max long bwd 59571
Time taken by simulation: 2252 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 42 0 610855.46875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4799842
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 10665, max fwd 27276; min bwd 28791, max bwd 43945
Min long fwd: 21459, max long fwd 30507; min long bwd 38642, max long bwd 48142
Time taken by simulation: 4244 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 64 0 343797.36328125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5360725
Min send: 10000000, max send 0
Min long send: 38056, max long send 68144
Min fwd: 5149, max fwd 20736; min bwd 17314, max bwd 33457
Min long fwd: 11639, max long fwd 22378; min long bwd 26559, max long bwd 34539
Time taken by simulation: 10421 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29599 microseconds

Stages 24
Micro-bs 1 Max mem: 2949765734.4
Predicted microbatch size for 24: 1
comm size 1638400
WARNING: no send time found, 24 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 24 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6789982
Min send: 10000000, max send 0
Min long send: 38055, max long send 74455
Min fwd: 26, max fwd 15549; min bwd 3842, max bwd 20573
Min long fwd: 7764, max long fwd 18097; min long bwd 11316, max long bwd 21840
Time taken by simulation: 45908 microseconds

{1: inf, 2: inf, 3: 5.986016, 4: 5.493991, 6: 5.017062, 8: 4.799842, 12: 5.360725, 16: 7.580423, 24: 6.789982}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1, 24: 1}
best config is: 8 1
expected time is 4.799842
3 per stage
24 servers!
Config:
ranks: range(6, 7)
train batch size: 128
partitions: 8
chunk_size: 1
data depth: 3
stage to rank map: 0,8,16;1,9,17;2,10,18;3,11,19;4,12,20;5,13,21;6,14,22;7,15,23;
World size is 24
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=6 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,8,16;1,9,17;2,10,18;3,11,19;4,12,20;5,13,21;6,14,22;7,15,23; --batch-size=42 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 37
dry run time 9.880254030227661
SHARED WEIGHTS ARE
[(0, 7)]
this rank  6 is part of pipeline replica  0
42 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
 > finished loading checkpoint in 43.948 seconds
START iteration 37, CKPT_AND_STOP: False
[2022-12-08 15:03:45.362949] Finished iteration 38, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 12377.305
START iteration 38, CKPT_AND_STOP: False
[2022-12-08 15:03:50.793860] Finished iteration 39, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5430.926
START iteration 39, CKPT_AND_STOP: False
[2022-12-08 15:03:56.239838] Finished iteration 40, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5445.978
START iteration 40, CKPT_AND_STOP: False
[2022-12-08 15:04:01.692827] Finished iteration 41, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5452.990
START iteration 41, CKPT_AND_STOP: False
[2022-12-08 15:04:07.176791] Finished iteration 42, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5483.964
START iteration 42, CKPT_AND_STOP: False
[2022-12-08 15:04:11.623196] Finished iteration 43, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4446.407
START iteration 43, CKPT_AND_STOP: False
[2022-12-08 15:04:15.962475] Finished iteration 44, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4339.279
START iteration 44, CKPT_AND_STOP: False
[2022-12-08 15:04:21.534818] Finished iteration 45, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5572.342
START iteration 45, CKPT_AND_STOP: False
[2022-12-08 15:04:25.860883] Finished iteration 46, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4326.066
START iteration 46, CKPT_AND_STOP: False
[2022-12-08 15:04:30.265271] Finished iteration 47, CKPT_AND_STOP: False, flag: tensor([3], dtype=torch.int32), speed: 4404.387
Begin to save checkpont and exit
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 6 signal handler called with signal 10
Opt ckpt time 10.4531729221344
Process done with return code 0
Parent process ID: 11928 node: 172.31.22.229
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 21 0 1916562.744140625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6803052
Min send: 10000000, max send 0
Min long send: 38109, max long send 62549
Min fwd: 45773, max fwd 59456; min bwd 92874, max bwd 103910
Min long fwd: 57033, max long fwd 64913; min long bwd 96930, max long bwd 106927
Time taken by simulation: 621 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 25 0 1338646.484375 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5804683
Min send: 10000000, max send 0
Min long send: 38055, max long send 64155
Min fwd: 30866, max fwd 48132; min bwd 66753, max bwd 79482
Min long fwd: 43307, max long fwd 50971; min long bwd 73461, max long bwd 80147
Time taken by simulation: 1063 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 42 0 770127.8076171875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5988334
Min send: 10000000, max send 0
Min long send: 38055, max long send 68059
Min fwd: 18837, max fwd 35859; min bwd 42358, max bwd 55388
Min long fwd: 27768, max long fwd 35092; min long bwd 51025, max long bwd 59414
Time taken by simulation: 2983 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 64 0 442992.24853515625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6489103
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 9901, max fwd 27419; min bwd 27605, max bwd 45180
Min long fwd: 21186, max long fwd 32479; min long bwd 41203, max long bwd 48557
Time taken by simulation: 6693 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8759578
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 5999, max fwd 22973; min bwd 17039, max bwd 34800
Min long fwd: 12470, max long fwd 25017; min long bwd 25566, max long bwd 36212
Time taken by simulation: 21447 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29868 microseconds

can't have 24 stages!
{1: inf, 2: inf, 3: 6.803052, 4: 5.804683, 6: 5.988334, 8: 6.489103, 12: 8.759578, 16: 7.580423}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1}
best config is: 4 1
expected time is 5.804683
5 per stage
20 servers!
Config:
ranks: range(6, 7)
train batch size: 128
partitions: 4
chunk_size: 1
data depth: 5
stage to rank map: 0,4,8,12,16;1,5,9,13,17;2,6,10,14,18;3,7,11,15,19;
World size is 20
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=6 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,4,8,12,16;1,5,9,13,17;2,6,10,14,18;3,7,11,15,19; --batch-size=25 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 47
dry run time 0.270066499710083
SHARED WEIGHTS ARE
[(0, 3)]
this rank  6 is part of pipeline replica  1
25 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 6 signal handler called with signal 10
Process done with return code 1
Parent process ID: 12893 node: 172.31.22.229
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 25 0 1731851.1962890625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7585451
Min send: 10000000, max send 0
Min long send: 38055, max long send 64155
Min fwd: 45773, max fwd 59456; min bwd 92460, max bwd 103910
Min long fwd: 56519, max long fwd 64913; min long bwd 96930, max long bwd 104722
Time taken by simulation: 735 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 32 0 1199719.8486328125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6885286
Min send: 10000000, max send 0
Min long send: 38109, max long send 65217
Min fwd: 31551, max fwd 49103; min bwd 67585, max bwd 79482
Min long fwd: 42800, max long fwd 50971; min long bwd 74672, max long bwd 82652
Time taken by simulation: 1356 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 64 0 548680.6640625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8215819
Min send: 10000000, max send 0
Min long send: 38055, max long send 68059
Min fwd: 17630, max fwd 35943; min bwd 42061, max bwd 55179
Min long fwd: 28151, max long fwd 36355; min long bwd 50517, max long bwd 61082
Time taken by simulation: 4558 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 64 0 442992.24853515625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6489103
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 9901, max fwd 27419; min bwd 27605, max bwd 45180
Min long fwd: 21186, max long fwd 32479; min long bwd 41203, max long bwd 48557
Time taken by simulation: 6472 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8759578
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 5999, max fwd 22973; min bwd 17039, max bwd 34800
Min long fwd: 12470, max long fwd 25017; min long bwd 25566, max long bwd 36212
Time taken by simulation: 21462 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29820 microseconds

can't have 24 stages!
{1: inf, 2: inf, 3: 7.585451, 4: 6.885286, 6: 8.215819, 8: 6.489103, 12: 8.759578, 16: 7.580423}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1}
best config is: 8 1
expected time is 6.489103
2 per stage
16 servers!
Config:
ranks: range(6, 7)
train batch size: 128
partitions: 8
chunk_size: 1
data depth: 2
stage to rank map: 0,8;1,9;2,10;3,11;4,12;5,13;6,14;7,15;
World size is 16
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=6 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,8;1,9;2,10;3,11;4,12;5,13;6,14;7,15; --batch-size=64 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 47
dry run time 0.006186723709106445
SHARED WEIGHTS ARE
[(0, 7)]
this rank  6 is part of pipeline replica  0
64 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 6 signal handler called with signal 10
 > finished loading checkpoint in 41.879 seconds
Process done with return code 1
Parent process ID: 13553 node: 172.31.19.171
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 32 0 1527054.19921875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8830859
Min send: 10000000, max send 0
Min long send: 38055, max long send 61744
Min fwd: 45773, max fwd 61214; min bwd 93190, max bwd 104086
Min long fwd: 56519, max long fwd 64913; min long bwd 96534, max long bwd 106927
Time taken by simulation: 919 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 42 0 1050667.96875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8392460
Min send: 10000000, max send 0
Min long send: 38071, max long send 65217
Min fwd: 32292, max fwd 49103; min bwd 66753, max bwd 79482
Min long fwd: 42823, max long fwd 51268; min long bwd 73813, max long bwd 81750
Time taken by simulation: 1768 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 64 0 548680.6640625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8215819
Min send: 10000000, max send 0
Min long send: 38055, max long send 68059
Min fwd: 17630, max fwd 35943; min bwd 42061, max bwd 55179
Min long fwd: 28151, max long fwd 36355; min long bwd 50517, max long bwd 61082
Time taken by simulation: 4545 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 11360042
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 11033, max fwd 28476; min bwd 28114, max bwd 44951
Min long fwd: 21153, max long fwd 31234; min long bwd 40297, max long bwd 49256
Time taken by simulation: 13367 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8759578
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 5999, max fwd 22973; min bwd 17039, max bwd 34800
Min long fwd: 12470, max long fwd 25017; min long bwd 25566, max long bwd 36212
Time taken by simulation: 21305 microseconds

can't have 16 stages!
can't have 24 stages!
{1: inf, 2: inf, 3: 8.830859, 4: 8.39246, 6: 8.215819, 8: 11.360042, 12: 8.759578}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1}
best config is: 6 1
expected time is 8.215819
2 per stage
12 servers!
Config:
ranks: range(6, 7)
train batch size: 128
partitions: 6
chunk_size: 1
data depth: 2
stage to rank map: 0,6;1,7;2,8;3,9;4,10;5,11;
World size is 12
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=6 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,6;1,7;2,8;3,9;4,10;5,11; --batch-size=64 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 47
dry run time 9.825609922409058
SHARED WEIGHTS ARE
[(0, 5)]
this rank  6 is part of pipeline replica  1
64 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 6 signal handler called with signal 10
 > finished loading checkpoint in 44.910 seconds
Process done with return code 0
Parent process ID: 14385 node: 172.31.28.236
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 32 0 1527054.19921875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8830859
Min send: 10000000, max send 0
Min long send: 38055, max long send 61744
Min fwd: 45773, max fwd 61214; min bwd 93190, max bwd 104086
Min long fwd: 56519, max long fwd 64913; min long bwd 96534, max long bwd 106927
Time taken by simulation: 916 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 42 0 1050667.96875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8392460
Min send: 10000000, max send 0
Min long send: 38071, max long send 65217
Min fwd: 32292, max fwd 49103; min bwd 66753, max bwd 79482
Min long fwd: 42823, max long fwd 51268; min long bwd 73813, max long bwd 81750
Time taken by simulation: 1786 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 64 0 548680.6640625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8215819
Min send: 10000000, max send 0
Min long send: 38055, max long send 68059
Min fwd: 17630, max fwd 35943; min bwd 42061, max bwd 55179
Min long fwd: 28151, max long fwd 36355; min long bwd 50517, max long bwd 61082
Time taken by simulation: 4520 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 11360042
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 11033, max fwd 28476; min bwd 28114, max bwd 44951
Min long fwd: 21153, max long fwd 31234; min long bwd 40297, max long bwd 49256
Time taken by simulation: 13108 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8759578
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 5999, max fwd 22973; min bwd 17039, max bwd 34800
Min long fwd: 12470, max long fwd 25017; min long bwd 25566, max long bwd 36212
Time taken by simulation: 21279 microseconds

can't have 16 stages!
can't have 24 stages!
{1: inf, 2: inf, 3: 8.830859, 4: 8.39246, 6: 8.215819, 8: 11.360042, 12: 8.759578}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1}
best config is: 6 1
expected time is 8.215819
2 per stage
12 servers!
Config:
ranks: range(6, 7)
train batch size: 128
partitions: 6
chunk_size: 1
data depth: 2
stage to rank map: 0,6;1,7;2,8;3,9;4,10;5,11;
World size is 12
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=6 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,6;1,7;2,8;3,9;4,10;5,11; --batch-size=64 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 47
dry run time 0.26400327682495117
SHARED WEIGHTS ARE
[(0, 5)]
this rank  6 is part of pipeline replica  1
64 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 6 signal handler called with signal 10
 > finished loading checkpoint in 41.409 seconds
Process done with return code 0
Parent process ID: 15217 node: 172.31.28.236
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 42 0 1334285.400390625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 10543558
Min send: 10000000, max send 0
Min long send: 38287, max long send 65217
Min fwd: 45773, max fwd 61214; min bwd 92331, max bwd 103910
Min long fwd: 52474, max long fwd 64913; min long bwd 98140, max long bwd 106927
Time taken by simulation: 1193 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 64 0 748630.126953125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 11457418
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 31994, max fwd 49123; min bwd 66753, max bwd 80221
Min long fwd: 40995, max long fwd 51310; min long bwd 72999, max long bwd 81750
Time taken by simulation: 2691 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 14725210
Min send: 10000000, max send 0
Min long send: 38055, max long send 70233
Min fwd: 16996, max fwd 37054; min bwd 39871, max bwd 55692
Min long fwd: 24877, max long fwd 36805; min long bwd 48154, max long bwd 62088
Time taken by simulation: 9251 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 11360042
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 11033, max fwd 28476; min bwd 28114, max bwd 44951
Min long fwd: 21153, max long fwd 31234; min long bwd 40297, max long bwd 49256
Time taken by simulation: 13058 microseconds

can't have 12 stages!
can't have 16 stages!
can't have 24 stages!
{1: inf, 2: inf, 3: 10.543558, 4: 11.457418, 6: 14.72521, 8: 11.360042}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1}
best config is: 3 1
expected time is 10.543558
3 per stage
9 servers!
Config:
ranks: range(6, 7)
train batch size: 128
partitions: 3
chunk_size: 1
data depth: 3
stage to rank map: 0,3,6;1,4,7;2,5,8;
World size is 9
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=6 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,3,6;1,4,7;2,5,8; --batch-size=42 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 47
dry run time 9.268440008163452
SHARED WEIGHTS ARE
[(0, 2)]
this rank  6 is part of pipeline replica  2
42 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
Parent process ID: 15492 node: 172.31.28.236
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 42 0 1334285.400390625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 10543558
Min send: 10000000, max send 0
Min long send: 38287, max long send 65217
Min fwd: 45773, max fwd 61214; min bwd 92331, max bwd 103910
Min long fwd: 52474, max long fwd 64913; min long bwd 98140, max long bwd 106927
Time taken by simulation: 1191 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 64 0 748630.126953125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 11457418
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 31994, max fwd 49123; min bwd 66753, max bwd 80221
Min long fwd: 40995, max long fwd 51310; min long bwd 72999, max long bwd 81750
Time taken by simulation: 2730 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 14725210
Min send: 10000000, max send 0
Min long send: 38055, max long send 70233
Min fwd: 16996, max fwd 37054; min bwd 39871, max bwd 55692
Min long fwd: 24877, max long fwd 36805; min long bwd 48154, max long bwd 62088
Time taken by simulation: 9211 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 11360042
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 11033, max fwd 28476; min bwd 28114, max bwd 44951
Min long fwd: 21153, max long fwd 31234; min long bwd 40297, max long bwd 49256
Time taken by simulation: 13093 microseconds

can't have 12 stages!
can't have 16 stages!
can't have 24 stages!
{1: inf, 2: inf, 3: 10.543558, 4: 11.457418, 6: 14.72521, 8: 11.360042}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1}
best config is: 3 1
expected time is 10.543558
3 per stage
9 servers!
Config:
ranks: range(6, 7)
train batch size: 128
partitions: 3
chunk_size: 1
data depth: 3
stage to rank map: 0,3,6;1,4,7;2,5,8;
World size is 9
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=6 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,3,6;1,4,7;2,5,8; --batch-size=42 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 47
dry run time 0.2206432819366455
SHARED WEIGHTS ARE
[(0, 2)]
this rank  6 is part of pipeline replica  2
42 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 6 signal handler called with signal 10
 > finished loading checkpoint in 85.786 seconds
Process done with return code 0
Parent process ID: 16747 node: 172.31.28.236
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 32 0 1527054.19921875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8830859
Min send: 10000000, max send 0
Min long send: 38055, max long send 61744
Min fwd: 45773, max fwd 61214; min bwd 93190, max bwd 104086
Min long fwd: 56519, max long fwd 64913; min long bwd 96534, max long bwd 106927
Time taken by simulation: 925 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 42 0 1050667.96875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8392460
Min send: 10000000, max send 0
Min long send: 38071, max long send 65217
Min fwd: 32292, max fwd 49103; min bwd 66753, max bwd 79482
Min long fwd: 42823, max long fwd 51268; min long bwd 73813, max long bwd 81750
Time taken by simulation: 1803 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 64 0 548680.6640625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8215819
Min send: 10000000, max send 0
Min long send: 38055, max long send 68059
Min fwd: 17630, max fwd 35943; min bwd 42061, max bwd 55179
Min long fwd: 28151, max long fwd 36355; min long bwd 50517, max long bwd 61082
Time taken by simulation: 4619 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 11360042
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 11033, max fwd 28476; min bwd 28114, max bwd 44951
Min long fwd: 21153, max long fwd 31234; min long bwd 40297, max long bwd 49256
Time taken by simulation: 13171 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8759578
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 5999, max fwd 22973; min bwd 17039, max bwd 34800
Min long fwd: 12470, max long fwd 25017; min long bwd 25566, max long bwd 36212
Time taken by simulation: 21348 microseconds

can't have 16 stages!
can't have 24 stages!
{1: inf, 2: inf, 3: 8.830859, 4: 8.39246, 6: 8.215819, 8: 11.360042, 12: 8.759578}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1}
best config is: 6 1
expected time is 8.215819
2 per stage
12 servers!
Config:
ranks: range(6, 7)
train batch size: 128
partitions: 6
chunk_size: 1
data depth: 2
stage to rank map: 0,6;1,7;2,8;3,9;4,10;5,11;
World size is 12
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=6 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,6;1,7;2,8;3,9;4,10;5,11; --batch-size=64 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 47
dry run time 9.19680142402649
SHARED WEIGHTS ARE
[(0, 5)]
this rank  6 is part of pipeline replica  1
64 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 6 signal handler called with signal 10
 > finished loading checkpoint in 48.981 seconds
Process done with return code 0
Parent process ID: 17583 node: 172.31.28.236
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 32 0 1527054.19921875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8830859
Min send: 10000000, max send 0
Min long send: 38055, max long send 61744
Min fwd: 45773, max fwd 61214; min bwd 93190, max bwd 104086
Min long fwd: 56519, max long fwd 64913; min long bwd 96534, max long bwd 106927
Time taken by simulation: 928 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 42 0 1050667.96875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8392460
Min send: 10000000, max send 0
Min long send: 38071, max long send 65217
Min fwd: 32292, max fwd 49103; min bwd 66753, max bwd 79482
Min long fwd: 42823, max long fwd 51268; min long bwd 73813, max long bwd 81750
Time taken by simulation: 1766 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 64 0 548680.6640625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8215819
Min send: 10000000, max send 0
Min long send: 38055, max long send 68059
Min fwd: 17630, max fwd 35943; min bwd 42061, max bwd 55179
Min long fwd: 28151, max long fwd 36355; min long bwd 50517, max long bwd 61082
Time taken by simulation: 4569 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 11360042
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 11033, max fwd 28476; min bwd 28114, max bwd 44951
Min long fwd: 21153, max long fwd 31234; min long bwd 40297, max long bwd 49256
Time taken by simulation: 13074 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8759578
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 5999, max fwd 22973; min bwd 17039, max bwd 34800
Min long fwd: 12470, max long fwd 25017; min long bwd 25566, max long bwd 36212
Time taken by simulation: 21363 microseconds

can't have 16 stages!
can't have 24 stages!
{1: inf, 2: inf, 3: 8.830859, 4: 8.39246, 6: 8.215819, 8: 11.360042, 12: 8.759578}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1}
best config is: 6 1
expected time is 8.215819
2 per stage
12 servers!
Config:
ranks: range(6, 7)
train batch size: 128
partitions: 6
chunk_size: 1
data depth: 2
stage to rank map: 0,6;1,7;2,8;3,9;4,10;5,11;
World size is 12
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=6 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,6;1,7;2,8;3,9;4,10;5,11; --batch-size=64 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 47
dry run time 9.181700468063354
SHARED WEIGHTS ARE
[(0, 5)]
this rank  6 is part of pipeline replica  1
64 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 6 signal handler called with signal 10
Process done with return code 1
Parent process ID: 18309 node: 172.31.21.45
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 32 0 1527054.19921875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8830859
Min send: 10000000, max send 0
Min long send: 38055, max long send 61744
Min fwd: 45773, max fwd 61214; min bwd 93190, max bwd 104086
Min long fwd: 56519, max long fwd 64913; min long bwd 96534, max long bwd 106927
Time taken by simulation: 922 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 42 0 1050667.96875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8392460
Min send: 10000000, max send 0
Min long send: 38071, max long send 65217
Min fwd: 32292, max fwd 49103; min bwd 66753, max bwd 79482
Min long fwd: 42823, max long fwd 51268; min long bwd 73813, max long bwd 81750
Time taken by simulation: 1820 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 64 0 548680.6640625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8215819
Min send: 10000000, max send 0
Min long send: 38055, max long send 68059
Min fwd: 17630, max fwd 35943; min bwd 42061, max bwd 55179
Min long fwd: 28151, max long fwd 36355; min long bwd 50517, max long bwd 61082
Time taken by simulation: 4547 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 11360042
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 11033, max fwd 28476; min bwd 28114, max bwd 44951
Min long fwd: 21153, max long fwd 31234; min long bwd 40297, max long bwd 49256
Time taken by simulation: 13098 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8759578
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 5999, max fwd 22973; min bwd 17039, max bwd 34800
Min long fwd: 12470, max long fwd 25017; min long bwd 25566, max long bwd 36212
Time taken by simulation: 21394 microseconds

can't have 16 stages!
can't have 24 stages!
{1: inf, 2: inf, 3: 8.830859, 4: 8.39246, 6: 8.215819, 8: 11.360042, 12: 8.759578}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1}
best config is: 6 1
expected time is 8.215819
2 per stage
12 servers!
Config:
ranks: range(6, 7)
train batch size: 128
partitions: 6
chunk_size: 1
data depth: 2
stage to rank map: 0,6;1,7;2,8;3,9;4,10;5,11;
World size is 12
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=6 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,6;1,7;2,8;3,9;4,10;5,11; --batch-size=64 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 47
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 6 signal handler called with signal 10
dry run time 9.166987419128418
SHARED WEIGHTS ARE
[(0, 5)]
this rank  6 is part of pipeline replica  1
64 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
 > finished loading checkpoint in 48.104 seconds
Process done with return code 0
Parent process ID: 19136 node: 172.31.21.45
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 32 0 1527054.19921875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8830859
Min send: 10000000, max send 0
Min long send: 38055, max long send 61744
Min fwd: 45773, max fwd 61214; min bwd 93190, max bwd 104086
Min long fwd: 56519, max long fwd 64913; min long bwd 96534, max long bwd 106927
Time taken by simulation: 918 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 42 0 1050667.96875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8392460
Min send: 10000000, max send 0
Min long send: 38071, max long send 65217
Min fwd: 32292, max fwd 49103; min bwd 66753, max bwd 79482
Min long fwd: 42823, max long fwd 51268; min long bwd 73813, max long bwd 81750
Time taken by simulation: 1830 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 64 0 548680.6640625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8215819
Min send: 10000000, max send 0
Min long send: 38055, max long send 68059
Min fwd: 17630, max fwd 35943; min bwd 42061, max bwd 55179
Min long fwd: 28151, max long fwd 36355; min long bwd 50517, max long bwd 61082
Time taken by simulation: 4562 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 11360042
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 11033, max fwd 28476; min bwd 28114, max bwd 44951
Min long fwd: 21153, max long fwd 31234; min long bwd 40297, max long bwd 49256
Time taken by simulation: 13083 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8759578
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 5999, max fwd 22973; min bwd 17039, max bwd 34800
Min long fwd: 12470, max long fwd 25017; min long bwd 25566, max long bwd 36212
Time taken by simulation: 21349 microseconds

can't have 16 stages!
can't have 24 stages!
{1: inf, 2: inf, 3: 8.830859, 4: 8.39246, 6: 8.215819, 8: 11.360042, 12: 8.759578}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1}
best config is: 6 1
expected time is 8.215819
2 per stage
12 servers!
Config:
ranks: range(6, 7)
train batch size: 128
partitions: 6
chunk_size: 1
data depth: 2
stage to rank map: 0,6;1,7;2,8;3,9;4,10;5,11;
World size is 12
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=6 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,6;1,7;2,8;3,9;4,10;5,11; --batch-size=64 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 47
dry run time 0.15890026092529297
SHARED WEIGHTS ARE
[(0, 5)]
this rank  6 is part of pipeline replica  1
64 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
 > finished loading checkpoint in 44.812 seconds
START iteration 47, CKPT_AND_STOP: False
[2022-12-08 15:22:35.062211] Finished iteration 48, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 11085.169
START iteration 48, CKPT_AND_STOP: False
[2022-12-08 15:22:42.569191] Finished iteration 49, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 7507.023
START iteration 49, CKPT_AND_STOP: False
[2022-12-08 15:22:50.100323] Finished iteration 50, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 7531.132
START iteration 50, CKPT_AND_STOP: False
[2022-12-08 15:22:57.780359] Finished iteration 51, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 7680.037
START iteration 51, CKPT_AND_STOP: False
[2022-12-08 15:23:05.437111] Finished iteration 52, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 7656.731
START iteration 52, CKPT_AND_STOP: False
[2022-12-08 15:23:12.057145] Finished iteration 53, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6620.055
START iteration 53, CKPT_AND_STOP: False
[2022-12-08 15:23:18.611442] Finished iteration 54, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6554.296
START iteration 54, CKPT_AND_STOP: False
[2022-12-08 15:23:25.341470] Finished iteration 55, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6730.028
START iteration 55, CKPT_AND_STOP: False
[2022-12-08 15:23:31.894857] Finished iteration 56, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6553.387
START iteration 56, CKPT_AND_STOP: False
[2022-12-08 15:23:38.532046] Finished iteration 57, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6637.189
START iteration 57, CKPT_AND_STOP: False
[2022-12-08 15:23:45.221046] Finished iteration 58, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6689.001
START iteration 58, CKPT_AND_STOP: False
[2022-12-08 15:23:51.793637] Finished iteration 59, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6572.591
START iteration 59, CKPT_AND_STOP: False
[2022-12-08 15:23:58.832783] Finished iteration 60, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 7039.146
START iteration 60, CKPT_AND_STOP: False
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 6 signal handler called with signal 10
[2022-12-08 15:24:05.570613] Finished iteration 61, CKPT_AND_STOP: True, flag: tensor([8], dtype=torch.int32), speed: 6737.830
Begin to save checkpont and exit
Opt ckpt time 14.52743124961853
Process done with return code 0
Parent process ID: 20085 node: 172.31.21.45
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 32 0 1527054.19921875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8830859
Min send: 10000000, max send 0
Min long send: 38055, max long send 61744
Min fwd: 45773, max fwd 61214; min bwd 93190, max bwd 104086
Min long fwd: 56519, max long fwd 64913; min long bwd 96534, max long bwd 106927
Time taken by simulation: 916 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 42 0 1050667.96875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8392460
Min send: 10000000, max send 0
Min long send: 38071, max long send 65217
Min fwd: 32292, max fwd 49103; min bwd 66753, max bwd 79482
Min long fwd: 42823, max long fwd 51268; min long bwd 73813, max long bwd 81750
Time taken by simulation: 1763 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 64 0 548680.6640625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8215819
Min send: 10000000, max send 0
Min long send: 38055, max long send 68059
Min fwd: 17630, max fwd 35943; min bwd 42061, max bwd 55179
Min long fwd: 28151, max long fwd 36355; min long bwd 50517, max long bwd 61082
Time taken by simulation: 4537 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 11360042
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 11033, max fwd 28476; min bwd 28114, max bwd 44951
Min long fwd: 21153, max long fwd 31234; min long bwd 40297, max long bwd 49256
Time taken by simulation: 13945 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8759578
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 5999, max fwd 22973; min bwd 17039, max bwd 34800
Min long fwd: 12470, max long fwd 25017; min long bwd 25566, max long bwd 36212
Time taken by simulation: 21470 microseconds

can't have 16 stages!
can't have 24 stages!
{1: inf, 2: inf, 3: 8.830859, 4: 8.39246, 6: 8.215819, 8: 11.360042, 12: 8.759578}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1}
best config is: 6 1
expected time is 8.215819
2 per stage
12 servers!
Config:
ranks: range(6, 7)
train batch size: 128
partitions: 6
chunk_size: 1
data depth: 2
stage to rank map: 0,6;1,7;2,8;3,9;4,10;5,11;
World size is 12
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=6 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,6;1,7;2,8;3,9;4,10;5,11; --batch-size=64 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 61
dry run time 0.15169239044189453
SHARED WEIGHTS ARE
[(0, 5)]
this rank  6 is part of pipeline replica  1
64 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 6 signal handler called with signal 10
 > finished loading checkpoint in 72.524 seconds
Process done with return code 0
Parent process ID: 21180 node: 172.31.21.45
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 21 0 1916562.744140625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6803052
Min send: 10000000, max send 0
Min long send: 38109, max long send 62549
Min fwd: 45773, max fwd 59456; min bwd 92874, max bwd 103910
Min long fwd: 57033, max long fwd 64913; min long bwd 96930, max long bwd 106927
Time taken by simulation: 650 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 32 0 1199719.8486328125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6885286
Min send: 10000000, max send 0
Min long send: 38109, max long send 65217
Min fwd: 31551, max fwd 49103; min bwd 67585, max bwd 79482
Min long fwd: 42800, max long fwd 50971; min long bwd 74672, max long bwd 82652
Time taken by simulation: 1353 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 42 0 770127.8076171875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5988334
Min send: 10000000, max send 0
Min long send: 38055, max long send 68059
Min fwd: 18837, max fwd 35859; min bwd 42358, max bwd 55388
Min long fwd: 27768, max long fwd 35092; min long bwd 51025, max long bwd 59414
Time taken by simulation: 3017 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 64 0 442992.24853515625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6489103
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 9901, max fwd 27419; min bwd 27605, max bwd 45180
Min long fwd: 21186, max long fwd 32479; min long bwd 41203, max long bwd 48557
Time taken by simulation: 6522 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8759578
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 5999, max fwd 22973; min bwd 17039, max bwd 34800
Min long fwd: 12470, max long fwd 25017; min long bwd 25566, max long bwd 36212
Time taken by simulation: 21348 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29558 microseconds

can't have 24 stages!
{1: inf, 2: inf, 3: 6.803052, 4: 6.885286, 6: 5.988334, 8: 6.489103, 12: 8.759578, 16: 7.580423}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1}
best config is: 6 1
expected time is 5.988334
3 per stage
18 servers!
Config:
ranks: range(6, 7)
train batch size: 128
partitions: 6
chunk_size: 1
data depth: 3
stage to rank map: 0,6,12;1,7,13;2,8,14;3,9,15;4,10,16;5,11,17;
World size is 18
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=6 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,6,12;1,7,13;2,8,14;3,9,15;4,10,16;5,11,17; --batch-size=42 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 61
dry run time 0.6260128021240234
SHARED WEIGHTS ARE
[(0, 5)]
this rank  6 is part of pipeline replica  1
42 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
 > finished loading checkpoint in 69.596 seconds
START iteration 61, CKPT_AND_STOP: False
[2022-12-08 15:28:32.618025] Finished iteration 62, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 11423.315
START iteration 62, CKPT_AND_STOP: False
[2022-12-08 15:28:38.738082] Finished iteration 63, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6120.077
START iteration 63, CKPT_AND_STOP: False
[2022-12-08 15:28:44.880005] Finished iteration 64, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6141.924
START iteration 64, CKPT_AND_STOP: False
[2022-12-08 15:28:51.054145] Finished iteration 65, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6174.135
START iteration 65, CKPT_AND_STOP: False
[2022-12-08 15:28:57.874090] Finished iteration 66, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6819.950
START iteration 66, CKPT_AND_STOP: False
[2022-12-08 15:29:02.947688] Finished iteration 67, CKPT_AND_STOP: False, flag: tensor([4], dtype=torch.int32), speed: 5073.599
Begin to save checkpont and exit
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 6 signal handler called with signal 10
Opt ckpt time 12.863281488418579
Process done with return code 0
Parent process ID: 22301 node: 172.31.21.45
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 21 0 1916562.744140625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6803052
Min send: 10000000, max send 0
Min long send: 38109, max long send 62549
Min fwd: 45773, max fwd 59456; min bwd 92874, max bwd 103910
Min long fwd: 57033, max long fwd 64913; min long bwd 96930, max long bwd 106927
Time taken by simulation: 611 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 32 0 1199719.8486328125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6885286
Min send: 10000000, max send 0
Min long send: 38109, max long send 65217
Min fwd: 31551, max fwd 49103; min bwd 67585, max bwd 79482
Min long fwd: 42800, max long fwd 50971; min long bwd 74672, max long bwd 82652
Time taken by simulation: 1361 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 42 0 770127.8076171875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5988334
Min send: 10000000, max send 0
Min long send: 38055, max long send 68059
Min fwd: 18837, max fwd 35859; min bwd 42358, max bwd 55388
Min long fwd: 27768, max long fwd 35092; min long bwd 51025, max long bwd 59414
Time taken by simulation: 2995 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 64 0 442992.24853515625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6489103
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 9901, max fwd 27419; min bwd 27605, max bwd 45180
Min long fwd: 21186, max long fwd 32479; min long bwd 41203, max long bwd 48557
Time taken by simulation: 6584 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8759578
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 5999, max fwd 22973; min bwd 17039, max bwd 34800
Min long fwd: 12470, max long fwd 25017; min long bwd 25566, max long bwd 36212
Time taken by simulation: 21320 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29690 microseconds

can't have 24 stages!
{1: inf, 2: inf, 3: 6.803052, 4: 6.885286, 6: 5.988334, 8: 6.489103, 12: 8.759578, 16: 7.580423}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1}
best config is: 6 1
expected time is 5.988334
3 per stage
18 servers!
Config:
ranks: range(6, 7)
train batch size: 128
partitions: 6
chunk_size: 1
data depth: 3
stage to rank map: 0,6,12;1,7,13;2,8,14;3,9,15;4,10,16;5,11,17;
World size is 18
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=6 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,6,12;1,7,13;2,8,14;3,9,15;4,10,16;5,11,17; --batch-size=42 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 67
dry run time 0.5047965049743652
SHARED WEIGHTS ARE
[(0, 5)]
this rank  6 is part of pipeline replica  1
42 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
 > finished loading checkpoint in 50.058 seconds
START iteration 67, CKPT_AND_STOP: False
[2022-12-08 15:31:12.614363] Finished iteration 68, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 11364.207
START iteration 68, CKPT_AND_STOP: False
[2022-12-08 15:31:18.733305] Finished iteration 69, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6118.993
START iteration 69, CKPT_AND_STOP: False
[2022-12-08 15:31:24.749179] Finished iteration 70, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6015.872
START iteration 70, CKPT_AND_STOP: False
[2022-12-08 15:31:30.908085] Finished iteration 71, CKPT_AND_STOP: False, flag: tensor([4], dtype=torch.int32), speed: 6158.906
Begin to save checkpont and exit
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 6 signal handler called with signal 10
Opt ckpt time 12.255191564559937
Process done with return code 0
Parent process ID: 23284 node: 172.31.19.112
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 25 0 1731851.1962890625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7585451
Min send: 10000000, max send 0
Min long send: 38055, max long send 64155
Min fwd: 45773, max fwd 59456; min bwd 92460, max bwd 103910
Min long fwd: 56519, max long fwd 64913; min long bwd 96930, max long bwd 104722
Time taken by simulation: 729 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 32 0 1199719.8486328125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6885286
Min send: 10000000, max send 0
Min long send: 38109, max long send 65217
Min fwd: 31551, max fwd 49103; min bwd 67585, max bwd 79482
Min long fwd: 42800, max long fwd 50971; min long bwd 74672, max long bwd 82652
Time taken by simulation: 1398 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 64 0 548680.6640625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8215819
Min send: 10000000, max send 0
Min long send: 38055, max long send 68059
Min fwd: 17630, max fwd 35943; min bwd 42061, max bwd 55179
Min long fwd: 28151, max long fwd 36355; min long bwd 50517, max long bwd 61082
Time taken by simulation: 4552 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 64 0 442992.24853515625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6489103
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 9901, max fwd 27419; min bwd 27605, max bwd 45180
Min long fwd: 21186, max long fwd 32479; min long bwd 41203, max long bwd 48557
Time taken by simulation: 6472 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8759578
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 5999, max fwd 22973; min bwd 17039, max bwd 34800
Min long fwd: 12470, max long fwd 25017; min long bwd 25566, max long bwd 36212
Time taken by simulation: 21296 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29547 microseconds

can't have 24 stages!
{1: inf, 2: inf, 3: 7.585451, 4: 6.885286, 6: 8.215819, 8: 6.489103, 12: 8.759578, 16: 7.580423}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1}
best config is: 8 1
expected time is 6.489103
2 per stage
16 servers!
Config:
ranks: range(6, 7)
train batch size: 128
partitions: 8
chunk_size: 1
data depth: 2
stage to rank map: 0,8;1,9;2,10;3,11;4,12;5,13;6,14;7,15;
World size is 16
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=6 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,8;1,9;2,10;3,11;4,12;5,13;6,14;7,15; --batch-size=64 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 71
dry run time 9.920267581939697
SHARED WEIGHTS ARE
[(0, 7)]
this rank  6 is part of pipeline replica  0
64 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 6 signal handler called with signal 10
 > finished loading checkpoint in 38.708 seconds
Process done with return code 0
Parent process ID: 18557 node: 172.31.23.137
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 25 0 1731851.1962890625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7585451
Min send: 10000000, max send 0
Min long send: 38055, max long send 64155
Min fwd: 45773, max fwd 59456; min bwd 92460, max bwd 103910
Min long fwd: 56519, max long fwd 64913; min long bwd 96930, max long bwd 104722
Time taken by simulation: 729 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 42 0 1050667.96875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8392460
Min send: 10000000, max send 0
Min long send: 38071, max long send 65217
Min fwd: 32292, max fwd 49103; min bwd 66753, max bwd 79482
Min long fwd: 42823, max long fwd 51268; min long bwd 73813, max long bwd 81750
Time taken by simulation: 1821 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 64 0 548680.6640625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8215819
Min send: 10000000, max send 0
Min long send: 38055, max long send 68059
Min fwd: 17630, max fwd 35943; min bwd 42061, max bwd 55179
Min long fwd: 28151, max long fwd 36355; min long bwd 50517, max long bwd 61082
Time taken by simulation: 4580 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 11360042
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 11033, max fwd 28476; min bwd 28114, max bwd 44951
Min long fwd: 21153, max long fwd 31234; min long bwd 40297, max long bwd 49256
Time taken by simulation: 13050 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8759578
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 5999, max fwd 22973; min bwd 17039, max bwd 34800
Min long fwd: 12470, max long fwd 25017; min long bwd 25566, max long bwd 36212
Time taken by simulation: 21416 microseconds

can't have 16 stages!
can't have 24 stages!
{1: inf, 2: inf, 3: 7.585451, 4: 8.39246, 6: 8.215819, 8: 11.360042, 12: 8.759578}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1}
best config is: 3 1
expected time is 7.585451
5 per stage
15 servers!
Config:
ranks: range(6, 7)
train batch size: 128
partitions: 3
chunk_size: 1
data depth: 5
stage to rank map: 0,3,6,9,12;1,4,7,10,13;2,5,8,11,14;
World size is 15
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=6 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,3,6,9,12;1,4,7,10,13;2,5,8,11,14; --batch-size=25 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 71
dry run time 9.999334812164307
SHARED WEIGHTS ARE
[(0, 2)]
this rank  6 is part of pipeline replica  2
25 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
 > finished loading checkpoint in 81.107 seconds
START iteration 71, CKPT_AND_STOP: False
[2022-12-08 15:36:27.989852] Finished iteration 72, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 9570.143
START iteration 72, CKPT_AND_STOP: False
[2022-12-08 15:36:35.319486] Finished iteration 73, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 7329.671
START iteration 73, CKPT_AND_STOP: False
[2022-12-08 15:36:42.671096] Finished iteration 74, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 7351.614
START iteration 74, CKPT_AND_STOP: False
[2022-12-08 15:36:49.795989] Finished iteration 75, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 7124.892
START iteration 75, CKPT_AND_STOP: False
[2022-12-08 15:36:57.124017] Finished iteration 76, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 7328.027
START iteration 76, CKPT_AND_STOP: False
[2022-12-08 15:37:03.152092] Finished iteration 77, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6028.077
START iteration 77, CKPT_AND_STOP: False
[2022-12-08 15:37:09.458953] Finished iteration 78, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6306.839
START iteration 78, CKPT_AND_STOP: False
[2022-12-08 15:37:15.417003] Finished iteration 79, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5958.072
START iteration 79, CKPT_AND_STOP: False
[2022-12-08 15:37:21.698100] Finished iteration 80, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6281.097
START iteration 80, CKPT_AND_STOP: False
[2022-12-08 15:37:27.955320] Finished iteration 81, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6257.220
START iteration 81, CKPT_AND_STOP: False
[2022-12-08 15:37:34.314248] Finished iteration 82, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6358.928
START iteration 82, CKPT_AND_STOP: False
[2022-12-08 15:37:40.515965] Finished iteration 83, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6201.718
START iteration 83, CKPT_AND_STOP: False
[2022-12-08 15:37:46.717350] Finished iteration 84, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6201.383
START iteration 84, CKPT_AND_STOP: False
[2022-12-08 15:37:52.892887] Finished iteration 85, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6175.538
START iteration 85, CKPT_AND_STOP: False
[2022-12-08 15:37:59.007055] Finished iteration 86, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6114.168
START iteration 86, CKPT_AND_STOP: False
[2022-12-08 15:38:05.177237] Finished iteration 87, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6170.182
START iteration 87, CKPT_AND_STOP: False
[2022-12-08 15:38:11.458257] Finished iteration 88, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6281.019
START iteration 88, CKPT_AND_STOP: False
[2022-12-08 15:38:17.670273] Finished iteration 89, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6212.014
START iteration 89, CKPT_AND_STOP: False
[2022-12-08 15:38:23.988845] Finished iteration 90, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6318.572
START iteration 90, CKPT_AND_STOP: False
[2022-12-08 15:38:30.264370] Finished iteration 91, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6275.527
START iteration 91, CKPT_AND_STOP: False
[2022-12-08 15:38:36.526959] Finished iteration 92, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6262.585
START iteration 92, CKPT_AND_STOP: False
[2022-12-08 15:38:42.930399] Finished iteration 93, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6403.445
START iteration 93, CKPT_AND_STOP: False
[2022-12-08 15:38:49.446638] Finished iteration 94, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6516.238
START iteration 94, CKPT_AND_STOP: False
[2022-12-08 15:38:55.765463] Finished iteration 95, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6318.825
START iteration 95, CKPT_AND_STOP: False
[2022-12-08 15:39:02.031725] Finished iteration 96, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6266.262
START iteration 96, CKPT_AND_STOP: False
[2022-12-08 15:39:08.257364] Finished iteration 97, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6225.640
START iteration 97, CKPT_AND_STOP: False
[2022-12-08 15:39:14.478090] Finished iteration 98, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6220.726
START iteration 98, CKPT_AND_STOP: False
[2022-12-08 15:39:20.583121] Finished iteration 99, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6105.032
START iteration 99, CKPT_AND_STOP: False
[2022-12-08 15:39:26.742838] Finished iteration 100, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6159.716
START iteration 100, CKPT_AND_STOP: False
[2022-12-08 15:39:32.957163] Finished iteration 101, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6214.319
START iteration 101, CKPT_AND_STOP: False
[2022-12-08 15:39:38.987668] Finished iteration 102, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6030.510
START iteration 102, CKPT_AND_STOP: False
[2022-12-08 15:39:45.193500] Finished iteration 103, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6205.833
START iteration 103, CKPT_AND_STOP: False
[2022-12-08 15:39:51.399873] Finished iteration 104, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6206.370
START iteration 104, CKPT_AND_STOP: False
[2022-12-08 15:39:57.634880] Finished iteration 105, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6235.011
START iteration 105, CKPT_AND_STOP: False
[2022-12-08 15:40:03.887206] Finished iteration 106, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6252.325
START iteration 106, CKPT_AND_STOP: False
[2022-12-08 15:40:10.140684] Finished iteration 107, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6253.479
START iteration 107, CKPT_AND_STOP: False
[2022-12-08 15:40:16.396827] Finished iteration 108, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6256.143
START iteration 108, CKPT_AND_STOP: False
[2022-12-08 15:40:22.713453] Finished iteration 109, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6316.626
START iteration 109, CKPT_AND_STOP: False
[2022-12-08 15:40:29.206130] Finished iteration 110, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6492.677
START iteration 110, CKPT_AND_STOP: False
[2022-12-08 15:40:35.370470] Finished iteration 111, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6164.337
START iteration 111, CKPT_AND_STOP: False
[2022-12-08 15:40:41.614240] Finished iteration 112, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6243.752
START iteration 112, CKPT_AND_STOP: False
[2022-12-08 15:40:47.893329] Finished iteration 113, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6279.110
START iteration 113, CKPT_AND_STOP: False
[2022-12-08 15:40:54.169770] Finished iteration 114, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6276.441
START iteration 114, CKPT_AND_STOP: False
[2022-12-08 15:41:00.267291] Finished iteration 115, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6097.522
START iteration 115, CKPT_AND_STOP: False
[2022-12-08 15:41:06.808013] Finished iteration 116, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6540.717
START iteration 116, CKPT_AND_STOP: False
[2022-12-08 15:41:13.632735] Finished iteration 117, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6824.727
START iteration 117, CKPT_AND_STOP: False
[2022-12-08 15:41:20.755748] Finished iteration 118, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 7123.013
START iteration 118, CKPT_AND_STOP: False
[2022-12-08 15:41:27.095549] Finished iteration 119, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6339.798
START iteration 119, CKPT_AND_STOP: False
[2022-12-08 15:41:33.801081] Finished iteration 120, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6705.534
START iteration 120, CKPT_AND_STOP: False
[2022-12-08 15:41:40.060567] Finished iteration 121, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6259.487
START iteration 121, CKPT_AND_STOP: False
[2022-12-08 15:41:46.298007] Finished iteration 122, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6237.440
START iteration 122, CKPT_AND_STOP: False
[2022-12-08 15:41:52.435878] Finished iteration 123, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6137.872
START iteration 123, CKPT_AND_STOP: False
[2022-12-08 15:41:58.806934] Finished iteration 124, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6371.056
START iteration 124, CKPT_AND_STOP: False
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 6 signal handler called with signal 10
[2022-12-08 15:42:04.969056] Finished iteration 125, CKPT_AND_STOP: True, flag: tensor([7], dtype=torch.int32), speed: 6162.121
Begin to save checkpont and exit
Opt ckpt time 15.74012279510498
Process done with return code 0
Parent process ID: 19932 node: 172.31.23.137
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 25 0 1731851.1962890625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7585451
Min send: 10000000, max send 0
Min long send: 38055, max long send 64155
Min fwd: 45773, max fwd 59456; min bwd 92460, max bwd 103910
Min long fwd: 56519, max long fwd 64913; min long bwd 96930, max long bwd 104722
Time taken by simulation: 724 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 32 0 1199719.8486328125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6885286
Min send: 10000000, max send 0
Min long send: 38109, max long send 65217
Min fwd: 31551, max fwd 49103; min bwd 67585, max bwd 79482
Min long fwd: 42800, max long fwd 50971; min long bwd 74672, max long bwd 82652
Time taken by simulation: 1378 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 64 0 548680.6640625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8215819
Min send: 10000000, max send 0
Min long send: 38055, max long send 68059
Min fwd: 17630, max fwd 35943; min bwd 42061, max bwd 55179
Min long fwd: 28151, max long fwd 36355; min long bwd 50517, max long bwd 61082
Time taken by simulation: 4588 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 64 0 442992.24853515625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6489103
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 9901, max fwd 27419; min bwd 27605, max bwd 45180
Min long fwd: 21186, max long fwd 32479; min long bwd 41203, max long bwd 48557
Time taken by simulation: 6534 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8759578
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 5999, max fwd 22973; min bwd 17039, max bwd 34800
Min long fwd: 12470, max long fwd 25017; min long bwd 25566, max long bwd 36212
Time taken by simulation: 21433 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29691 microseconds

can't have 24 stages!
{1: inf, 2: inf, 3: 7.585451, 4: 6.885286, 6: 8.215819, 8: 6.489103, 12: 8.759578, 16: 7.580423}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1}
best config is: 8 1
expected time is 6.489103
2 per stage
16 servers!
Config:
ranks: range(6, 7)
train batch size: 128
partitions: 8
chunk_size: 1
data depth: 2
stage to rank map: 0,8;1,9;2,10;3,11;4,12;5,13;6,14;7,15;
World size is 16
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=6 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,8;1,9;2,10;3,11;4,12;5,13;6,14;7,15; --batch-size=64 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 125
dry run time 9.79308009147644
SHARED WEIGHTS ARE
[(0, 7)]
this rank  6 is part of pipeline replica  0
64 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
 > finished loading checkpoint in 44.432 seconds
START iteration 125, CKPT_AND_STOP: False
[2022-12-08 15:44:15.421841] Finished iteration 126, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 13655.032
START iteration 126, CKPT_AND_STOP: False
[2022-12-08 15:44:23.219103] Finished iteration 127, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 7797.295
START iteration 127, CKPT_AND_STOP: False
[2022-12-08 15:44:30.259734] Finished iteration 128, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 7040.633
START iteration 128, CKPT_AND_STOP: False
[2022-12-08 15:44:36.797925] Finished iteration 129, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6538.191
START iteration 129, CKPT_AND_STOP: False
[2022-12-08 15:44:43.213626] Finished iteration 130, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6415.701
START iteration 130, CKPT_AND_STOP: False
[2022-12-08 15:44:48.568646] Finished iteration 131, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5355.021
START iteration 131, CKPT_AND_STOP: False
[2022-12-08 15:44:54.650343] Finished iteration 132, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6081.697
START iteration 132, CKPT_AND_STOP: False
