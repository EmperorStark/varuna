Parent process ID: 9811 node: 172.31.21.45
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 12 0 2007202.880859375 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4913759
Min send: 10000000, max send 0
Min long send: 38387, max long send 60521
Min fwd: 45773, max fwd 58711; min bwd 92748, max bwd 103910
Min long fwd: 56704, max long fwd 63285; min long bwd 98353, max long bwd 106648
Time taken by simulation: 375 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 16 0 1727535.5224609375 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4820532
Min send: 10000000, max send 0
Min long send: 38109, max long send 64155
Min fwd: 32292, max fwd 48132; min bwd 69446, max bwd 80083
Min long fwd: 43192, max long fwd 50561; min long bwd 74672, max long bwd 80151
Time taken by simulation: 721 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 25 0 976051.4526367188 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4466988
Min send: 10000000, max send 0
Min long send: 38237, max long send 65217
Min fwd: 19236, max fwd 35580; min bwd 42158, max bwd 57089
Min long fwd: 24076, max long fwd 35713; min long bwd 50505, max long bwd 59414
Time taken by simulation: 1760 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 32 0 700971.3134765625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4198444
Min send: 10000000, max send 0
Min long send: 38109, max long send 68059
Min fwd: 11544, max fwd 27276; min bwd 28686, max bwd 44788
Min long fwd: 22228, max long fwd 29781; min long bwd 41714, max long bwd 48296
Time taken by simulation: 3178 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 64 0 343797.36328125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5360725
Min send: 10000000, max send 0
Min long send: 38056, max long send 68144
Min fwd: 5149, max fwd 20736; min bwd 17314, max bwd 33457
Min long fwd: 11639, max long fwd 22378; min long bwd 26559, max long bwd 34539
Time taken by simulation: 10482 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 64 0 294405.0598144531 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5043807
Min send: 10000000, max send 0
Min long send: 38109, max long send 77793
Min fwd: 803, max fwd 17174; min bwd 10907, max bwd 28118
Min long fwd: 12084, max long fwd 20913; min long bwd 17914, max long bwd 26363
Time taken by simulation: 14250 microseconds

Stages 24
Micro-bs 1 Max mem: 2949765734.4
Predicted microbatch size for 24: 1
comm size 1638400
WARNING: no send time found, 24 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 24 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6789982
Min send: 10000000, max send 0
Min long send: 38055, max long send 74455
Min fwd: 26, max fwd 15549; min bwd 3842, max bwd 20573
Min long fwd: 7764, max long fwd 18097; min long bwd 11316, max long bwd 21840
Time taken by simulation: 46462 microseconds

{1: inf, 2: inf, 3: 4.913759, 4: 4.820532, 6: 4.466988, 8: 4.198444, 12: 5.360725, 16: 5.043807, 24: 6.789982}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1, 24: 1}
best config is: 8 1
expected time is 4.198444
4 per stage
32 servers!
Config:
ranks: range(14, 15)
train batch size: 128
partitions: 8
chunk_size: 1
data depth: 4
stage to rank map: 0,8,16,24;1,9,17,25;2,10,18,26;3,11,19,27;4,12,20,28;5,13,21,29;6,14,22,30;7,15,23,31;
World size is 32
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=14 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,8,16,24;1,9,17,25;2,10,18,26;3,11,19,27;4,12,20,28;5,13,21,29;6,14,22,30;7,15,23,31; --batch-size=32 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16
dry run time 0.047579050064086914
SHARED WEIGHTS ARE
[(0, 7)]
this rank  14 is part of pipeline replica  1
32 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
 > finished loading checkpoint in 0.222 seconds
START iteration 0, CKPT_AND_STOP: False
[2022-12-05 12:21:27.123548] Finished iteration 1, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 11617.811
START iteration 1, CKPT_AND_STOP: False
[2022-12-05 12:21:31.804770] Finished iteration 2, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4681.253
START iteration 2, CKPT_AND_STOP: False
[2022-12-05 12:21:36.499589] Finished iteration 3, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4694.823
START iteration 3, CKPT_AND_STOP: False
[2022-12-05 12:21:41.147421] Finished iteration 4, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4647.828
START iteration 4, CKPT_AND_STOP: False
[2022-12-05 12:21:46.716875] Finished iteration 5, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5569.453
START iteration 5, CKPT_AND_STOP: False
[2022-12-05 12:21:50.355474] Finished iteration 6, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3638.605
START iteration 6, CKPT_AND_STOP: False
[2022-12-05 12:21:53.935276] Finished iteration 7, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3579.803
START iteration 7, CKPT_AND_STOP: False
[2022-12-05 12:21:57.452735] Finished iteration 8, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3517.459
START iteration 8, CKPT_AND_STOP: False
[2022-12-05 12:22:01.532624] Finished iteration 9, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4079.888
START iteration 9, CKPT_AND_STOP: False
[2022-12-05 12:22:05.661609] Finished iteration 10, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4128.985
START iteration 10, CKPT_AND_STOP: False
[2022-12-05 12:22:09.422974] Finished iteration 11, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3761.365
START iteration 11, CKPT_AND_STOP: False
[2022-12-05 12:22:13.081249] Finished iteration 12, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3658.276
START iteration 12, CKPT_AND_STOP: False
[2022-12-05 12:22:16.703481] Finished iteration 13, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3622.236
START iteration 13, CKPT_AND_STOP: False
[2022-12-05 12:22:21.283156] Finished iteration 14, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4579.671
START iteration 14, CKPT_AND_STOP: False
[2022-12-05 12:22:24.910525] Finished iteration 15, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3627.371
START iteration 15, CKPT_AND_STOP: False
[2022-12-05 12:22:28.508577] Finished iteration 16, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3598.049
START iteration 16, CKPT_AND_STOP: False
[2022-12-05 12:22:32.090722] Finished iteration 17, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3582.145
START iteration 17, CKPT_AND_STOP: False
[2022-12-05 12:22:35.695857] Finished iteration 18, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3605.134
START iteration 18, CKPT_AND_STOP: False
[2022-12-05 12:22:39.280753] Finished iteration 19, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3584.895
START iteration 19, CKPT_AND_STOP: False
[2022-12-05 12:22:42.851507] Finished iteration 20, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3570.754
START iteration 20, CKPT_AND_STOP: False
[2022-12-05 12:22:46.460644] Finished iteration 21, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3609.138
START iteration 21, CKPT_AND_STOP: False
[2022-12-05 12:22:50.012840] Finished iteration 22, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3552.197
START iteration 22, CKPT_AND_STOP: False
[2022-12-05 12:22:53.695613] Finished iteration 23, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3682.774
START iteration 23, CKPT_AND_STOP: False
[2022-12-05 12:22:57.277264] Finished iteration 24, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3581.649
START iteration 24, CKPT_AND_STOP: False
[2022-12-05 12:23:00.848970] Finished iteration 25, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3571.708
START iteration 25, CKPT_AND_STOP: False
[2022-12-05 12:23:04.443123] Finished iteration 26, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3594.152
START iteration 26, CKPT_AND_STOP: False
[2022-12-05 12:23:08.132611] Finished iteration 27, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3689.488
START iteration 27, CKPT_AND_STOP: False
[2022-12-05 12:23:11.686850] Finished iteration 28, CKPT_AND_STOP: False, flag: tensor([1], dtype=torch.int32), speed: 3554.238
Begin to save checkpont and exit
Opt ckpt time 3.616661310195923
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 14 signal handler called with signal 10
Process done with return code 0
Parent process ID: 10137 node: 172.31.19.112
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 14 0 2006653.3203125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5367030
Min send: 10000000, max send 0
Min long send: 38387, max long send 60521
Min fwd: 45773, max fwd 60689; min bwd 93028, max bwd 103910
Min long fwd: 57033, max long fwd 64913; min long bwd 98397, max long bwd 102857
Time taken by simulation: 426 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 18 0 1481951.2939453125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4877293
Min send: 10000000, max send 0
Min long send: 38055, max long send 64155
Min fwd: 32292, max fwd 48132; min bwd 69316, max bwd 77937
Min long fwd: 43561, max long fwd 51496; min long bwd 71918, max long bwd 80151
Time taken by simulation: 805 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 32 0 876895.5078125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5017062
Min send: 10000000, max send 0
Min long send: 38071, max long send 66276
Min fwd: 18837, max fwd 35859; min bwd 42514, max bwd 56347
Min long fwd: 27753, max long fwd 35222; min long bwd 51765, max long bwd 59571
Time taken by simulation: 2249 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 42 0 610855.46875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4799842
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 10665, max fwd 27276; min bwd 28791, max bwd 43945
Min long fwd: 21459, max long fwd 30507; min long bwd 38642, max long bwd 48142
Time taken by simulation: 4243 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 64 0 343797.36328125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5360725
Min send: 10000000, max send 0
Min long send: 38056, max long send 68144
Min fwd: 5149, max fwd 20736; min bwd 17314, max bwd 33457
Min long fwd: 11639, max long fwd 22378; min long bwd 26559, max long bwd 34539
Time taken by simulation: 10519 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29648 microseconds

Stages 24
Micro-bs 1 Max mem: 2949765734.4
Predicted microbatch size for 24: 1
comm size 1638400
WARNING: no send time found, 24 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 24 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6789982
Min send: 10000000, max send 0
Min long send: 38055, max long send 74455
Min fwd: 26, max fwd 15549; min bwd 3842, max bwd 20573
Min long fwd: 7764, max long fwd 18097; min long bwd 11316, max long bwd 21840
Time taken by simulation: 46000 microseconds

{1: inf, 2: inf, 3: 5.36703, 4: 4.877293, 6: 5.017062, 8: 4.799842, 12: 5.360725, 16: 7.580423, 24: 6.789982}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1, 24: 1}
best config is: 8 1
expected time is 4.799842
3 per stage
24 servers!
Config:
ranks: range(14, 15)
train batch size: 128
partitions: 8
chunk_size: 1
data depth: 3
stage to rank map: 0,8,16;1,9,17;2,10,18;3,11,19;4,12,20;5,13,21;6,14,22;7,15,23;
World size is 24
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=14 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,8,16;1,9,17;2,10,18;3,11,19;4,12,20;5,13,21;6,14,22;7,15,23; --batch-size=42 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 28
dry run time 0.8899116516113281
SHARED WEIGHTS ARE
[(0, 7)]
this rank  14 is part of pipeline replica  1
42 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
 > finished loading checkpoint in 43.346 seconds
Signal handler called with signal 10


 STOPPING VARUNA !!



Process done with return code -10
Parent process ID: 11152 node: 172.31.21.254
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 16 0 2198285.64453125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5986016
Min send: 10000000, max send 0
Min long send: 38293, max long send 60521
Min fwd: 45773, max fwd 59456; min bwd 93556, max bwd 103910
Min long fwd: 57033, max long fwd 64913; min long bwd 97741, max long bwd 104518
Time taken by simulation: 486 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 21 0 1478731.4453125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5493991
Min send: 10000000, max send 0
Min long send: 38109, max long send 64155
Min fwd: 32128, max fwd 48180; min bwd 67776, max bwd 77208
Min long fwd: 43175, max long fwd 51496; min long bwd 74514, max long bwd 81205
Time taken by simulation: 903 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 32 0 876895.5078125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5017062
Min send: 10000000, max send 0
Min long send: 38071, max long send 66276
Min fwd: 18837, max fwd 35859; min bwd 42514, max bwd 56347
Min long fwd: 27753, max long fwd 35222; min long bwd 51765, max long bwd 59571
Time taken by simulation: 2251 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 42 0 610855.46875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4799842
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 10665, max fwd 27276; min bwd 28791, max bwd 43945
Min long fwd: 21459, max long fwd 30507; min long bwd 38642, max long bwd 48142
Time taken by simulation: 4280 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 64 0 343797.36328125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5360725
Min send: 10000000, max send 0
Min long send: 38056, max long send 68144
Min fwd: 5149, max fwd 20736; min bwd 17314, max bwd 33457
Min long fwd: 11639, max long fwd 22378; min long bwd 26559, max long bwd 34539
Time taken by simulation: 10418 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29650 microseconds

Stages 24
Micro-bs 1 Max mem: 2949765734.4
Predicted microbatch size for 24: 1
comm size 1638400
WARNING: no send time found, 24 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 24 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6789982
Min send: 10000000, max send 0
Min long send: 38055, max long send 74455
Min fwd: 26, max fwd 15549; min bwd 3842, max bwd 20573
Min long fwd: 7764, max long fwd 18097; min long bwd 11316, max long bwd 21840
Time taken by simulation: 45969 microseconds

{1: inf, 2: inf, 3: 5.986016, 4: 5.493991, 6: 5.017062, 8: 4.799842, 12: 5.360725, 16: 7.580423, 24: 6.789982}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1, 24: 1}
best config is: 8 1
expected time is 4.799842
3 per stage
24 servers!
Config:
ranks: range(14, 15)
train batch size: 128
partitions: 8
chunk_size: 1
data depth: 3
stage to rank map: 0,8,16;1,9,17;2,10,18;3,11,19;4,12,20;5,13,21;6,14,22;7,15,23;
World size is 24
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=14 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,8,16;1,9,17;2,10,18;3,11,19;4,12,20;5,13,21;6,14,22;7,15,23; --batch-size=42 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 28
dry run time 1.264465093612671
SHARED WEIGHTS ARE
[(0, 7)]
this rank  14 is part of pipeline replica  1
42 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
 > finished loading checkpoint in 40.909 seconds
Process done with return code 0
Parent process ID: 11959 node: 172.31.24.191
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 16 0 2198285.64453125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5986016
Min send: 10000000, max send 0
Min long send: 38293, max long send 60521
Min fwd: 45773, max fwd 59456; min bwd 93556, max bwd 103910
Min long fwd: 57033, max long fwd 64913; min long bwd 97741, max long bwd 104518
Time taken by simulation: 484 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 21 0 1478731.4453125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5493991
Min send: 10000000, max send 0
Min long send: 38109, max long send 64155
Min fwd: 32128, max fwd 48180; min bwd 67776, max bwd 77208
Min long fwd: 43175, max long fwd 51496; min long bwd 74514, max long bwd 81205
Time taken by simulation: 939 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 32 0 876895.5078125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5017062
Min send: 10000000, max send 0
Min long send: 38071, max long send 66276
Min fwd: 18837, max fwd 35859; min bwd 42514, max bwd 56347
Min long fwd: 27753, max long fwd 35222; min long bwd 51765, max long bwd 59571
Time taken by simulation: 2241 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 42 0 610855.46875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4799842
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 10665, max fwd 27276; min bwd 28791, max bwd 43945
Min long fwd: 21459, max long fwd 30507; min long bwd 38642, max long bwd 48142
Time taken by simulation: 4306 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 64 0 343797.36328125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5360725
Min send: 10000000, max send 0
Min long send: 38056, max long send 68144
Min fwd: 5149, max fwd 20736; min bwd 17314, max bwd 33457
Min long fwd: 11639, max long fwd 22378; min long bwd 26559, max long bwd 34539
Time taken by simulation: 10427 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29640 microseconds

Stages 24
Micro-bs 1 Max mem: 2949765734.4
Predicted microbatch size for 24: 1
comm size 1638400
WARNING: no send time found, 24 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 24 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6789982
Min send: 10000000, max send 0
Min long send: 38055, max long send 74455
Min fwd: 26, max fwd 15549; min bwd 3842, max bwd 20573
Min long fwd: 7764, max long fwd 18097; min long bwd 11316, max long bwd 21840
Time taken by simulation: 45800 microseconds

{1: inf, 2: inf, 3: 5.986016, 4: 5.493991, 6: 5.017062, 8: 4.799842, 12: 5.360725, 16: 7.580423, 24: 6.789982}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1, 24: 1}
best config is: 8 1
expected time is 4.799842
3 per stage
24 servers!
Config:
ranks: range(14, 15)
train batch size: 128
partitions: 8
chunk_size: 1
data depth: 3
stage to rank map: 0,8,16;1,9,17;2,10,18;3,11,19;4,12,20;5,13,21;6,14,22;7,15,23;
World size is 24
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=14 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,8,16;1,9,17;2,10,18;3,11,19;4,12,20;5,13,21;6,14,22;7,15,23; --batch-size=42 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 28
dry run time 0.8139045238494873
SHARED WEIGHTS ARE
[(0, 7)]
this rank  14 is part of pipeline replica  1
42 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
 > finished loading checkpoint in 36.499 seconds
START iteration 28, CKPT_AND_STOP: False
[2022-12-05 12:29:19.256882] Finished iteration 29, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 12541.874
START iteration 29, CKPT_AND_STOP: False
[2022-12-05 12:29:24.332396] Finished iteration 30, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5075.532
START iteration 30, CKPT_AND_STOP: False
[2022-12-05 12:29:30.934720] Finished iteration 31, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6602.323
START iteration 31, CKPT_AND_STOP: False
[2022-12-05 12:29:36.119329] Finished iteration 32, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5184.609
START iteration 32, CKPT_AND_STOP: False
[2022-12-05 12:29:41.499437] Finished iteration 33, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5380.108
START iteration 33, CKPT_AND_STOP: False
[2022-12-05 12:29:45.601173] Finished iteration 34, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4101.737
START iteration 34, CKPT_AND_STOP: False
[2022-12-05 12:29:49.682358] Finished iteration 35, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4081.186
START iteration 35, CKPT_AND_STOP: False
[2022-12-05 12:29:53.833407] Finished iteration 36, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4151.049
START iteration 36, CKPT_AND_STOP: False
[2022-12-05 12:29:57.927879] Finished iteration 37, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4094.472
START iteration 37, CKPT_AND_STOP: False
[2022-12-05 12:30:01.995342] Finished iteration 38, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4067.463
START iteration 38, CKPT_AND_STOP: False
[2022-12-05 12:30:06.041889] Finished iteration 39, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4046.547
START iteration 39, CKPT_AND_STOP: False
[2022-12-05 12:30:10.120990] Finished iteration 40, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4079.100
START iteration 40, CKPT_AND_STOP: False
[2022-12-05 12:30:14.245993] Finished iteration 41, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4125.004
START iteration 41, CKPT_AND_STOP: False
[2022-12-05 12:30:18.361725] Finished iteration 42, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4115.732
START iteration 42, CKPT_AND_STOP: False
[2022-12-05 12:30:22.480559] Finished iteration 43, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4118.835
START iteration 43, CKPT_AND_STOP: False
[2022-12-05 12:30:26.521709] Finished iteration 44, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4041.150
START iteration 44, CKPT_AND_STOP: False
[2022-12-05 12:30:30.512492] Finished iteration 45, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3990.783
START iteration 45, CKPT_AND_STOP: False
[2022-12-05 12:30:34.597070] Finished iteration 46, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4084.578
START iteration 46, CKPT_AND_STOP: False
[2022-12-05 12:30:38.722932] Finished iteration 47, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4125.861
START iteration 47, CKPT_AND_STOP: False
[2022-12-05 12:30:42.949080] Finished iteration 48, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4226.148
START iteration 48, CKPT_AND_STOP: False
[2022-12-05 12:30:47.035563] Finished iteration 49, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4086.483
START iteration 49, CKPT_AND_STOP: False
[2022-12-05 12:30:51.066754] Finished iteration 50, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4031.191
START iteration 50, CKPT_AND_STOP: False
[2022-12-05 12:30:55.112738] Finished iteration 51, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4045.983
START iteration 51, CKPT_AND_STOP: False
[2022-12-05 12:30:59.187493] Finished iteration 52, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4074.756
START iteration 52, CKPT_AND_STOP: False
[2022-12-05 12:31:03.257216] Finished iteration 53, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4069.723
START iteration 53, CKPT_AND_STOP: False
[2022-12-05 12:31:07.277479] Finished iteration 54, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4020.263
START iteration 54, CKPT_AND_STOP: False
[2022-12-05 12:31:11.338766] Finished iteration 55, CKPT_AND_STOP: False, flag: tensor([1], dtype=torch.int32), speed: 4061.287
Begin to save checkpont and exit
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 14 signal handler called with signal 10
Opt ckpt time 9.433671236038208
Process done with return code 0
Parent process ID: 12934 node: 172.31.30.133
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 18 0 1846814.0869140625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5987018
Min send: 10000000, max send 0
Min long send: 38387, max long send 60521
Min fwd: 45773, max fwd 59834; min bwd 93871, max bwd 104244
Min long fwd: 57033, max long fwd 64913; min long bwd 98140, max long bwd 103204
Time taken by simulation: 538 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 25 0 1338646.484375 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5804683
Min send: 10000000, max send 0
Min long send: 38055, max long send 64155
Min fwd: 30866, max fwd 48132; min bwd 66753, max bwd 79482
Min long fwd: 43307, max long fwd 50971; min long bwd 73461, max long bwd 80147
Time taken by simulation: 1071 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 42 0 770127.8076171875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5988334
Min send: 10000000, max send 0
Min long send: 38055, max long send 68059
Min fwd: 18837, max fwd 35859; min bwd 42358, max bwd 55388
Min long fwd: 27768, max long fwd 35092; min long bwd 51025, max long bwd 59414
Time taken by simulation: 2946 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 64 0 442992.24853515625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6489103
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 9901, max fwd 27419; min bwd 27605, max bwd 45180
Min long fwd: 21186, max long fwd 32479; min long bwd 41203, max long bwd 48557
Time taken by simulation: 6473 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8759578
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 5999, max fwd 22973; min bwd 17039, max bwd 34800
Min long fwd: 12470, max long fwd 25017; min long bwd 25566, max long bwd 36212
Time taken by simulation: 21336 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29541 microseconds

can't have 24 stages!
{1: inf, 2: inf, 3: 5.987018, 4: 5.804683, 6: 5.988334, 8: 6.489103, 12: 8.759578, 16: 7.580423}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1}
best config is: 4 1
expected time is 5.804683
5 per stage
20 servers!
Config:
ranks: range(14, 15)
train batch size: 128
partitions: 4
chunk_size: 1
data depth: 5
stage to rank map: 0,4,8,12,16;1,5,9,13,17;2,6,10,14,18;3,7,11,15,19;
World size is 20
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=14 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,4,8,12,16;1,5,9,13,17;2,6,10,14,18;3,7,11,15,19; --batch-size=25 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 55
dry run time 1.2000648975372314
SHARED WEIGHTS ARE
[(0, 3)]
this rank  14 is part of pipeline replica  3
25 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 14 signal handler called with signal 10
 > finished loading checkpoint in 64.936 seconds
Process done with return code 0
Parent process ID: 13852 node: 172.31.23.137
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 18 0 1846814.0869140625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5987018
Min send: 10000000, max send 0
Min long send: 38387, max long send 60521
Min fwd: 45773, max fwd 59834; min bwd 93871, max bwd 104244
Min long fwd: 57033, max long fwd 64913; min long bwd 98140, max long bwd 103204
Time taken by simulation: 538 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 25 0 1338646.484375 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5804683
Min send: 10000000, max send 0
Min long send: 38055, max long send 64155
Min fwd: 30866, max fwd 48132; min bwd 66753, max bwd 79482
Min long fwd: 43307, max long fwd 50971; min long bwd 73461, max long bwd 80147
Time taken by simulation: 1063 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 42 0 770127.8076171875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5988334
Min send: 10000000, max send 0
Min long send: 38055, max long send 68059
Min fwd: 18837, max fwd 35859; min bwd 42358, max bwd 55388
Min long fwd: 27768, max long fwd 35092; min long bwd 51025, max long bwd 59414
Time taken by simulation: 2956 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 64 0 442992.24853515625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6489103
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 9901, max fwd 27419; min bwd 27605, max bwd 45180
Min long fwd: 21186, max long fwd 32479; min long bwd 41203, max long bwd 48557
Time taken by simulation: 6479 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8759578
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 5999, max fwd 22973; min bwd 17039, max bwd 34800
Min long fwd: 12470, max long fwd 25017; min long bwd 25566, max long bwd 36212
Time taken by simulation: 21573 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29691 microseconds

can't have 24 stages!
{1: inf, 2: inf, 3: 5.987018, 4: 5.804683, 6: 5.988334, 8: 6.489103, 12: 8.759578, 16: 7.580423}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1}
best config is: 4 1
expected time is 5.804683
5 per stage
20 servers!
Config:
ranks: range(14, 15)
train batch size: 128
partitions: 4
chunk_size: 1
data depth: 5
stage to rank map: 0,4,8,12,16;1,5,9,13,17;2,6,10,14,18;3,7,11,15,19;
World size is 20
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=14 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,4,8,12,16;1,5,9,13,17;2,6,10,14,18;3,7,11,15,19; --batch-size=25 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 55
dry run time 0.876518964767456
SHARED WEIGHTS ARE
[(0, 3)]
this rank  14 is part of pipeline replica  3
25 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
 > finished loading checkpoint in 82.526 seconds
START iteration 55, CKPT_AND_STOP: False
[2022-12-05 12:36:16.791681] Finished iteration 56, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 9406.529
START iteration 56, CKPT_AND_STOP: False
[2022-12-05 12:36:22.858372] Finished iteration 57, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6066.726
START iteration 57, CKPT_AND_STOP: False
[2022-12-05 12:36:28.817999] Finished iteration 58, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5959.631
START iteration 58, CKPT_AND_STOP: False
[2022-12-05 12:36:34.853578] Finished iteration 59, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6035.578
START iteration 59, CKPT_AND_STOP: False
[2022-12-05 12:36:40.795155] Finished iteration 60, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5941.575
START iteration 60, CKPT_AND_STOP: False
[2022-12-05 12:36:45.726675] Finished iteration 61, CKPT_AND_STOP: False, flag: tensor([6], dtype=torch.int32), speed: 4931.523
Begin to save checkpont and exit
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 14 signal handler called with signal 10
Opt ckpt time 10.940637826919556
Process done with return code 0
Parent process ID: 14969 node: 172.31.23.137
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 16 0 2198285.64453125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5986016
Min send: 10000000, max send 0
Min long send: 38293, max long send 60521
Min fwd: 45773, max fwd 59456; min bwd 93556, max bwd 103910
Min long fwd: 57033, max long fwd 64913; min long bwd 97741, max long bwd 104518
Time taken by simulation: 480 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 21 0 1478731.4453125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5493991
Min send: 10000000, max send 0
Min long send: 38109, max long send 64155
Min fwd: 32128, max fwd 48180; min bwd 67776, max bwd 77208
Min long fwd: 43175, max long fwd 51496; min long bwd 74514, max long bwd 81205
Time taken by simulation: 929 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 32 0 876895.5078125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5017062
Min send: 10000000, max send 0
Min long send: 38071, max long send 66276
Min fwd: 18837, max fwd 35859; min bwd 42514, max bwd 56347
Min long fwd: 27753, max long fwd 35222; min long bwd 51765, max long bwd 59571
Time taken by simulation: 2251 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 42 0 610855.46875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4799842
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 10665, max fwd 27276; min bwd 28791, max bwd 43945
Min long fwd: 21459, max long fwd 30507; min long bwd 38642, max long bwd 48142
Time taken by simulation: 4218 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 64 0 343797.36328125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5360725
Min send: 10000000, max send 0
Min long send: 38056, max long send 68144
Min fwd: 5149, max fwd 20736; min bwd 17314, max bwd 33457
Min long fwd: 11639, max long fwd 22378; min long bwd 26559, max long bwd 34539
Time taken by simulation: 10417 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29617 microseconds

Stages 24
Micro-bs 1 Max mem: 2949765734.4
Predicted microbatch size for 24: 1
comm size 1638400
WARNING: no send time found, 24 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 24 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6789982
Min send: 10000000, max send 0
Min long send: 38055, max long send 74455
Min fwd: 26, max fwd 15549; min bwd 3842, max bwd 20573
Min long fwd: 7764, max long fwd 18097; min long bwd 11316, max long bwd 21840
Time taken by simulation: 45786 microseconds

{1: inf, 2: inf, 3: 5.986016, 4: 5.493991, 6: 5.017062, 8: 4.799842, 12: 5.360725, 16: 7.580423, 24: 6.789982}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1, 24: 1}
best config is: 8 1
expected time is 4.799842
3 per stage
24 servers!
Config:
ranks: range(14, 15)
train batch size: 128
partitions: 8
chunk_size: 1
data depth: 3
stage to rank map: 0,8,16;1,9,17;2,10,18;3,11,19;4,12,20;5,13,21;6,14,22;7,15,23;
World size is 24
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=14 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,8,16;1,9,17;2,10,18;3,11,19;4,12,20;5,13,21;6,14,22;7,15,23; --batch-size=42 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 61
dry run time 0.8439288139343262
SHARED WEIGHTS ARE
[(0, 7)]
this rank  14 is part of pipeline replica  1
42 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 14 signal handler called with signal 10
 > finished loading checkpoint in 38.535 seconds
Process done with return code 0
Parent process ID: 15784 node: 172.31.23.137
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 16 0 2198285.64453125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5986016
Min send: 10000000, max send 0
Min long send: 38293, max long send 60521
Min fwd: 45773, max fwd 59456; min bwd 93556, max bwd 103910
Min long fwd: 57033, max long fwd 64913; min long bwd 97741, max long bwd 104518
Time taken by simulation: 481 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 21 0 1478731.4453125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5493991
Min send: 10000000, max send 0
Min long send: 38109, max long send 64155
Min fwd: 32128, max fwd 48180; min bwd 67776, max bwd 77208
Min long fwd: 43175, max long fwd 51496; min long bwd 74514, max long bwd 81205
Time taken by simulation: 897 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 32 0 876895.5078125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5017062
Min send: 10000000, max send 0
Min long send: 38071, max long send 66276
Min fwd: 18837, max fwd 35859; min bwd 42514, max bwd 56347
Min long fwd: 27753, max long fwd 35222; min long bwd 51765, max long bwd 59571
Time taken by simulation: 2288 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 42 0 610855.46875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4799842
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 10665, max fwd 27276; min bwd 28791, max bwd 43945
Min long fwd: 21459, max long fwd 30507; min long bwd 38642, max long bwd 48142
Time taken by simulation: 4230 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 64 0 343797.36328125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5360725
Min send: 10000000, max send 0
Min long send: 38056, max long send 68144
Min fwd: 5149, max fwd 20736; min bwd 17314, max bwd 33457
Min long fwd: 11639, max long fwd 22378; min long bwd 26559, max long bwd 34539
Time taken by simulation: 10377 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29675 microseconds

Stages 24
Micro-bs 1 Max mem: 2949765734.4
Predicted microbatch size for 24: 1
comm size 1638400
WARNING: no send time found, 24 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 24 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6789982
Min send: 10000000, max send 0
Min long send: 38055, max long send 74455
Min fwd: 26, max fwd 15549; min bwd 3842, max bwd 20573
Min long fwd: 7764, max long fwd 18097; min long bwd 11316, max long bwd 21840
Time taken by simulation: 45920 microseconds

{1: inf, 2: inf, 3: 5.986016, 4: 5.493991, 6: 5.017062, 8: 4.799842, 12: 5.360725, 16: 7.580423, 24: 6.789982}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1, 24: 1}
best config is: 8 1
expected time is 4.799842
3 per stage
24 servers!
Config:
ranks: range(14, 15)
train batch size: 128
partitions: 8
chunk_size: 1
data depth: 3
stage to rank map: 0,8,16;1,9,17;2,10,18;3,11,19;4,12,20;5,13,21;6,14,22;7,15,23;
World size is 24
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=14 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,8,16;1,9,17;2,10,18;3,11,19;4,12,20;5,13,21;6,14,22;7,15,23; --batch-size=42 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 61
dry run time 0.9533662796020508
SHARED WEIGHTS ARE
[(0, 7)]
this rank  14 is part of pipeline replica  1
42 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 14 signal handler called with signal 10
 > finished loading checkpoint in 35.902 seconds
Process done with return code 0
Parent process ID: 16230 node: 172.31.29.147
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 18 0 1846814.0869140625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5987018
Min send: 10000000, max send 0
Min long send: 38387, max long send 60521
Min fwd: 45773, max fwd 59834; min bwd 93871, max bwd 104244
Min long fwd: 57033, max long fwd 64913; min long bwd 98140, max long bwd 103204
Time taken by simulation: 538 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 25 0 1338646.484375 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5804683
Min send: 10000000, max send 0
Min long send: 38055, max long send 64155
Min fwd: 30866, max fwd 48132; min bwd 66753, max bwd 79482
Min long fwd: 43307, max long fwd 50971; min long bwd 73461, max long bwd 80147
Time taken by simulation: 1095 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 42 0 770127.8076171875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5988334
Min send: 10000000, max send 0
Min long send: 38055, max long send 68059
Min fwd: 18837, max fwd 35859; min bwd 42358, max bwd 55388
Min long fwd: 27768, max long fwd 35092; min long bwd 51025, max long bwd 59414
Time taken by simulation: 3030 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 64 0 442992.24853515625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6489103
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 9901, max fwd 27419; min bwd 27605, max bwd 45180
Min long fwd: 21186, max long fwd 32479; min long bwd 41203, max long bwd 48557
Time taken by simulation: 6615 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8759578
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 5999, max fwd 22973; min bwd 17039, max bwd 34800
Min long fwd: 12470, max long fwd 25017; min long bwd 25566, max long bwd 36212
Time taken by simulation: 21603 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29935 microseconds

can't have 24 stages!
{1: inf, 2: inf, 3: 5.987018, 4: 5.804683, 6: 5.988334, 8: 6.489103, 12: 8.759578, 16: 7.580423}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1}
best config is: 4 1
expected time is 5.804683
5 per stage
20 servers!
Config:
ranks: range(14, 15)
train batch size: 128
partitions: 4
chunk_size: 1
data depth: 5
stage to rank map: 0,4,8,12,16;1,5,9,13,17;2,6,10,14,18;3,7,11,15,19;
World size is 20
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=14 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,4,8,12,16;1,5,9,13,17;2,6,10,14,18;3,7,11,15,19; --batch-size=25 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 61
dry run time 0.1344010829925537
SHARED WEIGHTS ARE
[(0, 3)]
this rank  14 is part of pipeline replica  3
25 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 14 signal handler called with signal 10
Process done with return code 1
Parent process ID: 16687 node: 172.31.27.21
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 21 0 1916562.744140625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6803052
Min send: 10000000, max send 0
Min long send: 38109, max long send 62549
Min fwd: 45773, max fwd 59456; min bwd 92874, max bwd 103910
Min long fwd: 57033, max long fwd 64913; min long bwd 96930, max long bwd 106927
Time taken by simulation: 613 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 25 0 1338646.484375 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5804683
Min send: 10000000, max send 0
Min long send: 38055, max long send 64155
Min fwd: 30866, max fwd 48132; min bwd 66753, max bwd 79482
Min long fwd: 43307, max long fwd 50971; min long bwd 73461, max long bwd 80147
Time taken by simulation: 1063 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 42 0 770127.8076171875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5988334
Min send: 10000000, max send 0
Min long send: 38055, max long send 68059
Min fwd: 18837, max fwd 35859; min bwd 42358, max bwd 55388
Min long fwd: 27768, max long fwd 35092; min long bwd 51025, max long bwd 59414
Time taken by simulation: 2996 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 64 0 442992.24853515625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6489103
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 9901, max fwd 27419; min bwd 27605, max bwd 45180
Min long fwd: 21186, max long fwd 32479; min long bwd 41203, max long bwd 48557
Time taken by simulation: 6537 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8759578
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 5999, max fwd 22973; min bwd 17039, max bwd 34800
Min long fwd: 12470, max long fwd 25017; min long bwd 25566, max long bwd 36212
Time taken by simulation: 21349 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29658 microseconds

can't have 24 stages!
{1: inf, 2: inf, 3: 6.803052, 4: 5.804683, 6: 5.988334, 8: 6.489103, 12: 8.759578, 16: 7.580423}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1}
best config is: 4 1
expected time is 5.804683
5 per stage
20 servers!
Config:
ranks: range(14, 15)
train batch size: 128
partitions: 4
chunk_size: 1
data depth: 5
stage to rank map: 0,4,8,12,16;1,5,9,13,17;2,6,10,14,18;3,7,11,15,19;
World size is 20
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=14 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,4,8,12,16;1,5,9,13,17;2,6,10,14,18;3,7,11,15,19; --batch-size=25 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 61
dry run time 1.6492700576782227
SHARED WEIGHTS ARE
[(0, 3)]
this rank  14 is part of pipeline replica  3
25 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 14 signal handler called with signal 10
 > finished loading checkpoint in 68.025 seconds
Process done with return code 0
Parent process ID: 17903 node: 172.31.27.21
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 18 0 1846814.0869140625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5987018
Min send: 10000000, max send 0
Min long send: 38387, max long send 60521
Min fwd: 45773, max fwd 59834; min bwd 93871, max bwd 104244
Min long fwd: 57033, max long fwd 64913; min long bwd 98140, max long bwd 103204
Time taken by simulation: 536 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 25 0 1338646.484375 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5804683
Min send: 10000000, max send 0
Min long send: 38055, max long send 64155
Min fwd: 30866, max fwd 48132; min bwd 66753, max bwd 79482
Min long fwd: 43307, max long fwd 50971; min long bwd 73461, max long bwd 80147
Time taken by simulation: 1068 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 42 0 770127.8076171875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5988334
Min send: 10000000, max send 0
Min long send: 38055, max long send 68059
Min fwd: 18837, max fwd 35859; min bwd 42358, max bwd 55388
Min long fwd: 27768, max long fwd 35092; min long bwd 51025, max long bwd 59414
Time taken by simulation: 2945 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 64 0 442992.24853515625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6489103
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 9901, max fwd 27419; min bwd 27605, max bwd 45180
Min long fwd: 21186, max long fwd 32479; min long bwd 41203, max long bwd 48557
Time taken by simulation: 6506 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8759578
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 5999, max fwd 22973; min bwd 17039, max bwd 34800
Min long fwd: 12470, max long fwd 25017; min long bwd 25566, max long bwd 36212
Time taken by simulation: 21307 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29632 microseconds

can't have 24 stages!
{1: inf, 2: inf, 3: 5.987018, 4: 5.804683, 6: 5.988334, 8: 6.489103, 12: 8.759578, 16: 7.580423}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1}
best config is: 4 1
expected time is 5.804683
5 per stage
20 servers!
Config:
ranks: range(14, 15)
train batch size: 128
partitions: 4
chunk_size: 1
data depth: 5
stage to rank map: 0,4,8,12,16;1,5,9,13,17;2,6,10,14,18;3,7,11,15,19;
World size is 20
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=14 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,4,8,12,16;1,5,9,13,17;2,6,10,14,18;3,7,11,15,19; --batch-size=25 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 61
dry run time 1.005122423171997
SHARED WEIGHTS ARE
[(0, 3)]
this rank  14 is part of pipeline replica  3
25 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
 > finished loading checkpoint in 86.318 seconds
START iteration 61, CKPT_AND_STOP: False
[2022-12-05 12:46:02.444802] Finished iteration 62, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 9485.087
START iteration 62, CKPT_AND_STOP: False
[2022-12-05 12:46:08.356248] Finished iteration 63, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5911.457
START iteration 63, CKPT_AND_STOP: False
[2022-12-05 12:46:14.251945] Finished iteration 64, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5895.696
START iteration 64, CKPT_AND_STOP: False
[2022-12-05 12:46:20.172060] Finished iteration 65, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5920.115
START iteration 65, CKPT_AND_STOP: False
[2022-12-05 12:46:26.124520] Finished iteration 66, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5952.461
START iteration 66, CKPT_AND_STOP: False
[2022-12-05 12:46:30.988838] Finished iteration 67, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4864.317
START iteration 67, CKPT_AND_STOP: False
[2022-12-05 12:46:35.865695] Finished iteration 68, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4876.858
START iteration 68, CKPT_AND_STOP: False
[2022-12-05 12:46:40.806474] Finished iteration 69, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4940.779
START iteration 69, CKPT_AND_STOP: False
[2022-12-05 12:46:45.687614] Finished iteration 70, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4881.141
START iteration 70, CKPT_AND_STOP: False
[2022-12-05 12:46:50.673342] Finished iteration 71, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4985.728
START iteration 71, CKPT_AND_STOP: False
[2022-12-05 12:46:55.649920] Finished iteration 72, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4976.578
START iteration 72, CKPT_AND_STOP: False
[2022-12-05 12:47:00.526847] Finished iteration 73, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4876.927
START iteration 73, CKPT_AND_STOP: False
[2022-12-05 12:47:05.484060] Finished iteration 74, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4957.214
START iteration 74, CKPT_AND_STOP: False
[2022-12-05 12:47:10.421224] Finished iteration 75, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4937.163
START iteration 75, CKPT_AND_STOP: False
[2022-12-05 12:47:15.283036] Finished iteration 76, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4861.813
START iteration 76, CKPT_AND_STOP: False
[2022-12-05 12:47:20.142779] Finished iteration 77, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4859.743
START iteration 77, CKPT_AND_STOP: False
[2022-12-05 12:47:25.089363] Finished iteration 78, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4946.582
START iteration 78, CKPT_AND_STOP: False
[2022-12-05 12:47:29.936869] Finished iteration 79, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4847.506
START iteration 79, CKPT_AND_STOP: False
[2022-12-05 12:47:34.835559] Finished iteration 80, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4898.692
START iteration 80, CKPT_AND_STOP: False
[2022-12-05 12:47:39.742074] Finished iteration 81, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4906.515
START iteration 81, CKPT_AND_STOP: False
[2022-12-05 12:47:44.669492] Finished iteration 82, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4927.418
START iteration 82, CKPT_AND_STOP: False
[2022-12-05 12:47:49.596652] Finished iteration 83, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4927.161
START iteration 83, CKPT_AND_STOP: False
[2022-12-05 12:47:54.445524] Finished iteration 84, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4848.869
START iteration 84, CKPT_AND_STOP: False
[2022-12-05 12:47:59.353822] Finished iteration 85, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4908.300
START iteration 85, CKPT_AND_STOP: False
[2022-12-05 12:48:04.233302] Finished iteration 86, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4879.480
START iteration 86, CKPT_AND_STOP: False
[2022-12-05 12:48:09.137120] Finished iteration 87, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4903.818
START iteration 87, CKPT_AND_STOP: False
[2022-12-05 12:48:14.073128] Finished iteration 88, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4936.009
START iteration 88, CKPT_AND_STOP: False
[2022-12-05 12:48:19.064599] Finished iteration 89, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4991.467
START iteration 89, CKPT_AND_STOP: False
[2022-12-05 12:48:23.968819] Finished iteration 90, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4904.223
START iteration 90, CKPT_AND_STOP: False
[2022-12-05 12:48:28.868549] Finished iteration 91, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4899.730
START iteration 91, CKPT_AND_STOP: False
[2022-12-05 12:48:33.859844] Finished iteration 92, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4991.294
START iteration 92, CKPT_AND_STOP: False
[2022-12-05 12:48:38.753037] Finished iteration 93, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4893.193
START iteration 93, CKPT_AND_STOP: False
[2022-12-05 12:48:43.608235] Finished iteration 94, CKPT_AND_STOP: False, flag: tensor([3], dtype=torch.int32), speed: 4855.198
Begin to save checkpont and exit
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 14 signal handler called with signal 10
Opt ckpt time 11.878629922866821
Process done with return code 0
Parent process ID: 19266 node: 172.31.27.21
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 18 0 1846814.0869140625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5987018
Min send: 10000000, max send 0
Min long send: 38387, max long send 60521
Min fwd: 45773, max fwd 59834; min bwd 93871, max bwd 104244
Min long fwd: 57033, max long fwd 64913; min long bwd 98140, max long bwd 103204
Time taken by simulation: 544 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 25 0 1338646.484375 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5804683
Min send: 10000000, max send 0
Min long send: 38055, max long send 64155
Min fwd: 30866, max fwd 48132; min bwd 66753, max bwd 79482
Min long fwd: 43307, max long fwd 50971; min long bwd 73461, max long bwd 80147
Time taken by simulation: 1064 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 42 0 770127.8076171875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5988334
Min send: 10000000, max send 0
Min long send: 38055, max long send 68059
Min fwd: 18837, max fwd 35859; min bwd 42358, max bwd 55388
Min long fwd: 27768, max long fwd 35092; min long bwd 51025, max long bwd 59414
Time taken by simulation: 3014 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 64 0 442992.24853515625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6489103
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 9901, max fwd 27419; min bwd 27605, max bwd 45180
Min long fwd: 21186, max long fwd 32479; min long bwd 41203, max long bwd 48557
Time taken by simulation: 6500 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8759578
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 5999, max fwd 22973; min bwd 17039, max bwd 34800
Min long fwd: 12470, max long fwd 25017; min long bwd 25566, max long bwd 36212
Time taken by simulation: 21337 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29628 microseconds

can't have 24 stages!
{1: inf, 2: inf, 3: 5.987018, 4: 5.804683, 6: 5.988334, 8: 6.489103, 12: 8.759578, 16: 7.580423}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1}
best config is: 4 1
expected time is 5.804683
5 per stage
20 servers!
Config:
ranks: range(14, 15)
train batch size: 128
partitions: 4
chunk_size: 1
data depth: 5
stage to rank map: 0,4,8,12,16;1,5,9,13,17;2,6,10,14,18;3,7,11,15,19;
World size is 20
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=14 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,4,8,12,16;1,5,9,13,17;2,6,10,14,18;3,7,11,15,19; --batch-size=25 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 94
dry run time 1.1768553256988525
SHARED WEIGHTS ARE
[(0, 3)]
this rank  14 is part of pipeline replica  3
25 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
 > finished loading checkpoint in 70.747 seconds
START iteration 94, CKPT_AND_STOP: False
[2022-12-05 12:51:01.025484] Finished iteration 95, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 9615.576
START iteration 95, CKPT_AND_STOP: False
[2022-12-05 12:51:07.011748] Finished iteration 96, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5986.281
START iteration 96, CKPT_AND_STOP: False
[2022-12-05 12:51:12.954760] Finished iteration 97, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5943.010
START iteration 97, CKPT_AND_STOP: False
[2022-12-05 12:51:18.936685] Finished iteration 98, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5981.928
START iteration 98, CKPT_AND_STOP: False
[2022-12-05 12:51:24.750128] Finished iteration 99, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5813.440
START iteration 99, CKPT_AND_STOP: False
[2022-12-05 12:51:29.624090] Finished iteration 100, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4873.964
START iteration 100, CKPT_AND_STOP: False
[2022-12-05 12:51:34.465550] Finished iteration 101, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4841.459
START iteration 101, CKPT_AND_STOP: False
[2022-12-05 12:51:39.345043] Finished iteration 102, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4879.494
START iteration 102, CKPT_AND_STOP: False
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  65536.0
[2022-12-05 12:51:44.173151] Finished iteration 103, CKPT_AND_STOP: False, flag: tensor([3], dtype=torch.int32), speed: 4828.109
Begin to save checkpont and exit
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 14 signal handler called with signal 10
Opt ckpt time 11.939125776290894
Process done with return code 0
Parent process ID: 20528 node: 172.31.27.21
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 12 0 2007202.880859375 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4913759
Min send: 10000000, max send 0
Min long send: 38387, max long send 60521
Min fwd: 45773, max fwd 58711; min bwd 92748, max bwd 103910
Min long fwd: 56704, max long fwd 63285; min long bwd 98353, max long bwd 106648
Time taken by simulation: 377 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 18 0 1481951.2939453125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4877293
Min send: 10000000, max send 0
Min long send: 38055, max long send 64155
Min fwd: 32292, max fwd 48132; min bwd 69316, max bwd 77937
Min long fwd: 43561, max long fwd 51496; min long bwd 71918, max long bwd 80151
Time taken by simulation: 778 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 25 0 976051.4526367188 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4466988
Min send: 10000000, max send 0
Min long send: 38237, max long send 65217
Min fwd: 19236, max fwd 35580; min bwd 42158, max bwd 57089
Min long fwd: 24076, max long fwd 35713; min long bwd 50505, max long bwd 59414
Time taken by simulation: 1786 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 42 0 610855.46875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4799842
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 10665, max fwd 27276; min bwd 28791, max bwd 43945
Min long fwd: 21459, max long fwd 30507; min long bwd 38642, max long bwd 48142
Time taken by simulation: 4279 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 64 0 343797.36328125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5360725
Min send: 10000000, max send 0
Min long send: 38056, max long send 68144
Min fwd: 5149, max fwd 20736; min bwd 17314, max bwd 33457
Min long fwd: 11639, max long fwd 22378; min long bwd 26559, max long bwd 34539
Time taken by simulation: 10396 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29601 microseconds

Stages 24
Micro-bs 1 Max mem: 2949765734.4
Predicted microbatch size for 24: 1
comm size 1638400
WARNING: no send time found, 24 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 24 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6789982
Min send: 10000000, max send 0
Min long send: 38055, max long send 74455
Min fwd: 26, max fwd 15549; min bwd 3842, max bwd 20573
Min long fwd: 7764, max long fwd 18097; min long bwd 11316, max long bwd 21840
Time taken by simulation: 45784 microseconds

{1: inf, 2: inf, 3: 4.913759, 4: 4.877293, 6: 4.466988, 8: 4.799842, 12: 5.360725, 16: 7.580423, 24: 6.789982}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1, 24: 1}
best config is: 6 1
expected time is 4.466988
5 per stage
30 servers!
Config:
ranks: range(14, 15)
train batch size: 128
partitions: 6
chunk_size: 1
data depth: 5
stage to rank map: 0,6,12,18,24;1,7,13,19,25;2,8,14,20,26;3,9,15,21,27;4,10,16,22,28;5,11,17,23,29;
World size is 30
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=14 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,6,12,18,24;1,7,13,19,25;2,8,14,20,26;3,9,15,21,27;4,10,16,22,28;5,11,17,23,29; --batch-size=25 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 103
dry run time 1.0511360168457031
SHARED WEIGHTS ARE
[(0, 5)]
this rank  14 is part of pipeline replica  2
25 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 14 signal handler called with signal 10
 > finished loading checkpoint in 50.439 seconds
Process done with return code 0
Parent process ID: 21478 node: 172.31.27.21
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 12 0 2007202.880859375 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4913759
Min send: 10000000, max send 0
Min long send: 38387, max long send 60521
Min fwd: 45773, max fwd 58711; min bwd 92748, max bwd 103910
Min long fwd: 56704, max long fwd 63285; min long bwd 98353, max long bwd 106648
Time taken by simulation: 370 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 16 0 1727535.5224609375 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4820532
Min send: 10000000, max send 0
Min long send: 38109, max long send 64155
Min fwd: 32292, max fwd 48132; min bwd 69446, max bwd 80083
Min long fwd: 43192, max long fwd 50561; min long bwd 74672, max long bwd 80151
Time taken by simulation: 690 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 25 0 976051.4526367188 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4466988
Min send: 10000000, max send 0
Min long send: 38237, max long send 65217
Min fwd: 19236, max fwd 35580; min bwd 42158, max bwd 57089
Min long fwd: 24076, max long fwd 35713; min long bwd 50505, max long bwd 59414
Time taken by simulation: 1750 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 32 0 700971.3134765625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4198444
Min send: 10000000, max send 0
Min long send: 38109, max long send 68059
Min fwd: 11544, max fwd 27276; min bwd 28686, max bwd 44788
Min long fwd: 22228, max long fwd 29781; min long bwd 41714, max long bwd 48296
Time taken by simulation: 3199 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 64 0 343797.36328125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5360725
Min send: 10000000, max send 0
Min long send: 38056, max long send 68144
Min fwd: 5149, max fwd 20736; min bwd 17314, max bwd 33457
Min long fwd: 11639, max long fwd 22378; min long bwd 26559, max long bwd 34539
Time taken by simulation: 10372 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 64 0 294405.0598144531 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5043807
Min send: 10000000, max send 0
Min long send: 38109, max long send 77793
Min fwd: 803, max fwd 17174; min bwd 10907, max bwd 28118
Min long fwd: 12084, max long fwd 20913; min long bwd 17914, max long bwd 26363
Time taken by simulation: 14159 microseconds

Stages 24
Micro-bs 1 Max mem: 2949765734.4
Predicted microbatch size for 24: 1
comm size 1638400
WARNING: no send time found, 24 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 24 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6789982
Min send: 10000000, max send 0
Min long send: 38055, max long send 74455
Min fwd: 26, max fwd 15549; min bwd 3842, max bwd 20573
Min long fwd: 7764, max long fwd 18097; min long bwd 11316, max long bwd 21840
Time taken by simulation: 45898 microseconds

{1: inf, 2: inf, 3: 4.913759, 4: 4.820532, 6: 4.466988, 8: 4.198444, 12: 5.360725, 16: 5.043807, 24: 6.789982}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1, 24: 1}
best config is: 8 1
expected time is 4.198444
4 per stage
32 servers!
Config:
ranks: range(14, 15)
train batch size: 128
partitions: 8
chunk_size: 1
data depth: 4
stage to rank map: 0,8,16,24;1,9,17,25;2,10,18,26;3,11,19,27;4,12,20,28;5,13,21,29;6,14,22,30;7,15,23,31;
World size is 32
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=14 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,8,16,24;1,9,17,25;2,10,18,26;3,11,19,27;4,12,20,28;5,13,21,29;6,14,22,30;7,15,23,31; --batch-size=32 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 103
dry run time 1.015685796737671
SHARED WEIGHTS ARE
[(0, 7)]
this rank  14 is part of pipeline replica  1
32 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
 > finished loading checkpoint in 43.972 seconds
START iteration 103, CKPT_AND_STOP: False
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  65536.0
[2022-12-05 12:55:05.370532] Finished iteration 104, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 11978.300
START iteration 104, CKPT_AND_STOP: False
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  32768.0
[2022-12-05 12:55:10.046907] Finished iteration 105, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4676.392
START iteration 105, CKPT_AND_STOP: False
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  16384.0
[2022-12-05 12:55:14.676749] Finished iteration 106, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4629.841
START iteration 106, CKPT_AND_STOP: False
[2022-12-05 12:55:19.346244] Finished iteration 107, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4669.496
START iteration 107, CKPT_AND_STOP: False
[2022-12-05 12:55:24.011086] Finished iteration 108, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4664.843
START iteration 108, CKPT_AND_STOP: False
[2022-12-05 12:55:27.601228] Finished iteration 109, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3590.142
START iteration 109, CKPT_AND_STOP: False
[2022-12-05 12:55:31.225249] Finished iteration 110, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3624.022
START iteration 110, CKPT_AND_STOP: False
[2022-12-05 12:55:34.782151] Finished iteration 111, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3556.901
START iteration 111, CKPT_AND_STOP: False
[2022-12-05 12:55:38.396431] Finished iteration 112, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3614.279
START iteration 112, CKPT_AND_STOP: False
[2022-12-05 12:55:42.082891] Finished iteration 113, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3686.462
START iteration 113, CKPT_AND_STOP: False
[2022-12-05 12:55:45.644008] Finished iteration 114, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3561.116
START iteration 114, CKPT_AND_STOP: False
[2022-12-05 12:55:49.211918] Finished iteration 115, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3567.908
START iteration 115, CKPT_AND_STOP: False
[2022-12-05 12:55:52.777892] Finished iteration 116, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3565.977
START iteration 116, CKPT_AND_STOP: False
[2022-12-05 12:55:56.360740] Finished iteration 117, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3582.846
START iteration 117, CKPT_AND_STOP: False
[2022-12-05 12:55:59.966971] Finished iteration 118, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3606.234
START iteration 118, CKPT_AND_STOP: False
[2022-12-05 12:56:03.545324] Finished iteration 119, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3578.350
START iteration 119, CKPT_AND_STOP: False
[2022-12-05 12:56:07.133361] Finished iteration 120, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3588.039
START iteration 120, CKPT_AND_STOP: False
[2022-12-05 12:56:10.793305] Finished iteration 121, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3659.945
START iteration 121, CKPT_AND_STOP: False
[2022-12-05 12:56:14.440324] Finished iteration 122, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3647.019
START iteration 122, CKPT_AND_STOP: False
[2022-12-05 12:56:18.075628] Finished iteration 123, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3635.304
START iteration 123, CKPT_AND_STOP: False
[2022-12-05 12:56:21.753430] Finished iteration 124, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3677.801
START iteration 124, CKPT_AND_STOP: False
[2022-12-05 12:56:25.399232] Finished iteration 125, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3645.802
START iteration 125, CKPT_AND_STOP: False
[2022-12-05 12:56:29.020546] Finished iteration 126, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3621.315
START iteration 126, CKPT_AND_STOP: False
[2022-12-05 12:56:32.545809] Finished iteration 127, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3525.263
START iteration 127, CKPT_AND_STOP: False
[2022-12-05 12:56:36.171584] Finished iteration 128, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3625.775
START iteration 128, CKPT_AND_STOP: False
[2022-12-05 12:56:39.825080] Finished iteration 129, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3653.495
START iteration 129, CKPT_AND_STOP: False
[2022-12-05 12:56:43.443573] Finished iteration 130, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3618.493
START iteration 130, CKPT_AND_STOP: False
[2022-12-05 12:56:47.106854] Finished iteration 131, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3663.280
START iteration 131, CKPT_AND_STOP: False
[2022-12-05 12:56:50.712574] Finished iteration 132, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3605.719
START iteration 132, CKPT_AND_STOP: False
[2022-12-05 12:56:54.288291] Finished iteration 133, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3575.716
START iteration 133, CKPT_AND_STOP: False
[2022-12-05 12:56:57.861262] Finished iteration 134, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3572.975
START iteration 134, CKPT_AND_STOP: False
[2022-12-05 12:57:01.445252] Finished iteration 135, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3583.991
START iteration 135, CKPT_AND_STOP: False
[2022-12-05 12:57:05.071249] Finished iteration 136, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3625.997
START iteration 136, CKPT_AND_STOP: False
[2022-12-05 12:57:08.750047] Finished iteration 137, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3678.795
START iteration 137, CKPT_AND_STOP: False
[2022-12-05 12:57:12.322129] Finished iteration 138, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3572.085
START iteration 138, CKPT_AND_STOP: False
[2022-12-05 12:57:15.984689] Finished iteration 139, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3662.559
START iteration 139, CKPT_AND_STOP: False
[2022-12-05 12:57:19.621445] Finished iteration 140, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3636.755
START iteration 140, CKPT_AND_STOP: False
[2022-12-05 12:57:23.270280] Finished iteration 141, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3648.837
START iteration 141, CKPT_AND_STOP: False
[2022-12-05 12:57:26.887636] Finished iteration 142, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3617.356
START iteration 142, CKPT_AND_STOP: False
[2022-12-05 12:57:30.463171] Finished iteration 143, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3575.533
START iteration 143, CKPT_AND_STOP: False
[2022-12-05 12:57:34.089803] Finished iteration 144, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3626.634
START iteration 144, CKPT_AND_STOP: False
[2022-12-05 12:57:37.639279] Finished iteration 145, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3549.477
START iteration 145, CKPT_AND_STOP: False
[2022-12-05 12:57:41.225350] Finished iteration 146, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3586.071
START iteration 146, CKPT_AND_STOP: False
[2022-12-05 12:57:44.784693] Finished iteration 147, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3559.342
START iteration 147, CKPT_AND_STOP: False
[2022-12-05 12:57:48.395724] Finished iteration 148, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3611.028
START iteration 148, CKPT_AND_STOP: False
[2022-12-05 12:57:51.980024] Finished iteration 149, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3584.303
START iteration 149, CKPT_AND_STOP: False
[2022-12-05 12:57:55.609839] Finished iteration 150, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3629.815
START iteration 150, CKPT_AND_STOP: False
[2022-12-05 12:57:59.250038] Finished iteration 151, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3640.200
START iteration 151, CKPT_AND_STOP: False
[2022-12-05 12:58:02.840093] Finished iteration 152, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3590.055
START iteration 152, CKPT_AND_STOP: False
[2022-12-05 12:58:06.431766] Finished iteration 153, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3591.671
START iteration 153, CKPT_AND_STOP: False
[2022-12-05 12:58:10.058941] Finished iteration 154, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3627.176
START iteration 154, CKPT_AND_STOP: False
[2022-12-05 12:58:13.759546] Finished iteration 155, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3700.605
START iteration 155, CKPT_AND_STOP: False
[2022-12-05 12:58:17.384308] Finished iteration 156, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3624.762
START iteration 156, CKPT_AND_STOP: False
[2022-12-05 12:58:21.093480] Finished iteration 157, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3709.171
START iteration 157, CKPT_AND_STOP: False
[2022-12-05 12:58:24.689742] Finished iteration 158, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3596.263
START iteration 158, CKPT_AND_STOP: False
[2022-12-05 12:58:28.300225] Finished iteration 159, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3610.483
START iteration 159, CKPT_AND_STOP: False
[2022-12-05 12:58:31.857583] Finished iteration 160, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3557.357
START iteration 160, CKPT_AND_STOP: False
[2022-12-05 12:58:35.536976] Finished iteration 161, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3679.394
START iteration 161, CKPT_AND_STOP: False
[2022-12-05 12:58:39.132926] Finished iteration 162, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3595.950
START iteration 162, CKPT_AND_STOP: False
[2022-12-05 12:58:42.765768] Finished iteration 163, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3632.842
START iteration 163, CKPT_AND_STOP: False
[2022-12-05 12:58:46.389484] Finished iteration 164, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3623.716
START iteration 164, CKPT_AND_STOP: False
[2022-12-05 12:58:50.011960] Finished iteration 165, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3622.476
START iteration 165, CKPT_AND_STOP: False
[2022-12-05 12:58:53.643054] Finished iteration 166, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3631.094
START iteration 166, CKPT_AND_STOP: False
[2022-12-05 12:58:57.215487] Finished iteration 167, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3572.432
START iteration 167, CKPT_AND_STOP: False
[2022-12-05 12:59:00.904066] Finished iteration 168, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3688.580
START iteration 168, CKPT_AND_STOP: False
[2022-12-05 12:59:04.534940] Finished iteration 169, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3630.874
START iteration 169, CKPT_AND_STOP: False
[2022-12-05 12:59:08.169812] Finished iteration 170, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3634.870
START iteration 170, CKPT_AND_STOP: False
[2022-12-05 12:59:11.773293] Finished iteration 171, CKPT_AND_STOP: False, flag: tensor([1], dtype=torch.int32), speed: 3603.479
Begin to save checkpont and exit
Opt ckpt time 3.166485071182251
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 14 signal handler called with signal 10
Process done with return code 0
Parent process ID: 21222 node: 172.31.30.89
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 12 0 2007202.880859375 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4913759
Min send: 10000000, max send 0
Min long send: 38387, max long send 60521
Min fwd: 45773, max fwd 58711; min bwd 92748, max bwd 103910
Min long fwd: 56704, max long fwd 63285; min long bwd 98353, max long bwd 106648
Time taken by simulation: 375 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 18 0 1481951.2939453125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4877293
Min send: 10000000, max send 0
Min long send: 38055, max long send 64155
Min fwd: 32292, max fwd 48132; min bwd 69316, max bwd 77937
Min long fwd: 43561, max long fwd 51496; min long bwd 71918, max long bwd 80151
Time taken by simulation: 865 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 25 0 976051.4526367188 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4466988
Min send: 10000000, max send 0
Min long send: 38237, max long send 65217
Min fwd: 19236, max fwd 35580; min bwd 42158, max bwd 57089
Min long fwd: 24076, max long fwd 35713; min long bwd 50505, max long bwd 59414
Time taken by simulation: 1841 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 42 0 610855.46875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4799842
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 10665, max fwd 27276; min bwd 28791, max bwd 43945
Min long fwd: 21459, max long fwd 30507; min long bwd 38642, max long bwd 48142
Time taken by simulation: 4288 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 64 0 343797.36328125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5360725
Min send: 10000000, max send 0
Min long send: 38056, max long send 68144
Min fwd: 5149, max fwd 20736; min bwd 17314, max bwd 33457
Min long fwd: 11639, max long fwd 22378; min long bwd 26559, max long bwd 34539
Time taken by simulation: 10470 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29648 microseconds

Stages 24
Micro-bs 1 Max mem: 2949765734.4
Predicted microbatch size for 24: 1
comm size 1638400
WARNING: no send time found, 24 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 24 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6789982
Min send: 10000000, max send 0
Min long send: 38055, max long send 74455
Min fwd: 26, max fwd 15549; min bwd 3842, max bwd 20573
Min long fwd: 7764, max long fwd 18097; min long bwd 11316, max long bwd 21840
Time taken by simulation: 45892 microseconds

{1: inf, 2: inf, 3: 4.913759, 4: 4.877293, 6: 4.466988, 8: 4.799842, 12: 5.360725, 16: 7.580423, 24: 6.789982}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1, 24: 1}
best config is: 6 1
expected time is 4.466988
5 per stage
30 servers!
Config:
ranks: range(14, 15)
train batch size: 128
partitions: 6
chunk_size: 1
data depth: 5
stage to rank map: 0,6,12,18,24;1,7,13,19,25;2,8,14,20,26;3,9,15,21,27;4,10,16,22,28;5,11,17,23,29;
World size is 30
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=14 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,6,12,18,24;1,7,13,19,25;2,8,14,20,26;3,9,15,21,27;4,10,16,22,28;5,11,17,23,29; --batch-size=25 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 171
dry run time 1.1294279098510742
SHARED WEIGHTS ARE
[(0, 5)]
this rank  14 is part of pipeline replica  2
25 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
 > finished loading checkpoint in 56.234 seconds
START iteration 171, CKPT_AND_STOP: False
[2022-12-05 13:01:41.906767] Finished iteration 172, CKPT_AND_STOP: False, flag: tensor([2], dtype=torch.int32), speed: 9930.863
Begin to save checkpont and exit
Opt ckpt time 7.663792133331299
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 14 signal handler called with signal 10
Process done with return code 0
Parent process ID: 22154 node: 172.31.30.89
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 12 0 2007202.880859375 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4913759
Min send: 10000000, max send 0
Min long send: 38387, max long send 60521
Min fwd: 45773, max fwd 58711; min bwd 92748, max bwd 103910
Min long fwd: 56704, max long fwd 63285; min long bwd 98353, max long bwd 106648
Time taken by simulation: 369 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 16 0 1727535.5224609375 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4820532
Min send: 10000000, max send 0
Min long send: 38109, max long send 64155
Min fwd: 32292, max fwd 48132; min bwd 69446, max bwd 80083
Min long fwd: 43192, max long fwd 50561; min long bwd 74672, max long bwd 80151
Time taken by simulation: 734 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 25 0 976051.4526367188 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4466988
Min send: 10000000, max send 0
Min long send: 38237, max long send 65217
Min fwd: 19236, max fwd 35580; min bwd 42158, max bwd 57089
Min long fwd: 24076, max long fwd 35713; min long bwd 50505, max long bwd 59414
Time taken by simulation: 1746 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 32 0 700971.3134765625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4198444
Min send: 10000000, max send 0
Min long send: 38109, max long send 68059
Min fwd: 11544, max fwd 27276; min bwd 28686, max bwd 44788
Min long fwd: 22228, max long fwd 29781; min long bwd 41714, max long bwd 48296
Time taken by simulation: 3253 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 64 0 343797.36328125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5360725
Min send: 10000000, max send 0
Min long send: 38056, max long send 68144
Min fwd: 5149, max fwd 20736; min bwd 17314, max bwd 33457
Min long fwd: 11639, max long fwd 22378; min long bwd 26559, max long bwd 34539
Time taken by simulation: 10420 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 64 0 294405.0598144531 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5043807
Min send: 10000000, max send 0
Min long send: 38109, max long send 77793
Min fwd: 803, max fwd 17174; min bwd 10907, max bwd 28118
Min long fwd: 12084, max long fwd 20913; min long bwd 17914, max long bwd 26363
Time taken by simulation: 14693 microseconds

Stages 24
Micro-bs 1 Max mem: 2949765734.4
Predicted microbatch size for 24: 1
comm size 1638400
WARNING: no send time found, 24 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 24 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6789982
Min send: 10000000, max send 0
Min long send: 38055, max long send 74455
Min fwd: 26, max fwd 15549; min bwd 3842, max bwd 20573
Min long fwd: 7764, max long fwd 18097; min long bwd 11316, max long bwd 21840
Time taken by simulation: 46114 microseconds

{1: inf, 2: inf, 3: 4.913759, 4: 4.820532, 6: 4.466988, 8: 4.198444, 12: 5.360725, 16: 5.043807, 24: 6.789982}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1, 24: 1}
best config is: 8 1
expected time is 4.198444
4 per stage
32 servers!
Config:
ranks: range(14, 15)
train batch size: 128
partitions: 8
chunk_size: 1
data depth: 4
stage to rank map: 0,8,16,24;1,9,17,25;2,10,18,26;3,11,19,27;4,12,20,28;5,13,21,29;6,14,22,30;7,15,23,31;
World size is 32
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=14 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,8,16,24;1,9,17,25;2,10,18,26;3,11,19,27;4,12,20,28;5,13,21,29;6,14,22,30;7,15,23,31; --batch-size=32 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 172
dry run time 1.0229387283325195
SHARED WEIGHTS ARE
[(0, 7)]
this rank  14 is part of pipeline replica  1
32 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
 > finished loading checkpoint in 45.584 seconds
START iteration 172, CKPT_AND_STOP: False
[2022-12-05 13:03:32.124688] Finished iteration 173, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 11697.734
START iteration 173, CKPT_AND_STOP: False
[2022-12-05 13:03:37.636576] Finished iteration 174, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5511.917
START iteration 174, CKPT_AND_STOP: False
[2022-12-05 13:03:42.355428] Finished iteration 175, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4718.850
START iteration 175, CKPT_AND_STOP: False
[2022-12-05 13:03:47.045398] Finished iteration 176, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4689.970
START iteration 176, CKPT_AND_STOP: False
[2022-12-05 13:03:51.653310] Finished iteration 177, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4607.912
START iteration 177, CKPT_AND_STOP: False
[2022-12-05 13:03:55.260251] Finished iteration 178, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3606.943
START iteration 178, CKPT_AND_STOP: False
[2022-12-05 13:03:58.820336] Finished iteration 179, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3560.083
START iteration 179, CKPT_AND_STOP: False
[2022-12-05 13:04:02.883175] Finished iteration 180, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4062.840
START iteration 180, CKPT_AND_STOP: False
[2022-12-05 13:04:07.062509] Finished iteration 181, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4179.336
START iteration 181, CKPT_AND_STOP: False
[2022-12-05 13:04:10.642537] Finished iteration 182, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3580.026
START iteration 182, CKPT_AND_STOP: False
[2022-12-05 13:04:14.184010] Finished iteration 183, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3541.474
START iteration 183, CKPT_AND_STOP: False
[2022-12-05 13:04:17.739674] Finished iteration 184, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3555.664
START iteration 184, CKPT_AND_STOP: False
[2022-12-05 13:04:21.359602] Finished iteration 185, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3619.929
START iteration 185, CKPT_AND_STOP: False
[2022-12-05 13:04:24.920060] Finished iteration 186, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3560.458
START iteration 186, CKPT_AND_STOP: False
[2022-12-05 13:04:28.496190] Finished iteration 187, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3576.129
START iteration 187, CKPT_AND_STOP: False
[2022-12-05 13:04:32.182591] Finished iteration 188, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3686.402
START iteration 188, CKPT_AND_STOP: False
[2022-12-05 13:04:35.938884] Finished iteration 189, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3756.291
START iteration 189, CKPT_AND_STOP: False
[2022-12-05 13:04:39.572898] Finished iteration 190, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3634.016
START iteration 190, CKPT_AND_STOP: False
[2022-12-05 13:04:43.300398] Finished iteration 191, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3727.499
START iteration 191, CKPT_AND_STOP: False
[2022-12-05 13:04:47.007372] Finished iteration 192, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3706.975
START iteration 192, CKPT_AND_STOP: False
[2022-12-05 13:04:50.731572] Finished iteration 193, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3724.199
START iteration 193, CKPT_AND_STOP: False
[2022-12-05 13:04:54.353743] Finished iteration 194, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3622.172
START iteration 194, CKPT_AND_STOP: False
[2022-12-05 13:04:58.017394] Finished iteration 195, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3663.651
START iteration 195, CKPT_AND_STOP: False
[2022-12-05 13:05:01.606000] Finished iteration 196, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3588.606
START iteration 196, CKPT_AND_STOP: False
[2022-12-05 13:05:05.157555] Finished iteration 197, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3551.555
START iteration 197, CKPT_AND_STOP: False
[2022-12-05 13:05:08.683887] Finished iteration 198, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3526.332
START iteration 198, CKPT_AND_STOP: False
[2022-12-05 13:05:12.263173] Finished iteration 199, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3579.287
START iteration 199, CKPT_AND_STOP: False
[2022-12-05 13:05:16.022209] Finished iteration 200, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3759.035
START iteration 200, CKPT_AND_STOP: False
[2022-12-05 13:05:19.576224] Finished iteration 201, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3554.016
START iteration 201, CKPT_AND_STOP: False
[2022-12-05 13:05:23.274465] Finished iteration 202, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3698.240
START iteration 202, CKPT_AND_STOP: False
[2022-12-05 13:05:26.867353] Finished iteration 203, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3592.888
START iteration 203, CKPT_AND_STOP: False
[2022-12-05 13:05:30.532699] Finished iteration 204, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3665.347
START iteration 204, CKPT_AND_STOP: False
[2022-12-05 13:05:34.143006] Finished iteration 205, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3610.307
START iteration 205, CKPT_AND_STOP: False
[2022-12-05 13:05:37.832976] Finished iteration 206, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3689.971
START iteration 206, CKPT_AND_STOP: False
[2022-12-05 13:05:41.500117] Finished iteration 207, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3667.141
START iteration 207, CKPT_AND_STOP: False
[2022-12-05 13:05:45.068524] Finished iteration 208, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3568.407
START iteration 208, CKPT_AND_STOP: False
[2022-12-05 13:05:48.640088] Finished iteration 209, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3571.563
START iteration 209, CKPT_AND_STOP: False
[2022-12-05 13:05:52.148887] Finished iteration 210, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3508.800
START iteration 210, CKPT_AND_STOP: False
[2022-12-05 13:05:55.724204] Finished iteration 211, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3575.317
START iteration 211, CKPT_AND_STOP: False
[2022-12-05 13:05:59.399694] Finished iteration 212, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3675.490
START iteration 212, CKPT_AND_STOP: False
[2022-12-05 13:06:02.995512] Finished iteration 213, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3595.819
START iteration 213, CKPT_AND_STOP: False
[2022-12-05 13:06:06.510121] Finished iteration 214, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3514.609
START iteration 214, CKPT_AND_STOP: False
[2022-12-05 13:06:10.118370] Finished iteration 215, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3608.248
START iteration 215, CKPT_AND_STOP: False
[2022-12-05 13:06:13.702131] Finished iteration 216, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3583.758
START iteration 216, CKPT_AND_STOP: False
[2022-12-05 13:06:17.299695] Finished iteration 217, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3597.566
START iteration 217, CKPT_AND_STOP: False
[2022-12-05 13:06:20.865175] Finished iteration 218, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3565.480
START iteration 218, CKPT_AND_STOP: False
[2022-12-05 13:06:24.466908] Finished iteration 219, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3601.732
START iteration 219, CKPT_AND_STOP: False
[2022-12-05 13:06:28.031426] Finished iteration 220, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3564.499
START iteration 220, CKPT_AND_STOP: False
[2022-12-05 13:06:31.677599] Finished iteration 221, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3646.190
START iteration 221, CKPT_AND_STOP: False
[2022-12-05 13:06:35.278412] Finished iteration 222, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3600.816
START iteration 222, CKPT_AND_STOP: False
[2022-12-05 13:06:38.896805] Finished iteration 223, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3618.392
START iteration 223, CKPT_AND_STOP: False
[2022-12-05 13:06:42.492858] Finished iteration 224, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3596.052
START iteration 224, CKPT_AND_STOP: False
[2022-12-05 13:06:46.139388] Finished iteration 225, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3646.529
START iteration 225, CKPT_AND_STOP: False
[2022-12-05 13:06:49.883700] Finished iteration 226, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3744.308
START iteration 226, CKPT_AND_STOP: False
[2022-12-05 13:06:53.503092] Finished iteration 227, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3619.397
START iteration 227, CKPT_AND_STOP: False
[2022-12-05 13:06:57.035733] Finished iteration 228, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3532.641
START iteration 228, CKPT_AND_STOP: False
[2022-12-05 13:07:00.608216] Finished iteration 229, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3572.483
START iteration 229, CKPT_AND_STOP: False
[2022-12-05 13:07:04.303551] Finished iteration 230, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3695.335
START iteration 230, CKPT_AND_STOP: False
[2022-12-05 13:07:07.943981] Finished iteration 231, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3640.430
START iteration 231, CKPT_AND_STOP: False
[2022-12-05 13:07:11.521368] Finished iteration 232, CKPT_AND_STOP: False, flag: tensor([1], dtype=torch.int32), speed: 3577.385
Begin to save checkpont and exit
Opt ckpt time 3.267875909805298
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 14 signal handler called with signal 10
Process done with return code 0
Parent process ID: 22935 node: 172.31.27.155
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 14 0 2006653.3203125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5367030
Min send: 10000000, max send 0
Min long send: 38387, max long send 60521
Min fwd: 45773, max fwd 60689; min bwd 93028, max bwd 103910
Min long fwd: 57033, max long fwd 64913; min long bwd 98397, max long bwd 102857
Time taken by simulation: 430 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 18 0 1481951.2939453125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4877293
Min send: 10000000, max send 0
Min long send: 38055, max long send 64155
Min fwd: 32292, max fwd 48132; min bwd 69316, max bwd 77937
Min long fwd: 43561, max long fwd 51496; min long bwd 71918, max long bwd 80151
Time taken by simulation: 771 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 32 0 876895.5078125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5017062
Min send: 10000000, max send 0
Min long send: 38071, max long send 66276
Min fwd: 18837, max fwd 35859; min bwd 42514, max bwd 56347
Min long fwd: 27753, max long fwd 35222; min long bwd 51765, max long bwd 59571
Time taken by simulation: 2281 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 42 0 610855.46875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4799842
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 10665, max fwd 27276; min bwd 28791, max bwd 43945
Min long fwd: 21459, max long fwd 30507; min long bwd 38642, max long bwd 48142
Time taken by simulation: 4223 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 64 0 343797.36328125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5360725
Min send: 10000000, max send 0
Min long send: 38056, max long send 68144
Min fwd: 5149, max fwd 20736; min bwd 17314, max bwd 33457
Min long fwd: 11639, max long fwd 22378; min long bwd 26559, max long bwd 34539
Time taken by simulation: 10787 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29697 microseconds

Stages 24
Micro-bs 1 Max mem: 2949765734.4
Predicted microbatch size for 24: 1
comm size 1638400
WARNING: no send time found, 24 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 24 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6789982
Min send: 10000000, max send 0
Min long send: 38055, max long send 74455
Min fwd: 26, max fwd 15549; min bwd 3842, max bwd 20573
Min long fwd: 7764, max long fwd 18097; min long bwd 11316, max long bwd 21840
Time taken by simulation: 45907 microseconds

{1: inf, 2: inf, 3: 5.36703, 4: 4.877293, 6: 5.017062, 8: 4.799842, 12: 5.360725, 16: 7.580423, 24: 6.789982}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1, 24: 1}
best config is: 8 1
expected time is 4.799842
3 per stage
24 servers!
Config:
ranks: range(14, 15)
train batch size: 128
partitions: 8
chunk_size: 1
data depth: 3
stage to rank map: 0,8,16;1,9,17;2,10,18;3,11,19;4,12,20;5,13,21;6,14,22;7,15,23;
World size is 24
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=14 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,8,16;1,9,17;2,10,18;3,11,19;4,12,20;5,13,21;6,14,22;7,15,23; --batch-size=42 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 232
dry run time 0.8956875801086426
SHARED WEIGHTS ARE
[(0, 7)]
this rank  14 is part of pipeline replica  1
42 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
 > finished loading checkpoint in 40.941 seconds
START iteration 232, CKPT_AND_STOP: False
[2022-12-05 13:09:29.745345] Finished iteration 233, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 12352.991
START iteration 233, CKPT_AND_STOP: False
[2022-12-05 13:09:34.880673] Finished iteration 234, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5135.364
START iteration 234, CKPT_AND_STOP: False
[2022-12-05 13:09:39.942897] Finished iteration 235, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5062.224
START iteration 235, CKPT_AND_STOP: False
[2022-12-05 13:09:45.049792] Finished iteration 236, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5106.895
START iteration 236, CKPT_AND_STOP: False
[2022-12-05 13:09:50.196091] Finished iteration 237, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5146.297
START iteration 237, CKPT_AND_STOP: False
[2022-12-05 13:09:54.344470] Finished iteration 238, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4148.382
START iteration 238, CKPT_AND_STOP: False
[2022-12-05 13:09:58.456263] Finished iteration 239, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4111.792
START iteration 239, CKPT_AND_STOP: False
[2022-12-05 13:10:02.548342] Finished iteration 240, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4092.080
START iteration 240, CKPT_AND_STOP: False
[2022-12-05 13:10:06.607828] Finished iteration 241, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4059.486
START iteration 241, CKPT_AND_STOP: False
[2022-12-05 13:10:10.663733] Finished iteration 242, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4055.905
START iteration 242, CKPT_AND_STOP: False
[2022-12-05 13:10:14.759993] Finished iteration 243, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4096.260
START iteration 243, CKPT_AND_STOP: False
[2022-12-05 13:10:18.874003] Finished iteration 244, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4114.011
START iteration 244, CKPT_AND_STOP: False
[2022-12-05 13:10:22.958943] Finished iteration 245, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4084.938
START iteration 245, CKPT_AND_STOP: False
[2022-12-05 13:10:27.102713] Finished iteration 246, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4143.771
START iteration 246, CKPT_AND_STOP: False
[2022-12-05 13:10:31.199797] Finished iteration 247, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4097.084
START iteration 247, CKPT_AND_STOP: False
[2022-12-05 13:10:35.313720] Finished iteration 248, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4113.923
START iteration 248, CKPT_AND_STOP: False
[2022-12-05 13:10:39.418691] Finished iteration 249, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4104.972
START iteration 249, CKPT_AND_STOP: False
[2022-12-05 13:10:43.547913] Finished iteration 250, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4129.223
START iteration 250, CKPT_AND_STOP: False
[2022-12-05 13:10:47.648500] Finished iteration 251, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4100.587
START iteration 251, CKPT_AND_STOP: False
[2022-12-05 13:10:51.701011] Finished iteration 252, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4052.509
START iteration 252, CKPT_AND_STOP: False
[2022-12-05 13:10:55.766247] Finished iteration 253, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4065.236
START iteration 253, CKPT_AND_STOP: False
[2022-12-05 13:10:59.798524] Finished iteration 254, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4032.278
START iteration 254, CKPT_AND_STOP: False
[2022-12-05 13:11:03.844747] Finished iteration 255, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4046.222
START iteration 255, CKPT_AND_STOP: False
[2022-12-05 13:11:07.931451] Finished iteration 256, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4086.705
START iteration 256, CKPT_AND_STOP: False
[2022-12-05 13:11:11.974279] Finished iteration 257, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4042.826
START iteration 257, CKPT_AND_STOP: False
[2022-12-05 13:11:16.107929] Finished iteration 258, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4133.651
START iteration 258, CKPT_AND_STOP: False
[2022-12-05 13:11:20.314494] Finished iteration 259, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4206.548
START iteration 259, CKPT_AND_STOP: False
[2022-12-05 13:11:24.444592] Finished iteration 260, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4130.116
START iteration 260, CKPT_AND_STOP: False
[2022-12-05 13:11:28.506016] Finished iteration 261, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4061.424
START iteration 261, CKPT_AND_STOP: False
[2022-12-05 13:11:32.587428] Finished iteration 262, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4081.413
START iteration 262, CKPT_AND_STOP: False
[2022-12-05 13:11:36.726680] Finished iteration 263, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4139.251
START iteration 263, CKPT_AND_STOP: False
[2022-12-05 13:11:40.782519] Finished iteration 264, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4055.839
START iteration 264, CKPT_AND_STOP: False
[2022-12-05 13:11:44.913706] Finished iteration 265, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4131.186
START iteration 265, CKPT_AND_STOP: False
[2022-12-05 13:11:48.992253] Finished iteration 266, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4078.548
START iteration 266, CKPT_AND_STOP: False
[2022-12-05 13:11:53.059204] Finished iteration 267, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4066.951
START iteration 267, CKPT_AND_STOP: False
[2022-12-05 13:11:57.144159] Finished iteration 268, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4084.955
START iteration 268, CKPT_AND_STOP: False
[2022-12-05 13:12:01.222213] Finished iteration 269, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4078.054
START iteration 269, CKPT_AND_STOP: False
[2022-12-05 13:12:05.332368] Finished iteration 270, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4110.155
START iteration 270, CKPT_AND_STOP: False
[2022-12-05 13:12:09.396152] Finished iteration 271, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4063.780
START iteration 271, CKPT_AND_STOP: False
[2022-12-05 13:12:13.485890] Finished iteration 272, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4089.741
START iteration 272, CKPT_AND_STOP: False
[2022-12-05 13:12:17.557757] Finished iteration 273, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4071.868
START iteration 273, CKPT_AND_STOP: False
[2022-12-05 13:12:21.609583] Finished iteration 274, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4051.826
START iteration 274, CKPT_AND_STOP: False
[2022-12-05 13:12:25.658175] Finished iteration 275, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4048.592
START iteration 275, CKPT_AND_STOP: False
[2022-12-05 13:12:29.756348] Finished iteration 276, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4098.172
START iteration 276, CKPT_AND_STOP: False
[2022-12-05 13:12:33.841169] Finished iteration 277, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4084.818
START iteration 277, CKPT_AND_STOP: False
[2022-12-05 13:12:37.953433] Finished iteration 278, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4112.268
START iteration 278, CKPT_AND_STOP: False
[2022-12-05 13:12:42.085347] Finished iteration 279, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4131.913
START iteration 279, CKPT_AND_STOP: False
[2022-12-05 13:12:46.155752] Finished iteration 280, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4070.405
START iteration 280, CKPT_AND_STOP: False
[2022-12-05 13:12:50.239247] Finished iteration 281, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4083.495
START iteration 281, CKPT_AND_STOP: False
[2022-12-05 13:12:54.435629] Finished iteration 282, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4196.383
START iteration 282, CKPT_AND_STOP: False
[2022-12-05 13:12:58.510926] Finished iteration 283, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4075.297
START iteration 283, CKPT_AND_STOP: False
[2022-12-05 13:13:02.627059] Finished iteration 284, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4116.133
START iteration 284, CKPT_AND_STOP: False
[2022-12-05 13:13:06.685583] Finished iteration 285, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4058.522
START iteration 285, CKPT_AND_STOP: False
[2022-12-05 13:13:10.750237] Finished iteration 286, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4064.656
START iteration 286, CKPT_AND_STOP: False
[2022-12-05 13:13:15.302066] Finished iteration 287, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4551.829
START iteration 287, CKPT_AND_STOP: False
[2022-12-05 13:13:19.374272] Finished iteration 288, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4072.206
START iteration 288, CKPT_AND_STOP: False
[2022-12-05 13:13:23.397105] Finished iteration 289, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4022.834
START iteration 289, CKPT_AND_STOP: False
[2022-12-05 13:13:27.553110] Finished iteration 290, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4156.003
START iteration 290, CKPT_AND_STOP: False
[2022-12-05 13:13:31.717815] Finished iteration 291, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4164.705
START iteration 291, CKPT_AND_STOP: False
[2022-12-05 13:13:35.864253] Finished iteration 292, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4146.438
START iteration 292, CKPT_AND_STOP: False
[2022-12-05 13:13:39.942887] Finished iteration 293, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4078.633
START iteration 293, CKPT_AND_STOP: False
[2022-12-05 13:13:43.937902] Finished iteration 294, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3995.015
START iteration 294, CKPT_AND_STOP: False
[2022-12-05 13:13:47.995085] Finished iteration 295, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4057.184
START iteration 295, CKPT_AND_STOP: False
[2022-12-05 13:13:52.129659] Finished iteration 296, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4134.574
START iteration 296, CKPT_AND_STOP: False
[2022-12-05 13:13:56.192036] Finished iteration 297, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4062.376
START iteration 297, CKPT_AND_STOP: False
[2022-12-05 13:14:01.066960] Finished iteration 298, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4874.925
START iteration 298, CKPT_AND_STOP: False
[2022-12-05 13:14:05.127659] Finished iteration 299, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4060.699
START iteration 299, CKPT_AND_STOP: False
[2022-12-05 13:14:09.244760] Finished iteration 300, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4117.099
START iteration 300, CKPT_AND_STOP: False
[2022-12-05 13:14:13.317886] Finished iteration 301, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4073.128
START iteration 301, CKPT_AND_STOP: False
[2022-12-05 13:14:17.513476] Finished iteration 302, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4195.590
START iteration 302, CKPT_AND_STOP: False
[2022-12-05 13:14:21.603573] Finished iteration 303, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4090.097
START iteration 303, CKPT_AND_STOP: False
[2022-12-05 13:14:25.701326] Finished iteration 304, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4097.753
START iteration 304, CKPT_AND_STOP: False
[2022-12-05 13:14:29.750734] Finished iteration 305, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4049.407
START iteration 305, CKPT_AND_STOP: False
[2022-12-05 13:14:33.828770] Finished iteration 306, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4078.037
START iteration 306, CKPT_AND_STOP: False
[2022-12-05 13:14:37.855467] Finished iteration 307, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4026.696
START iteration 307, CKPT_AND_STOP: False
[2022-12-05 13:14:41.952815] Finished iteration 308, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4097.348
START iteration 308, CKPT_AND_STOP: False
[2022-12-05 13:14:46.140441] Finished iteration 309, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4187.625
START iteration 309, CKPT_AND_STOP: False
[2022-12-05 13:14:50.212130] Finished iteration 310, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4071.688
START iteration 310, CKPT_AND_STOP: False
[2022-12-05 13:14:54.259917] Finished iteration 311, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4047.788
START iteration 311, CKPT_AND_STOP: False
[2022-12-05 13:14:58.419840] Finished iteration 312, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4159.920
START iteration 312, CKPT_AND_STOP: False
[2022-12-05 13:15:02.519364] Finished iteration 313, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4099.527
START iteration 313, CKPT_AND_STOP: False
[2022-12-05 13:15:06.609679] Finished iteration 314, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4090.314
START iteration 314, CKPT_AND_STOP: False
[2022-12-05 13:15:10.715620] Finished iteration 315, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4105.941
START iteration 315, CKPT_AND_STOP: False
[2022-12-05 13:15:14.845278] Finished iteration 316, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4129.660
START iteration 316, CKPT_AND_STOP: False
[2022-12-05 13:15:18.947466] Finished iteration 317, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4102.186
START iteration 317, CKPT_AND_STOP: False
[2022-12-05 13:15:23.012572] Finished iteration 318, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4065.107
START iteration 318, CKPT_AND_STOP: False
[2022-12-05 13:15:27.068007] Finished iteration 319, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4055.435
START iteration 319, CKPT_AND_STOP: False
[2022-12-05 13:15:31.149030] Finished iteration 320, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4081.023
START iteration 320, CKPT_AND_STOP: False
[2022-12-05 13:15:36.104319] Finished iteration 321, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4955.288
START iteration 321, CKPT_AND_STOP: False
[2022-12-05 13:15:40.108357] Finished iteration 322, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4004.035
START iteration 322, CKPT_AND_STOP: False
