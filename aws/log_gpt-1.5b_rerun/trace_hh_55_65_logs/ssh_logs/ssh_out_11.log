Parent process ID: 10001 node: 172.31.19.171
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 12 0 2007202.880859375 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4913759
Min send: 10000000, max send 0
Min long send: 38387, max long send 60521
Min fwd: 45773, max fwd 58711; min bwd 92748, max bwd 103910
Min long fwd: 56704, max long fwd 63285; min long bwd 98353, max long bwd 106648
Time taken by simulation: 371 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 16 0 1727535.5224609375 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4820532
Min send: 10000000, max send 0
Min long send: 38109, max long send 64155
Min fwd: 32292, max fwd 48132; min bwd 69446, max bwd 80083
Min long fwd: 43192, max long fwd 50561; min long bwd 74672, max long bwd 80151
Time taken by simulation: 695 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 25 0 976051.4526367188 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4466988
Min send: 10000000, max send 0
Min long send: 38237, max long send 65217
Min fwd: 19236, max fwd 35580; min bwd 42158, max bwd 57089
Min long fwd: 24076, max long fwd 35713; min long bwd 50505, max long bwd 59414
Time taken by simulation: 1753 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 32 0 700971.3134765625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4198444
Min send: 10000000, max send 0
Min long send: 38109, max long send 68059
Min fwd: 11544, max fwd 27276; min bwd 28686, max bwd 44788
Min long fwd: 22228, max long fwd 29781; min long bwd 41714, max long bwd 48296
Time taken by simulation: 3220 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 64 0 343797.36328125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5360725
Min send: 10000000, max send 0
Min long send: 38056, max long send 68144
Min fwd: 5149, max fwd 20736; min bwd 17314, max bwd 33457
Min long fwd: 11639, max long fwd 22378; min long bwd 26559, max long bwd 34539
Time taken by simulation: 10428 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 64 0 294405.0598144531 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5043807
Min send: 10000000, max send 0
Min long send: 38109, max long send 77793
Min fwd: 803, max fwd 17174; min bwd 10907, max bwd 28118
Min long fwd: 12084, max long fwd 20913; min long bwd 17914, max long bwd 26363
Time taken by simulation: 14317 microseconds

Stages 24
Micro-bs 1 Max mem: 2949765734.4
Predicted microbatch size for 24: 1
comm size 1638400
WARNING: no send time found, 24 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 24 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6789982
Min send: 10000000, max send 0
Min long send: 38055, max long send 74455
Min fwd: 26, max fwd 15549; min bwd 3842, max bwd 20573
Min long fwd: 7764, max long fwd 18097; min long bwd 11316, max long bwd 21840
Time taken by simulation: 46074 microseconds

{1: inf, 2: inf, 3: 4.913759, 4: 4.820532, 6: 4.466988, 8: 4.198444, 12: 5.360725, 16: 5.043807, 24: 6.789982}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1, 24: 1}
best config is: 8 1
expected time is 4.198444
4 per stage
32 servers!
Config:
ranks: range(11, 12)
train batch size: 128
partitions: 8
chunk_size: 1
data depth: 4
stage to rank map: 0,8,16,24;1,9,17,25;2,10,18,26;3,11,19,27;4,12,20,28;5,13,21,29;6,14,22,30;7,15,23,31;
World size is 32
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=11 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,8,16,24;1,9,17,25;2,10,18,26;3,11,19,27;4,12,20,28;5,13,21,29;6,14,22,30;7,15,23,31; --batch-size=32 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16
dry run time 0.9501280784606934
SHARED WEIGHTS ARE
[(0, 7)]
this rank  11 is part of pipeline replica  1
32 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
 > finished loading checkpoint in 0.204 seconds
START iteration 0, CKPT_AND_STOP: False
[2022-12-05 12:21:27.125304] Finished iteration 1, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 11618.079
START iteration 1, CKPT_AND_STOP: False
[2022-12-05 12:21:31.806368] Finished iteration 2, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4681.090
START iteration 2, CKPT_AND_STOP: False
[2022-12-05 12:21:36.501170] Finished iteration 3, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4694.805
START iteration 3, CKPT_AND_STOP: False
[2022-12-05 12:21:41.148969] Finished iteration 4, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4647.799
START iteration 4, CKPT_AND_STOP: False
[2022-12-05 12:21:46.718433] Finished iteration 5, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5569.464
START iteration 5, CKPT_AND_STOP: False
[2022-12-05 12:21:50.357132] Finished iteration 6, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3638.699
START iteration 6, CKPT_AND_STOP: False
[2022-12-05 12:21:53.936919] Finished iteration 7, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3579.787
START iteration 7, CKPT_AND_STOP: False
[2022-12-05 12:21:57.454386] Finished iteration 8, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3517.467
START iteration 8, CKPT_AND_STOP: False
[2022-12-05 12:22:01.534227] Finished iteration 9, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4079.842
START iteration 9, CKPT_AND_STOP: False
[2022-12-05 12:22:05.663257] Finished iteration 10, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4129.030
START iteration 10, CKPT_AND_STOP: False
[2022-12-05 12:22:09.424645] Finished iteration 11, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3761.388
START iteration 11, CKPT_AND_STOP: False
[2022-12-05 12:22:13.083021] Finished iteration 12, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3658.373
START iteration 12, CKPT_AND_STOP: False
[2022-12-05 12:22:16.705079] Finished iteration 13, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3622.060
START iteration 13, CKPT_AND_STOP: False
[2022-12-05 12:22:21.284770] Finished iteration 14, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4579.690
START iteration 14, CKPT_AND_STOP: False
[2022-12-05 12:22:24.912136] Finished iteration 15, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3627.366
START iteration 15, CKPT_AND_STOP: False
[2022-12-05 12:22:28.510179] Finished iteration 16, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3598.044
START iteration 16, CKPT_AND_STOP: False
[2022-12-05 12:22:32.092453] Finished iteration 17, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3582.272
START iteration 17, CKPT_AND_STOP: False
[2022-12-05 12:22:35.697736] Finished iteration 18, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3605.282
START iteration 18, CKPT_AND_STOP: False
[2022-12-05 12:22:39.282350] Finished iteration 19, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3584.617
START iteration 19, CKPT_AND_STOP: False
[2022-12-05 12:22:42.853110] Finished iteration 20, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3570.759
START iteration 20, CKPT_AND_STOP: False
[2022-12-05 12:22:46.462436] Finished iteration 21, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3609.326
START iteration 21, CKPT_AND_STOP: False
[2022-12-05 12:22:50.014479] Finished iteration 22, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3552.044
START iteration 22, CKPT_AND_STOP: False
[2022-12-05 12:22:53.697291] Finished iteration 23, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3682.812
START iteration 23, CKPT_AND_STOP: False
[2022-12-05 12:22:57.279053] Finished iteration 24, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3581.757
START iteration 24, CKPT_AND_STOP: False
[2022-12-05 12:23:00.850700] Finished iteration 25, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3571.652
START iteration 25, CKPT_AND_STOP: False
[2022-12-05 12:23:04.444810] Finished iteration 26, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3594.109
START iteration 26, CKPT_AND_STOP: False
[2022-12-05 12:23:08.134415] Finished iteration 27, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3689.600
START iteration 27, CKPT_AND_STOP: False
[2022-12-05 12:23:11.688652] Finished iteration 28, CKPT_AND_STOP: False, flag: tensor([1], dtype=torch.int32), speed: 3554.242
Begin to save checkpont and exit
Opt ckpt time 3.4267020225524902
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 11 signal handler called with signal 10
Process done with return code 0
Parent process ID: 10381 node: 172.31.28.236
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 14 0 2006653.3203125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5367030
Min send: 10000000, max send 0
Min long send: 38387, max long send 60521
Min fwd: 45773, max fwd 60689; min bwd 93028, max bwd 103910
Min long fwd: 57033, max long fwd 64913; min long bwd 98397, max long bwd 102857
Time taken by simulation: 426 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 18 0 1481951.2939453125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4877293
Min send: 10000000, max send 0
Min long send: 38055, max long send 64155
Min fwd: 32292, max fwd 48132; min bwd 69316, max bwd 77937
Min long fwd: 43561, max long fwd 51496; min long bwd 71918, max long bwd 80151
Time taken by simulation: 782 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 32 0 876895.5078125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5017062
Min send: 10000000, max send 0
Min long send: 38071, max long send 66276
Min fwd: 18837, max fwd 35859; min bwd 42514, max bwd 56347
Min long fwd: 27753, max long fwd 35222; min long bwd 51765, max long bwd 59571
Time taken by simulation: 2285 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 42 0 610855.46875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4799842
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 10665, max fwd 27276; min bwd 28791, max bwd 43945
Min long fwd: 21459, max long fwd 30507; min long bwd 38642, max long bwd 48142
Time taken by simulation: 4302 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 64 0 343797.36328125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5360725
Min send: 10000000, max send 0
Min long send: 38056, max long send 68144
Min fwd: 5149, max fwd 20736; min bwd 17314, max bwd 33457
Min long fwd: 11639, max long fwd 22378; min long bwd 26559, max long bwd 34539
Time taken by simulation: 10384 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29838 microseconds

Stages 24
Micro-bs 1 Max mem: 2949765734.4
Predicted microbatch size for 24: 1
comm size 1638400
WARNING: no send time found, 24 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 24 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6789982
Min send: 10000000, max send 0
Min long send: 38055, max long send 74455
Min fwd: 26, max fwd 15549; min bwd 3842, max bwd 20573
Min long fwd: 7764, max long fwd 18097; min long bwd 11316, max long bwd 21840
Time taken by simulation: 45819 microseconds

{1: inf, 2: inf, 3: 5.36703, 4: 4.877293, 6: 5.017062, 8: 4.799842, 12: 5.360725, 16: 7.580423, 24: 6.789982}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1, 24: 1}
best config is: 8 1
expected time is 4.799842
3 per stage
24 servers!
Config:
ranks: range(11, 12)
train batch size: 128
partitions: 8
chunk_size: 1
data depth: 3
stage to rank map: 0,8,16;1,9,17;2,10,18;3,11,19;4,12,20;5,13,21;6,14,22;7,15,23;
World size is 24
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=11 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,8,16;1,9,17;2,10,18;3,11,19;4,12,20;5,13,21;6,14,22;7,15,23; --batch-size=42 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 28
dry run time 0.6902515888214111
SHARED WEIGHTS ARE
[(0, 7)]
this rank  11 is part of pipeline replica  1
42 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 11 signal handler called with signal 10
 > finished loading checkpoint in 43.353 seconds
Process done with return code 0
Parent process ID: 11180 node: 172.31.28.236
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 16 0 2198285.64453125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5986016
Min send: 10000000, max send 0
Min long send: 38293, max long send 60521
Min fwd: 45773, max fwd 59456; min bwd 93556, max bwd 103910
Min long fwd: 57033, max long fwd 64913; min long bwd 97741, max long bwd 104518
Time taken by simulation: 483 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 21 0 1478731.4453125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5493991
Min send: 10000000, max send 0
Min long send: 38109, max long send 64155
Min fwd: 32128, max fwd 48180; min bwd 67776, max bwd 77208
Min long fwd: 43175, max long fwd 51496; min long bwd 74514, max long bwd 81205
Time taken by simulation: 898 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 32 0 876895.5078125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5017062
Min send: 10000000, max send 0
Min long send: 38071, max long send 66276
Min fwd: 18837, max fwd 35859; min bwd 42514, max bwd 56347
Min long fwd: 27753, max long fwd 35222; min long bwd 51765, max long bwd 59571
Time taken by simulation: 2307 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 42 0 610855.46875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4799842
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 10665, max fwd 27276; min bwd 28791, max bwd 43945
Min long fwd: 21459, max long fwd 30507; min long bwd 38642, max long bwd 48142
Time taken by simulation: 4218 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 64 0 343797.36328125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5360725
Min send: 10000000, max send 0
Min long send: 38056, max long send 68144
Min fwd: 5149, max fwd 20736; min bwd 17314, max bwd 33457
Min long fwd: 11639, max long fwd 22378; min long bwd 26559, max long bwd 34539
Time taken by simulation: 10432 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29573 microseconds

Stages 24
Micro-bs 1 Max mem: 2949765734.4
Predicted microbatch size for 24: 1
comm size 1638400
WARNING: no send time found, 24 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 24 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6789982
Min send: 10000000, max send 0
Min long send: 38055, max long send 74455
Min fwd: 26, max fwd 15549; min bwd 3842, max bwd 20573
Min long fwd: 7764, max long fwd 18097; min long bwd 11316, max long bwd 21840
Time taken by simulation: 45770 microseconds

{1: inf, 2: inf, 3: 5.986016, 4: 5.493991, 6: 5.017062, 8: 4.799842, 12: 5.360725, 16: 7.580423, 24: 6.789982}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1, 24: 1}
best config is: 8 1
expected time is 4.799842
3 per stage
24 servers!
Config:
ranks: range(11, 12)
train batch size: 128
partitions: 8
chunk_size: 1
data depth: 3
stage to rank map: 0,8,16;1,9,17;2,10,18;3,11,19;4,12,20;5,13,21;6,14,22;7,15,23;
World size is 24
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=11 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,8,16;1,9,17;2,10,18;3,11,19;4,12,20;5,13,21;6,14,22;7,15,23; --batch-size=42 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 28
dry run time 0.8201174736022949
SHARED WEIGHTS ARE
[(0, 7)]
this rank  11 is part of pipeline replica  1
42 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
 > finished loading checkpoint in 40.919 seconds
Process done with return code 0
Parent process ID: 11950 node: 172.31.21.45
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 16 0 2198285.64453125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5986016
Min send: 10000000, max send 0
Min long send: 38293, max long send 60521
Min fwd: 45773, max fwd 59456; min bwd 93556, max bwd 103910
Min long fwd: 57033, max long fwd 64913; min long bwd 97741, max long bwd 104518
Time taken by simulation: 491 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 21 0 1478731.4453125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5493991
Min send: 10000000, max send 0
Min long send: 38109, max long send 64155
Min fwd: 32128, max fwd 48180; min bwd 67776, max bwd 77208
Min long fwd: 43175, max long fwd 51496; min long bwd 74514, max long bwd 81205
Time taken by simulation: 891 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 32 0 876895.5078125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5017062
Min send: 10000000, max send 0
Min long send: 38071, max long send 66276
Min fwd: 18837, max fwd 35859; min bwd 42514, max bwd 56347
Min long fwd: 27753, max long fwd 35222; min long bwd 51765, max long bwd 59571
Time taken by simulation: 2257 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 42 0 610855.46875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4799842
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 10665, max fwd 27276; min bwd 28791, max bwd 43945
Min long fwd: 21459, max long fwd 30507; min long bwd 38642, max long bwd 48142
Time taken by simulation: 4206 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 64 0 343797.36328125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5360725
Min send: 10000000, max send 0
Min long send: 38056, max long send 68144
Min fwd: 5149, max fwd 20736; min bwd 17314, max bwd 33457
Min long fwd: 11639, max long fwd 22378; min long bwd 26559, max long bwd 34539
Time taken by simulation: 10409 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29723 microseconds

Stages 24
Micro-bs 1 Max mem: 2949765734.4
Predicted microbatch size for 24: 1
comm size 1638400
WARNING: no send time found, 24 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 24 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6789982
Min send: 10000000, max send 0
Min long send: 38055, max long send 74455
Min fwd: 26, max fwd 15549; min bwd 3842, max bwd 20573
Min long fwd: 7764, max long fwd 18097; min long bwd 11316, max long bwd 21840
Time taken by simulation: 45944 microseconds

{1: inf, 2: inf, 3: 5.986016, 4: 5.493991, 6: 5.017062, 8: 4.799842, 12: 5.360725, 16: 7.580423, 24: 6.789982}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1, 24: 1}
best config is: 8 1
expected time is 4.799842
3 per stage
24 servers!
Config:
ranks: range(11, 12)
train batch size: 128
partitions: 8
chunk_size: 1
data depth: 3
stage to rank map: 0,8,16;1,9,17;2,10,18;3,11,19;4,12,20;5,13,21;6,14,22;7,15,23;
World size is 24
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=11 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,8,16;1,9,17;2,10,18;3,11,19;4,12,20;5,13,21;6,14,22;7,15,23; --batch-size=42 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 28
dry run time 0.2989006042480469
SHARED WEIGHTS ARE
[(0, 7)]
this rank  11 is part of pipeline replica  1
42 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
 > finished loading checkpoint in 36.509 seconds
START iteration 28, CKPT_AND_STOP: False
[2022-12-05 12:29:19.257186] Finished iteration 29, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 12541.814
START iteration 29, CKPT_AND_STOP: False
[2022-12-05 12:29:24.332684] Finished iteration 30, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5075.528
START iteration 30, CKPT_AND_STOP: False
[2022-12-05 12:29:30.934998] Finished iteration 31, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6602.314
START iteration 31, CKPT_AND_STOP: False
[2022-12-05 12:29:36.119622] Finished iteration 32, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5184.624
START iteration 32, CKPT_AND_STOP: False
[2022-12-05 12:29:41.499756] Finished iteration 33, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5380.131
START iteration 33, CKPT_AND_STOP: False
[2022-12-05 12:29:45.601481] Finished iteration 34, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4101.730
START iteration 34, CKPT_AND_STOP: False
[2022-12-05 12:29:49.682687] Finished iteration 35, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4081.206
START iteration 35, CKPT_AND_STOP: False
[2022-12-05 12:29:53.833769] Finished iteration 36, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4151.081
START iteration 36, CKPT_AND_STOP: False
[2022-12-05 12:29:57.928267] Finished iteration 37, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4094.500
START iteration 37, CKPT_AND_STOP: False
[2022-12-05 12:30:01.995696] Finished iteration 38, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4067.428
START iteration 38, CKPT_AND_STOP: False
[2022-12-05 12:30:06.042261] Finished iteration 39, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4046.564
START iteration 39, CKPT_AND_STOP: False
[2022-12-05 12:30:10.121287] Finished iteration 40, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4079.027
START iteration 40, CKPT_AND_STOP: False
[2022-12-05 12:30:14.246416] Finished iteration 41, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4125.129
START iteration 41, CKPT_AND_STOP: False
[2022-12-05 12:30:18.362043] Finished iteration 42, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4115.626
START iteration 42, CKPT_AND_STOP: False
[2022-12-05 12:30:22.480915] Finished iteration 43, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4118.873
START iteration 43, CKPT_AND_STOP: False
[2022-12-05 12:30:26.522029] Finished iteration 44, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4041.114
START iteration 44, CKPT_AND_STOP: False
[2022-12-05 12:30:30.512807] Finished iteration 45, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3990.778
START iteration 45, CKPT_AND_STOP: False
[2022-12-05 12:30:34.597606] Finished iteration 46, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4084.799
START iteration 46, CKPT_AND_STOP: False
[2022-12-05 12:30:38.723330] Finished iteration 47, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4125.725
START iteration 47, CKPT_AND_STOP: False
[2022-12-05 12:30:42.949568] Finished iteration 48, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4226.236
START iteration 48, CKPT_AND_STOP: False
[2022-12-05 12:30:47.035909] Finished iteration 49, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4086.343
START iteration 49, CKPT_AND_STOP: False
[2022-12-05 12:30:51.067084] Finished iteration 50, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4031.173
START iteration 50, CKPT_AND_STOP: False
[2022-12-05 12:30:55.113194] Finished iteration 51, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4046.110
START iteration 51, CKPT_AND_STOP: False
[2022-12-05 12:30:59.187897] Finished iteration 52, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4074.703
START iteration 52, CKPT_AND_STOP: False
[2022-12-05 12:31:03.257625] Finished iteration 53, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4069.729
START iteration 53, CKPT_AND_STOP: False
[2022-12-05 12:31:07.277783] Finished iteration 54, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4020.157
START iteration 54, CKPT_AND_STOP: False
[2022-12-05 12:31:11.339162] Finished iteration 55, CKPT_AND_STOP: False, flag: tensor([1], dtype=torch.int32), speed: 4061.378
Begin to save checkpont and exit
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 11 signal handler called with signal 10
Opt ckpt time 9.396868467330933
Process done with return code 0
Parent process ID: 12875 node: 172.31.21.45
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 18 0 1846814.0869140625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5987018
Min send: 10000000, max send 0
Min long send: 38387, max long send 60521
Min fwd: 45773, max fwd 59834; min bwd 93871, max bwd 104244
Min long fwd: 57033, max long fwd 64913; min long bwd 98140, max long bwd 103204
Time taken by simulation: 551 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 25 0 1338646.484375 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5804683
Min send: 10000000, max send 0
Min long send: 38055, max long send 64155
Min fwd: 30866, max fwd 48132; min bwd 66753, max bwd 79482
Min long fwd: 43307, max long fwd 50971; min long bwd 73461, max long bwd 80147
Time taken by simulation: 1064 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 42 0 770127.8076171875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5988334
Min send: 10000000, max send 0
Min long send: 38055, max long send 68059
Min fwd: 18837, max fwd 35859; min bwd 42358, max bwd 55388
Min long fwd: 27768, max long fwd 35092; min long bwd 51025, max long bwd 59414
Time taken by simulation: 2994 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 64 0 442992.24853515625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6489103
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 9901, max fwd 27419; min bwd 27605, max bwd 45180
Min long fwd: 21186, max long fwd 32479; min long bwd 41203, max long bwd 48557
Time taken by simulation: 6518 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8759578
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 5999, max fwd 22973; min bwd 17039, max bwd 34800
Min long fwd: 12470, max long fwd 25017; min long bwd 25566, max long bwd 36212
Time taken by simulation: 21354 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29530 microseconds

can't have 24 stages!
{1: inf, 2: inf, 3: 5.987018, 4: 5.804683, 6: 5.988334, 8: 6.489103, 12: 8.759578, 16: 7.580423}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1}
best config is: 4 1
expected time is 5.804683
5 per stage
20 servers!
Config:
ranks: range(11, 12)
train batch size: 128
partitions: 4
chunk_size: 1
data depth: 5
stage to rank map: 0,4,8,12,16;1,5,9,13,17;2,6,10,14,18;3,7,11,15,19;
World size is 20
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=11 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,4,8,12,16;1,5,9,13,17;2,6,10,14,18;3,7,11,15,19; --batch-size=25 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 55
dry run time 0.15797924995422363
SHARED WEIGHTS ARE
[(0, 3)]
this rank  11 is part of pipeline replica  2
25 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 11 signal handler called with signal 10
 > finished loading checkpoint in 64.917 seconds
Process done with return code 0
Parent process ID: 13709 node: 172.31.19.112
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 18 0 1846814.0869140625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5987018
Min send: 10000000, max send 0
Min long send: 38387, max long send 60521
Min fwd: 45773, max fwd 59834; min bwd 93871, max bwd 104244
Min long fwd: 57033, max long fwd 64913; min long bwd 98140, max long bwd 103204
Time taken by simulation: 672 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 25 0 1338646.484375 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5804683
Min send: 10000000, max send 0
Min long send: 38055, max long send 64155
Min fwd: 30866, max fwd 48132; min bwd 66753, max bwd 79482
Min long fwd: 43307, max long fwd 50971; min long bwd 73461, max long bwd 80147
Time taken by simulation: 1540 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 42 0 770127.8076171875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5988334
Min send: 10000000, max send 0
Min long send: 38055, max long send 68059
Min fwd: 18837, max fwd 35859; min bwd 42358, max bwd 55388
Min long fwd: 27768, max long fwd 35092; min long bwd 51025, max long bwd 59414
Time taken by simulation: 3901 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 64 0 442992.24853515625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6489103
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 9901, max fwd 27419; min bwd 27605, max bwd 45180
Min long fwd: 21186, max long fwd 32479; min long bwd 41203, max long bwd 48557
Time taken by simulation: 7879 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8759578
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 5999, max fwd 22973; min bwd 17039, max bwd 34800
Min long fwd: 12470, max long fwd 25017; min long bwd 25566, max long bwd 36212
Time taken by simulation: 26990 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 36522 microseconds

can't have 24 stages!
{1: inf, 2: inf, 3: 5.987018, 4: 5.804683, 6: 5.988334, 8: 6.489103, 12: 8.759578, 16: 7.580423}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1}
best config is: 4 1
expected time is 5.804683
5 per stage
20 servers!
Config:
ranks: range(11, 12)
train batch size: 128
partitions: 4
chunk_size: 1
data depth: 5
stage to rank map: 0,4,8,12,16;1,5,9,13,17;2,6,10,14,18;3,7,11,15,19;
World size is 20
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=11 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,4,8,12,16;1,5,9,13,17;2,6,10,14,18;3,7,11,15,19; --batch-size=25 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 55
dry run time 1.331225872039795
SHARED WEIGHTS ARE
[(0, 3)]
this rank  11 is part of pipeline replica  2
25 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
 > finished loading checkpoint in 82.519 seconds
START iteration 55, CKPT_AND_STOP: False
[2022-12-05 12:36:16.789917] Finished iteration 56, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 9406.528
START iteration 56, CKPT_AND_STOP: False
[2022-12-05 12:36:22.856624] Finished iteration 57, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6066.730
START iteration 57, CKPT_AND_STOP: False
[2022-12-05 12:36:28.816266] Finished iteration 58, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5959.644
START iteration 58, CKPT_AND_STOP: False
[2022-12-05 12:36:34.851841] Finished iteration 59, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6035.573
START iteration 59, CKPT_AND_STOP: False
[2022-12-05 12:36:40.793410] Finished iteration 60, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5941.570
START iteration 60, CKPT_AND_STOP: False
[2022-12-05 12:36:45.724901] Finished iteration 61, CKPT_AND_STOP: False, flag: tensor([6], dtype=torch.int32), speed: 4931.492
Begin to save checkpont and exit
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 11 signal handler called with signal 10
Opt ckpt time 11.807209968566895
Process done with return code 0
Parent process ID: 14821 node: 172.31.19.112
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 16 0 2198285.64453125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5986016
Min send: 10000000, max send 0
Min long send: 38293, max long send 60521
Min fwd: 45773, max fwd 59456; min bwd 93556, max bwd 103910
Min long fwd: 57033, max long fwd 64913; min long bwd 97741, max long bwd 104518
Time taken by simulation: 481 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 21 0 1478731.4453125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5493991
Min send: 10000000, max send 0
Min long send: 38109, max long send 64155
Min fwd: 32128, max fwd 48180; min bwd 67776, max bwd 77208
Min long fwd: 43175, max long fwd 51496; min long bwd 74514, max long bwd 81205
Time taken by simulation: 897 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 32 0 876895.5078125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5017062
Min send: 10000000, max send 0
Min long send: 38071, max long send 66276
Min fwd: 18837, max fwd 35859; min bwd 42514, max bwd 56347
Min long fwd: 27753, max long fwd 35222; min long bwd 51765, max long bwd 59571
Time taken by simulation: 2289 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 42 0 610855.46875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4799842
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 10665, max fwd 27276; min bwd 28791, max bwd 43945
Min long fwd: 21459, max long fwd 30507; min long bwd 38642, max long bwd 48142
Time taken by simulation: 4213 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 64 0 343797.36328125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5360725
Min send: 10000000, max send 0
Min long send: 38056, max long send 68144
Min fwd: 5149, max fwd 20736; min bwd 17314, max bwd 33457
Min long fwd: 11639, max long fwd 22378; min long bwd 26559, max long bwd 34539
Time taken by simulation: 10462 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29738 microseconds

Stages 24
Micro-bs 1 Max mem: 2949765734.4
Predicted microbatch size for 24: 1
comm size 1638400
WARNING: no send time found, 24 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 24 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6789982
Min send: 10000000, max send 0
Min long send: 38055, max long send 74455
Min fwd: 26, max fwd 15549; min bwd 3842, max bwd 20573
Min long fwd: 7764, max long fwd 18097; min long bwd 11316, max long bwd 21840
Time taken by simulation: 45898 microseconds

{1: inf, 2: inf, 3: 5.986016, 4: 5.493991, 6: 5.017062, 8: 4.799842, 12: 5.360725, 16: 7.580423, 24: 6.789982}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1, 24: 1}
best config is: 8 1
expected time is 4.799842
3 per stage
24 servers!
Config:
ranks: range(11, 12)
train batch size: 128
partitions: 8
chunk_size: 1
data depth: 3
stage to rank map: 0,8,16;1,9,17;2,10,18;3,11,19;4,12,20;5,13,21;6,14,22;7,15,23;
World size is 24
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=11 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,8,16;1,9,17;2,10,18;3,11,19;4,12,20;5,13,21;6,14,22;7,15,23; --batch-size=42 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 61
dry run time 1.0007834434509277
SHARED WEIGHTS ARE
[(0, 7)]
this rank  11 is part of pipeline replica  1
42 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 11 signal handler called with signal 10
 > finished loading checkpoint in 38.552 seconds
Process done with return code 0
Parent process ID: 15634 node: 172.31.19.112
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 16 0 2198285.64453125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5986016
Min send: 10000000, max send 0
Min long send: 38293, max long send 60521
Min fwd: 45773, max fwd 59456; min bwd 93556, max bwd 103910
Min long fwd: 57033, max long fwd 64913; min long bwd 97741, max long bwd 104518
Time taken by simulation: 478 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 21 0 1478731.4453125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5493991
Min send: 10000000, max send 0
Min long send: 38109, max long send 64155
Min fwd: 32128, max fwd 48180; min bwd 67776, max bwd 77208
Min long fwd: 43175, max long fwd 51496; min long bwd 74514, max long bwd 81205
Time taken by simulation: 919 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 32 0 876895.5078125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5017062
Min send: 10000000, max send 0
Min long send: 38071, max long send 66276
Min fwd: 18837, max fwd 35859; min bwd 42514, max bwd 56347
Min long fwd: 27753, max long fwd 35222; min long bwd 51765, max long bwd 59571
Time taken by simulation: 2300 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 42 0 610855.46875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4799842
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 10665, max fwd 27276; min bwd 28791, max bwd 43945
Min long fwd: 21459, max long fwd 30507; min long bwd 38642, max long bwd 48142
Time taken by simulation: 4241 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 64 0 343797.36328125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5360725
Min send: 10000000, max send 0
Min long send: 38056, max long send 68144
Min fwd: 5149, max fwd 20736; min bwd 17314, max bwd 33457
Min long fwd: 11639, max long fwd 22378; min long bwd 26559, max long bwd 34539
Time taken by simulation: 10437 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29769 microseconds

Stages 24
Micro-bs 1 Max mem: 2949765734.4
Predicted microbatch size for 24: 1
comm size 1638400
WARNING: no send time found, 24 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 24 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6789982
Min send: 10000000, max send 0
Min long send: 38055, max long send 74455
Min fwd: 26, max fwd 15549; min bwd 3842, max bwd 20573
Min long fwd: 7764, max long fwd 18097; min long bwd 11316, max long bwd 21840
Time taken by simulation: 45727 microseconds

{1: inf, 2: inf, 3: 5.986016, 4: 5.493991, 6: 5.017062, 8: 4.799842, 12: 5.360725, 16: 7.580423, 24: 6.789982}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1, 24: 1}
best config is: 8 1
expected time is 4.799842
3 per stage
24 servers!
Config:
ranks: range(11, 12)
train batch size: 128
partitions: 8
chunk_size: 1
data depth: 3
stage to rank map: 0,8,16;1,9,17;2,10,18;3,11,19;4,12,20;5,13,21;6,14,22;7,15,23;
World size is 24
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=11 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,8,16;1,9,17;2,10,18;3,11,19;4,12,20;5,13,21;6,14,22;7,15,23; --batch-size=42 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 61
dry run time 1.0381269454956055
SHARED WEIGHTS ARE
[(0, 7)]
this rank  11 is part of pipeline replica  1
42 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 11 signal handler called with signal 10
 > finished loading checkpoint in 35.918 seconds
Process done with return code 0
Parent process ID: 16462 node: 172.31.28.143
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 18 0 1846814.0869140625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5987018
Min send: 10000000, max send 0
Min long send: 38387, max long send 60521
Min fwd: 45773, max fwd 59834; min bwd 93871, max bwd 104244
Min long fwd: 57033, max long fwd 64913; min long bwd 98140, max long bwd 103204
Time taken by simulation: 536 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 25 0 1338646.484375 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5804683
Min send: 10000000, max send 0
Min long send: 38055, max long send 64155
Min fwd: 30866, max fwd 48132; min bwd 66753, max bwd 79482
Min long fwd: 43307, max long fwd 50971; min long bwd 73461, max long bwd 80147
Time taken by simulation: 1066 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 42 0 770127.8076171875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5988334
Min send: 10000000, max send 0
Min long send: 38055, max long send 68059
Min fwd: 18837, max fwd 35859; min bwd 42358, max bwd 55388
Min long fwd: 27768, max long fwd 35092; min long bwd 51025, max long bwd 59414
Time taken by simulation: 2993 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 64 0 442992.24853515625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6489103
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 9901, max fwd 27419; min bwd 27605, max bwd 45180
Min long fwd: 21186, max long fwd 32479; min long bwd 41203, max long bwd 48557
Time taken by simulation: 6497 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8759578
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 5999, max fwd 22973; min bwd 17039, max bwd 34800
Min long fwd: 12470, max long fwd 25017; min long bwd 25566, max long bwd 36212
Time taken by simulation: 21471 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 30006 microseconds

can't have 24 stages!
{1: inf, 2: inf, 3: 5.987018, 4: 5.804683, 6: 5.988334, 8: 6.489103, 12: 8.759578, 16: 7.580423}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1}
best config is: 4 1
expected time is 5.804683
5 per stage
20 servers!
Config:
ranks: range(11, 12)
train batch size: 128
partitions: 4
chunk_size: 1
data depth: 5
stage to rank map: 0,4,8,12,16;1,5,9,13,17;2,6,10,14,18;3,7,11,15,19;
World size is 20
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=11 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,4,8,12,16;1,5,9,13,17;2,6,10,14,18;3,7,11,15,19; --batch-size=25 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 61
dry run time 1.1879267692565918
SHARED WEIGHTS ARE
[(0, 3)]
this rank  11 is part of pipeline replica  2
25 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 11 signal handler called with signal 10
Process done with return code 1
Parent process ID: 17645 node: 172.31.28.143
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 21 0 1916562.744140625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6803052
Min send: 10000000, max send 0
Min long send: 38109, max long send 62549
Min fwd: 45773, max fwd 59456; min bwd 92874, max bwd 103910
Min long fwd: 57033, max long fwd 64913; min long bwd 96930, max long bwd 106927
Time taken by simulation: 615 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 25 0 1338646.484375 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5804683
Min send: 10000000, max send 0
Min long send: 38055, max long send 64155
Min fwd: 30866, max fwd 48132; min bwd 66753, max bwd 79482
Min long fwd: 43307, max long fwd 50971; min long bwd 73461, max long bwd 80147
Time taken by simulation: 1101 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 42 0 770127.8076171875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5988334
Min send: 10000000, max send 0
Min long send: 38055, max long send 68059
Min fwd: 18837, max fwd 35859; min bwd 42358, max bwd 55388
Min long fwd: 27768, max long fwd 35092; min long bwd 51025, max long bwd 59414
Time taken by simulation: 2954 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 64 0 442992.24853515625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6489103
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 9901, max fwd 27419; min bwd 27605, max bwd 45180
Min long fwd: 21186, max long fwd 32479; min long bwd 41203, max long bwd 48557
Time taken by simulation: 6448 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8759578
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 5999, max fwd 22973; min bwd 17039, max bwd 34800
Min long fwd: 12470, max long fwd 25017; min long bwd 25566, max long bwd 36212
Time taken by simulation: 21390 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29705 microseconds

can't have 24 stages!
{1: inf, 2: inf, 3: 6.803052, 4: 5.804683, 6: 5.988334, 8: 6.489103, 12: 8.759578, 16: 7.580423}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1}
best config is: 4 1
expected time is 5.804683
5 per stage
20 servers!
Config:
ranks: range(11, 12)
train batch size: 128
partitions: 4
chunk_size: 1
data depth: 5
stage to rank map: 0,4,8,12,16;1,5,9,13,17;2,6,10,14,18;3,7,11,15,19;
World size is 20
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=11 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,4,8,12,16;1,5,9,13,17;2,6,10,14,18;3,7,11,15,19; --batch-size=25 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 61
dry run time 1.8041975498199463
SHARED WEIGHTS ARE
[(0, 3)]
this rank  11 is part of pipeline replica  2
25 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 11 signal handler called with signal 10
 > finished loading checkpoint in 68.011 seconds
Process done with return code 0
Parent process ID: 18870 node: 172.31.28.143
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 18 0 1846814.0869140625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5987018
Min send: 10000000, max send 0
Min long send: 38387, max long send 60521
Min fwd: 45773, max fwd 59834; min bwd 93871, max bwd 104244
Min long fwd: 57033, max long fwd 64913; min long bwd 98140, max long bwd 103204
Time taken by simulation: 541 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 25 0 1338646.484375 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5804683
Min send: 10000000, max send 0
Min long send: 38055, max long send 64155
Min fwd: 30866, max fwd 48132; min bwd 66753, max bwd 79482
Min long fwd: 43307, max long fwd 50971; min long bwd 73461, max long bwd 80147
Time taken by simulation: 1096 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 42 0 770127.8076171875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5988334
Min send: 10000000, max send 0
Min long send: 38055, max long send 68059
Min fwd: 18837, max fwd 35859; min bwd 42358, max bwd 55388
Min long fwd: 27768, max long fwd 35092; min long bwd 51025, max long bwd 59414
Time taken by simulation: 2987 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 64 0 442992.24853515625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6489103
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 9901, max fwd 27419; min bwd 27605, max bwd 45180
Min long fwd: 21186, max long fwd 32479; min long bwd 41203, max long bwd 48557
Time taken by simulation: 6527 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8759578
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 5999, max fwd 22973; min bwd 17039, max bwd 34800
Min long fwd: 12470, max long fwd 25017; min long bwd 25566, max long bwd 36212
Time taken by simulation: 21356 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29561 microseconds

can't have 24 stages!
{1: inf, 2: inf, 3: 5.987018, 4: 5.804683, 6: 5.988334, 8: 6.489103, 12: 8.759578, 16: 7.580423}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1}
best config is: 4 1
expected time is 5.804683
5 per stage
20 servers!
Config:
ranks: range(11, 12)
train batch size: 128
partitions: 4
chunk_size: 1
data depth: 5
stage to rank map: 0,4,8,12,16;1,5,9,13,17;2,6,10,14,18;3,7,11,15,19;
World size is 20
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=11 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,4,8,12,16;1,5,9,13,17;2,6,10,14,18;3,7,11,15,19; --batch-size=25 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 61
dry run time 1.2528183460235596
SHARED WEIGHTS ARE
[(0, 3)]
this rank  11 is part of pipeline replica  2
25 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
 > finished loading checkpoint in 86.313 seconds
START iteration 61, CKPT_AND_STOP: False
[2022-12-05 12:46:02.447047] Finished iteration 62, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 9484.985
START iteration 62, CKPT_AND_STOP: False
[2022-12-05 12:46:08.358494] Finished iteration 63, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5911.458
START iteration 63, CKPT_AND_STOP: False
[2022-12-05 12:46:14.254113] Finished iteration 64, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5895.621
START iteration 64, CKPT_AND_STOP: False
[2022-12-05 12:46:20.174637] Finished iteration 65, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5920.514
START iteration 65, CKPT_AND_STOP: False
[2022-12-05 12:46:26.126838] Finished iteration 66, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5952.210
START iteration 66, CKPT_AND_STOP: False
[2022-12-05 12:46:30.991080] Finished iteration 67, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4864.244
START iteration 67, CKPT_AND_STOP: False
[2022-12-05 12:46:35.867884] Finished iteration 68, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4876.804
START iteration 68, CKPT_AND_STOP: False
[2022-12-05 12:46:40.808621] Finished iteration 69, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4940.738
START iteration 69, CKPT_AND_STOP: False
[2022-12-05 12:46:45.689917] Finished iteration 70, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4881.296
START iteration 70, CKPT_AND_STOP: False
[2022-12-05 12:46:50.675629] Finished iteration 71, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4985.711
START iteration 71, CKPT_AND_STOP: False
[2022-12-05 12:46:55.652255] Finished iteration 72, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4976.623
START iteration 72, CKPT_AND_STOP: False
[2022-12-05 12:47:00.529143] Finished iteration 73, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4876.872
START iteration 73, CKPT_AND_STOP: False
[2022-12-05 12:47:05.486273] Finished iteration 74, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4957.148
START iteration 74, CKPT_AND_STOP: False
[2022-12-05 12:47:10.423437] Finished iteration 75, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4937.165
START iteration 75, CKPT_AND_STOP: False
[2022-12-05 12:47:15.285214] Finished iteration 76, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4861.775
START iteration 76, CKPT_AND_STOP: False
[2022-12-05 12:47:20.145082] Finished iteration 77, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4859.869
START iteration 77, CKPT_AND_STOP: False
[2022-12-05 12:47:25.091631] Finished iteration 78, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4946.548
START iteration 78, CKPT_AND_STOP: False
[2022-12-05 12:47:29.939083] Finished iteration 79, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4847.451
START iteration 79, CKPT_AND_STOP: False
[2022-12-05 12:47:34.837828] Finished iteration 80, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4898.746
START iteration 80, CKPT_AND_STOP: False
[2022-12-05 12:47:39.744263] Finished iteration 81, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4906.436
START iteration 81, CKPT_AND_STOP: False
[2022-12-05 12:47:44.671757] Finished iteration 82, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4927.492
START iteration 82, CKPT_AND_STOP: False
[2022-12-05 12:47:49.598860] Finished iteration 83, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4927.103
START iteration 83, CKPT_AND_STOP: False
[2022-12-05 12:47:54.447749] Finished iteration 84, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4848.890
START iteration 84, CKPT_AND_STOP: False
[2022-12-05 12:47:59.356182] Finished iteration 85, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4908.436
START iteration 85, CKPT_AND_STOP: False
[2022-12-05 12:48:04.235603] Finished iteration 86, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4879.418
START iteration 86, CKPT_AND_STOP: False
[2022-12-05 12:48:09.139347] Finished iteration 87, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4903.744
START iteration 87, CKPT_AND_STOP: False
[2022-12-05 12:48:14.075360] Finished iteration 88, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4936.013
START iteration 88, CKPT_AND_STOP: False
[2022-12-05 12:48:19.066848] Finished iteration 89, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4991.487
START iteration 89, CKPT_AND_STOP: False
[2022-12-05 12:48:23.971030] Finished iteration 90, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4904.182
START iteration 90, CKPT_AND_STOP: False
[2022-12-05 12:48:28.870853] Finished iteration 91, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4899.821
START iteration 91, CKPT_AND_STOP: False
[2022-12-05 12:48:33.862059] Finished iteration 92, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4991.208
START iteration 92, CKPT_AND_STOP: False
[2022-12-05 12:48:38.755332] Finished iteration 93, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4893.274
START iteration 93, CKPT_AND_STOP: False
[2022-12-05 12:48:43.610590] Finished iteration 94, CKPT_AND_STOP: False, flag: tensor([3], dtype=torch.int32), speed: 4855.258
Begin to save checkpont and exit
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 11 signal handler called with signal 10
Opt ckpt time 12.171528339385986
Process done with return code 0
Parent process ID: 20179 node: 172.31.28.143
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 18 0 1846814.0869140625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5987018
Min send: 10000000, max send 0
Min long send: 38387, max long send 60521
Min fwd: 45773, max fwd 59834; min bwd 93871, max bwd 104244
Min long fwd: 57033, max long fwd 64913; min long bwd 98140, max long bwd 103204
Time taken by simulation: 528 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 25 0 1338646.484375 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5804683
Min send: 10000000, max send 0
Min long send: 38055, max long send 64155
Min fwd: 30866, max fwd 48132; min bwd 66753, max bwd 79482
Min long fwd: 43307, max long fwd 50971; min long bwd 73461, max long bwd 80147
Time taken by simulation: 1063 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 42 0 770127.8076171875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5988334
Min send: 10000000, max send 0
Min long send: 38055, max long send 68059
Min fwd: 18837, max fwd 35859; min bwd 42358, max bwd 55388
Min long fwd: 27768, max long fwd 35092; min long bwd 51025, max long bwd 59414
Time taken by simulation: 3019 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 64 0 442992.24853515625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6489103
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 9901, max fwd 27419; min bwd 27605, max bwd 45180
Min long fwd: 21186, max long fwd 32479; min long bwd 41203, max long bwd 48557
Time taken by simulation: 6511 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8759578
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 5999, max fwd 22973; min bwd 17039, max bwd 34800
Min long fwd: 12470, max long fwd 25017; min long bwd 25566, max long bwd 36212
Time taken by simulation: 21335 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29565 microseconds

can't have 24 stages!
{1: inf, 2: inf, 3: 5.987018, 4: 5.804683, 6: 5.988334, 8: 6.489103, 12: 8.759578, 16: 7.580423}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1}
best config is: 4 1
expected time is 5.804683
5 per stage
20 servers!
Config:
ranks: range(11, 12)
train batch size: 128
partitions: 4
chunk_size: 1
data depth: 5
stage to rank map: 0,4,8,12,16;1,5,9,13,17;2,6,10,14,18;3,7,11,15,19;
World size is 20
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=11 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,4,8,12,16;1,5,9,13,17;2,6,10,14,18;3,7,11,15,19; --batch-size=25 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 94
dry run time 1.4262588024139404
SHARED WEIGHTS ARE
[(0, 3)]
this rank  11 is part of pipeline replica  2
25 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
 > finished loading checkpoint in 70.741 seconds
START iteration 94, CKPT_AND_STOP: False
[2022-12-05 12:51:01.027705] Finished iteration 95, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 9615.434
START iteration 95, CKPT_AND_STOP: False
[2022-12-05 12:51:07.014217] Finished iteration 96, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5986.530
START iteration 96, CKPT_AND_STOP: False
[2022-12-05 12:51:12.957091] Finished iteration 97, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5942.874
START iteration 97, CKPT_AND_STOP: False
[2022-12-05 12:51:18.938989] Finished iteration 98, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5981.901
START iteration 98, CKPT_AND_STOP: False
[2022-12-05 12:51:24.752512] Finished iteration 99, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5813.523
START iteration 99, CKPT_AND_STOP: False
[2022-12-05 12:51:29.626312] Finished iteration 100, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4873.801
START iteration 100, CKPT_AND_STOP: False
[2022-12-05 12:51:34.467833] Finished iteration 101, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4841.518
START iteration 101, CKPT_AND_STOP: False
[2022-12-05 12:51:39.347298] Finished iteration 102, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4879.467
START iteration 102, CKPT_AND_STOP: False
11 : update_scale(): _has_overflow, dynamic. _loss_scale =  65536.0
[2022-12-05 12:51:44.175534] Finished iteration 103, CKPT_AND_STOP: False, flag: tensor([3], dtype=torch.int32), speed: 4828.236
Begin to save checkpont and exit
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 11 signal handler called with signal 10
Opt ckpt time 12.841691255569458
Process done with return code 0
Parent process ID: 21437 node: 172.31.28.143
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 12 0 2007202.880859375 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4913759
Min send: 10000000, max send 0
Min long send: 38387, max long send 60521
Min fwd: 45773, max fwd 58711; min bwd 92748, max bwd 103910
Min long fwd: 56704, max long fwd 63285; min long bwd 98353, max long bwd 106648
Time taken by simulation: 378 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 18 0 1481951.2939453125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4877293
Min send: 10000000, max send 0
Min long send: 38055, max long send 64155
Min fwd: 32292, max fwd 48132; min bwd 69316, max bwd 77937
Min long fwd: 43561, max long fwd 51496; min long bwd 71918, max long bwd 80151
Time taken by simulation: 778 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 25 0 976051.4526367188 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4466988
Min send: 10000000, max send 0
Min long send: 38237, max long send 65217
Min fwd: 19236, max fwd 35580; min bwd 42158, max bwd 57089
Min long fwd: 24076, max long fwd 35713; min long bwd 50505, max long bwd 59414
Time taken by simulation: 1790 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 42 0 610855.46875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4799842
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 10665, max fwd 27276; min bwd 28791, max bwd 43945
Min long fwd: 21459, max long fwd 30507; min long bwd 38642, max long bwd 48142
Time taken by simulation: 4237 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 64 0 343797.36328125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5360725
Min send: 10000000, max send 0
Min long send: 38056, max long send 68144
Min fwd: 5149, max fwd 20736; min bwd 17314, max bwd 33457
Min long fwd: 11639, max long fwd 22378; min long bwd 26559, max long bwd 34539
Time taken by simulation: 10464 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29731 microseconds

Stages 24
Micro-bs 1 Max mem: 2949765734.4
Predicted microbatch size for 24: 1
comm size 1638400
WARNING: no send time found, 24 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 24 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6789982
Min send: 10000000, max send 0
Min long send: 38055, max long send 74455
Min fwd: 26, max fwd 15549; min bwd 3842, max bwd 20573
Min long fwd: 7764, max long fwd 18097; min long bwd 11316, max long bwd 21840
Time taken by simulation: 45994 microseconds

{1: inf, 2: inf, 3: 4.913759, 4: 4.877293, 6: 4.466988, 8: 4.799842, 12: 5.360725, 16: 7.580423, 24: 6.789982}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1, 24: 1}
best config is: 6 1
expected time is 4.466988
5 per stage
30 servers!
Config:
ranks: range(11, 12)
train batch size: 128
partitions: 6
chunk_size: 1
data depth: 5
stage to rank map: 0,6,12,18,24;1,7,13,19,25;2,8,14,20,26;3,9,15,21,27;4,10,16,22,28;5,11,17,23,29;
World size is 30
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=11 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,6,12,18,24;1,7,13,19,25;2,8,14,20,26;3,9,15,21,27;4,10,16,22,28;5,11,17,23,29; --batch-size=25 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 103
dry run time 1.2363033294677734
SHARED WEIGHTS ARE
[(0, 5)]
this rank  11 is part of pipeline replica  1
25 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 11 signal handler called with signal 10
 > finished loading checkpoint in 50.429 seconds
Process done with return code 0
Parent process ID: 22395 node: 172.31.28.143
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 12 0 2007202.880859375 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4913759
Min send: 10000000, max send 0
Min long send: 38387, max long send 60521
Min fwd: 45773, max fwd 58711; min bwd 92748, max bwd 103910
Min long fwd: 56704, max long fwd 63285; min long bwd 98353, max long bwd 106648
Time taken by simulation: 371 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 16 0 1727535.5224609375 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4820532
Min send: 10000000, max send 0
Min long send: 38109, max long send 64155
Min fwd: 32292, max fwd 48132; min bwd 69446, max bwd 80083
Min long fwd: 43192, max long fwd 50561; min long bwd 74672, max long bwd 80151
Time taken by simulation: 688 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 25 0 976051.4526367188 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4466988
Min send: 10000000, max send 0
Min long send: 38237, max long send 65217
Min fwd: 19236, max fwd 35580; min bwd 42158, max bwd 57089
Min long fwd: 24076, max long fwd 35713; min long bwd 50505, max long bwd 59414
Time taken by simulation: 1776 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 32 0 700971.3134765625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4198444
Min send: 10000000, max send 0
Min long send: 38109, max long send 68059
Min fwd: 11544, max fwd 27276; min bwd 28686, max bwd 44788
Min long fwd: 22228, max long fwd 29781; min long bwd 41714, max long bwd 48296
Time taken by simulation: 3210 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 64 0 343797.36328125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5360725
Min send: 10000000, max send 0
Min long send: 38056, max long send 68144
Min fwd: 5149, max fwd 20736; min bwd 17314, max bwd 33457
Min long fwd: 11639, max long fwd 22378; min long bwd 26559, max long bwd 34539
Time taken by simulation: 10727 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 64 0 294405.0598144531 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5043807
Min send: 10000000, max send 0
Min long send: 38109, max long send 77793
Min fwd: 803, max fwd 17174; min bwd 10907, max bwd 28118
Min long fwd: 12084, max long fwd 20913; min long bwd 17914, max long bwd 26363
Time taken by simulation: 14185 microseconds

Stages 24
Micro-bs 1 Max mem: 2949765734.4
Predicted microbatch size for 24: 1
comm size 1638400
WARNING: no send time found, 24 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 24 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6789982
Min send: 10000000, max send 0
Min long send: 38055, max long send 74455
Min fwd: 26, max fwd 15549; min bwd 3842, max bwd 20573
Min long fwd: 7764, max long fwd 18097; min long bwd 11316, max long bwd 21840
Time taken by simulation: 45796 microseconds

{1: inf, 2: inf, 3: 4.913759, 4: 4.820532, 6: 4.466988, 8: 4.198444, 12: 5.360725, 16: 5.043807, 24: 6.789982}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1, 24: 1}
best config is: 8 1
expected time is 4.198444
4 per stage
32 servers!
Config:
ranks: range(11, 12)
train batch size: 128
partitions: 8
chunk_size: 1
data depth: 4
stage to rank map: 0,8,16,24;1,9,17,25;2,10,18,26;3,11,19,27;4,12,20,28;5,13,21,29;6,14,22,30;7,15,23,31;
World size is 32
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=11 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,8,16,24;1,9,17,25;2,10,18,26;3,11,19,27;4,12,20,28;5,13,21,29;6,14,22,30;7,15,23,31; --batch-size=32 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 103
dry run time 1.2662954330444336
SHARED WEIGHTS ARE
[(0, 7)]
this rank  11 is part of pipeline replica  1
32 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
 > finished loading checkpoint in 43.988 seconds
START iteration 103, CKPT_AND_STOP: False
11 : update_scale(): _has_overflow, dynamic. _loss_scale =  65536.0
[2022-12-05 12:55:05.372892] Finished iteration 104, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 11978.123
START iteration 104, CKPT_AND_STOP: False
11 : update_scale(): _has_overflow, dynamic. _loss_scale =  32768.0
[2022-12-05 12:55:10.049482] Finished iteration 105, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4676.606
START iteration 105, CKPT_AND_STOP: False
11 : update_scale(): _has_overflow, dynamic. _loss_scale =  16384.0
[2022-12-05 12:55:14.679298] Finished iteration 106, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4629.819
START iteration 106, CKPT_AND_STOP: False
[2022-12-05 12:55:19.348713] Finished iteration 107, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4669.413
START iteration 107, CKPT_AND_STOP: False
[2022-12-05 12:55:24.013575] Finished iteration 108, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4664.864
START iteration 108, CKPT_AND_STOP: False
[2022-12-05 12:55:27.603672] Finished iteration 109, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3590.096
START iteration 109, CKPT_AND_STOP: False
[2022-12-05 12:55:31.227657] Finished iteration 110, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3623.988
START iteration 110, CKPT_AND_STOP: False
[2022-12-05 12:55:34.784519] Finished iteration 111, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3556.861
START iteration 111, CKPT_AND_STOP: False
[2022-12-05 12:55:38.398871] Finished iteration 112, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3614.350
START iteration 112, CKPT_AND_STOP: False
[2022-12-05 12:55:42.085159] Finished iteration 113, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3686.290
START iteration 113, CKPT_AND_STOP: False
[2022-12-05 12:55:45.646427] Finished iteration 114, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3561.265
START iteration 114, CKPT_AND_STOP: False
[2022-12-05 12:55:49.214242] Finished iteration 115, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3567.817
START iteration 115, CKPT_AND_STOP: False
[2022-12-05 12:55:52.780252] Finished iteration 116, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3566.015
START iteration 116, CKPT_AND_STOP: False
[2022-12-05 12:55:56.362935] Finished iteration 117, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3582.679
START iteration 117, CKPT_AND_STOP: False
[2022-12-05 12:55:59.969374] Finished iteration 118, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3606.439
START iteration 118, CKPT_AND_STOP: False
[2022-12-05 12:56:03.547699] Finished iteration 119, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3578.323
START iteration 119, CKPT_AND_STOP: False
[2022-12-05 12:56:07.135768] Finished iteration 120, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3588.072
START iteration 120, CKPT_AND_STOP: False
[2022-12-05 12:56:10.795617] Finished iteration 121, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3659.848
START iteration 121, CKPT_AND_STOP: False
[2022-12-05 12:56:14.442627] Finished iteration 122, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3647.010
START iteration 122, CKPT_AND_STOP: False
[2022-12-05 12:56:18.077911] Finished iteration 123, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3635.284
START iteration 123, CKPT_AND_STOP: False
[2022-12-05 12:56:21.755738] Finished iteration 124, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3677.830
START iteration 124, CKPT_AND_STOP: False
[2022-12-05 12:56:25.401662] Finished iteration 125, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3645.922
START iteration 125, CKPT_AND_STOP: False
[2022-12-05 12:56:29.022915] Finished iteration 126, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3621.252
START iteration 126, CKPT_AND_STOP: False
[2022-12-05 12:56:32.548123] Finished iteration 127, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3525.207
START iteration 127, CKPT_AND_STOP: False
[2022-12-05 12:56:36.174233] Finished iteration 128, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3626.109
START iteration 128, CKPT_AND_STOP: False
[2022-12-05 12:56:39.827579] Finished iteration 129, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3653.346
START iteration 129, CKPT_AND_STOP: False
[2022-12-05 12:56:43.446002] Finished iteration 130, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3618.424
START iteration 130, CKPT_AND_STOP: False
[2022-12-05 12:56:47.109206] Finished iteration 131, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3663.205
START iteration 131, CKPT_AND_STOP: False
[2022-12-05 12:56:50.714953] Finished iteration 132, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3605.747
START iteration 132, CKPT_AND_STOP: False
[2022-12-05 12:56:54.290710] Finished iteration 133, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3575.754
START iteration 133, CKPT_AND_STOP: False
[2022-12-05 12:56:57.863551] Finished iteration 134, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3572.843
START iteration 134, CKPT_AND_STOP: False
[2022-12-05 12:57:01.447605] Finished iteration 135, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3584.054
START iteration 135, CKPT_AND_STOP: False
[2022-12-05 12:57:05.073553] Finished iteration 136, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3625.947
START iteration 136, CKPT_AND_STOP: False
[2022-12-05 12:57:08.752468] Finished iteration 137, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3678.913
START iteration 137, CKPT_AND_STOP: False
[2022-12-05 12:57:12.324553] Finished iteration 138, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3572.085
START iteration 138, CKPT_AND_STOP: False
[2022-12-05 12:57:15.987124] Finished iteration 139, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3662.574
START iteration 139, CKPT_AND_STOP: False
[2022-12-05 12:57:19.623803] Finished iteration 140, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3636.680
START iteration 140, CKPT_AND_STOP: False
[2022-12-05 12:57:23.272632] Finished iteration 141, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3648.826
START iteration 141, CKPT_AND_STOP: False
[2022-12-05 12:57:26.889975] Finished iteration 142, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3617.344
START iteration 142, CKPT_AND_STOP: False
[2022-12-05 12:57:30.465771] Finished iteration 143, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3575.794
START iteration 143, CKPT_AND_STOP: False
[2022-12-05 12:57:34.092294] Finished iteration 144, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3626.525
START iteration 144, CKPT_AND_STOP: False
[2022-12-05 12:57:37.641649] Finished iteration 145, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3549.356
START iteration 145, CKPT_AND_STOP: False
[2022-12-05 12:57:41.227746] Finished iteration 146, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3586.096
START iteration 146, CKPT_AND_STOP: False
[2022-12-05 12:57:44.787100] Finished iteration 147, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3559.354
START iteration 147, CKPT_AND_STOP: False
[2022-12-05 12:57:48.398057] Finished iteration 148, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3610.957
START iteration 148, CKPT_AND_STOP: False
[2022-12-05 12:57:51.982330] Finished iteration 149, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3584.276
START iteration 149, CKPT_AND_STOP: False
[2022-12-05 12:57:55.612616] Finished iteration 150, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3630.280
START iteration 150, CKPT_AND_STOP: False
[2022-12-05 12:57:59.252325] Finished iteration 151, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3639.712
START iteration 151, CKPT_AND_STOP: False
[2022-12-05 12:58:02.842400] Finished iteration 152, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3590.074
START iteration 152, CKPT_AND_STOP: False
[2022-12-05 12:58:06.434061] Finished iteration 153, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3591.660
START iteration 153, CKPT_AND_STOP: False
[2022-12-05 12:58:10.061346] Finished iteration 154, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3627.286
START iteration 154, CKPT_AND_STOP: False
[2022-12-05 12:58:13.762041] Finished iteration 155, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3700.693
START iteration 155, CKPT_AND_STOP: False
[2022-12-05 12:58:17.386797] Finished iteration 156, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3624.755
START iteration 156, CKPT_AND_STOP: False
[2022-12-05 12:58:21.095923] Finished iteration 157, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3709.127
START iteration 157, CKPT_AND_STOP: False
[2022-12-05 12:58:24.692012] Finished iteration 158, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3596.089
START iteration 158, CKPT_AND_STOP: False
[2022-12-05 12:58:28.302724] Finished iteration 159, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3610.712
START iteration 159, CKPT_AND_STOP: False
[2022-12-05 12:58:31.860030] Finished iteration 160, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3557.307
START iteration 160, CKPT_AND_STOP: False
[2022-12-05 12:58:35.539277] Finished iteration 161, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3679.247
START iteration 161, CKPT_AND_STOP: False
[2022-12-05 12:58:39.135326] Finished iteration 162, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3596.049
START iteration 162, CKPT_AND_STOP: False
[2022-12-05 12:58:42.768121] Finished iteration 163, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3632.795
START iteration 163, CKPT_AND_STOP: False
[2022-12-05 12:58:46.391849] Finished iteration 164, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3623.729
START iteration 164, CKPT_AND_STOP: False
[2022-12-05 12:58:50.014354] Finished iteration 165, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3622.504
START iteration 165, CKPT_AND_STOP: False
[2022-12-05 12:58:53.645466] Finished iteration 166, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3631.113
START iteration 166, CKPT_AND_STOP: False
[2022-12-05 12:58:57.218032] Finished iteration 167, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3572.563
START iteration 167, CKPT_AND_STOP: False
[2022-12-05 12:59:00.906347] Finished iteration 168, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3688.318
START iteration 168, CKPT_AND_STOP: False
[2022-12-05 12:59:04.537505] Finished iteration 169, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3631.156
START iteration 169, CKPT_AND_STOP: False
[2022-12-05 12:59:08.172168] Finished iteration 170, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3634.662
START iteration 170, CKPT_AND_STOP: False
[2022-12-05 12:59:11.775605] Finished iteration 171, CKPT_AND_STOP: False, flag: tensor([1], dtype=torch.int32), speed: 3603.440
Begin to save checkpont and exit
Opt ckpt time 3.5959692001342773
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 11 signal handler called with signal 10
Process done with return code 0
Parent process ID: 23759 node: 172.31.17.209
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 12 0 2007202.880859375 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4913759
Min send: 10000000, max send 0
Min long send: 38387, max long send 60521
Min fwd: 45773, max fwd 58711; min bwd 92748, max bwd 103910
Min long fwd: 56704, max long fwd 63285; min long bwd 98353, max long bwd 106648
Time taken by simulation: 402 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 18 0 1481951.2939453125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4877293
Min send: 10000000, max send 0
Min long send: 38055, max long send 64155
Min fwd: 32292, max fwd 48132; min bwd 69316, max bwd 77937
Min long fwd: 43561, max long fwd 51496; min long bwd 71918, max long bwd 80151
Time taken by simulation: 784 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 25 0 976051.4526367188 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4466988
Min send: 10000000, max send 0
Min long send: 38237, max long send 65217
Min fwd: 19236, max fwd 35580; min bwd 42158, max bwd 57089
Min long fwd: 24076, max long fwd 35713; min long bwd 50505, max long bwd 59414
Time taken by simulation: 1752 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 42 0 610855.46875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4799842
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 10665, max fwd 27276; min bwd 28791, max bwd 43945
Min long fwd: 21459, max long fwd 30507; min long bwd 38642, max long bwd 48142
Time taken by simulation: 4219 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 64 0 343797.36328125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5360725
Min send: 10000000, max send 0
Min long send: 38056, max long send 68144
Min fwd: 5149, max fwd 20736; min bwd 17314, max bwd 33457
Min long fwd: 11639, max long fwd 22378; min long bwd 26559, max long bwd 34539
Time taken by simulation: 10497 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29656 microseconds

Stages 24
Micro-bs 1 Max mem: 2949765734.4
Predicted microbatch size for 24: 1
comm size 1638400
WARNING: no send time found, 24 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 24 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6789982
Min send: 10000000, max send 0
Min long send: 38055, max long send 74455
Min fwd: 26, max fwd 15549; min bwd 3842, max bwd 20573
Min long fwd: 7764, max long fwd 18097; min long bwd 11316, max long bwd 21840
Time taken by simulation: 45762 microseconds

{1: inf, 2: inf, 3: 4.913759, 4: 4.877293, 6: 4.466988, 8: 4.799842, 12: 5.360725, 16: 7.580423, 24: 6.789982}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1, 24: 1}
best config is: 6 1
expected time is 4.466988
5 per stage
30 servers!
Config:
ranks: range(11, 12)
train batch size: 128
partitions: 6
chunk_size: 1
data depth: 5
stage to rank map: 0,6,12,18,24;1,7,13,19,25;2,8,14,20,26;3,9,15,21,27;4,10,16,22,28;5,11,17,23,29;
World size is 30
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=11 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,6,12,18,24;1,7,13,19,25;2,8,14,20,26;3,9,15,21,27;4,10,16,22,28;5,11,17,23,29; --batch-size=25 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 171
dry run time 1.059049129486084
SHARED WEIGHTS ARE
[(0, 5)]
this rank  11 is part of pipeline replica  1
25 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
 > finished loading checkpoint in 56.214 seconds
START iteration 171, CKPT_AND_STOP: False
[2022-12-05 13:01:41.907671] Finished iteration 172, CKPT_AND_STOP: False, flag: tensor([2], dtype=torch.int32), speed: 9930.822
Begin to save checkpont and exit
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 11 signal handler called with signal 10
Opt ckpt time 11.468333959579468
Process done with return code 0
Parent process ID: 24699 node: 172.31.17.209
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 12 0 2007202.880859375 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4913759
Min send: 10000000, max send 0
Min long send: 38387, max long send 60521
Min fwd: 45773, max fwd 58711; min bwd 92748, max bwd 103910
Min long fwd: 56704, max long fwd 63285; min long bwd 98353, max long bwd 106648
Time taken by simulation: 367 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 16 0 1727535.5224609375 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4820532
Min send: 10000000, max send 0
Min long send: 38109, max long send 64155
Min fwd: 32292, max fwd 48132; min bwd 69446, max bwd 80083
Min long fwd: 43192, max long fwd 50561; min long bwd 74672, max long bwd 80151
Time taken by simulation: 691 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 25 0 976051.4526367188 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4466988
Min send: 10000000, max send 0
Min long send: 38237, max long send 65217
Min fwd: 19236, max fwd 35580; min bwd 42158, max bwd 57089
Min long fwd: 24076, max long fwd 35713; min long bwd 50505, max long bwd 59414
Time taken by simulation: 1744 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 32 0 700971.3134765625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4198444
Min send: 10000000, max send 0
Min long send: 38109, max long send 68059
Min fwd: 11544, max fwd 27276; min bwd 28686, max bwd 44788
Min long fwd: 22228, max long fwd 29781; min long bwd 41714, max long bwd 48296
Time taken by simulation: 3185 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 64 0 343797.36328125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5360725
Min send: 10000000, max send 0
Min long send: 38056, max long send 68144
Min fwd: 5149, max fwd 20736; min bwd 17314, max bwd 33457
Min long fwd: 11639, max long fwd 22378; min long bwd 26559, max long bwd 34539
Time taken by simulation: 10501 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 64 0 294405.0598144531 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5043807
Min send: 10000000, max send 0
Min long send: 38109, max long send 77793
Min fwd: 803, max fwd 17174; min bwd 10907, max bwd 28118
Min long fwd: 12084, max long fwd 20913; min long bwd 17914, max long bwd 26363
Time taken by simulation: 14240 microseconds

Stages 24
Micro-bs 1 Max mem: 2949765734.4
Predicted microbatch size for 24: 1
comm size 1638400
WARNING: no send time found, 24 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 24 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6789982
Min send: 10000000, max send 0
Min long send: 38055, max long send 74455
Min fwd: 26, max fwd 15549; min bwd 3842, max bwd 20573
Min long fwd: 7764, max long fwd 18097; min long bwd 11316, max long bwd 21840
Time taken by simulation: 47996 microseconds

{1: inf, 2: inf, 3: 4.913759, 4: 4.820532, 6: 4.466988, 8: 4.198444, 12: 5.360725, 16: 5.043807, 24: 6.789982}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1, 24: 1}
best config is: 8 1
expected time is 4.198444
4 per stage
32 servers!
Config:
ranks: range(11, 12)
train batch size: 128
partitions: 8
chunk_size: 1
data depth: 4
stage to rank map: 0,8,16,24;1,9,17,25;2,10,18,26;3,11,19,27;4,12,20,28;5,13,21,29;6,14,22,30;7,15,23,31;
World size is 32
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=11 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,8,16,24;1,9,17,25;2,10,18,26;3,11,19,27;4,12,20,28;5,13,21,29;6,14,22,30;7,15,23,31; --batch-size=32 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 172
dry run time 0.9320011138916016
SHARED WEIGHTS ARE
[(0, 7)]
this rank  11 is part of pipeline replica  1
32 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
 > finished loading checkpoint in 45.589 seconds
START iteration 172, CKPT_AND_STOP: False
[2022-12-05 13:03:32.125738] Finished iteration 173, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 11697.414
START iteration 173, CKPT_AND_STOP: False
[2022-12-05 13:03:37.637795] Finished iteration 174, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5512.079
START iteration 174, CKPT_AND_STOP: False
[2022-12-05 13:03:42.356418] Finished iteration 175, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4718.622
START iteration 175, CKPT_AND_STOP: False
[2022-12-05 13:03:47.046322] Finished iteration 176, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4689.906
START iteration 176, CKPT_AND_STOP: False
[2022-12-05 13:03:51.654373] Finished iteration 177, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4608.051
START iteration 177, CKPT_AND_STOP: False
[2022-12-05 13:03:55.261360] Finished iteration 178, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3606.985
START iteration 178, CKPT_AND_STOP: False
[2022-12-05 13:03:58.821396] Finished iteration 179, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3560.037
START iteration 179, CKPT_AND_STOP: False
[2022-12-05 13:04:02.884199] Finished iteration 180, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4062.805
START iteration 180, CKPT_AND_STOP: False
[2022-12-05 13:04:07.063792] Finished iteration 181, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4179.593
START iteration 181, CKPT_AND_STOP: False
[2022-12-05 13:04:10.643701] Finished iteration 182, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3579.910
START iteration 182, CKPT_AND_STOP: False
[2022-12-05 13:04:14.185155] Finished iteration 183, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3541.451
START iteration 183, CKPT_AND_STOP: False
[2022-12-05 13:04:17.740819] Finished iteration 184, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3555.665
START iteration 184, CKPT_AND_STOP: False
[2022-12-05 13:04:21.360686] Finished iteration 185, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3619.869
START iteration 185, CKPT_AND_STOP: False
[2022-12-05 13:04:24.921093] Finished iteration 186, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3560.405
START iteration 186, CKPT_AND_STOP: False
[2022-12-05 13:04:28.497119] Finished iteration 187, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3576.027
START iteration 187, CKPT_AND_STOP: False
[2022-12-05 13:04:32.183665] Finished iteration 188, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3686.546
START iteration 188, CKPT_AND_STOP: False
[2022-12-05 13:04:35.939821] Finished iteration 189, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3756.156
START iteration 189, CKPT_AND_STOP: False
[2022-12-05 13:04:39.574035] Finished iteration 190, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3634.213
START iteration 190, CKPT_AND_STOP: False
[2022-12-05 13:04:43.301472] Finished iteration 191, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3727.438
START iteration 191, CKPT_AND_STOP: False
[2022-12-05 13:04:47.008540] Finished iteration 192, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3707.050
START iteration 192, CKPT_AND_STOP: False
[2022-12-05 13:04:50.732549] Finished iteration 193, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3724.027
START iteration 193, CKPT_AND_STOP: False
[2022-12-05 13:04:54.354750] Finished iteration 194, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3622.200
START iteration 194, CKPT_AND_STOP: False
[2022-12-05 13:04:58.018403] Finished iteration 195, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3663.653
START iteration 195, CKPT_AND_STOP: False
[2022-12-05 13:05:01.607032] Finished iteration 196, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3588.629
START iteration 196, CKPT_AND_STOP: False
[2022-12-05 13:05:05.158537] Finished iteration 197, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3551.506
START iteration 197, CKPT_AND_STOP: False
[2022-12-05 13:05:08.684856] Finished iteration 198, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3526.318
START iteration 198, CKPT_AND_STOP: False
[2022-12-05 13:05:12.264188] Finished iteration 199, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3579.332
START iteration 199, CKPT_AND_STOP: False
[2022-12-05 13:05:16.023184] Finished iteration 200, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3758.996
START iteration 200, CKPT_AND_STOP: False
[2022-12-05 13:05:19.577226] Finished iteration 201, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3554.042
START iteration 201, CKPT_AND_STOP: False
[2022-12-05 13:05:23.275457] Finished iteration 202, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3698.231
START iteration 202, CKPT_AND_STOP: False
[2022-12-05 13:05:26.868297] Finished iteration 203, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3592.841
START iteration 203, CKPT_AND_STOP: False
[2022-12-05 13:05:30.533776] Finished iteration 204, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3665.478
START iteration 204, CKPT_AND_STOP: False
[2022-12-05 13:05:34.144005] Finished iteration 205, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3610.229
START iteration 205, CKPT_AND_STOP: False
[2022-12-05 13:05:37.834086] Finished iteration 206, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3690.081
START iteration 206, CKPT_AND_STOP: False
[2022-12-05 13:05:41.501137] Finished iteration 207, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3667.051
START iteration 207, CKPT_AND_STOP: False
[2022-12-05 13:05:45.069684] Finished iteration 208, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3568.545
START iteration 208, CKPT_AND_STOP: False
[2022-12-05 13:05:48.641089] Finished iteration 209, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3571.408
START iteration 209, CKPT_AND_STOP: False
[2022-12-05 13:05:52.149897] Finished iteration 210, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3508.807
START iteration 210, CKPT_AND_STOP: False
[2022-12-05 13:05:55.725265] Finished iteration 211, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3575.369
START iteration 211, CKPT_AND_STOP: False
[2022-12-05 13:05:59.400889] Finished iteration 212, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3675.620
START iteration 212, CKPT_AND_STOP: False
[2022-12-05 13:06:02.996490] Finished iteration 213, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3595.604
START iteration 213, CKPT_AND_STOP: False
[2022-12-05 13:06:06.511302] Finished iteration 214, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3514.809
START iteration 214, CKPT_AND_STOP: False
[2022-12-05 13:06:10.119432] Finished iteration 215, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3608.134
START iteration 215, CKPT_AND_STOP: False
[2022-12-05 13:06:13.703184] Finished iteration 216, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3583.751
START iteration 216, CKPT_AND_STOP: False
[2022-12-05 13:06:17.300665] Finished iteration 217, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3597.481
START iteration 217, CKPT_AND_STOP: False
[2022-12-05 13:06:20.866389] Finished iteration 218, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3565.724
START iteration 218, CKPT_AND_STOP: False
[2022-12-05 13:06:24.467881] Finished iteration 219, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3601.492
START iteration 219, CKPT_AND_STOP: False
[2022-12-05 13:06:28.032569] Finished iteration 220, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3564.688
START iteration 220, CKPT_AND_STOP: False
[2022-12-05 13:06:31.678509] Finished iteration 221, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3645.940
START iteration 221, CKPT_AND_STOP: False
[2022-12-05 13:06:35.279554] Finished iteration 222, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3601.043
START iteration 222, CKPT_AND_STOP: False
[2022-12-05 13:06:38.897898] Finished iteration 223, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3618.346
START iteration 223, CKPT_AND_STOP: False
[2022-12-05 13:06:42.494011] Finished iteration 224, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3596.113
START iteration 224, CKPT_AND_STOP: False
[2022-12-05 13:06:46.140530] Finished iteration 225, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3646.517
START iteration 225, CKPT_AND_STOP: False
[2022-12-05 13:06:49.884759] Finished iteration 226, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3744.232
START iteration 226, CKPT_AND_STOP: False
[2022-12-05 13:06:53.504188] Finished iteration 227, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3619.428
START iteration 227, CKPT_AND_STOP: False
[2022-12-05 13:06:57.036822] Finished iteration 228, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3532.635
START iteration 228, CKPT_AND_STOP: False
[2022-12-05 13:07:00.609212] Finished iteration 229, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3572.390
START iteration 229, CKPT_AND_STOP: False
[2022-12-05 13:07:04.304666] Finished iteration 230, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3695.453
START iteration 230, CKPT_AND_STOP: False
[2022-12-05 13:07:07.945049] Finished iteration 231, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3640.383
START iteration 231, CKPT_AND_STOP: False
[2022-12-05 13:07:11.522506] Finished iteration 232, CKPT_AND_STOP: False, flag: tensor([1], dtype=torch.int32), speed: 3577.458
Begin to save checkpont and exit
Opt ckpt time 3.583230972290039
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 11 signal handler called with signal 10
Process done with return code 0
Parent process ID: 25826 node: 172.31.17.209
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 14 0 2006653.3203125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5367030
Min send: 10000000, max send 0
Min long send: 38387, max long send 60521
Min fwd: 45773, max fwd 60689; min bwd 93028, max bwd 103910
Min long fwd: 57033, max long fwd 64913; min long bwd 98397, max long bwd 102857
Time taken by simulation: 427 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 18 0 1481951.2939453125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4877293
Min send: 10000000, max send 0
Min long send: 38055, max long send 64155
Min fwd: 32292, max fwd 48132; min bwd 69316, max bwd 77937
Min long fwd: 43561, max long fwd 51496; min long bwd 71918, max long bwd 80151
Time taken by simulation: 774 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 32 0 876895.5078125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5017062
Min send: 10000000, max send 0
Min long send: 38071, max long send 66276
Min fwd: 18837, max fwd 35859; min bwd 42514, max bwd 56347
Min long fwd: 27753, max long fwd 35222; min long bwd 51765, max long bwd 59571
Time taken by simulation: 2280 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 42 0 610855.46875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4799842
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 10665, max fwd 27276; min bwd 28791, max bwd 43945
Min long fwd: 21459, max long fwd 30507; min long bwd 38642, max long bwd 48142
Time taken by simulation: 4223 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 64 0 343797.36328125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5360725
Min send: 10000000, max send 0
Min long send: 38056, max long send 68144
Min fwd: 5149, max fwd 20736; min bwd 17314, max bwd 33457
Min long fwd: 11639, max long fwd 22378; min long bwd 26559, max long bwd 34539
Time taken by simulation: 10452 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29680 microseconds

Stages 24
Micro-bs 1 Max mem: 2949765734.4
Predicted microbatch size for 24: 1
comm size 1638400
WARNING: no send time found, 24 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 24 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6789982
Min send: 10000000, max send 0
Min long send: 38055, max long send 74455
Min fwd: 26, max fwd 15549; min bwd 3842, max bwd 20573
Min long fwd: 7764, max long fwd 18097; min long bwd 11316, max long bwd 21840
Time taken by simulation: 45914 microseconds

{1: inf, 2: inf, 3: 5.36703, 4: 4.877293, 6: 5.017062, 8: 4.799842, 12: 5.360725, 16: 7.580423, 24: 6.789982}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1, 24: 1}
best config is: 8 1
expected time is 4.799842
3 per stage
24 servers!
Config:
ranks: range(11, 12)
train batch size: 128
partitions: 8
chunk_size: 1
data depth: 3
stage to rank map: 0,8,16;1,9,17;2,10,18;3,11,19;4,12,20;5,13,21;6,14,22;7,15,23;
World size is 24
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=11 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,8,16;1,9,17;2,10,18;3,11,19;4,12,20;5,13,21;6,14,22;7,15,23; --batch-size=42 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 232
dry run time 1.1231012344360352
SHARED WEIGHTS ARE
[(0, 7)]
this rank  11 is part of pipeline replica  1
42 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
 > finished loading checkpoint in 40.964 seconds
START iteration 232, CKPT_AND_STOP: False
[2022-12-05 13:09:29.742898] Finished iteration 233, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 12352.755
START iteration 233, CKPT_AND_STOP: False
[2022-12-05 13:09:34.878396] Finished iteration 234, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5135.527
START iteration 234, CKPT_AND_STOP: False
[2022-12-05 13:09:39.940507] Finished iteration 235, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5062.113
START iteration 235, CKPT_AND_STOP: False
[2022-12-05 13:09:45.047377] Finished iteration 236, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5106.870
START iteration 236, CKPT_AND_STOP: False
[2022-12-05 13:09:50.193732] Finished iteration 237, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5146.352
START iteration 237, CKPT_AND_STOP: False
[2022-12-05 13:09:54.342209] Finished iteration 238, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4148.479
START iteration 238, CKPT_AND_STOP: False
[2022-12-05 13:09:58.453885] Finished iteration 239, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4111.675
START iteration 239, CKPT_AND_STOP: False
[2022-12-05 13:10:02.545869] Finished iteration 240, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4091.985
START iteration 240, CKPT_AND_STOP: False
[2022-12-05 13:10:06.605492] Finished iteration 241, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4059.623
START iteration 241, CKPT_AND_STOP: False
[2022-12-05 13:10:10.661445] Finished iteration 242, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4055.950
START iteration 242, CKPT_AND_STOP: False
[2022-12-05 13:10:14.757800] Finished iteration 243, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4096.357
START iteration 243, CKPT_AND_STOP: False
[2022-12-05 13:10:18.871707] Finished iteration 244, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4113.907
START iteration 244, CKPT_AND_STOP: False
[2022-12-05 13:10:22.956537] Finished iteration 245, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4084.830
START iteration 245, CKPT_AND_STOP: False
[2022-12-05 13:10:27.100472] Finished iteration 246, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4143.936
START iteration 246, CKPT_AND_STOP: False
[2022-12-05 13:10:31.197423] Finished iteration 247, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4096.951
START iteration 247, CKPT_AND_STOP: False
[2022-12-05 13:10:35.311275] Finished iteration 248, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4113.852
START iteration 248, CKPT_AND_STOP: False
[2022-12-05 13:10:39.416204] Finished iteration 249, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4104.929
START iteration 249, CKPT_AND_STOP: False
[2022-12-05 13:10:43.545537] Finished iteration 250, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4129.332
START iteration 250, CKPT_AND_STOP: False
[2022-12-05 13:10:47.646108] Finished iteration 251, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4100.572
START iteration 251, CKPT_AND_STOP: False
[2022-12-05 13:10:51.698594] Finished iteration 252, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4052.486
START iteration 252, CKPT_AND_STOP: False
[2022-12-05 13:10:55.764038] Finished iteration 253, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4065.441
START iteration 253, CKPT_AND_STOP: False
[2022-12-05 13:10:59.796278] Finished iteration 254, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4032.242
START iteration 254, CKPT_AND_STOP: False
[2022-12-05 13:11:03.842317] Finished iteration 255, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4046.042
START iteration 255, CKPT_AND_STOP: False
[2022-12-05 13:11:07.929102] Finished iteration 256, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4086.785
START iteration 256, CKPT_AND_STOP: False
[2022-12-05 13:11:11.971822] Finished iteration 257, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4042.718
START iteration 257, CKPT_AND_STOP: False
[2022-12-05 13:11:16.105515] Finished iteration 258, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4133.694
START iteration 258, CKPT_AND_STOP: False
[2022-12-05 13:11:20.311986] Finished iteration 259, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4206.472
START iteration 259, CKPT_AND_STOP: False
[2022-12-05 13:11:24.442345] Finished iteration 260, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4130.356
START iteration 260, CKPT_AND_STOP: False
[2022-12-05 13:11:28.503799] Finished iteration 261, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4061.454
START iteration 261, CKPT_AND_STOP: False
[2022-12-05 13:11:32.585235] Finished iteration 262, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4081.439
START iteration 262, CKPT_AND_STOP: False
[2022-12-05 13:11:36.724449] Finished iteration 263, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4139.211
START iteration 263, CKPT_AND_STOP: False
[2022-12-05 13:11:40.780085] Finished iteration 264, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4055.640
START iteration 264, CKPT_AND_STOP: False
[2022-12-05 13:11:44.911376] Finished iteration 265, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4131.290
START iteration 265, CKPT_AND_STOP: False
[2022-12-05 13:11:48.989869] Finished iteration 266, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4078.494
START iteration 266, CKPT_AND_STOP: False
[2022-12-05 13:11:53.056969] Finished iteration 267, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4067.097
START iteration 267, CKPT_AND_STOP: False
[2022-12-05 13:11:57.141890] Finished iteration 268, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4084.923
START iteration 268, CKPT_AND_STOP: False
[2022-12-05 13:12:01.219777] Finished iteration 269, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4077.888
START iteration 269, CKPT_AND_STOP: False
[2022-12-05 13:12:05.330093] Finished iteration 270, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4110.316
START iteration 270, CKPT_AND_STOP: False
[2022-12-05 13:12:09.393817] Finished iteration 271, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4063.723
START iteration 271, CKPT_AND_STOP: False
[2022-12-05 13:12:13.483555] Finished iteration 272, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4089.738
START iteration 272, CKPT_AND_STOP: False
[2022-12-05 13:12:17.555485] Finished iteration 273, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4071.926
START iteration 273, CKPT_AND_STOP: False
[2022-12-05 13:12:21.607150] Finished iteration 274, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4051.668
START iteration 274, CKPT_AND_STOP: False
[2022-12-05 13:12:25.655809] Finished iteration 275, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4048.659
START iteration 275, CKPT_AND_STOP: False
[2022-12-05 13:12:29.754000] Finished iteration 276, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4098.191
START iteration 276, CKPT_AND_STOP: False
[2022-12-05 13:12:33.839070] Finished iteration 277, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4085.068
START iteration 277, CKPT_AND_STOP: False
[2022-12-05 13:12:37.951027] Finished iteration 278, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4111.959
START iteration 278, CKPT_AND_STOP: False
[2022-12-05 13:12:42.083178] Finished iteration 279, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4132.153
START iteration 279, CKPT_AND_STOP: False
[2022-12-05 13:12:46.153596] Finished iteration 280, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4070.415
START iteration 280, CKPT_AND_STOP: False
[2022-12-05 13:12:50.236972] Finished iteration 281, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4083.376
START iteration 281, CKPT_AND_STOP: False
[2022-12-05 13:12:54.433394] Finished iteration 282, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4196.424
START iteration 282, CKPT_AND_STOP: False
[2022-12-05 13:12:58.508713] Finished iteration 283, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4075.321
START iteration 283, CKPT_AND_STOP: False
[2022-12-05 13:13:02.624653] Finished iteration 284, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4115.940
START iteration 284, CKPT_AND_STOP: False
[2022-12-05 13:13:06.683310] Finished iteration 285, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4058.656
START iteration 285, CKPT_AND_STOP: False
[2022-12-05 13:13:10.748053] Finished iteration 286, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4064.745
START iteration 286, CKPT_AND_STOP: False
[2022-12-05 13:13:15.299835] Finished iteration 287, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4551.780
START iteration 287, CKPT_AND_STOP: False
[2022-12-05 13:13:19.371859] Finished iteration 288, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4072.026
START iteration 288, CKPT_AND_STOP: False
[2022-12-05 13:13:23.394839] Finished iteration 289, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4022.979
START iteration 289, CKPT_AND_STOP: False
[2022-12-05 13:13:27.550909] Finished iteration 290, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4156.067
START iteration 290, CKPT_AND_STOP: False
[2022-12-05 13:13:31.715605] Finished iteration 291, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4164.697
START iteration 291, CKPT_AND_STOP: False
[2022-12-05 13:13:35.862048] Finished iteration 292, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4146.443
START iteration 292, CKPT_AND_STOP: False
[2022-12-05 13:13:39.940719] Finished iteration 293, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4078.653
START iteration 293, CKPT_AND_STOP: False
[2022-12-05 13:13:43.935504] Finished iteration 294, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3994.805
START iteration 294, CKPT_AND_STOP: False
[2022-12-05 13:13:47.992797] Finished iteration 295, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4057.292
START iteration 295, CKPT_AND_STOP: False
[2022-12-05 13:13:52.127269] Finished iteration 296, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4134.474
START iteration 296, CKPT_AND_STOP: False
[2022-12-05 13:13:56.189710] Finished iteration 297, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4062.441
START iteration 297, CKPT_AND_STOP: False
[2022-12-05 13:14:01.064691] Finished iteration 298, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4874.978
START iteration 298, CKPT_AND_STOP: False
[2022-12-05 13:14:05.125305] Finished iteration 299, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4060.617
START iteration 299, CKPT_AND_STOP: False
[2022-12-05 13:14:09.242438] Finished iteration 300, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4117.132
START iteration 300, CKPT_AND_STOP: False
[2022-12-05 13:14:13.315639] Finished iteration 301, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4073.202
START iteration 301, CKPT_AND_STOP: False
[2022-12-05 13:14:17.511247] Finished iteration 302, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4195.608
START iteration 302, CKPT_AND_STOP: False
[2022-12-05 13:14:21.601185] Finished iteration 303, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4089.938
START iteration 303, CKPT_AND_STOP: False
[2022-12-05 13:14:25.699187] Finished iteration 304, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4098.001
START iteration 304, CKPT_AND_STOP: False
[2022-12-05 13:14:29.748623] Finished iteration 305, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4049.416
START iteration 305, CKPT_AND_STOP: False
[2022-12-05 13:14:33.826528] Finished iteration 306, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4077.921
START iteration 306, CKPT_AND_STOP: False
[2022-12-05 13:14:37.853100] Finished iteration 307, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4026.576
START iteration 307, CKPT_AND_STOP: False
[2022-12-05 13:14:41.950669] Finished iteration 308, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4097.567
START iteration 308, CKPT_AND_STOP: False
[2022-12-05 13:14:46.138215] Finished iteration 309, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4187.546
START iteration 309, CKPT_AND_STOP: False
[2022-12-05 13:14:50.209802] Finished iteration 310, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4071.589
START iteration 310, CKPT_AND_STOP: False
[2022-12-05 13:14:54.257718] Finished iteration 311, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4047.898
START iteration 311, CKPT_AND_STOP: False
[2022-12-05 13:14:58.417483] Finished iteration 312, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4159.783
START iteration 312, CKPT_AND_STOP: False
[2022-12-05 13:15:02.517098] Finished iteration 313, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4099.613
START iteration 313, CKPT_AND_STOP: False
[2022-12-05 13:15:06.607380] Finished iteration 314, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4090.284
START iteration 314, CKPT_AND_STOP: False
[2022-12-05 13:15:10.713318] Finished iteration 315, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4105.939
START iteration 315, CKPT_AND_STOP: False
[2022-12-05 13:15:14.842955] Finished iteration 316, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4129.637
START iteration 316, CKPT_AND_STOP: False
[2022-12-05 13:15:18.945302] Finished iteration 317, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4102.345
START iteration 317, CKPT_AND_STOP: False
[2022-12-05 13:15:23.010438] Finished iteration 318, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4065.138
START iteration 318, CKPT_AND_STOP: False
[2022-12-05 13:15:27.065821] Finished iteration 319, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4055.383
START iteration 319, CKPT_AND_STOP: False
[2022-12-05 13:15:31.146846] Finished iteration 320, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4081.008
START iteration 320, CKPT_AND_STOP: False
[2022-12-05 13:15:36.102148] Finished iteration 321, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4955.319
START iteration 321, CKPT_AND_STOP: False
[2022-12-05 13:15:40.106116] Finished iteration 322, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4003.968
START iteration 322, CKPT_AND_STOP: False
