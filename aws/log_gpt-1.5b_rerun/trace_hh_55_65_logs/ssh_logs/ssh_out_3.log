Parent process ID: 10137 node: 172.31.27.216
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 12 0 2007202.880859375 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4913759
Min send: 10000000, max send 0
Min long send: 38387, max long send 60521
Min fwd: 45773, max fwd 58711; min bwd 92748, max bwd 103910
Min long fwd: 56704, max long fwd 63285; min long bwd 98353, max long bwd 106648
Time taken by simulation: 366 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 16 0 1727535.5224609375 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4820532
Min send: 10000000, max send 0
Min long send: 38109, max long send 64155
Min fwd: 32292, max fwd 48132; min bwd 69446, max bwd 80083
Min long fwd: 43192, max long fwd 50561; min long bwd 74672, max long bwd 80151
Time taken by simulation: 698 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 25 0 976051.4526367188 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4466988
Min send: 10000000, max send 0
Min long send: 38237, max long send 65217
Min fwd: 19236, max fwd 35580; min bwd 42158, max bwd 57089
Min long fwd: 24076, max long fwd 35713; min long bwd 50505, max long bwd 59414
Time taken by simulation: 1803 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 32 0 700971.3134765625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4198444
Min send: 10000000, max send 0
Min long send: 38109, max long send 68059
Min fwd: 11544, max fwd 27276; min bwd 28686, max bwd 44788
Min long fwd: 22228, max long fwd 29781; min long bwd 41714, max long bwd 48296
Time taken by simulation: 3243 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 64 0 343797.36328125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5360725
Min send: 10000000, max send 0
Min long send: 38056, max long send 68144
Min fwd: 5149, max fwd 20736; min bwd 17314, max bwd 33457
Min long fwd: 11639, max long fwd 22378; min long bwd 26559, max long bwd 34539
Time taken by simulation: 10457 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 64 0 294405.0598144531 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5043807
Min send: 10000000, max send 0
Min long send: 38109, max long send 77793
Min fwd: 803, max fwd 17174; min bwd 10907, max bwd 28118
Min long fwd: 12084, max long fwd 20913; min long bwd 17914, max long bwd 26363
Time taken by simulation: 14295 microseconds

Stages 24
Micro-bs 1 Max mem: 2949765734.4
Predicted microbatch size for 24: 1
comm size 1638400
WARNING: no send time found, 24 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 24 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6789982
Min send: 10000000, max send 0
Min long send: 38055, max long send 74455
Min fwd: 26, max fwd 15549; min bwd 3842, max bwd 20573
Min long fwd: 7764, max long fwd 18097; min long bwd 11316, max long bwd 21840
Time taken by simulation: 45946 microseconds

{1: inf, 2: inf, 3: 4.913759, 4: 4.820532, 6: 4.466988, 8: 4.198444, 12: 5.360725, 16: 5.043807, 24: 6.789982}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1, 24: 1}
best config is: 8 1
expected time is 4.198444
4 per stage
32 servers!
Config:
ranks: range(3, 4)
train batch size: 128
partitions: 8
chunk_size: 1
data depth: 4
stage to rank map: 0,8,16,24;1,9,17,25;2,10,18,26;3,11,19,27;4,12,20,28;5,13,21,29;6,14,22,30;7,15,23,31;
World size is 32
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=3 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,8,16,24;1,9,17,25;2,10,18,26;3,11,19,27;4,12,20,28;5,13,21,29;6,14,22,30;7,15,23,31; --batch-size=32 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16
dry run time 0.9057590961456299
SHARED WEIGHTS ARE
[(0, 7)]
this rank  3 is part of pipeline replica  0
32 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
 > finished loading checkpoint in 0.200 seconds
START iteration 0, CKPT_AND_STOP: False
[2022-12-05 12:21:27.127024] Finished iteration 1, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 11618.006
START iteration 1, CKPT_AND_STOP: False
[2022-12-05 12:21:31.808155] Finished iteration 2, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4681.159
START iteration 2, CKPT_AND_STOP: False
[2022-12-05 12:21:36.502802] Finished iteration 3, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4694.649
START iteration 3, CKPT_AND_STOP: False
[2022-12-05 12:21:41.150667] Finished iteration 4, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4647.863
START iteration 4, CKPT_AND_STOP: False
[2022-12-05 12:21:46.720156] Finished iteration 5, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5569.492
START iteration 5, CKPT_AND_STOP: False
[2022-12-05 12:21:50.358886] Finished iteration 6, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3638.728
START iteration 6, CKPT_AND_STOP: False
[2022-12-05 12:21:53.938637] Finished iteration 7, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3579.754
START iteration 7, CKPT_AND_STOP: False
[2022-12-05 12:21:57.456298] Finished iteration 8, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3517.662
START iteration 8, CKPT_AND_STOP: False
[2022-12-05 12:22:01.535938] Finished iteration 9, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4079.635
START iteration 9, CKPT_AND_STOP: False
[2022-12-05 12:22:05.665101] Finished iteration 10, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4129.165
START iteration 10, CKPT_AND_STOP: False
[2022-12-05 12:22:09.426359] Finished iteration 11, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3761.257
START iteration 11, CKPT_AND_STOP: False
[2022-12-05 12:22:13.085015] Finished iteration 12, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3658.655
START iteration 12, CKPT_AND_STOP: False
[2022-12-05 12:22:16.706862] Finished iteration 13, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3621.850
START iteration 13, CKPT_AND_STOP: False
[2022-12-05 12:22:21.286487] Finished iteration 14, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4579.623
START iteration 14, CKPT_AND_STOP: False
[2022-12-05 12:22:24.913859] Finished iteration 15, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3627.373
START iteration 15, CKPT_AND_STOP: False
[2022-12-05 12:22:28.511959] Finished iteration 16, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3598.105
START iteration 16, CKPT_AND_STOP: False
[2022-12-05 12:22:32.094164] Finished iteration 17, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3582.201
START iteration 17, CKPT_AND_STOP: False
[2022-12-05 12:22:35.699428] Finished iteration 18, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3605.263
START iteration 18, CKPT_AND_STOP: False
[2022-12-05 12:22:39.284162] Finished iteration 19, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3584.731
START iteration 19, CKPT_AND_STOP: False
[2022-12-05 12:22:42.854752] Finished iteration 20, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3570.593
START iteration 20, CKPT_AND_STOP: False
[2022-12-05 12:22:46.464149] Finished iteration 21, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3609.397
START iteration 21, CKPT_AND_STOP: False
[2022-12-05 12:22:50.016181] Finished iteration 22, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3552.032
START iteration 22, CKPT_AND_STOP: False
[2022-12-05 12:22:53.698913] Finished iteration 23, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3682.736
START iteration 23, CKPT_AND_STOP: False
[2022-12-05 12:22:57.280816] Finished iteration 24, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3581.899
START iteration 24, CKPT_AND_STOP: False
[2022-12-05 12:23:00.852386] Finished iteration 25, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3571.567
START iteration 25, CKPT_AND_STOP: False
[2022-12-05 12:23:04.446446] Finished iteration 26, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3594.066
START iteration 26, CKPT_AND_STOP: False
[2022-12-05 12:23:08.136172] Finished iteration 27, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3689.723
START iteration 27, CKPT_AND_STOP: False
[2022-12-05 12:23:11.690431] Finished iteration 28, CKPT_AND_STOP: False, flag: tensor([1], dtype=torch.int32), speed: 3554.262
Begin to save checkpont and exit
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 3 signal handler called with signal 10
Opt ckpt time 6.901312589645386
Process done with return code 0
Parent process ID: 10684 node: 172.31.27.216
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 14 0 2006653.3203125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5367030
Min send: 10000000, max send 0
Min long send: 38387, max long send 60521
Min fwd: 45773, max fwd 60689; min bwd 93028, max bwd 103910
Min long fwd: 57033, max long fwd 64913; min long bwd 98397, max long bwd 102857
Time taken by simulation: 455 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 18 0 1481951.2939453125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4877293
Min send: 10000000, max send 0
Min long send: 38055, max long send 64155
Min fwd: 32292, max fwd 48132; min bwd 69316, max bwd 77937
Min long fwd: 43561, max long fwd 51496; min long bwd 71918, max long bwd 80151
Time taken by simulation: 774 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 32 0 876895.5078125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5017062
Min send: 10000000, max send 0
Min long send: 38071, max long send 66276
Min fwd: 18837, max fwd 35859; min bwd 42514, max bwd 56347
Min long fwd: 27753, max long fwd 35222; min long bwd 51765, max long bwd 59571
Time taken by simulation: 2274 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 42 0 610855.46875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4799842
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 10665, max fwd 27276; min bwd 28791, max bwd 43945
Min long fwd: 21459, max long fwd 30507; min long bwd 38642, max long bwd 48142
Time taken by simulation: 4288 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 64 0 343797.36328125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5360725
Min send: 10000000, max send 0
Min long send: 38056, max long send 68144
Min fwd: 5149, max fwd 20736; min bwd 17314, max bwd 33457
Min long fwd: 11639, max long fwd 22378; min long bwd 26559, max long bwd 34539
Time taken by simulation: 10499 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29853 microseconds

Stages 24
Micro-bs 1 Max mem: 2949765734.4
Predicted microbatch size for 24: 1
comm size 1638400
WARNING: no send time found, 24 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 24 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6789982
Min send: 10000000, max send 0
Min long send: 38055, max long send 74455
Min fwd: 26, max fwd 15549; min bwd 3842, max bwd 20573
Min long fwd: 7764, max long fwd 18097; min long bwd 11316, max long bwd 21840
Time taken by simulation: 45865 microseconds

{1: inf, 2: inf, 3: 5.36703, 4: 4.877293, 6: 5.017062, 8: 4.799842, 12: 5.360725, 16: 7.580423, 24: 6.789982}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1, 24: 1}
best config is: 8 1
expected time is 4.799842
3 per stage
24 servers!
Config:
ranks: range(3, 4)
train batch size: 128
partitions: 8
chunk_size: 1
data depth: 3
stage to rank map: 0,8,16;1,9,17;2,10,18;3,11,19;4,12,20;5,13,21;6,14,22;7,15,23;
World size is 24
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=3 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,8,16;1,9,17;2,10,18;3,11,19;4,12,20;5,13,21;6,14,22;7,15,23; --batch-size=42 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 28
dry run time 0.969231128692627
SHARED WEIGHTS ARE
[(0, 7)]
this rank  3 is part of pipeline replica  0
42 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 3 signal handler called with signal 10
 > finished loading checkpoint in 43.363 seconds
Process done with return code 0
Parent process ID: 11484 node: 172.31.27.216
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 16 0 2198285.64453125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5986016
Min send: 10000000, max send 0
Min long send: 38293, max long send 60521
Min fwd: 45773, max fwd 59456; min bwd 93556, max bwd 103910
Min long fwd: 57033, max long fwd 64913; min long bwd 97741, max long bwd 104518
Time taken by simulation: 483 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 21 0 1478731.4453125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5493991
Min send: 10000000, max send 0
Min long send: 38109, max long send 64155
Min fwd: 32128, max fwd 48180; min bwd 67776, max bwd 77208
Min long fwd: 43175, max long fwd 51496; min long bwd 74514, max long bwd 81205
Time taken by simulation: 941 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 32 0 876895.5078125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5017062
Min send: 10000000, max send 0
Min long send: 38071, max long send 66276
Min fwd: 18837, max fwd 35859; min bwd 42514, max bwd 56347
Min long fwd: 27753, max long fwd 35222; min long bwd 51765, max long bwd 59571
Time taken by simulation: 2309 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 42 0 610855.46875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4799842
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 10665, max fwd 27276; min bwd 28791, max bwd 43945
Min long fwd: 21459, max long fwd 30507; min long bwd 38642, max long bwd 48142
Time taken by simulation: 4232 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 64 0 343797.36328125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5360725
Min send: 10000000, max send 0
Min long send: 38056, max long send 68144
Min fwd: 5149, max fwd 20736; min bwd 17314, max bwd 33457
Min long fwd: 11639, max long fwd 22378; min long bwd 26559, max long bwd 34539
Time taken by simulation: 10430 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29720 microseconds

Stages 24
Micro-bs 1 Max mem: 2949765734.4
Predicted microbatch size for 24: 1
comm size 1638400
WARNING: no send time found, 24 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 24 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6789982
Min send: 10000000, max send 0
Min long send: 38055, max long send 74455
Min fwd: 26, max fwd 15549; min bwd 3842, max bwd 20573
Min long fwd: 7764, max long fwd 18097; min long bwd 11316, max long bwd 21840
Time taken by simulation: 45967 microseconds

{1: inf, 2: inf, 3: 5.986016, 4: 5.493991, 6: 5.017062, 8: 4.799842, 12: 5.360725, 16: 7.580423, 24: 6.789982}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1, 24: 1}
best config is: 8 1
expected time is 4.799842
3 per stage
24 servers!
Config:
ranks: range(3, 4)
train batch size: 128
partitions: 8
chunk_size: 1
data depth: 3
stage to rank map: 0,8,16;1,9,17;2,10,18;3,11,19;4,12,20;5,13,21;6,14,22;7,15,23;
World size is 24
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=3 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,8,16;1,9,17;2,10,18;3,11,19;4,12,20;5,13,21;6,14,22;7,15,23; --batch-size=42 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 28
dry run time 0.9586129188537598
SHARED WEIGHTS ARE
[(0, 7)]
this rank  3 is part of pipeline replica  0
42 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 3 signal handler called with signal 10
 > finished loading checkpoint in 40.923 seconds
Process done with return code 0
Parent process ID: 12282 node: 172.31.27.216
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 16 0 2198285.64453125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5986016
Min send: 10000000, max send 0
Min long send: 38293, max long send 60521
Min fwd: 45773, max fwd 59456; min bwd 93556, max bwd 103910
Min long fwd: 57033, max long fwd 64913; min long bwd 97741, max long bwd 104518
Time taken by simulation: 486 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 21 0 1478731.4453125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5493991
Min send: 10000000, max send 0
Min long send: 38109, max long send 64155
Min fwd: 32128, max fwd 48180; min bwd 67776, max bwd 77208
Min long fwd: 43175, max long fwd 51496; min long bwd 74514, max long bwd 81205
Time taken by simulation: 933 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 32 0 876895.5078125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5017062
Min send: 10000000, max send 0
Min long send: 38071, max long send 66276
Min fwd: 18837, max fwd 35859; min bwd 42514, max bwd 56347
Min long fwd: 27753, max long fwd 35222; min long bwd 51765, max long bwd 59571
Time taken by simulation: 2274 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 42 0 610855.46875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4799842
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 10665, max fwd 27276; min bwd 28791, max bwd 43945
Min long fwd: 21459, max long fwd 30507; min long bwd 38642, max long bwd 48142
Time taken by simulation: 4234 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 64 0 343797.36328125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5360725
Min send: 10000000, max send 0
Min long send: 38056, max long send 68144
Min fwd: 5149, max fwd 20736; min bwd 17314, max bwd 33457
Min long fwd: 11639, max long fwd 22378; min long bwd 26559, max long bwd 34539
Time taken by simulation: 10413 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29664 microseconds

Stages 24
Micro-bs 1 Max mem: 2949765734.4
Predicted microbatch size for 24: 1
comm size 1638400
WARNING: no send time found, 24 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 24 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6789982
Min send: 10000000, max send 0
Min long send: 38055, max long send 74455
Min fwd: 26, max fwd 15549; min bwd 3842, max bwd 20573
Min long fwd: 7764, max long fwd 18097; min long bwd 11316, max long bwd 21840
Time taken by simulation: 45839 microseconds

{1: inf, 2: inf, 3: 5.986016, 4: 5.493991, 6: 5.017062, 8: 4.799842, 12: 5.360725, 16: 7.580423, 24: 6.789982}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1, 24: 1}
best config is: 8 1
expected time is 4.799842
3 per stage
24 servers!
Config:
ranks: range(3, 4)
train batch size: 128
partitions: 8
chunk_size: 1
data depth: 3
stage to rank map: 0,8,16;1,9,17;2,10,18;3,11,19;4,12,20;5,13,21;6,14,22;7,15,23;
World size is 24
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=3 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,8,16;1,9,17;2,10,18;3,11,19;4,12,20;5,13,21;6,14,22;7,15,23; --batch-size=42 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 28
dry run time 1.1045253276824951
SHARED WEIGHTS ARE
[(0, 7)]
this rank  3 is part of pipeline replica  0
42 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
 > finished loading checkpoint in 36.517 seconds
START iteration 28, CKPT_AND_STOP: False
[2022-12-05 12:29:19.260016] Finished iteration 29, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 12541.690
START iteration 29, CKPT_AND_STOP: False
[2022-12-05 12:29:24.335494] Finished iteration 30, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5075.507
START iteration 30, CKPT_AND_STOP: False
[2022-12-05 12:29:30.937751] Finished iteration 31, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6602.258
START iteration 31, CKPT_AND_STOP: False
[2022-12-05 12:29:36.122427] Finished iteration 32, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5184.675
START iteration 32, CKPT_AND_STOP: False
[2022-12-05 12:29:41.502491] Finished iteration 33, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5380.064
START iteration 33, CKPT_AND_STOP: False
[2022-12-05 12:29:45.604246] Finished iteration 34, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4101.755
START iteration 34, CKPT_AND_STOP: False
[2022-12-05 12:29:49.685412] Finished iteration 35, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4081.166
START iteration 35, CKPT_AND_STOP: False
[2022-12-05 12:29:53.836613] Finished iteration 36, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4151.202
START iteration 36, CKPT_AND_STOP: False
[2022-12-05 12:29:57.931168] Finished iteration 37, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4094.555
START iteration 37, CKPT_AND_STOP: False
[2022-12-05 12:30:01.998343] Finished iteration 38, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4067.174
START iteration 38, CKPT_AND_STOP: False
[2022-12-05 12:30:06.044915] Finished iteration 39, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4046.572
START iteration 39, CKPT_AND_STOP: False
[2022-12-05 12:30:10.123919] Finished iteration 40, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4079.005
START iteration 40, CKPT_AND_STOP: False
[2022-12-05 12:30:14.249145] Finished iteration 41, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4125.226
START iteration 41, CKPT_AND_STOP: False
[2022-12-05 12:30:18.364763] Finished iteration 42, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4115.617
START iteration 42, CKPT_AND_STOP: False
[2022-12-05 12:30:22.483870] Finished iteration 43, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4119.107
START iteration 43, CKPT_AND_STOP: False
[2022-12-05 12:30:26.524963] Finished iteration 44, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4041.094
START iteration 44, CKPT_AND_STOP: False
[2022-12-05 12:30:30.515580] Finished iteration 45, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3990.616
START iteration 45, CKPT_AND_STOP: False
[2022-12-05 12:30:34.600323] Finished iteration 46, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4084.744
START iteration 46, CKPT_AND_STOP: False
[2022-12-05 12:30:38.726100] Finished iteration 47, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4125.777
START iteration 47, CKPT_AND_STOP: False
[2022-12-05 12:30:42.952272] Finished iteration 48, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4226.171
START iteration 48, CKPT_AND_STOP: False
[2022-12-05 12:30:47.038854] Finished iteration 49, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4086.583
START iteration 49, CKPT_AND_STOP: False
[2022-12-05 12:30:51.069708] Finished iteration 50, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4030.854
START iteration 50, CKPT_AND_STOP: False
[2022-12-05 12:30:55.116000] Finished iteration 51, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4046.291
START iteration 51, CKPT_AND_STOP: False
[2022-12-05 12:30:59.190765] Finished iteration 52, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4074.761
START iteration 52, CKPT_AND_STOP: False
[2022-12-05 12:31:03.260292] Finished iteration 53, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4069.531
START iteration 53, CKPT_AND_STOP: False
[2022-12-05 12:31:07.280676] Finished iteration 54, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4020.352
START iteration 54, CKPT_AND_STOP: False
[2022-12-05 12:31:11.341970] Finished iteration 55, CKPT_AND_STOP: False, flag: tensor([1], dtype=torch.int32), speed: 4061.327
Begin to save checkpont and exit
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 3 signal handler called with signal 10
Opt ckpt time 9.352144956588745
Process done with return code 0
Parent process ID: 13206 node: 172.31.27.216
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 18 0 1846814.0869140625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5987018
Min send: 10000000, max send 0
Min long send: 38387, max long send 60521
Min fwd: 45773, max fwd 59834; min bwd 93871, max bwd 104244
Min long fwd: 57033, max long fwd 64913; min long bwd 98140, max long bwd 103204
Time taken by simulation: 550 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 25 0 1338646.484375 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5804683
Min send: 10000000, max send 0
Min long send: 38055, max long send 64155
Min fwd: 30866, max fwd 48132; min bwd 66753, max bwd 79482
Min long fwd: 43307, max long fwd 50971; min long bwd 73461, max long bwd 80147
Time taken by simulation: 1100 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 42 0 770127.8076171875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5988334
Min send: 10000000, max send 0
Min long send: 38055, max long send 68059
Min fwd: 18837, max fwd 35859; min bwd 42358, max bwd 55388
Min long fwd: 27768, max long fwd 35092; min long bwd 51025, max long bwd 59414
Time taken by simulation: 3021 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 64 0 442992.24853515625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6489103
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 9901, max fwd 27419; min bwd 27605, max bwd 45180
Min long fwd: 21186, max long fwd 32479; min long bwd 41203, max long bwd 48557
Time taken by simulation: 6587 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8759578
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 5999, max fwd 22973; min bwd 17039, max bwd 34800
Min long fwd: 12470, max long fwd 25017; min long bwd 25566, max long bwd 36212
Time taken by simulation: 21358 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29596 microseconds

can't have 24 stages!
{1: inf, 2: inf, 3: 5.987018, 4: 5.804683, 6: 5.988334, 8: 6.489103, 12: 8.759578, 16: 7.580423}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1}
best config is: 4 1
expected time is 5.804683
5 per stage
20 servers!
Config:
ranks: range(3, 4)
train batch size: 128
partitions: 4
chunk_size: 1
data depth: 5
stage to rank map: 0,4,8,12,16;1,5,9,13,17;2,6,10,14,18;3,7,11,15,19;
World size is 20
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=3 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,4,8,12,16;1,5,9,13,17;2,6,10,14,18;3,7,11,15,19; --batch-size=25 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 55
dry run time 1.0429575443267822
SHARED WEIGHTS ARE
[(0, 3)]
this rank  3 is part of pipeline replica  0
25 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 3 signal handler called with signal 10
 > finished loading checkpoint in 64.928 seconds
Process done with return code 0
Parent process ID: 14274 node: 172.31.27.216
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 18 0 1846814.0869140625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5987018
Min send: 10000000, max send 0
Min long send: 38387, max long send 60521
Min fwd: 45773, max fwd 59834; min bwd 93871, max bwd 104244
Min long fwd: 57033, max long fwd 64913; min long bwd 98140, max long bwd 103204
Time taken by simulation: 534 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 25 0 1338646.484375 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5804683
Min send: 10000000, max send 0
Min long send: 38055, max long send 64155
Min fwd: 30866, max fwd 48132; min bwd 66753, max bwd 79482
Min long fwd: 43307, max long fwd 50971; min long bwd 73461, max long bwd 80147
Time taken by simulation: 1070 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 42 0 770127.8076171875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5988334
Min send: 10000000, max send 0
Min long send: 38055, max long send 68059
Min fwd: 18837, max fwd 35859; min bwd 42358, max bwd 55388
Min long fwd: 27768, max long fwd 35092; min long bwd 51025, max long bwd 59414
Time taken by simulation: 3038 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 64 0 442992.24853515625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6489103
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 9901, max fwd 27419; min bwd 27605, max bwd 45180
Min long fwd: 21186, max long fwd 32479; min long bwd 41203, max long bwd 48557
Time taken by simulation: 6493 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8759578
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 5999, max fwd 22973; min bwd 17039, max bwd 34800
Min long fwd: 12470, max long fwd 25017; min long bwd 25566, max long bwd 36212
Time taken by simulation: 22496 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29587 microseconds

can't have 24 stages!
{1: inf, 2: inf, 3: 5.987018, 4: 5.804683, 6: 5.988334, 8: 6.489103, 12: 8.759578, 16: 7.580423}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1}
best config is: 4 1
expected time is 5.804683
5 per stage
20 servers!
Config:
ranks: range(3, 4)
train batch size: 128
partitions: 4
chunk_size: 1
data depth: 5
stage to rank map: 0,4,8,12,16;1,5,9,13,17;2,6,10,14,18;3,7,11,15,19;
World size is 20
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=3 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,4,8,12,16;1,5,9,13,17;2,6,10,14,18;3,7,11,15,19; --batch-size=25 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 55
dry run time 1.3818931579589844
SHARED WEIGHTS ARE
[(0, 3)]
this rank  3 is part of pipeline replica  0
25 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
 > finished loading checkpoint in 82.516 seconds
START iteration 55, CKPT_AND_STOP: False
[2022-12-05 12:36:16.793707] Finished iteration 56, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 9406.596
START iteration 56, CKPT_AND_STOP: False
[2022-12-05 12:36:22.860426] Finished iteration 57, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6066.740
START iteration 57, CKPT_AND_STOP: False
[2022-12-05 12:36:28.819994] Finished iteration 58, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5959.571
START iteration 58, CKPT_AND_STOP: False
[2022-12-05 12:36:34.855505] Finished iteration 59, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6035.510
START iteration 59, CKPT_AND_STOP: False
[2022-12-05 12:36:40.797205] Finished iteration 60, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5941.666
START iteration 60, CKPT_AND_STOP: False
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 3 signal handler called with signal 10
[2022-12-05 12:36:45.728606] Finished iteration 61, CKPT_AND_STOP: True, flag: tensor([6], dtype=torch.int32), speed: 4931.436
Begin to save checkpont and exit
Opt ckpt time 21.789064168930054
Process done with return code 0
Parent process ID: 15350 node: 172.31.27.216
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 16 0 2198285.64453125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5986016
Min send: 10000000, max send 0
Min long send: 38293, max long send 60521
Min fwd: 45773, max fwd 59456; min bwd 93556, max bwd 103910
Min long fwd: 57033, max long fwd 64913; min long bwd 97741, max long bwd 104518
Time taken by simulation: 501 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 21 0 1478731.4453125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5493991
Min send: 10000000, max send 0
Min long send: 38109, max long send 64155
Min fwd: 32128, max fwd 48180; min bwd 67776, max bwd 77208
Min long fwd: 43175, max long fwd 51496; min long bwd 74514, max long bwd 81205
Time taken by simulation: 894 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 32 0 876895.5078125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5017062
Min send: 10000000, max send 0
Min long send: 38071, max long send 66276
Min fwd: 18837, max fwd 35859; min bwd 42514, max bwd 56347
Min long fwd: 27753, max long fwd 35222; min long bwd 51765, max long bwd 59571
Time taken by simulation: 2333 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 42 0 610855.46875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4799842
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 10665, max fwd 27276; min bwd 28791, max bwd 43945
Min long fwd: 21459, max long fwd 30507; min long bwd 38642, max long bwd 48142
Time taken by simulation: 4213 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 64 0 343797.36328125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5360725
Min send: 10000000, max send 0
Min long send: 38056, max long send 68144
Min fwd: 5149, max fwd 20736; min bwd 17314, max bwd 33457
Min long fwd: 11639, max long fwd 22378; min long bwd 26559, max long bwd 34539
Time taken by simulation: 10387 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29634 microseconds

Stages 24
Micro-bs 1 Max mem: 2949765734.4
Predicted microbatch size for 24: 1
comm size 1638400
WARNING: no send time found, 24 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 24 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6789982
Min send: 10000000, max send 0
Min long send: 38055, max long send 74455
Min fwd: 26, max fwd 15549; min bwd 3842, max bwd 20573
Min long fwd: 7764, max long fwd 18097; min long bwd 11316, max long bwd 21840
Time taken by simulation: 45875 microseconds

{1: inf, 2: inf, 3: 5.986016, 4: 5.493991, 6: 5.017062, 8: 4.799842, 12: 5.360725, 16: 7.580423, 24: 6.789982}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1, 24: 1}
best config is: 8 1
expected time is 4.799842
3 per stage
24 servers!
Config:
ranks: range(3, 4)
train batch size: 128
partitions: 8
chunk_size: 1
data depth: 3
stage to rank map: 0,8,16;1,9,17;2,10,18;3,11,19;4,12,20;5,13,21;6,14,22;7,15,23;
World size is 24
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=3 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,8,16;1,9,17;2,10,18;3,11,19;4,12,20;5,13,21;6,14,22;7,15,23; --batch-size=42 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 61
dry run time 1.0828020572662354
SHARED WEIGHTS ARE
[(0, 7)]
this rank  3 is part of pipeline replica  0
42 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 3 signal handler called with signal 10
 > finished loading checkpoint in 38.556 seconds
Process done with return code 0
Parent process ID: 16163 node: 172.31.27.216
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 16 0 2198285.64453125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5986016
Min send: 10000000, max send 0
Min long send: 38293, max long send 60521
Min fwd: 45773, max fwd 59456; min bwd 93556, max bwd 103910
Min long fwd: 57033, max long fwd 64913; min long bwd 97741, max long bwd 104518
Time taken by simulation: 481 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 21 0 1478731.4453125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5493991
Min send: 10000000, max send 0
Min long send: 38109, max long send 64155
Min fwd: 32128, max fwd 48180; min bwd 67776, max bwd 77208
Min long fwd: 43175, max long fwd 51496; min long bwd 74514, max long bwd 81205
Time taken by simulation: 896 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 32 0 876895.5078125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5017062
Min send: 10000000, max send 0
Min long send: 38071, max long send 66276
Min fwd: 18837, max fwd 35859; min bwd 42514, max bwd 56347
Min long fwd: 27753, max long fwd 35222; min long bwd 51765, max long bwd 59571
Time taken by simulation: 2284 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 42 0 610855.46875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4799842
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 10665, max fwd 27276; min bwd 28791, max bwd 43945
Min long fwd: 21459, max long fwd 30507; min long bwd 38642, max long bwd 48142
Time taken by simulation: 4257 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 64 0 343797.36328125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5360725
Min send: 10000000, max send 0
Min long send: 38056, max long send 68144
Min fwd: 5149, max fwd 20736; min bwd 17314, max bwd 33457
Min long fwd: 11639, max long fwd 22378; min long bwd 26559, max long bwd 34539
Time taken by simulation: 10435 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29657 microseconds

Stages 24
Micro-bs 1 Max mem: 2949765734.4
Predicted microbatch size for 24: 1
comm size 1638400
WARNING: no send time found, 24 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 24 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6789982
Min send: 10000000, max send 0
Min long send: 38055, max long send 74455
Min fwd: 26, max fwd 15549; min bwd 3842, max bwd 20573
Min long fwd: 7764, max long fwd 18097; min long bwd 11316, max long bwd 21840
Time taken by simulation: 45908 microseconds

{1: inf, 2: inf, 3: 5.986016, 4: 5.493991, 6: 5.017062, 8: 4.799842, 12: 5.360725, 16: 7.580423, 24: 6.789982}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1, 24: 1}
best config is: 8 1
expected time is 4.799842
3 per stage
24 servers!
Config:
ranks: range(3, 4)
train batch size: 128
partitions: 8
chunk_size: 1
data depth: 3
stage to rank map: 0,8,16;1,9,17;2,10,18;3,11,19;4,12,20;5,13,21;6,14,22;7,15,23;
World size is 24
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=3 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,8,16;1,9,17;2,10,18;3,11,19;4,12,20;5,13,21;6,14,22;7,15,23; --batch-size=42 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 61
dry run time 0.8990447521209717
SHARED WEIGHTS ARE
[(0, 7)]
this rank  3 is part of pipeline replica  0
42 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 3 signal handler called with signal 10
 > finished loading checkpoint in 35.923 seconds
Process done with return code 0
Parent process ID: 16985 node: 172.31.27.216
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 18 0 1846814.0869140625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5987018
Min send: 10000000, max send 0
Min long send: 38387, max long send 60521
Min fwd: 45773, max fwd 59834; min bwd 93871, max bwd 104244
Min long fwd: 57033, max long fwd 64913; min long bwd 98140, max long bwd 103204
Time taken by simulation: 572 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 25 0 1338646.484375 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5804683
Min send: 10000000, max send 0
Min long send: 38055, max long send 64155
Min fwd: 30866, max fwd 48132; min bwd 66753, max bwd 79482
Min long fwd: 43307, max long fwd 50971; min long bwd 73461, max long bwd 80147
Time taken by simulation: 1063 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 42 0 770127.8076171875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5988334
Min send: 10000000, max send 0
Min long send: 38055, max long send 68059
Min fwd: 18837, max fwd 35859; min bwd 42358, max bwd 55388
Min long fwd: 27768, max long fwd 35092; min long bwd 51025, max long bwd 59414
Time taken by simulation: 2982 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 64 0 442992.24853515625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6489103
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 9901, max fwd 27419; min bwd 27605, max bwd 45180
Min long fwd: 21186, max long fwd 32479; min long bwd 41203, max long bwd 48557
Time taken by simulation: 6471 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8759578
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 5999, max fwd 22973; min bwd 17039, max bwd 34800
Min long fwd: 12470, max long fwd 25017; min long bwd 25566, max long bwd 36212
Time taken by simulation: 21299 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 31152 microseconds

can't have 24 stages!
{1: inf, 2: inf, 3: 5.987018, 4: 5.804683, 6: 5.988334, 8: 6.489103, 12: 8.759578, 16: 7.580423}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1}
best config is: 4 1
expected time is 5.804683
5 per stage
20 servers!
Config:
ranks: range(3, 4)
train batch size: 128
partitions: 4
chunk_size: 1
data depth: 5
stage to rank map: 0,4,8,12,16;1,5,9,13,17;2,6,10,14,18;3,7,11,15,19;
World size is 20
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=3 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,4,8,12,16;1,5,9,13,17;2,6,10,14,18;3,7,11,15,19; --batch-size=25 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 61
dry run time 1.1343841552734375
SHARED WEIGHTS ARE
[(0, 3)]
this rank  3 is part of pipeline replica  0
25 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 3 signal handler called with signal 10
Process done with return code 1
Parent process ID: 18167 node: 172.31.27.216
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 21 0 1916562.744140625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6803052
Min send: 10000000, max send 0
Min long send: 38109, max long send 62549
Min fwd: 45773, max fwd 59456; min bwd 92874, max bwd 103910
Min long fwd: 57033, max long fwd 64913; min long bwd 96930, max long bwd 106927
Time taken by simulation: 612 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 25 0 1338646.484375 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5804683
Min send: 10000000, max send 0
Min long send: 38055, max long send 64155
Min fwd: 30866, max fwd 48132; min bwd 66753, max bwd 79482
Min long fwd: 43307, max long fwd 50971; min long bwd 73461, max long bwd 80147
Time taken by simulation: 1102 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 42 0 770127.8076171875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5988334
Min send: 10000000, max send 0
Min long send: 38055, max long send 68059
Min fwd: 18837, max fwd 35859; min bwd 42358, max bwd 55388
Min long fwd: 27768, max long fwd 35092; min long bwd 51025, max long bwd 59414
Time taken by simulation: 2969 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 64 0 442992.24853515625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6489103
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 9901, max fwd 27419; min bwd 27605, max bwd 45180
Min long fwd: 21186, max long fwd 32479; min long bwd 41203, max long bwd 48557
Time taken by simulation: 6500 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8759578
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 5999, max fwd 22973; min bwd 17039, max bwd 34800
Min long fwd: 12470, max long fwd 25017; min long bwd 25566, max long bwd 36212
Time taken by simulation: 21368 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29672 microseconds

can't have 24 stages!
{1: inf, 2: inf, 3: 6.803052, 4: 5.804683, 6: 5.988334, 8: 6.489103, 12: 8.759578, 16: 7.580423}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1}
best config is: 4 1
expected time is 5.804683
5 per stage
20 servers!
Config:
ranks: range(3, 4)
train batch size: 128
partitions: 4
chunk_size: 1
data depth: 5
stage to rank map: 0,4,8,12,16;1,5,9,13,17;2,6,10,14,18;3,7,11,15,19;
World size is 20
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=3 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,4,8,12,16;1,5,9,13,17;2,6,10,14,18;3,7,11,15,19; --batch-size=25 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 61
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 3 signal handler called with signal 10
dry run time 0.00529932975769043
SHARED WEIGHTS ARE
[(0, 3)]
this rank  3 is part of pipeline replica  0
25 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
 > finished loading checkpoint in 68.009 seconds
Process done with return code 0
Parent process ID: 19394 node: 172.31.27.216
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 18 0 1846814.0869140625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5987018
Min send: 10000000, max send 0
Min long send: 38387, max long send 60521
Min fwd: 45773, max fwd 59834; min bwd 93871, max bwd 104244
Min long fwd: 57033, max long fwd 64913; min long bwd 98140, max long bwd 103204
Time taken by simulation: 530 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 25 0 1338646.484375 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5804683
Min send: 10000000, max send 0
Min long send: 38055, max long send 64155
Min fwd: 30866, max fwd 48132; min bwd 66753, max bwd 79482
Min long fwd: 43307, max long fwd 50971; min long bwd 73461, max long bwd 80147
Time taken by simulation: 1067 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 42 0 770127.8076171875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5988334
Min send: 10000000, max send 0
Min long send: 38055, max long send 68059
Min fwd: 18837, max fwd 35859; min bwd 42358, max bwd 55388
Min long fwd: 27768, max long fwd 35092; min long bwd 51025, max long bwd 59414
Time taken by simulation: 2955 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 64 0 442992.24853515625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6489103
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 9901, max fwd 27419; min bwd 27605, max bwd 45180
Min long fwd: 21186, max long fwd 32479; min long bwd 41203, max long bwd 48557
Time taken by simulation: 6497 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8759578
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 5999, max fwd 22973; min bwd 17039, max bwd 34800
Min long fwd: 12470, max long fwd 25017; min long bwd 25566, max long bwd 36212
Time taken by simulation: 21446 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29626 microseconds

can't have 24 stages!
{1: inf, 2: inf, 3: 5.987018, 4: 5.804683, 6: 5.988334, 8: 6.489103, 12: 8.759578, 16: 7.580423}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1}
best config is: 4 1
expected time is 5.804683
5 per stage
20 servers!
Config:
ranks: range(3, 4)
train batch size: 128
partitions: 4
chunk_size: 1
data depth: 5
stage to rank map: 0,4,8,12,16;1,5,9,13,17;2,6,10,14,18;3,7,11,15,19;
World size is 20
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=3 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,4,8,12,16;1,5,9,13,17;2,6,10,14,18;3,7,11,15,19; --batch-size=25 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 61
dry run time 1.0964930057525635
SHARED WEIGHTS ARE
[(0, 3)]
this rank  3 is part of pipeline replica  0
25 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
 > finished loading checkpoint in 86.309 seconds
START iteration 61, CKPT_AND_STOP: False
[2022-12-05 12:46:02.447197] Finished iteration 62, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 9484.863
START iteration 62, CKPT_AND_STOP: False
[2022-12-05 12:46:08.358652] Finished iteration 63, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5911.501
START iteration 63, CKPT_AND_STOP: False
[2022-12-05 12:46:14.254459] Finished iteration 64, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5895.807
START iteration 64, CKPT_AND_STOP: False
[2022-12-05 12:46:20.174837] Finished iteration 65, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5920.377
START iteration 65, CKPT_AND_STOP: False
[2022-12-05 12:46:26.127314] Finished iteration 66, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5952.477
START iteration 66, CKPT_AND_STOP: False
[2022-12-05 12:46:30.991311] Finished iteration 67, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4863.998
START iteration 67, CKPT_AND_STOP: False
[2022-12-05 12:46:35.868040] Finished iteration 68, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4876.729
START iteration 68, CKPT_AND_STOP: False
[2022-12-05 12:46:40.808871] Finished iteration 69, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4940.831
START iteration 69, CKPT_AND_STOP: False
[2022-12-05 12:46:45.690136] Finished iteration 70, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4881.264
START iteration 70, CKPT_AND_STOP: False
[2022-12-05 12:46:50.675865] Finished iteration 71, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4985.730
START iteration 71, CKPT_AND_STOP: False
[2022-12-05 12:46:55.652308] Finished iteration 72, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4976.444
START iteration 72, CKPT_AND_STOP: False
[2022-12-05 12:47:00.529226] Finished iteration 73, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4876.917
START iteration 73, CKPT_AND_STOP: False
[2022-12-05 12:47:05.486349] Finished iteration 74, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4957.125
START iteration 74, CKPT_AND_STOP: False
[2022-12-05 12:47:10.423639] Finished iteration 75, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4937.289
START iteration 75, CKPT_AND_STOP: False
[2022-12-05 12:47:15.285471] Finished iteration 76, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4861.829
START iteration 76, CKPT_AND_STOP: False
[2022-12-05 12:47:20.145201] Finished iteration 77, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4859.732
START iteration 77, CKPT_AND_STOP: False
[2022-12-05 12:47:25.091911] Finished iteration 78, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4946.709
START iteration 78, CKPT_AND_STOP: False
[2022-12-05 12:47:29.939275] Finished iteration 79, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4847.366
START iteration 79, CKPT_AND_STOP: False
[2022-12-05 12:47:34.838003] Finished iteration 80, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4898.728
START iteration 80, CKPT_AND_STOP: False
[2022-12-05 12:47:39.744446] Finished iteration 81, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4906.443
START iteration 81, CKPT_AND_STOP: False
[2022-12-05 12:47:44.671997] Finished iteration 82, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4927.551
START iteration 82, CKPT_AND_STOP: False
[2022-12-05 12:47:49.598911] Finished iteration 83, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4926.914
START iteration 83, CKPT_AND_STOP: False
[2022-12-05 12:47:54.447907] Finished iteration 84, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4848.996
START iteration 84, CKPT_AND_STOP: False
[2022-12-05 12:47:59.356346] Finished iteration 85, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4908.438
START iteration 85, CKPT_AND_STOP: False
[2022-12-05 12:48:04.235740] Finished iteration 86, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4879.394
START iteration 86, CKPT_AND_STOP: False
[2022-12-05 12:48:09.139592] Finished iteration 87, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4903.853
START iteration 87, CKPT_AND_STOP: False
[2022-12-05 12:48:14.075726] Finished iteration 88, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4936.134
START iteration 88, CKPT_AND_STOP: False
[2022-12-05 12:48:19.067005] Finished iteration 89, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4991.279
START iteration 89, CKPT_AND_STOP: False
[2022-12-05 12:48:23.971129] Finished iteration 90, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4904.124
START iteration 90, CKPT_AND_STOP: False
[2022-12-05 12:48:28.871106] Finished iteration 91, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4899.976
START iteration 91, CKPT_AND_STOP: False
[2022-12-05 12:48:33.862287] Finished iteration 92, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4991.181
START iteration 92, CKPT_AND_STOP: False
[2022-12-05 12:48:38.755554] Finished iteration 93, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4893.267
START iteration 93, CKPT_AND_STOP: False
[2022-12-05 12:48:43.610731] Finished iteration 94, CKPT_AND_STOP: False, flag: tensor([3], dtype=torch.int32), speed: 4855.177
Begin to save checkpont and exit
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 3 signal handler called with signal 10
Opt ckpt time 21.992122650146484
Process done with return code 0
Parent process ID: 20703 node: 172.31.27.216
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 18 0 1846814.0869140625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5987018
Min send: 10000000, max send 0
Min long send: 38387, max long send 60521
Min fwd: 45773, max fwd 59834; min bwd 93871, max bwd 104244
Min long fwd: 57033, max long fwd 64913; min long bwd 98140, max long bwd 103204
Time taken by simulation: 541 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 25 0 1338646.484375 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5804683
Min send: 10000000, max send 0
Min long send: 38055, max long send 64155
Min fwd: 30866, max fwd 48132; min bwd 66753, max bwd 79482
Min long fwd: 43307, max long fwd 50971; min long bwd 73461, max long bwd 80147
Time taken by simulation: 1065 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 42 0 770127.8076171875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5988334
Min send: 10000000, max send 0
Min long send: 38055, max long send 68059
Min fwd: 18837, max fwd 35859; min bwd 42358, max bwd 55388
Min long fwd: 27768, max long fwd 35092; min long bwd 51025, max long bwd 59414
Time taken by simulation: 2966 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 64 0 442992.24853515625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6489103
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 9901, max fwd 27419; min bwd 27605, max bwd 45180
Min long fwd: 21186, max long fwd 32479; min long bwd 41203, max long bwd 48557
Time taken by simulation: 6483 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 8759578
Min send: 10000000, max send 0
Min long send: 38055, max long send 72424
Min fwd: 5999, max fwd 22973; min bwd 17039, max bwd 34800
Min long fwd: 12470, max long fwd 25017; min long bwd 25566, max long bwd 36212
Time taken by simulation: 21461 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29953 microseconds

can't have 24 stages!
{1: inf, 2: inf, 3: 5.987018, 4: 5.804683, 6: 5.988334, 8: 6.489103, 12: 8.759578, 16: 7.580423}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1}
best config is: 4 1
expected time is 5.804683
5 per stage
20 servers!
Config:
ranks: range(3, 4)
train batch size: 128
partitions: 4
chunk_size: 1
data depth: 5
stage to rank map: 0,4,8,12,16;1,5,9,13,17;2,6,10,14,18;3,7,11,15,19;
World size is 20
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=3 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,4,8,12,16;1,5,9,13,17;2,6,10,14,18;3,7,11,15,19; --batch-size=25 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 94
dry run time 1.2758119106292725
SHARED WEIGHTS ARE
[(0, 3)]
this rank  3 is part of pipeline replica  0
25 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
 > finished loading checkpoint in 70.736 seconds
START iteration 94, CKPT_AND_STOP: False
[2022-12-05 12:51:01.027826] Finished iteration 95, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 9615.233
START iteration 95, CKPT_AND_STOP: False
[2022-12-05 12:51:07.014322] Finished iteration 96, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5986.528
START iteration 96, CKPT_AND_STOP: False
[2022-12-05 12:51:12.957201] Finished iteration 97, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5942.876
START iteration 97, CKPT_AND_STOP: False
[2022-12-05 12:51:18.939132] Finished iteration 98, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5981.935
START iteration 98, CKPT_AND_STOP: False
[2022-12-05 12:51:24.752711] Finished iteration 99, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5813.578
START iteration 99, CKPT_AND_STOP: False
[2022-12-05 12:51:29.626595] Finished iteration 100, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4873.884
START iteration 100, CKPT_AND_STOP: False
[2022-12-05 12:51:34.467948] Finished iteration 101, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4841.354
START iteration 101, CKPT_AND_STOP: False
[2022-12-05 12:51:39.347582] Finished iteration 102, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4879.633
START iteration 102, CKPT_AND_STOP: False
3 : update_scale(): _has_overflow, dynamic. _loss_scale =  65536.0
[2022-12-05 12:51:44.175611] Finished iteration 103, CKPT_AND_STOP: False, flag: tensor([3], dtype=torch.int32), speed: 4828.031
Begin to save checkpont and exit
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 3 signal handler called with signal 10
Opt ckpt time 21.309417247772217
Process done with return code 0
Parent process ID: 21963 node: 172.31.27.216
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 12 0 2007202.880859375 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4913759
Min send: 10000000, max send 0
Min long send: 38387, max long send 60521
Min fwd: 45773, max fwd 58711; min bwd 92748, max bwd 103910
Min long fwd: 56704, max long fwd 63285; min long bwd 98353, max long bwd 106648
Time taken by simulation: 371 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 18 0 1481951.2939453125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4877293
Min send: 10000000, max send 0
Min long send: 38055, max long send 64155
Min fwd: 32292, max fwd 48132; min bwd 69316, max bwd 77937
Min long fwd: 43561, max long fwd 51496; min long bwd 71918, max long bwd 80151
Time taken by simulation: 800 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 25 0 976051.4526367188 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4466988
Min send: 10000000, max send 0
Min long send: 38237, max long send 65217
Min fwd: 19236, max fwd 35580; min bwd 42158, max bwd 57089
Min long fwd: 24076, max long fwd 35713; min long bwd 50505, max long bwd 59414
Time taken by simulation: 1756 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 42 0 610855.46875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4799842
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 10665, max fwd 27276; min bwd 28791, max bwd 43945
Min long fwd: 21459, max long fwd 30507; min long bwd 38642, max long bwd 48142
Time taken by simulation: 4315 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 64 0 343797.36328125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5360725
Min send: 10000000, max send 0
Min long send: 38056, max long send 68144
Min fwd: 5149, max fwd 20736; min bwd 17314, max bwd 33457
Min long fwd: 11639, max long fwd 22378; min long bwd 26559, max long bwd 34539
Time taken by simulation: 10369 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29589 microseconds

Stages 24
Micro-bs 1 Max mem: 2949765734.4
Predicted microbatch size for 24: 1
comm size 1638400
WARNING: no send time found, 24 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 24 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6789982
Min send: 10000000, max send 0
Min long send: 38055, max long send 74455
Min fwd: 26, max fwd 15549; min bwd 3842, max bwd 20573
Min long fwd: 7764, max long fwd 18097; min long bwd 11316, max long bwd 21840
Time taken by simulation: 46053 microseconds

{1: inf, 2: inf, 3: 4.913759, 4: 4.877293, 6: 4.466988, 8: 4.799842, 12: 5.360725, 16: 7.580423, 24: 6.789982}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1, 24: 1}
best config is: 6 1
expected time is 4.466988
5 per stage
30 servers!
Config:
ranks: range(3, 4)
train batch size: 128
partitions: 6
chunk_size: 1
data depth: 5
stage to rank map: 0,6,12,18,24;1,7,13,19,25;2,8,14,20,26;3,9,15,21,27;4,10,16,22,28;5,11,17,23,29;
World size is 30
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=3 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,6,12,18,24;1,7,13,19,25;2,8,14,20,26;3,9,15,21,27;4,10,16,22,28;5,11,17,23,29; --batch-size=25 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 103
dry run time 1.1574890613555908
SHARED WEIGHTS ARE
[(0, 5)]
this rank  3 is part of pipeline replica  0
25 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 3 signal handler called with signal 10
 > finished loading checkpoint in 50.440 seconds
Process done with return code 0
Parent process ID: 22910 node: 172.31.27.216
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 12 0 2007202.880859375 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4913759
Min send: 10000000, max send 0
Min long send: 38387, max long send 60521
Min fwd: 45773, max fwd 58711; min bwd 92748, max bwd 103910
Min long fwd: 56704, max long fwd 63285; min long bwd 98353, max long bwd 106648
Time taken by simulation: 372 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 16 0 1727535.5224609375 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4820532
Min send: 10000000, max send 0
Min long send: 38109, max long send 64155
Min fwd: 32292, max fwd 48132; min bwd 69446, max bwd 80083
Min long fwd: 43192, max long fwd 50561; min long bwd 74672, max long bwd 80151
Time taken by simulation: 690 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 25 0 976051.4526367188 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4466988
Min send: 10000000, max send 0
Min long send: 38237, max long send 65217
Min fwd: 19236, max fwd 35580; min bwd 42158, max bwd 57089
Min long fwd: 24076, max long fwd 35713; min long bwd 50505, max long bwd 59414
Time taken by simulation: 1757 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 32 0 700971.3134765625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4198444
Min send: 10000000, max send 0
Min long send: 38109, max long send 68059
Min fwd: 11544, max fwd 27276; min bwd 28686, max bwd 44788
Min long fwd: 22228, max long fwd 29781; min long bwd 41714, max long bwd 48296
Time taken by simulation: 3201 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 64 0 343797.36328125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5360725
Min send: 10000000, max send 0
Min long send: 38056, max long send 68144
Min fwd: 5149, max fwd 20736; min bwd 17314, max bwd 33457
Min long fwd: 11639, max long fwd 22378; min long bwd 26559, max long bwd 34539
Time taken by simulation: 10480 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 64 0 294405.0598144531 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5043807
Min send: 10000000, max send 0
Min long send: 38109, max long send 77793
Min fwd: 803, max fwd 17174; min bwd 10907, max bwd 28118
Min long fwd: 12084, max long fwd 20913; min long bwd 17914, max long bwd 26363
Time taken by simulation: 14198 microseconds

Stages 24
Micro-bs 1 Max mem: 2949765734.4
Predicted microbatch size for 24: 1
comm size 1638400
WARNING: no send time found, 24 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 24 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6789982
Min send: 10000000, max send 0
Min long send: 38055, max long send 74455
Min fwd: 26, max fwd 15549; min bwd 3842, max bwd 20573
Min long fwd: 7764, max long fwd 18097; min long bwd 11316, max long bwd 21840
Time taken by simulation: 46114 microseconds

{1: inf, 2: inf, 3: 4.913759, 4: 4.820532, 6: 4.466988, 8: 4.198444, 12: 5.360725, 16: 5.043807, 24: 6.789982}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1, 24: 1}
best config is: 8 1
expected time is 4.198444
4 per stage
32 servers!
Config:
ranks: range(3, 4)
train batch size: 128
partitions: 8
chunk_size: 1
data depth: 4
stage to rank map: 0,8,16,24;1,9,17,25;2,10,18,26;3,11,19,27;4,12,20,28;5,13,21,29;6,14,22,30;7,15,23,31;
World size is 32
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=3 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,8,16,24;1,9,17,25;2,10,18,26;3,11,19,27;4,12,20,28;5,13,21,29;6,14,22,30;7,15,23,31; --batch-size=32 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 103
dry run time 0.0047948360443115234
SHARED WEIGHTS ARE
[(0, 7)]
this rank  3 is part of pipeline replica  0
32 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
 > finished loading checkpoint in 43.990 seconds
START iteration 103, CKPT_AND_STOP: False
3 : update_scale(): _has_overflow, dynamic. _loss_scale =  65536.0
[2022-12-05 12:55:05.373037] Finished iteration 104, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 11978.077
START iteration 104, CKPT_AND_STOP: False
3 : update_scale(): _has_overflow, dynamic. _loss_scale =  32768.0
[2022-12-05 12:55:10.049572] Finished iteration 105, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4676.555
START iteration 105, CKPT_AND_STOP: False
3 : update_scale(): _has_overflow, dynamic. _loss_scale =  16384.0
[2022-12-05 12:55:14.679523] Finished iteration 106, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4629.950
START iteration 106, CKPT_AND_STOP: False
[2022-12-05 12:55:19.349098] Finished iteration 107, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4669.575
START iteration 107, CKPT_AND_STOP: False
[2022-12-05 12:55:24.013834] Finished iteration 108, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4664.737
START iteration 108, CKPT_AND_STOP: False
[2022-12-05 12:55:27.603872] Finished iteration 109, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3590.038
START iteration 109, CKPT_AND_STOP: False
[2022-12-05 12:55:31.227817] Finished iteration 110, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3623.946
START iteration 110, CKPT_AND_STOP: False
[2022-12-05 12:55:34.784665] Finished iteration 111, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3556.847
START iteration 111, CKPT_AND_STOP: False
[2022-12-05 12:55:38.399098] Finished iteration 112, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3614.434
START iteration 112, CKPT_AND_STOP: False
[2022-12-05 12:55:42.085550] Finished iteration 113, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3686.451
START iteration 113, CKPT_AND_STOP: False
[2022-12-05 12:55:45.646534] Finished iteration 114, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3560.985
START iteration 114, CKPT_AND_STOP: False
[2022-12-05 12:55:49.214499] Finished iteration 115, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3567.966
START iteration 115, CKPT_AND_STOP: False
[2022-12-05 12:55:52.780530] Finished iteration 116, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3566.030
START iteration 116, CKPT_AND_STOP: False
[2022-12-05 12:55:56.363275] Finished iteration 117, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3582.747
START iteration 117, CKPT_AND_STOP: False
[2022-12-05 12:55:59.969747] Finished iteration 118, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3606.472
START iteration 118, CKPT_AND_STOP: False
[2022-12-05 12:56:03.547835] Finished iteration 119, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3578.088
START iteration 119, CKPT_AND_STOP: False
[2022-12-05 12:56:07.135850] Finished iteration 120, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3588.015
START iteration 120, CKPT_AND_STOP: False
[2022-12-05 12:56:10.795805] Finished iteration 121, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3659.956
START iteration 121, CKPT_AND_STOP: False
[2022-12-05 12:56:14.442847] Finished iteration 122, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3647.041
START iteration 122, CKPT_AND_STOP: False
[2022-12-05 12:56:18.078188] Finished iteration 123, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3635.342
START iteration 123, CKPT_AND_STOP: False
[2022-12-05 12:56:21.756009] Finished iteration 124, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3677.820
START iteration 124, CKPT_AND_STOP: False
[2022-12-05 12:56:25.401897] Finished iteration 125, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3645.889
START iteration 125, CKPT_AND_STOP: False
[2022-12-05 12:56:29.023139] Finished iteration 126, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3621.242
START iteration 126, CKPT_AND_STOP: False
[2022-12-05 12:56:32.548453] Finished iteration 127, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3525.313
START iteration 127, CKPT_AND_STOP: False
[2022-12-05 12:56:36.174389] Finished iteration 128, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3625.937
START iteration 128, CKPT_AND_STOP: False
[2022-12-05 12:56:39.827577] Finished iteration 129, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3653.188
START iteration 129, CKPT_AND_STOP: False
[2022-12-05 12:56:43.446106] Finished iteration 130, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3618.529
START iteration 130, CKPT_AND_STOP: False
[2022-12-05 12:56:47.109410] Finished iteration 131, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3663.303
START iteration 131, CKPT_AND_STOP: False
[2022-12-05 12:56:50.715143] Finished iteration 132, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3605.733
START iteration 132, CKPT_AND_STOP: False
[2022-12-05 12:56:54.290787] Finished iteration 133, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3575.645
START iteration 133, CKPT_AND_STOP: False
[2022-12-05 12:56:57.863840] Finished iteration 134, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3573.054
START iteration 134, CKPT_AND_STOP: False
[2022-12-05 12:57:01.447791] Finished iteration 135, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3583.950
START iteration 135, CKPT_AND_STOP: False
[2022-12-05 12:57:05.073768] Finished iteration 136, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3625.978
START iteration 136, CKPT_AND_STOP: False
[2022-12-05 12:57:08.752611] Finished iteration 137, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3678.843
START iteration 137, CKPT_AND_STOP: False
[2022-12-05 12:57:12.324785] Finished iteration 138, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3572.174
START iteration 138, CKPT_AND_STOP: False
[2022-12-05 12:57:15.987235] Finished iteration 139, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3662.450
START iteration 139, CKPT_AND_STOP: False
[2022-12-05 12:57:19.624079] Finished iteration 140, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3636.844
START iteration 140, CKPT_AND_STOP: False
[2022-12-05 12:57:23.272837] Finished iteration 141, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3648.759
START iteration 141, CKPT_AND_STOP: False
[2022-12-05 12:57:26.890119] Finished iteration 142, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3617.282
START iteration 142, CKPT_AND_STOP: False
[2022-12-05 12:57:30.465987] Finished iteration 143, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3575.868
START iteration 143, CKPT_AND_STOP: False
[2022-12-05 12:57:34.092679] Finished iteration 144, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3626.690
START iteration 144, CKPT_AND_STOP: False
[2022-12-05 12:57:37.642025] Finished iteration 145, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3549.348
START iteration 145, CKPT_AND_STOP: False
[2022-12-05 12:57:41.227841] Finished iteration 146, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3585.821
START iteration 146, CKPT_AND_STOP: False
[2022-12-05 12:57:44.787312] Finished iteration 147, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3559.467
START iteration 147, CKPT_AND_STOP: False
[2022-12-05 12:57:48.398160] Finished iteration 148, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3610.848
START iteration 148, CKPT_AND_STOP: False
[2022-12-05 12:57:51.982464] Finished iteration 149, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3584.303
START iteration 149, CKPT_AND_STOP: False
[2022-12-05 12:57:55.612770] Finished iteration 150, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3630.306
START iteration 150, CKPT_AND_STOP: False
[2022-12-05 12:57:59.252644] Finished iteration 151, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3639.874
START iteration 151, CKPT_AND_STOP: False
[2022-12-05 12:58:02.842564] Finished iteration 152, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3589.921
START iteration 152, CKPT_AND_STOP: False
[2022-12-05 12:58:06.434167] Finished iteration 153, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3591.602
START iteration 153, CKPT_AND_STOP: False
[2022-12-05 12:58:10.061432] Finished iteration 154, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3627.266
START iteration 154, CKPT_AND_STOP: False
[2022-12-05 12:58:13.762109] Finished iteration 155, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3700.677
START iteration 155, CKPT_AND_STOP: False
[2022-12-05 12:58:17.386898] Finished iteration 156, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3624.789
START iteration 156, CKPT_AND_STOP: False
[2022-12-05 12:58:21.096056] Finished iteration 157, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3709.155
START iteration 157, CKPT_AND_STOP: False
[2022-12-05 12:58:24.692217] Finished iteration 158, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3596.162
START iteration 158, CKPT_AND_STOP: False
[2022-12-05 12:58:28.302790] Finished iteration 159, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3610.574
START iteration 159, CKPT_AND_STOP: False
[2022-12-05 12:58:31.860347] Finished iteration 160, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3557.557
START iteration 160, CKPT_AND_STOP: False
[2022-12-05 12:58:35.539344] Finished iteration 161, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3678.996
START iteration 161, CKPT_AND_STOP: False
[2022-12-05 12:58:39.135574] Finished iteration 162, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3596.231
START iteration 162, CKPT_AND_STOP: False
[2022-12-05 12:58:42.768664] Finished iteration 163, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3633.090
START iteration 163, CKPT_AND_STOP: False
[2022-12-05 12:58:46.392183] Finished iteration 164, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3623.518
START iteration 164, CKPT_AND_STOP: False
[2022-12-05 12:58:50.014523] Finished iteration 165, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3622.340
START iteration 165, CKPT_AND_STOP: False
[2022-12-05 12:58:53.645599] Finished iteration 166, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3631.076
START iteration 166, CKPT_AND_STOP: False
[2022-12-05 12:58:57.218121] Finished iteration 167, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3572.522
START iteration 167, CKPT_AND_STOP: False
[2022-12-05 12:59:00.906487] Finished iteration 168, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3688.366
START iteration 168, CKPT_AND_STOP: False
[2022-12-05 12:59:04.537654] Finished iteration 169, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3631.167
START iteration 169, CKPT_AND_STOP: False
[2022-12-05 12:59:08.172398] Finished iteration 170, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3634.744
START iteration 170, CKPT_AND_STOP: False
[2022-12-05 12:59:11.775975] Finished iteration 171, CKPT_AND_STOP: False, flag: tensor([1], dtype=torch.int32), speed: 3603.574
Begin to save checkpont and exit
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 3 signal handler called with signal 10
Opt ckpt time 7.5082550048828125
Process done with return code 0
Parent process ID: 24029 node: 172.31.27.216
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 12 0 2007202.880859375 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4913759
Min send: 10000000, max send 0
Min long send: 38387, max long send 60521
Min fwd: 45773, max fwd 58711; min bwd 92748, max bwd 103910
Min long fwd: 56704, max long fwd 63285; min long bwd 98353, max long bwd 106648
Time taken by simulation: 381 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 18 0 1481951.2939453125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4877293
Min send: 10000000, max send 0
Min long send: 38055, max long send 64155
Min fwd: 32292, max fwd 48132; min bwd 69316, max bwd 77937
Min long fwd: 43561, max long fwd 51496; min long bwd 71918, max long bwd 80151
Time taken by simulation: 776 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 25 0 976051.4526367188 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4466988
Min send: 10000000, max send 0
Min long send: 38237, max long send 65217
Min fwd: 19236, max fwd 35580; min bwd 42158, max bwd 57089
Min long fwd: 24076, max long fwd 35713; min long bwd 50505, max long bwd 59414
Time taken by simulation: 1777 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 42 0 610855.46875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4799842
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 10665, max fwd 27276; min bwd 28791, max bwd 43945
Min long fwd: 21459, max long fwd 30507; min long bwd 38642, max long bwd 48142
Time taken by simulation: 4251 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 64 0 343797.36328125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5360725
Min send: 10000000, max send 0
Min long send: 38056, max long send 68144
Min fwd: 5149, max fwd 20736; min bwd 17314, max bwd 33457
Min long fwd: 11639, max long fwd 22378; min long bwd 26559, max long bwd 34539
Time taken by simulation: 10422 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 31036 microseconds

Stages 24
Micro-bs 1 Max mem: 2949765734.4
Predicted microbatch size for 24: 1
comm size 1638400
WARNING: no send time found, 24 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 24 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6789982
Min send: 10000000, max send 0
Min long send: 38055, max long send 74455
Min fwd: 26, max fwd 15549; min bwd 3842, max bwd 20573
Min long fwd: 7764, max long fwd 18097; min long bwd 11316, max long bwd 21840
Time taken by simulation: 46771 microseconds

{1: inf, 2: inf, 3: 4.913759, 4: 4.877293, 6: 4.466988, 8: 4.799842, 12: 5.360725, 16: 7.580423, 24: 6.789982}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1, 24: 1}
best config is: 6 1
expected time is 4.466988
5 per stage
30 servers!
Config:
ranks: range(3, 4)
train batch size: 128
partitions: 6
chunk_size: 1
data depth: 5
stage to rank map: 0,6,12,18,24;1,7,13,19,25;2,8,14,20,26;3,9,15,21,27;4,10,16,22,28;5,11,17,23,29;
World size is 30
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=3 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,6,12,18,24;1,7,13,19,25;2,8,14,20,26;3,9,15,21,27;4,10,16,22,28;5,11,17,23,29; --batch-size=25 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 171
dry run time 0.8754067420959473
SHARED WEIGHTS ARE
[(0, 5)]
this rank  3 is part of pipeline replica  0
25 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
 > finished loading checkpoint in 56.233 seconds
START iteration 171, CKPT_AND_STOP: False
[2022-12-05 13:01:41.910555] Finished iteration 172, CKPT_AND_STOP: False, flag: tensor([2], dtype=torch.int32), speed: 9930.867
Begin to save checkpont and exit
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 3 signal handler called with signal 10
Opt ckpt time 8.767526149749756
Process done with return code 0
Parent process ID: 24962 node: 172.31.27.216
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 12 0 2007202.880859375 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4913759
Min send: 10000000, max send 0
Min long send: 38387, max long send 60521
Min fwd: 45773, max fwd 58711; min bwd 92748, max bwd 103910
Min long fwd: 56704, max long fwd 63285; min long bwd 98353, max long bwd 106648
Time taken by simulation: 371 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 16 0 1727535.5224609375 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4820532
Min send: 10000000, max send 0
Min long send: 38109, max long send 64155
Min fwd: 32292, max fwd 48132; min bwd 69446, max bwd 80083
Min long fwd: 43192, max long fwd 50561; min long bwd 74672, max long bwd 80151
Time taken by simulation: 733 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 25 0 976051.4526367188 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4466988
Min send: 10000000, max send 0
Min long send: 38237, max long send 65217
Min fwd: 19236, max fwd 35580; min bwd 42158, max bwd 57089
Min long fwd: 24076, max long fwd 35713; min long bwd 50505, max long bwd 59414
Time taken by simulation: 1753 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 32 0 700971.3134765625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4198444
Min send: 10000000, max send 0
Min long send: 38109, max long send 68059
Min fwd: 11544, max fwd 27276; min bwd 28686, max bwd 44788
Min long fwd: 22228, max long fwd 29781; min long bwd 41714, max long bwd 48296
Time taken by simulation: 3170 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 64 0 343797.36328125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5360725
Min send: 10000000, max send 0
Min long send: 38056, max long send 68144
Min fwd: 5149, max fwd 20736; min bwd 17314, max bwd 33457
Min long fwd: 11639, max long fwd 22378; min long bwd 26559, max long bwd 34539
Time taken by simulation: 10377 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 64 0 294405.0598144531 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5043807
Min send: 10000000, max send 0
Min long send: 38109, max long send 77793
Min fwd: 803, max fwd 17174; min bwd 10907, max bwd 28118
Min long fwd: 12084, max long fwd 20913; min long bwd 17914, max long bwd 26363
Time taken by simulation: 14185 microseconds

Stages 24
Micro-bs 1 Max mem: 2949765734.4
Predicted microbatch size for 24: 1
comm size 1638400
WARNING: no send time found, 24 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 24 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6789982
Min send: 10000000, max send 0
Min long send: 38055, max long send 74455
Min fwd: 26, max fwd 15549; min bwd 3842, max bwd 20573
Min long fwd: 7764, max long fwd 18097; min long bwd 11316, max long bwd 21840
Time taken by simulation: 45953 microseconds

{1: inf, 2: inf, 3: 4.913759, 4: 4.820532, 6: 4.466988, 8: 4.198444, 12: 5.360725, 16: 5.043807, 24: 6.789982}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1, 24: 1}
best config is: 8 1
expected time is 4.198444
4 per stage
32 servers!
Config:
ranks: range(3, 4)
train batch size: 128
partitions: 8
chunk_size: 1
data depth: 4
stage to rank map: 0,8,16,24;1,9,17,25;2,10,18,26;3,11,19,27;4,12,20,28;5,13,21,29;6,14,22,30;7,15,23,31;
World size is 32
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=3 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,8,16,24;1,9,17,25;2,10,18,26;3,11,19,27;4,12,20,28;5,13,21,29;6,14,22,30;7,15,23,31; --batch-size=32 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 172
dry run time 0.9635388851165771
SHARED WEIGHTS ARE
[(0, 7)]
this rank  3 is part of pipeline replica  0
32 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
 > finished loading checkpoint in 45.596 seconds
START iteration 172, CKPT_AND_STOP: False
[2022-12-05 13:03:32.130210] Finished iteration 173, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 11698.922
START iteration 173, CKPT_AND_STOP: False
[2022-12-05 13:03:37.640582] Finished iteration 174, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5510.399
START iteration 174, CKPT_AND_STOP: False
[2022-12-05 13:03:42.359202] Finished iteration 175, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4718.620
START iteration 175, CKPT_AND_STOP: False
[2022-12-05 13:03:47.049091] Finished iteration 176, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4689.887
START iteration 176, CKPT_AND_STOP: False
[2022-12-05 13:03:51.657274] Finished iteration 177, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4608.185
START iteration 177, CKPT_AND_STOP: False
[2022-12-05 13:03:55.264181] Finished iteration 178, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3606.907
START iteration 178, CKPT_AND_STOP: False
[2022-12-05 13:03:58.824222] Finished iteration 179, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3560.040
START iteration 179, CKPT_AND_STOP: False
[2022-12-05 13:04:02.886993] Finished iteration 180, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4062.771
START iteration 180, CKPT_AND_STOP: False
[2022-12-05 13:04:07.066546] Finished iteration 181, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4179.554
START iteration 181, CKPT_AND_STOP: False
[2022-12-05 13:04:10.646299] Finished iteration 182, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3579.753
START iteration 182, CKPT_AND_STOP: False
[2022-12-05 13:04:14.188050] Finished iteration 183, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3541.749
START iteration 183, CKPT_AND_STOP: False
[2022-12-05 13:04:17.743534] Finished iteration 184, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3555.486
START iteration 184, CKPT_AND_STOP: False
[2022-12-05 13:04:21.363648] Finished iteration 185, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3620.114
START iteration 185, CKPT_AND_STOP: False
[2022-12-05 13:04:24.924291] Finished iteration 186, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3560.643
START iteration 186, CKPT_AND_STOP: False
[2022-12-05 13:04:28.500009] Finished iteration 187, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3575.718
START iteration 187, CKPT_AND_STOP: False
[2022-12-05 13:04:32.186287] Finished iteration 188, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3686.277
START iteration 188, CKPT_AND_STOP: False
[2022-12-05 13:04:35.942667] Finished iteration 189, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3756.381
START iteration 189, CKPT_AND_STOP: False
[2022-12-05 13:04:39.576657] Finished iteration 190, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3633.991
START iteration 190, CKPT_AND_STOP: False
[2022-12-05 13:04:43.304296] Finished iteration 191, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3727.639
START iteration 191, CKPT_AND_STOP: False
[2022-12-05 13:04:47.011160] Finished iteration 192, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3706.864
START iteration 192, CKPT_AND_STOP: False
[2022-12-05 13:04:50.735272] Finished iteration 193, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3724.112
START iteration 193, CKPT_AND_STOP: False
[2022-12-05 13:04:54.357446] Finished iteration 194, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3622.175
START iteration 194, CKPT_AND_STOP: False
[2022-12-05 13:04:58.021152] Finished iteration 195, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3663.705
START iteration 195, CKPT_AND_STOP: False
[2022-12-05 13:05:01.609816] Finished iteration 196, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3588.662
START iteration 196, CKPT_AND_STOP: False
[2022-12-05 13:05:05.161240] Finished iteration 197, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3551.427
START iteration 197, CKPT_AND_STOP: False
[2022-12-05 13:05:08.687593] Finished iteration 198, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3526.352
START iteration 198, CKPT_AND_STOP: False
[2022-12-05 13:05:12.267107] Finished iteration 199, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3579.514
START iteration 199, CKPT_AND_STOP: False
[2022-12-05 13:05:16.025924] Finished iteration 200, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3758.817
START iteration 200, CKPT_AND_STOP: False
[2022-12-05 13:05:19.579925] Finished iteration 201, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3554.000
START iteration 201, CKPT_AND_STOP: False
[2022-12-05 13:05:23.278209] Finished iteration 202, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3698.283
START iteration 202, CKPT_AND_STOP: False
[2022-12-05 13:05:26.870939] Finished iteration 203, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3592.731
START iteration 203, CKPT_AND_STOP: False
[2022-12-05 13:05:30.536476] Finished iteration 204, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3665.537
START iteration 204, CKPT_AND_STOP: False
[2022-12-05 13:05:34.146752] Finished iteration 205, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3610.276
START iteration 205, CKPT_AND_STOP: False
[2022-12-05 13:05:37.836986] Finished iteration 206, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3690.234
START iteration 206, CKPT_AND_STOP: False
[2022-12-05 13:05:41.504034] Finished iteration 207, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3667.048
START iteration 207, CKPT_AND_STOP: False
[2022-12-05 13:05:45.072374] Finished iteration 208, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3568.340
START iteration 208, CKPT_AND_STOP: False
[2022-12-05 13:05:48.643940] Finished iteration 209, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3571.567
START iteration 209, CKPT_AND_STOP: False
[2022-12-05 13:05:52.152684] Finished iteration 210, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3508.743
START iteration 210, CKPT_AND_STOP: False
[2022-12-05 13:05:55.727998] Finished iteration 211, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3575.314
START iteration 211, CKPT_AND_STOP: False
[2022-12-05 13:05:59.403635] Finished iteration 212, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3675.636
START iteration 212, CKPT_AND_STOP: False
[2022-12-05 13:06:02.999062] Finished iteration 213, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3595.428
START iteration 213, CKPT_AND_STOP: False
[2022-12-05 13:06:06.513963] Finished iteration 214, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3514.901
START iteration 214, CKPT_AND_STOP: False
[2022-12-05 13:06:10.122256] Finished iteration 215, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3608.293
START iteration 215, CKPT_AND_STOP: False
[2022-12-05 13:06:13.705946] Finished iteration 216, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3583.690
START iteration 216, CKPT_AND_STOP: False
[2022-12-05 13:06:17.303471] Finished iteration 217, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3597.525
START iteration 217, CKPT_AND_STOP: False
[2022-12-05 13:06:20.869021] Finished iteration 218, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3565.550
START iteration 218, CKPT_AND_STOP: False
[2022-12-05 13:06:24.470680] Finished iteration 219, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3601.659
START iteration 219, CKPT_AND_STOP: False
[2022-12-05 13:06:28.035346] Finished iteration 220, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3564.667
START iteration 220, CKPT_AND_STOP: False
[2022-12-05 13:06:31.681228] Finished iteration 221, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3645.881
START iteration 221, CKPT_AND_STOP: False
[2022-12-05 13:06:35.282190] Finished iteration 222, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3600.962
START iteration 222, CKPT_AND_STOP: False
[2022-12-05 13:06:38.900503] Finished iteration 223, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3618.313
START iteration 223, CKPT_AND_STOP: False
[2022-12-05 13:06:42.496750] Finished iteration 224, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3596.247
START iteration 224, CKPT_AND_STOP: False
[2022-12-05 13:06:46.143351] Finished iteration 225, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3646.601
START iteration 225, CKPT_AND_STOP: False
[2022-12-05 13:06:49.887581] Finished iteration 226, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3744.230
START iteration 226, CKPT_AND_STOP: False
[2022-12-05 13:06:53.506853] Finished iteration 227, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3619.272
START iteration 227, CKPT_AND_STOP: False
[2022-12-05 13:06:57.039495] Finished iteration 228, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3532.641
START iteration 228, CKPT_AND_STOP: False
[2022-12-05 13:07:00.611811] Finished iteration 229, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3572.316
START iteration 229, CKPT_AND_STOP: False
[2022-12-05 13:07:04.307576] Finished iteration 230, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3695.765
START iteration 230, CKPT_AND_STOP: False
[2022-12-05 13:07:07.947864] Finished iteration 231, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3640.288
START iteration 231, CKPT_AND_STOP: False
[2022-12-05 13:07:11.525277] Finished iteration 232, CKPT_AND_STOP: False, flag: tensor([1], dtype=torch.int32), speed: 3577.414
Begin to save checkpont and exit
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 3 signal handler called with signal 10
Opt ckpt time 7.056177616119385
Process done with return code 0
Parent process ID: 26077 node: 172.31.27.216
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 14 0 2006653.3203125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5367030
Min send: 10000000, max send 0
Min long send: 38387, max long send 60521
Min fwd: 45773, max fwd 60689; min bwd 93028, max bwd 103910
Min long fwd: 57033, max long fwd 64913; min long bwd 98397, max long bwd 102857
Time taken by simulation: 460 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 18 0 1481951.2939453125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4877293
Min send: 10000000, max send 0
Min long send: 38055, max long send 64155
Min fwd: 32292, max fwd 48132; min bwd 69316, max bwd 77937
Min long fwd: 43561, max long fwd 51496; min long bwd 71918, max long bwd 80151
Time taken by simulation: 776 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 32 0 876895.5078125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5017062
Min send: 10000000, max send 0
Min long send: 38071, max long send 66276
Min fwd: 18837, max fwd 35859; min bwd 42514, max bwd 56347
Min long fwd: 27753, max long fwd 35222; min long bwd 51765, max long bwd 59571
Time taken by simulation: 2295 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 42 0 610855.46875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4799842
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 10665, max fwd 27276; min bwd 28791, max bwd 43945
Min long fwd: 21459, max long fwd 30507; min long bwd 38642, max long bwd 48142
Time taken by simulation: 4240 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 64 0 343797.36328125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5360725
Min send: 10000000, max send 0
Min long send: 38056, max long send 68144
Min fwd: 5149, max fwd 20736; min bwd 17314, max bwd 33457
Min long fwd: 11639, max long fwd 22378; min long bwd 26559, max long bwd 34539
Time taken by simulation: 10445 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29717 microseconds

Stages 24
Micro-bs 1 Max mem: 2949765734.4
Predicted microbatch size for 24: 1
comm size 1638400
WARNING: no send time found, 24 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 24 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6789982
Min send: 10000000, max send 0
Min long send: 38055, max long send 74455
Min fwd: 26, max fwd 15549; min bwd 3842, max bwd 20573
Min long fwd: 7764, max long fwd 18097; min long bwd 11316, max long bwd 21840
Time taken by simulation: 45816 microseconds

{1: inf, 2: inf, 3: 5.36703, 4: 4.877293, 6: 5.017062, 8: 4.799842, 12: 5.360725, 16: 7.580423, 24: 6.789982}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1, 24: 1}
best config is: 8 1
expected time is 4.799842
3 per stage
24 servers!
Config:
ranks: range(3, 4)
train batch size: 128
partitions: 8
chunk_size: 1
data depth: 3
stage to rank map: 0,8,16;1,9,17;2,10,18;3,11,19;4,12,20;5,13,21;6,14,22;7,15,23;
World size is 24
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=3 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,8,16;1,9,17;2,10,18;3,11,19;4,12,20;5,13,21;6,14,22;7,15,23; --batch-size=42 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 232
dry run time 1.1497368812561035
SHARED WEIGHTS ARE
[(0, 7)]
this rank  3 is part of pipeline replica  0
42 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
 > finished loading checkpoint in 40.966 seconds
START iteration 232, CKPT_AND_STOP: False
[2022-12-05 13:09:29.745914] Finished iteration 233, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 12352.949
START iteration 233, CKPT_AND_STOP: False
[2022-12-05 13:09:34.881133] Finished iteration 234, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5135.249
START iteration 234, CKPT_AND_STOP: False
[2022-12-05 13:09:39.943111] Finished iteration 235, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5061.978
START iteration 235, CKPT_AND_STOP: False
[2022-12-05 13:09:45.050205] Finished iteration 236, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5107.091
START iteration 236, CKPT_AND_STOP: False
[2022-12-05 13:09:50.196458] Finished iteration 237, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5146.255
START iteration 237, CKPT_AND_STOP: False
[2022-12-05 13:09:54.344782] Finished iteration 238, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4148.326
START iteration 238, CKPT_AND_STOP: False
[2022-12-05 13:09:58.456952] Finished iteration 239, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4112.166
START iteration 239, CKPT_AND_STOP: False
[2022-12-05 13:10:02.548360] Finished iteration 240, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4091.411
START iteration 240, CKPT_AND_STOP: False
[2022-12-05 13:10:06.608264] Finished iteration 241, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4059.902
START iteration 241, CKPT_AND_STOP: False
[2022-12-05 13:10:10.664091] Finished iteration 242, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4055.829
START iteration 242, CKPT_AND_STOP: False
[2022-12-05 13:10:14.760609] Finished iteration 243, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4096.515
START iteration 243, CKPT_AND_STOP: False
[2022-12-05 13:10:18.874171] Finished iteration 244, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4113.564
START iteration 244, CKPT_AND_STOP: False
[2022-12-05 13:10:22.959251] Finished iteration 245, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4085.082
START iteration 245, CKPT_AND_STOP: False
[2022-12-05 13:10:27.103239] Finished iteration 246, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4143.986
START iteration 246, CKPT_AND_STOP: False
[2022-12-05 13:10:31.200064] Finished iteration 247, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4096.827
START iteration 247, CKPT_AND_STOP: False
[2022-12-05 13:10:35.313953] Finished iteration 248, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4113.889
START iteration 248, CKPT_AND_STOP: False
[2022-12-05 13:10:39.419129] Finished iteration 249, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4105.180
START iteration 249, CKPT_AND_STOP: False
[2022-12-05 13:10:43.548253] Finished iteration 250, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4129.120
START iteration 250, CKPT_AND_STOP: False
[2022-12-05 13:10:47.648951] Finished iteration 251, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4100.698
START iteration 251, CKPT_AND_STOP: False
[2022-12-05 13:10:51.701415] Finished iteration 252, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4052.464
START iteration 252, CKPT_AND_STOP: False
[2022-12-05 13:10:55.766818] Finished iteration 253, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4065.403
START iteration 253, CKPT_AND_STOP: False
[2022-12-05 13:10:59.798902] Finished iteration 254, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4032.084
START iteration 254, CKPT_AND_STOP: False
[2022-12-05 13:11:03.844980] Finished iteration 255, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4046.077
START iteration 255, CKPT_AND_STOP: False
[2022-12-05 13:11:07.931908] Finished iteration 256, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4086.930
START iteration 256, CKPT_AND_STOP: False
[2022-12-05 13:11:11.974626] Finished iteration 257, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4042.717
START iteration 257, CKPT_AND_STOP: False
[2022-12-05 13:11:16.108356] Finished iteration 258, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4133.728
START iteration 258, CKPT_AND_STOP: False
[2022-12-05 13:11:20.314834] Finished iteration 259, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4206.477
START iteration 259, CKPT_AND_STOP: False
[2022-12-05 13:11:24.444954] Finished iteration 260, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4130.124
START iteration 260, CKPT_AND_STOP: False
[2022-12-05 13:11:28.506481] Finished iteration 261, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4061.526
START iteration 261, CKPT_AND_STOP: False
[2022-12-05 13:11:32.587973] Finished iteration 262, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4081.492
START iteration 262, CKPT_AND_STOP: False
[2022-12-05 13:11:36.727090] Finished iteration 263, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4139.117
START iteration 263, CKPT_AND_STOP: False
[2022-12-05 13:11:40.782663] Finished iteration 264, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4055.572
START iteration 264, CKPT_AND_STOP: False
[2022-12-05 13:11:44.914173] Finished iteration 265, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4131.508
START iteration 265, CKPT_AND_STOP: False
[2022-12-05 13:11:48.992496] Finished iteration 266, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4078.325
START iteration 266, CKPT_AND_STOP: False
[2022-12-05 13:11:53.059575] Finished iteration 267, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4067.079
START iteration 267, CKPT_AND_STOP: False
[2022-12-05 13:11:57.144467] Finished iteration 268, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4084.892
START iteration 268, CKPT_AND_STOP: False
[2022-12-05 13:12:01.222482] Finished iteration 269, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4078.015
START iteration 269, CKPT_AND_STOP: False
[2022-12-05 13:12:05.332556] Finished iteration 270, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4110.074
START iteration 270, CKPT_AND_STOP: False
[2022-12-05 13:12:09.396577] Finished iteration 271, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4064.013
START iteration 271, CKPT_AND_STOP: False
[2022-12-05 13:12:13.486233] Finished iteration 272, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4089.661
START iteration 272, CKPT_AND_STOP: False
[2022-12-05 13:12:17.558326] Finished iteration 273, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4072.096
START iteration 273, CKPT_AND_STOP: False
[2022-12-05 13:12:21.609882] Finished iteration 274, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4051.556
START iteration 274, CKPT_AND_STOP: False
[2022-12-05 13:12:25.658444] Finished iteration 275, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4048.561
START iteration 275, CKPT_AND_STOP: False
[2022-12-05 13:12:29.756923] Finished iteration 276, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4098.463
START iteration 276, CKPT_AND_STOP: False
[2022-12-05 13:12:33.841803] Finished iteration 277, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4084.901
START iteration 277, CKPT_AND_STOP: False
[2022-12-05 13:12:37.953553] Finished iteration 278, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4111.746
START iteration 278, CKPT_AND_STOP: False
[2022-12-05 13:12:42.085693] Finished iteration 279, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4132.140
START iteration 279, CKPT_AND_STOP: False
[2022-12-05 13:12:46.156342] Finished iteration 280, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4070.649
START iteration 280, CKPT_AND_STOP: False
[2022-12-05 13:12:50.239332] Finished iteration 281, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4082.990
START iteration 281, CKPT_AND_STOP: False
[2022-12-05 13:12:54.435827] Finished iteration 282, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4196.495
START iteration 282, CKPT_AND_STOP: False
[2022-12-05 13:12:58.511365] Finished iteration 283, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4075.535
START iteration 283, CKPT_AND_STOP: False
[2022-12-05 13:13:02.627310] Finished iteration 284, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4115.948
START iteration 284, CKPT_AND_STOP: False
[2022-12-05 13:13:06.685969] Finished iteration 285, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4058.659
START iteration 285, CKPT_AND_STOP: False
[2022-12-05 13:13:10.750516] Finished iteration 286, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4064.547
START iteration 286, CKPT_AND_STOP: False
[2022-12-05 13:13:15.302324] Finished iteration 287, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4551.809
START iteration 287, CKPT_AND_STOP: False
[2022-12-05 13:13:19.374383] Finished iteration 288, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4072.058
START iteration 288, CKPT_AND_STOP: False
[2022-12-05 13:13:23.397564] Finished iteration 289, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4023.181
START iteration 289, CKPT_AND_STOP: False
[2022-12-05 13:13:27.553469] Finished iteration 290, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4155.906
START iteration 290, CKPT_AND_STOP: False
[2022-12-05 13:13:31.718141] Finished iteration 291, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4164.671
START iteration 291, CKPT_AND_STOP: False
[2022-12-05 13:13:35.864695] Finished iteration 292, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4146.552
START iteration 292, CKPT_AND_STOP: False
[2022-12-05 13:13:39.943234] Finished iteration 293, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4078.542
START iteration 293, CKPT_AND_STOP: False
[2022-12-05 13:13:43.938351] Finished iteration 294, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3995.116
START iteration 294, CKPT_AND_STOP: False
[2022-12-05 13:13:47.995423] Finished iteration 295, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4057.072
START iteration 295, CKPT_AND_STOP: False
[2022-12-05 13:13:52.129949] Finished iteration 296, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4134.526
START iteration 296, CKPT_AND_STOP: False
[2022-12-05 13:13:56.192819] Finished iteration 297, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4062.868
START iteration 297, CKPT_AND_STOP: False
[2022-12-05 13:14:01.067178] Finished iteration 298, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4874.360
START iteration 298, CKPT_AND_STOP: False
[2022-12-05 13:14:05.127781] Finished iteration 299, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4060.604
START iteration 299, CKPT_AND_STOP: False
[2022-12-05 13:14:09.244961] Finished iteration 300, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4117.179
START iteration 300, CKPT_AND_STOP: False
[2022-12-05 13:14:13.318112] Finished iteration 301, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4073.152
START iteration 301, CKPT_AND_STOP: False
[2022-12-05 13:14:17.513888] Finished iteration 302, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4195.775
START iteration 302, CKPT_AND_STOP: False
[2022-12-05 13:14:21.603927] Finished iteration 303, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4090.037
START iteration 303, CKPT_AND_STOP: False
[2022-12-05 13:14:25.701778] Finished iteration 304, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4097.852
START iteration 304, CKPT_AND_STOP: False
[2022-12-05 13:14:29.751177] Finished iteration 305, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4049.398
START iteration 305, CKPT_AND_STOP: False
[2022-12-05 13:14:33.829079] Finished iteration 306, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4077.900
START iteration 306, CKPT_AND_STOP: False
[2022-12-05 13:14:37.855717] Finished iteration 307, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4026.640
START iteration 307, CKPT_AND_STOP: False
[2022-12-05 13:14:41.953230] Finished iteration 308, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4097.512
START iteration 308, CKPT_AND_STOP: False
[2022-12-05 13:14:46.140706] Finished iteration 309, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4187.479
START iteration 309, CKPT_AND_STOP: False
[2022-12-05 13:14:50.212483] Finished iteration 310, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4071.775
START iteration 310, CKPT_AND_STOP: False
[2022-12-05 13:14:54.260471] Finished iteration 311, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4047.989
START iteration 311, CKPT_AND_STOP: False
[2022-12-05 13:14:58.420165] Finished iteration 312, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4159.695
START iteration 312, CKPT_AND_STOP: False
[2022-12-05 13:15:02.519398] Finished iteration 313, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4099.233
START iteration 313, CKPT_AND_STOP: False
[2022-12-05 13:15:06.609975] Finished iteration 314, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4090.576
START iteration 314, CKPT_AND_STOP: False
[2022-12-05 13:15:10.715978] Finished iteration 315, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4106.004
START iteration 315, CKPT_AND_STOP: False
[2022-12-05 13:15:14.845479] Finished iteration 316, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4129.499
START iteration 316, CKPT_AND_STOP: False
[2022-12-05 13:15:18.947899] Finished iteration 317, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4102.421
START iteration 317, CKPT_AND_STOP: False
[2022-12-05 13:15:23.013020] Finished iteration 318, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4065.121
START iteration 318, CKPT_AND_STOP: False
[2022-12-05 13:15:27.068403] Finished iteration 319, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4055.381
START iteration 319, CKPT_AND_STOP: False
[2022-12-05 13:15:31.149351] Finished iteration 320, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4080.949
START iteration 320, CKPT_AND_STOP: False
[2022-12-05 13:15:36.104676] Finished iteration 321, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4955.325
START iteration 321, CKPT_AND_STOP: False
[2022-12-05 13:15:40.109025] Finished iteration 322, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4004.349
START iteration 322, CKPT_AND_STOP: False
