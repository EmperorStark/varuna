Parent process ID: 9633 node: 172.31.28.143
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 12 0 2007202.880859375 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4913759
Min send: 10000000, max send 0
Min long send: 38387, max long send 60521
Min fwd: 45773, max fwd 58711; min bwd 92748, max bwd 103910
Min long fwd: 56704, max long fwd 63285; min long bwd 98353, max long bwd 106648
Time taken by simulation: 419 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 16 0 1727535.5224609375 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4820532
Min send: 10000000, max send 0
Min long send: 38109, max long send 64155
Min fwd: 32292, max fwd 48132; min bwd 69446, max bwd 80083
Min long fwd: 43192, max long fwd 50561; min long bwd 74672, max long bwd 80151
Time taken by simulation: 693 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 25 0 976051.4526367188 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4466988
Min send: 10000000, max send 0
Min long send: 38237, max long send 65217
Min fwd: 19236, max fwd 35580; min bwd 42158, max bwd 57089
Min long fwd: 24076, max long fwd 35713; min long bwd 50505, max long bwd 59414
Time taken by simulation: 1750 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 32 0 700971.3134765625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4198444
Min send: 10000000, max send 0
Min long send: 38109, max long send 68059
Min fwd: 11544, max fwd 27276; min bwd 28686, max bwd 44788
Min long fwd: 22228, max long fwd 29781; min long bwd 41714, max long bwd 48296
Time taken by simulation: 3178 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 64 0 343797.36328125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5360725
Min send: 10000000, max send 0
Min long send: 38056, max long send 68144
Min fwd: 5149, max fwd 20736; min bwd 17314, max bwd 33457
Min long fwd: 11639, max long fwd 22378; min long bwd 26559, max long bwd 34539
Time taken by simulation: 10388 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 64 0 294405.0598144531 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5043807
Min send: 10000000, max send 0
Min long send: 38109, max long send 77793
Min fwd: 803, max fwd 17174; min bwd 10907, max bwd 28118
Min long fwd: 12084, max long fwd 20913; min long bwd 17914, max long bwd 26363
Time taken by simulation: 14167 microseconds

Stages 24
Micro-bs 1 Max mem: 2949765734.4
Predicted microbatch size for 24: 1
comm size 1638400
WARNING: no send time found, 24 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 24 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6789982
Min send: 10000000, max send 0
Min long send: 38055, max long send 74455
Min fwd: 26, max fwd 15549; min bwd 3842, max bwd 20573
Min long fwd: 7764, max long fwd 18097; min long bwd 11316, max long bwd 21840
Time taken by simulation: 45865 microseconds

{1: inf, 2: inf, 3: 4.913759, 4: 4.820532, 6: 4.466988, 8: 4.198444, 12: 5.360725, 16: 5.043807, 24: 6.789982}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1, 24: 1}
best config is: 8 1
expected time is 4.198444
4 per stage
32 servers!
Config:
ranks: range(23, 24)
train batch size: 128
partitions: 8
chunk_size: 1
data depth: 4
stage to rank map: 0,8,16,24;1,9,17,25;2,10,18,26;3,11,19,27;4,12,20,28;5,13,21,29;6,14,22,30;7,15,23,31;
World size is 32
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=23 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,8,16,24;1,9,17,25;2,10,18,26;3,11,19,27;4,12,20,28;5,13,21,29;6,14,22,30;7,15,23,31; --batch-size=32 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16
dry run time 1.0683708190917969
SHARED WEIGHTS ARE
[(0, 7)]
this rank  23 is part of pipeline replica  2
32 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
 > finished loading checkpoint in 0.187 seconds
START iteration 0, CKPT_AND_STOP: False
[2022-12-05 12:21:27.124962] Finished iteration 1, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 11618.076
START iteration 1, CKPT_AND_STOP: False
[2022-12-05 12:21:31.806343] Finished iteration 2, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4681.413
START iteration 2, CKPT_AND_STOP: False
[2022-12-05 12:21:36.501082] Finished iteration 3, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4694.740
START iteration 3, CKPT_AND_STOP: False
[2022-12-05 12:21:41.148838] Finished iteration 4, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4647.756
START iteration 4, CKPT_AND_STOP: False
[2022-12-05 12:21:46.718373] Finished iteration 5, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5569.536
START iteration 5, CKPT_AND_STOP: False
[2022-12-05 12:21:50.356854] Finished iteration 6, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3638.481
START iteration 6, CKPT_AND_STOP: False
[2022-12-05 12:21:53.936860] Finished iteration 7, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3580.006
START iteration 7, CKPT_AND_STOP: False
[2022-12-05 12:21:57.454285] Finished iteration 8, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3517.424
START iteration 8, CKPT_AND_STOP: False
[2022-12-05 12:22:01.534249] Finished iteration 9, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4079.964
START iteration 9, CKPT_AND_STOP: False
[2022-12-05 12:22:05.663153] Finished iteration 10, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4128.905
START iteration 10, CKPT_AND_STOP: False
[2022-12-05 12:22:09.424541] Finished iteration 11, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3761.389
START iteration 11, CKPT_AND_STOP: False
[2022-12-05 12:22:13.082716] Finished iteration 12, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3658.175
START iteration 12, CKPT_AND_STOP: False
[2022-12-05 12:22:16.705068] Finished iteration 13, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3622.350
START iteration 13, CKPT_AND_STOP: False
[2022-12-05 12:22:21.284663] Finished iteration 14, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4579.597
START iteration 14, CKPT_AND_STOP: False
[2022-12-05 12:22:24.912089] Finished iteration 15, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3627.426
START iteration 15, CKPT_AND_STOP: False
[2022-12-05 12:22:28.510075] Finished iteration 16, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3597.986
START iteration 16, CKPT_AND_STOP: False
[2022-12-05 12:22:32.092240] Finished iteration 17, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3582.165
START iteration 17, CKPT_AND_STOP: False
[2022-12-05 12:22:35.697537] Finished iteration 18, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3605.293
START iteration 18, CKPT_AND_STOP: False
[2022-12-05 12:22:39.282149] Finished iteration 19, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3584.615
START iteration 19, CKPT_AND_STOP: False
[2022-12-05 12:22:42.853202] Finished iteration 20, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3571.049
START iteration 20, CKPT_AND_STOP: False
[2022-12-05 12:22:46.462074] Finished iteration 21, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3608.876
START iteration 21, CKPT_AND_STOP: False
[2022-12-05 12:22:50.014532] Finished iteration 22, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3552.454
START iteration 22, CKPT_AND_STOP: False
[2022-12-05 12:22:53.697128] Finished iteration 23, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3682.600
START iteration 23, CKPT_AND_STOP: False
[2022-12-05 12:22:57.278881] Finished iteration 24, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3581.748
START iteration 24, CKPT_AND_STOP: False
[2022-12-05 12:23:00.850567] Finished iteration 25, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3571.690
START iteration 25, CKPT_AND_STOP: False
[2022-12-05 12:23:04.444684] Finished iteration 26, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3594.117
START iteration 26, CKPT_AND_STOP: False
[2022-12-05 12:23:08.134296] Finished iteration 27, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3689.610
START iteration 27, CKPT_AND_STOP: False
[2022-12-05 12:23:11.688215] Finished iteration 28, CKPT_AND_STOP: False, flag: tensor([1], dtype=torch.int32), speed: 3553.920
Begin to save checkpont and exit
Opt ckpt time 3.673227310180664
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 23 signal handler called with signal 10
Process done with return code 0
Parent process ID: 10294 node: 172.31.17.209
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 14 0 2006653.3203125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5367030
Min send: 10000000, max send 0
Min long send: 38387, max long send 60521
Min fwd: 45773, max fwd 60689; min bwd 93028, max bwd 103910
Min long fwd: 57033, max long fwd 64913; min long bwd 98397, max long bwd 102857
Time taken by simulation: 505 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 18 0 1481951.2939453125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4877293
Min send: 10000000, max send 0
Min long send: 38055, max long send 64155
Min fwd: 32292, max fwd 48132; min bwd 69316, max bwd 77937
Min long fwd: 43561, max long fwd 51496; min long bwd 71918, max long bwd 80151
Time taken by simulation: 777 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 32 0 876895.5078125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5017062
Min send: 10000000, max send 0
Min long send: 38071, max long send 66276
Min fwd: 18837, max fwd 35859; min bwd 42514, max bwd 56347
Min long fwd: 27753, max long fwd 35222; min long bwd 51765, max long bwd 59571
Time taken by simulation: 2283 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 42 0 610855.46875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4799842
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 10665, max fwd 27276; min bwd 28791, max bwd 43945
Min long fwd: 21459, max long fwd 30507; min long bwd 38642, max long bwd 48142
Time taken by simulation: 4352 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 64 0 343797.36328125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5360725
Min send: 10000000, max send 0
Min long send: 38056, max long send 68144
Min fwd: 5149, max fwd 20736; min bwd 17314, max bwd 33457
Min long fwd: 11639, max long fwd 22378; min long bwd 26559, max long bwd 34539
Time taken by simulation: 10399 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29585 microseconds

Stages 24
Micro-bs 1 Max mem: 2949765734.4
Predicted microbatch size for 24: 1
comm size 1638400
WARNING: no send time found, 24 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 24 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6789982
Min send: 10000000, max send 0
Min long send: 38055, max long send 74455
Min fwd: 26, max fwd 15549; min bwd 3842, max bwd 20573
Min long fwd: 7764, max long fwd 18097; min long bwd 11316, max long bwd 21840
Time taken by simulation: 46097 microseconds

{1: inf, 2: inf, 3: 5.36703, 4: 4.877293, 6: 5.017062, 8: 4.799842, 12: 5.360725, 16: 7.580423, 24: 6.789982}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1, 24: 1}
best config is: 8 1
expected time is 4.799842
3 per stage
24 servers!
Config:
ranks: range(23, 24)
train batch size: 128
partitions: 8
chunk_size: 1
data depth: 3
stage to rank map: 0,8,16;1,9,17;2,10,18;3,11,19;4,12,20;5,13,21;6,14,22;7,15,23;
World size is 24
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=23 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,8,16;1,9,17;2,10,18;3,11,19;4,12,20;5,13,21;6,14,22;7,15,23; --batch-size=42 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 28
dry run time 0.9429359436035156
SHARED WEIGHTS ARE
[(0, 7)]
this rank  23 is part of pipeline replica  2
42 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
 > finished loading checkpoint in 43.310 seconds
Process done with return code 0
Parent process ID: 10680 node: 172.31.27.21
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 16 0 2198285.64453125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5986016
Min send: 10000000, max send 0
Min long send: 38293, max long send 60521
Min fwd: 45773, max fwd 59456; min bwd 93556, max bwd 103910
Min long fwd: 57033, max long fwd 64913; min long bwd 97741, max long bwd 104518
Time taken by simulation: 485 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 21 0 1478731.4453125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5493991
Min send: 10000000, max send 0
Min long send: 38109, max long send 64155
Min fwd: 32128, max fwd 48180; min bwd 67776, max bwd 77208
Min long fwd: 43175, max long fwd 51496; min long bwd 74514, max long bwd 81205
Time taken by simulation: 930 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 32 0 876895.5078125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5017062
Min send: 10000000, max send 0
Min long send: 38071, max long send 66276
Min fwd: 18837, max fwd 35859; min bwd 42514, max bwd 56347
Min long fwd: 27753, max long fwd 35222; min long bwd 51765, max long bwd 59571
Time taken by simulation: 2254 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 42 0 610855.46875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4799842
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 10665, max fwd 27276; min bwd 28791, max bwd 43945
Min long fwd: 21459, max long fwd 30507; min long bwd 38642, max long bwd 48142
Time taken by simulation: 4278 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 64 0 343797.36328125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5360725
Min send: 10000000, max send 0
Min long send: 38056, max long send 68144
Min fwd: 5149, max fwd 20736; min bwd 17314, max bwd 33457
Min long fwd: 11639, max long fwd 22378; min long bwd 26559, max long bwd 34539
Time taken by simulation: 10390 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29642 microseconds

Stages 24
Micro-bs 1 Max mem: 2949765734.4
Predicted microbatch size for 24: 1
comm size 1638400
WARNING: no send time found, 24 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 24 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6789982
Min send: 10000000, max send 0
Min long send: 38055, max long send 74455
Min fwd: 26, max fwd 15549; min bwd 3842, max bwd 20573
Min long fwd: 7764, max long fwd 18097; min long bwd 11316, max long bwd 21840
Time taken by simulation: 45818 microseconds

{1: inf, 2: inf, 3: 5.986016, 4: 5.493991, 6: 5.017062, 8: 4.799842, 12: 5.360725, 16: 7.580423, 24: 6.789982}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1, 24: 1}
best config is: 8 1
expected time is 4.799842
3 per stage
24 servers!
Config:
ranks: range(23, 24)
train batch size: 128
partitions: 8
chunk_size: 1
data depth: 3
stage to rank map: 0,8,16;1,9,17;2,10,18;3,11,19;4,12,20;5,13,21;6,14,22;7,15,23;
World size is 24
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=23 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,8,16;1,9,17;2,10,18;3,11,19;4,12,20;5,13,21;6,14,22;7,15,23; --batch-size=42 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 28
dry run time 0.9784977436065674
SHARED WEIGHTS ARE
[(0, 7)]
this rank  23 is part of pipeline replica  2
42 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
 > finished loading checkpoint in 40.912 seconds
Process done with return code 0
Parent process ID: 11035 node: 172.31.30.89
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 16 0 2198285.64453125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5986016
Min send: 10000000, max send 0
Min long send: 38293, max long send 60521
Min fwd: 45773, max fwd 59456; min bwd 93556, max bwd 103910
Min long fwd: 57033, max long fwd 64913; min long bwd 97741, max long bwd 104518
Time taken by simulation: 486 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 21 0 1478731.4453125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5493991
Min send: 10000000, max send 0
Min long send: 38109, max long send 64155
Min fwd: 32128, max fwd 48180; min bwd 67776, max bwd 77208
Min long fwd: 43175, max long fwd 51496; min long bwd 74514, max long bwd 81205
Time taken by simulation: 903 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 32 0 876895.5078125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5017062
Min send: 10000000, max send 0
Min long send: 38071, max long send 66276
Min fwd: 18837, max fwd 35859; min bwd 42514, max bwd 56347
Min long fwd: 27753, max long fwd 35222; min long bwd 51765, max long bwd 59571
Time taken by simulation: 2290 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 42 0 610855.46875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4799842
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 10665, max fwd 27276; min bwd 28791, max bwd 43945
Min long fwd: 21459, max long fwd 30507; min long bwd 38642, max long bwd 48142
Time taken by simulation: 4237 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 64 0 343797.36328125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5360725
Min send: 10000000, max send 0
Min long send: 38056, max long send 68144
Min fwd: 5149, max fwd 20736; min bwd 17314, max bwd 33457
Min long fwd: 11639, max long fwd 22378; min long bwd 26559, max long bwd 34539
Time taken by simulation: 10399 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29617 microseconds

Stages 24
Micro-bs 1 Max mem: 2949765734.4
Predicted microbatch size for 24: 1
comm size 1638400
WARNING: no send time found, 24 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 24 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6789982
Min send: 10000000, max send 0
Min long send: 38055, max long send 74455
Min fwd: 26, max fwd 15549; min bwd 3842, max bwd 20573
Min long fwd: 7764, max long fwd 18097; min long bwd 11316, max long bwd 21840
Time taken by simulation: 45927 microseconds

{1: inf, 2: inf, 3: 5.986016, 4: 5.493991, 6: 5.017062, 8: 4.799842, 12: 5.360725, 16: 7.580423, 24: 6.789982}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1, 24: 1}
best config is: 8 1
expected time is 4.799842
3 per stage
24 servers!
Config:
ranks: range(23, 24)
train batch size: 128
partitions: 8
chunk_size: 1
data depth: 3
stage to rank map: 0,8,16;1,9,17;2,10,18;3,11,19;4,12,20;5,13,21;6,14,22;7,15,23;
World size is 24
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=23 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,8,16;1,9,17;2,10,18;3,11,19;4,12,20;5,13,21;6,14,22;7,15,23; --batch-size=42 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 28
dry run time 1.2431702613830566
SHARED WEIGHTS ARE
[(0, 7)]
this rank  23 is part of pipeline replica  2
42 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
 > finished loading checkpoint in 36.506 seconds
START iteration 28, CKPT_AND_STOP: False
[2022-12-05 12:29:19.254961] Finished iteration 29, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 12541.876
START iteration 29, CKPT_AND_STOP: False
[2022-12-05 12:29:24.330550] Finished iteration 30, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5075.623
START iteration 30, CKPT_AND_STOP: False
[2022-12-05 12:29:30.932967] Finished iteration 31, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6602.418
START iteration 31, CKPT_AND_STOP: False
[2022-12-05 12:29:36.117513] Finished iteration 32, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5184.547
START iteration 32, CKPT_AND_STOP: False
[2022-12-05 12:29:41.497547] Finished iteration 33, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5380.034
START iteration 33, CKPT_AND_STOP: False
[2022-12-05 12:29:45.599548] Finished iteration 34, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4102.001
START iteration 34, CKPT_AND_STOP: False
[2022-12-05 12:29:49.680548] Finished iteration 35, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4081.001
START iteration 35, CKPT_AND_STOP: False
[2022-12-05 12:29:53.831583] Finished iteration 36, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4151.034
START iteration 36, CKPT_AND_STOP: False
[2022-12-05 12:29:57.926237] Finished iteration 37, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4094.653
START iteration 37, CKPT_AND_STOP: False
[2022-12-05 12:30:01.993708] Finished iteration 38, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4067.472
START iteration 38, CKPT_AND_STOP: False
[2022-12-05 12:30:06.040265] Finished iteration 39, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4046.554
START iteration 39, CKPT_AND_STOP: False
[2022-12-05 12:30:10.119319] Finished iteration 40, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4079.057
START iteration 40, CKPT_AND_STOP: False
[2022-12-05 12:30:14.244224] Finished iteration 41, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4124.905
START iteration 41, CKPT_AND_STOP: False
[2022-12-05 12:30:18.360059] Finished iteration 42, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4115.833
START iteration 42, CKPT_AND_STOP: False
[2022-12-05 12:30:22.478627] Finished iteration 43, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4118.570
START iteration 43, CKPT_AND_STOP: False
[2022-12-05 12:30:26.520095] Finished iteration 44, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4041.465
START iteration 44, CKPT_AND_STOP: False
[2022-12-05 12:30:30.510884] Finished iteration 45, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3990.793
START iteration 45, CKPT_AND_STOP: False
[2022-12-05 12:30:34.595232] Finished iteration 46, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4084.348
START iteration 46, CKPT_AND_STOP: False
[2022-12-05 12:30:38.721178] Finished iteration 47, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4125.946
START iteration 47, CKPT_AND_STOP: False
[2022-12-05 12:30:42.947365] Finished iteration 48, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4226.186
START iteration 48, CKPT_AND_STOP: False
[2022-12-05 12:30:47.033824] Finished iteration 49, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4086.459
START iteration 49, CKPT_AND_STOP: False
[2022-12-05 12:30:51.065126] Finished iteration 50, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4031.303
START iteration 50, CKPT_AND_STOP: False
[2022-12-05 12:30:55.110976] Finished iteration 51, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4045.851
START iteration 51, CKPT_AND_STOP: False
[2022-12-05 12:30:59.185802] Finished iteration 52, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4074.826
START iteration 52, CKPT_AND_STOP: False
[2022-12-05 12:31:03.255430] Finished iteration 53, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4069.625
START iteration 53, CKPT_AND_STOP: False
[2022-12-05 12:31:07.275658] Finished iteration 54, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4020.230
START iteration 54, CKPT_AND_STOP: False
[2022-12-05 12:31:11.336880] Finished iteration 55, CKPT_AND_STOP: False, flag: tensor([1], dtype=torch.int32), speed: 4061.222
Begin to save checkpont and exit
Opt ckpt time 9.494339227676392
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 23 signal handler called with signal 10
Process done with return code 0
Parent process ID: 11003 node: 172.31.22.165
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 16 0 2198285.64453125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5986016
Min send: 10000000, max send 0
Min long send: 38293, max long send 60521
Min fwd: 45773, max fwd 59456; min bwd 93556, max bwd 103910
Min long fwd: 57033, max long fwd 64913; min long bwd 97741, max long bwd 104518
Time taken by simulation: 508 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 21 0 1478731.4453125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5493991
Min send: 10000000, max send 0
Min long send: 38109, max long send 64155
Min fwd: 32128, max fwd 48180; min bwd 67776, max bwd 77208
Min long fwd: 43175, max long fwd 51496; min long bwd 74514, max long bwd 81205
Time taken by simulation: 897 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 32 0 876895.5078125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5017062
Min send: 10000000, max send 0
Min long send: 38071, max long send 66276
Min fwd: 18837, max fwd 35859; min bwd 42514, max bwd 56347
Min long fwd: 27753, max long fwd 35222; min long bwd 51765, max long bwd 59571
Time taken by simulation: 2287 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 42 0 610855.46875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4799842
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 10665, max fwd 27276; min bwd 28791, max bwd 43945
Min long fwd: 21459, max long fwd 30507; min long bwd 38642, max long bwd 48142
Time taken by simulation: 4225 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 64 0 343797.36328125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5360725
Min send: 10000000, max send 0
Min long send: 38056, max long send 68144
Min fwd: 5149, max fwd 20736; min bwd 17314, max bwd 33457
Min long fwd: 11639, max long fwd 22378; min long bwd 26559, max long bwd 34539
Time taken by simulation: 10414 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29512 microseconds

Stages 24
Micro-bs 1 Max mem: 2949765734.4
Predicted microbatch size for 24: 1
comm size 1638400
WARNING: no send time found, 24 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 24 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6789982
Min send: 10000000, max send 0
Min long send: 38055, max long send 74455
Min fwd: 26, max fwd 15549; min bwd 3842, max bwd 20573
Min long fwd: 7764, max long fwd 18097; min long bwd 11316, max long bwd 21840
Time taken by simulation: 45836 microseconds

{1: inf, 2: inf, 3: 5.986016, 4: 5.493991, 6: 5.017062, 8: 4.799842, 12: 5.360725, 16: 7.580423, 24: 6.789982}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1, 24: 1}
best config is: 8 1
expected time is 4.799842
3 per stage
24 servers!
Config:
ranks: range(23, 24)
train batch size: 128
partitions: 8
chunk_size: 1
data depth: 3
stage to rank map: 0,8,16;1,9,17;2,10,18;3,11,19;4,12,20;5,13,21;6,14,22;7,15,23;
World size is 24
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=23 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,8,16;1,9,17;2,10,18;3,11,19;4,12,20;5,13,21;6,14,22;7,15,23; --batch-size=42 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 61
dry run time 0.8792564868927002
SHARED WEIGHTS ARE
[(0, 7)]
this rank  23 is part of pipeline replica  2
42 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 23 signal handler called with signal 10
 > finished loading checkpoint in 38.540 seconds
Process done with return code 0
Parent process ID: 11825 node: 172.31.22.165
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 16 0 2198285.64453125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5986016
Min send: 10000000, max send 0
Min long send: 38293, max long send 60521
Min fwd: 45773, max fwd 59456; min bwd 93556, max bwd 103910
Min long fwd: 57033, max long fwd 64913; min long bwd 97741, max long bwd 104518
Time taken by simulation: 486 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 21 0 1478731.4453125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5493991
Min send: 10000000, max send 0
Min long send: 38109, max long send 64155
Min fwd: 32128, max fwd 48180; min bwd 67776, max bwd 77208
Min long fwd: 43175, max long fwd 51496; min long bwd 74514, max long bwd 81205
Time taken by simulation: 926 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 32 0 876895.5078125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5017062
Min send: 10000000, max send 0
Min long send: 38071, max long send 66276
Min fwd: 18837, max fwd 35859; min bwd 42514, max bwd 56347
Min long fwd: 27753, max long fwd 35222; min long bwd 51765, max long bwd 59571
Time taken by simulation: 2240 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 42 0 610855.46875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4799842
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 10665, max fwd 27276; min bwd 28791, max bwd 43945
Min long fwd: 21459, max long fwd 30507; min long bwd 38642, max long bwd 48142
Time taken by simulation: 4268 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 64 0 343797.36328125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5360725
Min send: 10000000, max send 0
Min long send: 38056, max long send 68144
Min fwd: 5149, max fwd 20736; min bwd 17314, max bwd 33457
Min long fwd: 11639, max long fwd 22378; min long bwd 26559, max long bwd 34539
Time taken by simulation: 10477 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29912 microseconds

Stages 24
Micro-bs 1 Max mem: 2949765734.4
Predicted microbatch size for 24: 1
comm size 1638400
WARNING: no send time found, 24 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 24 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6789982
Min send: 10000000, max send 0
Min long send: 38055, max long send 74455
Min fwd: 26, max fwd 15549; min bwd 3842, max bwd 20573
Min long fwd: 7764, max long fwd 18097; min long bwd 11316, max long bwd 21840
Time taken by simulation: 45804 microseconds

{1: inf, 2: inf, 3: 5.986016, 4: 5.493991, 6: 5.017062, 8: 4.799842, 12: 5.360725, 16: 7.580423, 24: 6.789982}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1, 24: 1}
best config is: 8 1
expected time is 4.799842
3 per stage
24 servers!
Config:
ranks: range(23, 24)
train batch size: 128
partitions: 8
chunk_size: 1
data depth: 3
stage to rank map: 0,8,16;1,9,17;2,10,18;3,11,19;4,12,20;5,13,21;6,14,22;7,15,23;
World size is 24
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=23 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,8,16;1,9,17;2,10,18;3,11,19;4,12,20;5,13,21;6,14,22;7,15,23; --batch-size=42 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 61
dry run time 0.8435506820678711
SHARED WEIGHTS ARE
[(0, 7)]
this rank  23 is part of pipeline replica  2
42 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 23 signal handler called with signal 10
 > finished loading checkpoint in 35.906 seconds
Process done with return code 0
Parent process ID: 12350 node: 172.31.19.171
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 12 0 2007202.880859375 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4913759
Min send: 10000000, max send 0
Min long send: 38387, max long send 60521
Min fwd: 45773, max fwd 58711; min bwd 92748, max bwd 103910
Min long fwd: 56704, max long fwd 63285; min long bwd 98353, max long bwd 106648
Time taken by simulation: 372 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 18 0 1481951.2939453125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4877293
Min send: 10000000, max send 0
Min long send: 38055, max long send 64155
Min fwd: 32292, max fwd 48132; min bwd 69316, max bwd 77937
Min long fwd: 43561, max long fwd 51496; min long bwd 71918, max long bwd 80151
Time taken by simulation: 775 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 25 0 976051.4526367188 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4466988
Min send: 10000000, max send 0
Min long send: 38237, max long send 65217
Min fwd: 19236, max fwd 35580; min bwd 42158, max bwd 57089
Min long fwd: 24076, max long fwd 35713; min long bwd 50505, max long bwd 59414
Time taken by simulation: 1783 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 42 0 610855.46875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4799842
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 10665, max fwd 27276; min bwd 28791, max bwd 43945
Min long fwd: 21459, max long fwd 30507; min long bwd 38642, max long bwd 48142
Time taken by simulation: 4257 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 64 0 343797.36328125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5360725
Min send: 10000000, max send 0
Min long send: 38056, max long send 68144
Min fwd: 5149, max fwd 20736; min bwd 17314, max bwd 33457
Min long fwd: 11639, max long fwd 22378; min long bwd 26559, max long bwd 34539
Time taken by simulation: 10446 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29801 microseconds

Stages 24
Micro-bs 1 Max mem: 2949765734.4
Predicted microbatch size for 24: 1
comm size 1638400
WARNING: no send time found, 24 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 24 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6789982
Min send: 10000000, max send 0
Min long send: 38055, max long send 74455
Min fwd: 26, max fwd 15549; min bwd 3842, max bwd 20573
Min long fwd: 7764, max long fwd 18097; min long bwd 11316, max long bwd 21840
Time taken by simulation: 46035 microseconds

{1: inf, 2: inf, 3: 4.913759, 4: 4.877293, 6: 4.466988, 8: 4.799842, 12: 5.360725, 16: 7.580423, 24: 6.789982}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1, 24: 1}
best config is: 6 1
expected time is 4.466988
5 per stage
30 servers!
Config:
ranks: range(23, 24)
train batch size: 128
partitions: 6
chunk_size: 1
data depth: 5
stage to rank map: 0,6,12,18,24;1,7,13,19,25;2,8,14,20,26;3,9,15,21,27;4,10,16,22,28;5,11,17,23,29;
World size is 30
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=23 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,6,12,18,24;1,7,13,19,25;2,8,14,20,26;3,9,15,21,27;4,10,16,22,28;5,11,17,23,29; --batch-size=25 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 103
dry run time 1.2108724117279053
SHARED WEIGHTS ARE
[(0, 5)]
this rank  23 is part of pipeline replica  3
25 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 23 signal handler called with signal 10
 > finished loading checkpoint in 50.426 seconds
Process done with return code 0
Parent process ID: 13311 node: 172.31.19.171
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 12 0 2007202.880859375 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4913759
Min send: 10000000, max send 0
Min long send: 38387, max long send 60521
Min fwd: 45773, max fwd 58711; min bwd 92748, max bwd 103910
Min long fwd: 56704, max long fwd 63285; min long bwd 98353, max long bwd 106648
Time taken by simulation: 372 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 16 0 1727535.5224609375 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4820532
Min send: 10000000, max send 0
Min long send: 38109, max long send 64155
Min fwd: 32292, max fwd 48132; min bwd 69446, max bwd 80083
Min long fwd: 43192, max long fwd 50561; min long bwd 74672, max long bwd 80151
Time taken by simulation: 697 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 25 0 976051.4526367188 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4466988
Min send: 10000000, max send 0
Min long send: 38237, max long send 65217
Min fwd: 19236, max fwd 35580; min bwd 42158, max bwd 57089
Min long fwd: 24076, max long fwd 35713; min long bwd 50505, max long bwd 59414
Time taken by simulation: 1771 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 32 0 700971.3134765625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4198444
Min send: 10000000, max send 0
Min long send: 38109, max long send 68059
Min fwd: 11544, max fwd 27276; min bwd 28686, max bwd 44788
Min long fwd: 22228, max long fwd 29781; min long bwd 41714, max long bwd 48296
Time taken by simulation: 3208 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 64 0 343797.36328125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5360725
Min send: 10000000, max send 0
Min long send: 38056, max long send 68144
Min fwd: 5149, max fwd 20736; min bwd 17314, max bwd 33457
Min long fwd: 11639, max long fwd 22378; min long bwd 26559, max long bwd 34539
Time taken by simulation: 10490 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 64 0 294405.0598144531 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5043807
Min send: 10000000, max send 0
Min long send: 38109, max long send 77793
Min fwd: 803, max fwd 17174; min bwd 10907, max bwd 28118
Min long fwd: 12084, max long fwd 20913; min long bwd 17914, max long bwd 26363
Time taken by simulation: 14217 microseconds

Stages 24
Micro-bs 1 Max mem: 2949765734.4
Predicted microbatch size for 24: 1
comm size 1638400
WARNING: no send time found, 24 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 24 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6789982
Min send: 10000000, max send 0
Min long send: 38055, max long send 74455
Min fwd: 26, max fwd 15549; min bwd 3842, max bwd 20573
Min long fwd: 7764, max long fwd 18097; min long bwd 11316, max long bwd 21840
Time taken by simulation: 46048 microseconds

{1: inf, 2: inf, 3: 4.913759, 4: 4.820532, 6: 4.466988, 8: 4.198444, 12: 5.360725, 16: 5.043807, 24: 6.789982}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1, 24: 1}
best config is: 8 1
expected time is 4.198444
4 per stage
32 servers!
Config:
ranks: range(23, 24)
train batch size: 128
partitions: 8
chunk_size: 1
data depth: 4
stage to rank map: 0,8,16,24;1,9,17,25;2,10,18,26;3,11,19,27;4,12,20,28;5,13,21,29;6,14,22,30;7,15,23,31;
World size is 32
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=23 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,8,16,24;1,9,17,25;2,10,18,26;3,11,19,27;4,12,20,28;5,13,21,29;6,14,22,30;7,15,23,31; --batch-size=32 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 103
dry run time 1.2305097579956055
SHARED WEIGHTS ARE
[(0, 7)]
this rank  23 is part of pipeline replica  2
32 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
 > finished loading checkpoint in 43.968 seconds
START iteration 103, CKPT_AND_STOP: False
23 : update_scale(): _has_overflow, dynamic. _loss_scale =  65536.0
[2022-12-05 12:55:05.369849] Finished iteration 104, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 11978.406
START iteration 104, CKPT_AND_STOP: False
23 : update_scale(): _has_overflow, dynamic. _loss_scale =  32768.0
[2022-12-05 12:55:10.046466] Finished iteration 105, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4676.644
START iteration 105, CKPT_AND_STOP: False
23 : update_scale(): _has_overflow, dynamic. _loss_scale =  16384.0
[2022-12-05 12:55:14.676340] Finished iteration 106, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4629.875
START iteration 106, CKPT_AND_STOP: False
[2022-12-05 12:55:19.345578] Finished iteration 107, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4669.237
START iteration 107, CKPT_AND_STOP: False
[2022-12-05 12:55:24.010412] Finished iteration 108, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4664.836
START iteration 108, CKPT_AND_STOP: False
[2022-12-05 12:55:27.600789] Finished iteration 109, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3590.377
START iteration 109, CKPT_AND_STOP: False
[2022-12-05 12:55:31.224808] Finished iteration 110, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3624.018
START iteration 110, CKPT_AND_STOP: False
[2022-12-05 12:55:34.781643] Finished iteration 111, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3556.833
START iteration 111, CKPT_AND_STOP: False
[2022-12-05 12:55:38.395683] Finished iteration 112, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3614.045
START iteration 112, CKPT_AND_STOP: False
[2022-12-05 12:55:42.082348] Finished iteration 113, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3686.661
START iteration 113, CKPT_AND_STOP: False
[2022-12-05 12:55:45.643598] Finished iteration 114, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3561.249
START iteration 114, CKPT_AND_STOP: False
[2022-12-05 12:55:49.211175] Finished iteration 115, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3567.580
START iteration 115, CKPT_AND_STOP: False
[2022-12-05 12:55:52.777525] Finished iteration 116, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3566.349
START iteration 116, CKPT_AND_STOP: False
[2022-12-05 12:55:56.360055] Finished iteration 117, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3582.530
START iteration 117, CKPT_AND_STOP: False
[2022-12-05 12:55:59.966510] Finished iteration 118, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3606.456
START iteration 118, CKPT_AND_STOP: False
[2022-12-05 12:56:03.544751] Finished iteration 119, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3578.239
START iteration 119, CKPT_AND_STOP: False
[2022-12-05 12:56:07.132914] Finished iteration 120, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3588.162
START iteration 120, CKPT_AND_STOP: False
[2022-12-05 12:56:10.792860] Finished iteration 121, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3659.948
START iteration 121, CKPT_AND_STOP: False
[2022-12-05 12:56:14.439884] Finished iteration 122, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3647.023
START iteration 122, CKPT_AND_STOP: False
[2022-12-05 12:56:18.075253] Finished iteration 123, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3635.374
START iteration 123, CKPT_AND_STOP: False
[2022-12-05 12:56:21.753089] Finished iteration 124, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3677.832
START iteration 124, CKPT_AND_STOP: False
[2022-12-05 12:56:25.398768] Finished iteration 125, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3645.683
START iteration 125, CKPT_AND_STOP: False
[2022-12-05 12:56:29.020060] Finished iteration 126, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3621.288
START iteration 126, CKPT_AND_STOP: False
[2022-12-05 12:56:32.545419] Finished iteration 127, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3525.359
START iteration 127, CKPT_AND_STOP: False
[2022-12-05 12:56:36.171092] Finished iteration 128, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3625.674
START iteration 128, CKPT_AND_STOP: False
[2022-12-05 12:56:39.824615] Finished iteration 129, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3653.523
START iteration 129, CKPT_AND_STOP: False
[2022-12-05 12:56:43.443071] Finished iteration 130, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3618.458
START iteration 130, CKPT_AND_STOP: False
[2022-12-05 12:56:47.106448] Finished iteration 131, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3663.374
START iteration 131, CKPT_AND_STOP: False
[2022-12-05 12:56:50.711961] Finished iteration 132, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3605.518
START iteration 132, CKPT_AND_STOP: False
[2022-12-05 12:56:54.287727] Finished iteration 133, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3575.761
START iteration 133, CKPT_AND_STOP: False
[2022-12-05 12:56:57.860857] Finished iteration 134, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3573.128
START iteration 134, CKPT_AND_STOP: False
[2022-12-05 12:57:01.444804] Finished iteration 135, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3583.948
START iteration 135, CKPT_AND_STOP: False
[2022-12-05 12:57:05.070773] Finished iteration 136, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3625.968
START iteration 136, CKPT_AND_STOP: False
[2022-12-05 12:57:08.749482] Finished iteration 137, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3678.710
START iteration 137, CKPT_AND_STOP: False
[2022-12-05 12:57:12.321736] Finished iteration 138, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3572.254
START iteration 138, CKPT_AND_STOP: False
[2022-12-05 12:57:15.984261] Finished iteration 139, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3662.524
START iteration 139, CKPT_AND_STOP: False
[2022-12-05 12:57:19.621060] Finished iteration 140, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3636.798
START iteration 140, CKPT_AND_STOP: False
[2022-12-05 12:57:23.269843] Finished iteration 141, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3648.782
START iteration 141, CKPT_AND_STOP: False
[2022-12-05 12:57:26.887071] Finished iteration 142, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3617.231
START iteration 142, CKPT_AND_STOP: False
[2022-12-05 12:57:30.462697] Finished iteration 143, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3575.626
START iteration 143, CKPT_AND_STOP: False
[2022-12-05 12:57:34.089328] Finished iteration 144, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3626.631
START iteration 144, CKPT_AND_STOP: False
[2022-12-05 12:57:37.638922] Finished iteration 145, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3549.591
START iteration 145, CKPT_AND_STOP: False
[2022-12-05 12:57:41.224986] Finished iteration 146, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3586.067
START iteration 146, CKPT_AND_STOP: False
[2022-12-05 12:57:44.784220] Finished iteration 147, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3559.233
START iteration 147, CKPT_AND_STOP: False
[2022-12-05 12:57:48.395045] Finished iteration 148, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3610.826
START iteration 148, CKPT_AND_STOP: False
[2022-12-05 12:57:51.979584] Finished iteration 149, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3584.539
START iteration 149, CKPT_AND_STOP: False
[2022-12-05 12:57:55.609386] Finished iteration 150, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3629.803
START iteration 150, CKPT_AND_STOP: False
[2022-12-05 12:57:59.249473] Finished iteration 151, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3640.087
START iteration 151, CKPT_AND_STOP: False
[2022-12-05 12:58:02.839712] Finished iteration 152, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3590.237
START iteration 152, CKPT_AND_STOP: False
[2022-12-05 12:58:06.431223] Finished iteration 153, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3591.512
START iteration 153, CKPT_AND_STOP: False
[2022-12-05 12:58:10.058430] Finished iteration 154, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3627.207
START iteration 154, CKPT_AND_STOP: False
[2022-12-05 12:58:13.759030] Finished iteration 155, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3700.599
START iteration 155, CKPT_AND_STOP: False
[2022-12-05 12:58:17.383986] Finished iteration 156, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3624.957
START iteration 156, CKPT_AND_STOP: False
[2022-12-05 12:58:21.092920] Finished iteration 157, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3708.934
START iteration 157, CKPT_AND_STOP: False
[2022-12-05 12:58:24.689362] Finished iteration 158, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3596.440
START iteration 158, CKPT_AND_STOP: False
[2022-12-05 12:58:28.299814] Finished iteration 159, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3610.453
START iteration 159, CKPT_AND_STOP: False
[2022-12-05 12:58:31.857097] Finished iteration 160, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3557.283
START iteration 160, CKPT_AND_STOP: False
[2022-12-05 12:58:35.536623] Finished iteration 161, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3679.527
START iteration 161, CKPT_AND_STOP: False
[2022-12-05 12:58:39.132366] Finished iteration 162, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3595.742
START iteration 162, CKPT_AND_STOP: False
[2022-12-05 12:58:42.765464] Finished iteration 163, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3633.096
START iteration 163, CKPT_AND_STOP: False
[2022-12-05 12:58:46.389029] Finished iteration 164, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3623.566
START iteration 164, CKPT_AND_STOP: False
[2022-12-05 12:58:50.011396] Finished iteration 165, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3622.365
START iteration 165, CKPT_AND_STOP: False
[2022-12-05 12:58:53.642271] Finished iteration 166, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3630.877
START iteration 166, CKPT_AND_STOP: False
[2022-12-05 12:58:57.215053] Finished iteration 167, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3572.785
START iteration 167, CKPT_AND_STOP: False
[2022-12-05 12:59:00.903687] Finished iteration 168, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3688.631
START iteration 168, CKPT_AND_STOP: False
[2022-12-05 12:59:04.534626] Finished iteration 169, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3630.939
START iteration 169, CKPT_AND_STOP: False
[2022-12-05 12:59:08.169266] Finished iteration 170, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3634.641
START iteration 170, CKPT_AND_STOP: False
[2022-12-05 12:59:11.772918] Finished iteration 171, CKPT_AND_STOP: False, flag: tensor([1], dtype=torch.int32), speed: 3603.648
Begin to save checkpont and exit
Opt ckpt time 4.04806923866272
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 23 signal handler called with signal 10
Process done with return code 0
Parent process ID: 15007 node: 172.31.21.254
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 12 0 2007202.880859375 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4913759
Min send: 10000000, max send 0
Min long send: 38387, max long send 60521
Min fwd: 45773, max fwd 58711; min bwd 92748, max bwd 103910
Min long fwd: 56704, max long fwd 63285; min long bwd 98353, max long bwd 106648
Time taken by simulation: 374 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 18 0 1481951.2939453125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4877293
Min send: 10000000, max send 0
Min long send: 38055, max long send 64155
Min fwd: 32292, max fwd 48132; min bwd 69316, max bwd 77937
Min long fwd: 43561, max long fwd 51496; min long bwd 71918, max long bwd 80151
Time taken by simulation: 775 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 25 0 976051.4526367188 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4466988
Min send: 10000000, max send 0
Min long send: 38237, max long send 65217
Min fwd: 19236, max fwd 35580; min bwd 42158, max bwd 57089
Min long fwd: 24076, max long fwd 35713; min long bwd 50505, max long bwd 59414
Time taken by simulation: 1758 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 42 0 610855.46875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4799842
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 10665, max fwd 27276; min bwd 28791, max bwd 43945
Min long fwd: 21459, max long fwd 30507; min long bwd 38642, max long bwd 48142
Time taken by simulation: 4240 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 64 0 343797.36328125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5360725
Min send: 10000000, max send 0
Min long send: 38056, max long send 68144
Min fwd: 5149, max fwd 20736; min bwd 17314, max bwd 33457
Min long fwd: 11639, max long fwd 22378; min long bwd 26559, max long bwd 34539
Time taken by simulation: 10400 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29641 microseconds

Stages 24
Micro-bs 1 Max mem: 2949765734.4
Predicted microbatch size for 24: 1
comm size 1638400
WARNING: no send time found, 24 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 24 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6789982
Min send: 10000000, max send 0
Min long send: 38055, max long send 74455
Min fwd: 26, max fwd 15549; min bwd 3842, max bwd 20573
Min long fwd: 7764, max long fwd 18097; min long bwd 11316, max long bwd 21840
Time taken by simulation: 45943 microseconds

{1: inf, 2: inf, 3: 4.913759, 4: 4.877293, 6: 4.466988, 8: 4.799842, 12: 5.360725, 16: 7.580423, 24: 6.789982}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1, 24: 1}
best config is: 6 1
expected time is 4.466988
5 per stage
30 servers!
Config:
ranks: range(23, 24)
train batch size: 128
partitions: 6
chunk_size: 1
data depth: 5
stage to rank map: 0,6,12,18,24;1,7,13,19,25;2,8,14,20,26;3,9,15,21,27;4,10,16,22,28;5,11,17,23,29;
World size is 30
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=23 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,6,12,18,24;1,7,13,19,25;2,8,14,20,26;3,9,15,21,27;4,10,16,22,28;5,11,17,23,29; --batch-size=25 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 171
dry run time 1.1804530620574951
SHARED WEIGHTS ARE
[(0, 5)]
this rank  23 is part of pipeline replica  3
25 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
 > finished loading checkpoint in 56.225 seconds
START iteration 171, CKPT_AND_STOP: False
[2022-12-05 13:01:41.907291] Finished iteration 172, CKPT_AND_STOP: False, flag: tensor([2], dtype=torch.int32), speed: 9931.073
Begin to save checkpont and exit
Opt ckpt time 8.047838926315308
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 23 signal handler called with signal 10
Process done with return code 0
Parent process ID: 15943 node: 172.31.21.254
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 12 0 2007202.880859375 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4913759
Min send: 10000000, max send 0
Min long send: 38387, max long send 60521
Min fwd: 45773, max fwd 58711; min bwd 92748, max bwd 103910
Min long fwd: 56704, max long fwd 63285; min long bwd 98353, max long bwd 106648
Time taken by simulation: 414 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 16 0 1727535.5224609375 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4820532
Min send: 10000000, max send 0
Min long send: 38109, max long send 64155
Min fwd: 32292, max fwd 48132; min bwd 69446, max bwd 80083
Min long fwd: 43192, max long fwd 50561; min long bwd 74672, max long bwd 80151
Time taken by simulation: 696 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 25 0 976051.4526367188 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4466988
Min send: 10000000, max send 0
Min long send: 38237, max long send 65217
Min fwd: 19236, max fwd 35580; min bwd 42158, max bwd 57089
Min long fwd: 24076, max long fwd 35713; min long bwd 50505, max long bwd 59414
Time taken by simulation: 1822 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 32 0 700971.3134765625 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4198444
Min send: 10000000, max send 0
Min long send: 38109, max long send 68059
Min fwd: 11544, max fwd 27276; min bwd 28686, max bwd 44788
Min long fwd: 22228, max long fwd 29781; min long bwd 41714, max long bwd 48296
Time taken by simulation: 3216 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 64 0 343797.36328125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5360725
Min send: 10000000, max send 0
Min long send: 38056, max long send 68144
Min fwd: 5149, max fwd 20736; min bwd 17314, max bwd 33457
Min long fwd: 11639, max long fwd 22378; min long bwd 26559, max long bwd 34539
Time taken by simulation: 10490 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 64 0 294405.0598144531 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5043807
Min send: 10000000, max send 0
Min long send: 38109, max long send 77793
Min fwd: 803, max fwd 17174; min bwd 10907, max bwd 28118
Min long fwd: 12084, max long fwd 20913; min long bwd 17914, max long bwd 26363
Time taken by simulation: 14262 microseconds

Stages 24
Micro-bs 1 Max mem: 2949765734.4
Predicted microbatch size for 24: 1
comm size 1638400
WARNING: no send time found, 24 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 24 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6789982
Min send: 10000000, max send 0
Min long send: 38055, max long send 74455
Min fwd: 26, max fwd 15549; min bwd 3842, max bwd 20573
Min long fwd: 7764, max long fwd 18097; min long bwd 11316, max long bwd 21840
Time taken by simulation: 45958 microseconds

{1: inf, 2: inf, 3: 4.913759, 4: 4.820532, 6: 4.466988, 8: 4.198444, 12: 5.360725, 16: 5.043807, 24: 6.789982}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1, 24: 1}
best config is: 8 1
expected time is 4.198444
4 per stage
32 servers!
Config:
ranks: range(23, 24)
train batch size: 128
partitions: 8
chunk_size: 1
data depth: 4
stage to rank map: 0,8,16,24;1,9,17,25;2,10,18,26;3,11,19,27;4,12,20,28;5,13,21,29;6,14,22,30;7,15,23,31;
World size is 32
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=23 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,8,16,24;1,9,17,25;2,10,18,26;3,11,19,27;4,12,20,28;5,13,21,29;6,14,22,30;7,15,23,31; --batch-size=32 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 172
dry run time 1.0016162395477295
SHARED WEIGHTS ARE
[(0, 7)]
this rank  23 is part of pipeline replica  2
32 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
 > finished loading checkpoint in 45.579 seconds
START iteration 172, CKPT_AND_STOP: False
[2022-12-05 13:03:32.125396] Finished iteration 173, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 11698.389
START iteration 173, CKPT_AND_STOP: False
[2022-12-05 13:03:37.637223] Finished iteration 174, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5511.877
START iteration 174, CKPT_AND_STOP: False
[2022-12-05 13:03:42.355892] Finished iteration 175, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4718.668
START iteration 175, CKPT_AND_STOP: False
[2022-12-05 13:03:47.045972] Finished iteration 176, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4690.078
START iteration 176, CKPT_AND_STOP: False
[2022-12-05 13:03:51.653858] Finished iteration 177, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4607.886
START iteration 177, CKPT_AND_STOP: False
[2022-12-05 13:03:55.260795] Finished iteration 178, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3606.942
START iteration 178, CKPT_AND_STOP: False
[2022-12-05 13:03:58.820769] Finished iteration 179, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3559.970
START iteration 179, CKPT_AND_STOP: False
[2022-12-05 13:04:02.880410] Finished iteration 180, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4059.643
START iteration 180, CKPT_AND_STOP: False
[2022-12-05 13:04:07.063152] Finished iteration 181, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4182.742
START iteration 181, CKPT_AND_STOP: False
[2022-12-05 13:04:10.643022] Finished iteration 182, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3579.870
START iteration 182, CKPT_AND_STOP: False
[2022-12-05 13:04:14.184738] Finished iteration 183, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3541.713
START iteration 183, CKPT_AND_STOP: False
[2022-12-05 13:04:17.740264] Finished iteration 184, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3555.529
START iteration 184, CKPT_AND_STOP: False
[2022-12-05 13:04:21.360255] Finished iteration 185, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3619.992
START iteration 185, CKPT_AND_STOP: False
[2022-12-05 13:04:24.920729] Finished iteration 186, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3560.472
START iteration 186, CKPT_AND_STOP: False
[2022-12-05 13:04:28.496837] Finished iteration 187, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3576.113
START iteration 187, CKPT_AND_STOP: False
[2022-12-05 13:04:32.183272] Finished iteration 188, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3686.433
START iteration 188, CKPT_AND_STOP: False
[2022-12-05 13:04:35.939417] Finished iteration 189, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3756.143
START iteration 189, CKPT_AND_STOP: False
[2022-12-05 13:04:39.573568] Finished iteration 190, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3634.150
START iteration 190, CKPT_AND_STOP: False
[2022-12-05 13:04:43.300892] Finished iteration 191, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3727.326
START iteration 191, CKPT_AND_STOP: False
[2022-12-05 13:04:47.007860] Finished iteration 192, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3706.964
START iteration 192, CKPT_AND_STOP: False
[2022-12-05 13:04:50.732142] Finished iteration 193, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3724.283
START iteration 193, CKPT_AND_STOP: False
[2022-12-05 13:04:54.354359] Finished iteration 194, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3622.218
START iteration 194, CKPT_AND_STOP: False
[2022-12-05 13:04:58.018045] Finished iteration 195, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3663.686
START iteration 195, CKPT_AND_STOP: False
[2022-12-05 13:05:01.606684] Finished iteration 196, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3588.638
START iteration 196, CKPT_AND_STOP: False
[2022-12-05 13:05:05.158200] Finished iteration 197, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3551.516
START iteration 197, CKPT_AND_STOP: False
[2022-12-05 13:05:08.684357] Finished iteration 198, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3526.155
START iteration 198, CKPT_AND_STOP: False
[2022-12-05 13:05:12.263621] Finished iteration 199, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3579.267
START iteration 199, CKPT_AND_STOP: False
[2022-12-05 13:05:16.022790] Finished iteration 200, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3759.168
START iteration 200, CKPT_AND_STOP: False
[2022-12-05 13:05:19.576831] Finished iteration 201, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3554.040
START iteration 201, CKPT_AND_STOP: False
[2022-12-05 13:05:23.274986] Finished iteration 202, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3698.155
START iteration 202, CKPT_AND_STOP: False
[2022-12-05 13:05:26.867961] Finished iteration 203, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3592.980
START iteration 203, CKPT_AND_STOP: False
[2022-12-05 13:05:30.533197] Finished iteration 204, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3665.231
START iteration 204, CKPT_AND_STOP: False
[2022-12-05 13:05:34.143541] Finished iteration 205, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3610.344
START iteration 205, CKPT_AND_STOP: False
[2022-12-05 13:05:37.833496] Finished iteration 206, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3689.957
START iteration 206, CKPT_AND_STOP: False
[2022-12-05 13:05:41.500743] Finished iteration 207, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3667.245
START iteration 207, CKPT_AND_STOP: False
[2022-12-05 13:05:45.069027] Finished iteration 208, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3568.284
START iteration 208, CKPT_AND_STOP: False
[2022-12-05 13:05:48.640707] Finished iteration 209, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3571.677
START iteration 209, CKPT_AND_STOP: False
[2022-12-05 13:05:52.149372] Finished iteration 210, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3508.668
START iteration 210, CKPT_AND_STOP: False
[2022-12-05 13:05:55.724818] Finished iteration 211, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3575.446
START iteration 211, CKPT_AND_STOP: False
[2022-12-05 13:05:59.400259] Finished iteration 212, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3675.442
START iteration 212, CKPT_AND_STOP: False
[2022-12-05 13:06:02.996168] Finished iteration 213, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3595.908
START iteration 213, CKPT_AND_STOP: False
[2022-12-05 13:06:06.510851] Finished iteration 214, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3514.686
START iteration 214, CKPT_AND_STOP: False
[2022-12-05 13:06:10.119080] Finished iteration 215, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3608.229
START iteration 215, CKPT_AND_STOP: False
[2022-12-05 13:06:13.702785] Finished iteration 216, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3583.699
START iteration 216, CKPT_AND_STOP: False
[2022-12-05 13:06:17.300230] Finished iteration 217, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3597.448
START iteration 217, CKPT_AND_STOP: False
[2022-12-05 13:06:20.865856] Finished iteration 218, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3565.627
START iteration 218, CKPT_AND_STOP: False
[2022-12-05 13:06:24.467590] Finished iteration 219, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3601.733
START iteration 219, CKPT_AND_STOP: False
[2022-12-05 13:06:28.032089] Finished iteration 220, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3564.497
START iteration 220, CKPT_AND_STOP: False
[2022-12-05 13:06:31.678126] Finished iteration 221, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3646.039
START iteration 221, CKPT_AND_STOP: False
[2022-12-05 13:06:35.279101] Finished iteration 222, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3600.975
START iteration 222, CKPT_AND_STOP: False
[2022-12-05 13:06:38.897322] Finished iteration 223, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3618.221
START iteration 223, CKPT_AND_STOP: False
[2022-12-05 13:06:42.493334] Finished iteration 224, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3596.009
START iteration 224, CKPT_AND_STOP: False
[2022-12-05 13:06:46.139918] Finished iteration 225, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3646.586
START iteration 225, CKPT_AND_STOP: False
[2022-12-05 13:06:49.884206] Finished iteration 226, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3744.289
START iteration 226, CKPT_AND_STOP: False
[2022-12-05 13:06:53.503562] Finished iteration 227, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3619.355
START iteration 227, CKPT_AND_STOP: False
[2022-12-05 13:06:57.036373] Finished iteration 228, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3532.812
START iteration 228, CKPT_AND_STOP: False
[2022-12-05 13:07:00.608865] Finished iteration 229, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3572.491
START iteration 229, CKPT_AND_STOP: False
[2022-12-05 13:07:04.304118] Finished iteration 230, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3695.256
START iteration 230, CKPT_AND_STOP: False
[2022-12-05 13:07:07.944558] Finished iteration 231, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3640.438
START iteration 231, CKPT_AND_STOP: False
[2022-12-05 13:07:11.521872] Finished iteration 232, CKPT_AND_STOP: False, flag: tensor([1], dtype=torch.int32), speed: 3577.314
Begin to save checkpont and exit
Opt ckpt time 3.3943607807159424
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 23 signal handler called with signal 10
Process done with return code 0
Parent process ID: 20921 node: 172.31.17.44
48 cutpoints
Stages 1
Micro-bs 1 Max mem: 35008318771.20003
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 17531106099.199993
Predicted microbatch size for 2: -1
Stages 3
Micro-bs 1 Max mem: 12228800511.999996
Predicted microbatch size for 3: 1
comm size 1638400
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 14 0 2006653.3203125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5367030
Min send: 10000000, max send 0
Min long send: 38387, max long send 60521
Min fwd: 45773, max fwd 60689; min bwd 93028, max bwd 103910
Min long fwd: 57033, max long fwd 64913; min long bwd 98397, max long bwd 102857
Time taken by simulation: 427 microseconds

Stages 4
Micro-bs 1 Max mem: 9577647718.399998
Predicted microbatch size for 4: 1
comm size 1638400
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 18 0 1481951.2939453125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4877293
Min send: 10000000, max send 0
Min long send: 38055, max long send 64155
Min fwd: 32292, max fwd 48132; min bwd 69316, max bwd 77937
Min long fwd: 43561, max long fwd 51496; min long bwd 71918, max long bwd 80151
Time taken by simulation: 775 microseconds

Stages 6
Micro-bs 1 Max mem: 6926494924.799999
Predicted microbatch size for 6: 1
comm size 1638400
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 32 0 876895.5078125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5017062
Min send: 10000000, max send 0
Min long send: 38071, max long send 66276
Min fwd: 18837, max fwd 35859; min bwd 42514, max bwd 56347
Min long fwd: 27753, max long fwd 35222; min long bwd 51765, max long bwd 59571
Time taken by simulation: 2284 microseconds

Stages 8
Micro-bs 1 Max mem: 5600918528.0
Predicted microbatch size for 8: 1
comm size 1638400
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 42 0 610855.46875 38055.03383759529
End of simulation:  Mini-batch time (usec) = 4799842
Min send: 10000000, max send 0
Min long send: 38071, max long send 68059
Min fwd: 10665, max fwd 27276; min bwd 28791, max bwd 43945
Min long fwd: 21459, max long fwd 30507; min long bwd 38642, max long bwd 48142
Time taken by simulation: 4234 microseconds

Stages 12
Micro-bs 1 Max mem: 4275342131.2000003
Predicted microbatch size for 12: 1
comm size 1638400
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 64 0 343797.36328125 38055.03383759529
End of simulation:  Mini-batch time (usec) = 5360725
Min send: 10000000, max send 0
Min long send: 38056, max long send 68144
Min fwd: 5149, max fwd 20736; min bwd 17314, max bwd 33457
Min long fwd: 11639, max long fwd 22378; min long bwd 26559, max long bwd 34539
Time taken by simulation: 10404 microseconds

Stages 16
Micro-bs 1 Max mem: 3612553932.8
Predicted microbatch size for 16: 1
comm size 1638400
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 7580423
Min send: 10000000, max send 0
Min long send: 38056, max long send 77793
Min fwd: 803, max fwd 17420; min bwd 10356, max bwd 28687
Min long fwd: 10499, max long fwd 20148; min long bwd 17021, max long bwd 27905
Time taken by simulation: 29662 microseconds

Stages 24
Micro-bs 1 Max mem: 2949765734.4
Predicted microbatch size for 24: 1
comm size 1638400
WARNING: no send time found, 24 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 24 128 0 0 38055.03383759529
End of simulation:  Mini-batch time (usec) = 6789982
Min send: 10000000, max send 0
Min long send: 38055, max long send 74455
Min fwd: 26, max fwd 15549; min bwd 3842, max bwd 20573
Min long fwd: 7764, max long fwd 18097; min long bwd 11316, max long bwd 21840
Time taken by simulation: 45884 microseconds

{1: inf, 2: inf, 3: 5.36703, 4: 4.877293, 6: 5.017062, 8: 4.799842, 12: 5.360725, 16: 7.580423, 24: 6.789982}
{1: -1, 2: -1, 3: 1, 4: 1, 6: 1, 8: 1, 12: 1, 16: 1, 24: 1}
best config is: 8 1
expected time is 4.799842
3 per stage
24 servers!
Config:
ranks: range(23, 24)
train batch size: 128
partitions: 8
chunk_size: 1
data depth: 3
stage to rank map: 0,8,16;1,9,17;2,10,18;3,11,19;4,12,20;5,13,21;6,14,22;7,15,23;
World size is 24
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=23 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0,8,16;1,9,17;2,10,18;3,11,19;4,12,20;5,13,21;6,14,22;7,15,23; --batch-size=42 --num-layers 48 --hidden-size 1600 --num-attention-heads 25 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 232
dry run time 0.9936275482177734
SHARED WEIGHTS ARE
[(0, 7)]
this rank  23 is part of pipeline replica  2
42 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
 > finished loading checkpoint in 40.949 seconds
START iteration 232, CKPT_AND_STOP: False
[2022-12-05 13:09:29.743134] Finished iteration 233, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 12353.215
START iteration 233, CKPT_AND_STOP: False
[2022-12-05 13:09:34.878463] Finished iteration 234, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5135.358
START iteration 234, CKPT_AND_STOP: False
[2022-12-05 13:09:39.940692] Finished iteration 235, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5062.231
START iteration 235, CKPT_AND_STOP: False
[2022-12-05 13:09:45.047553] Finished iteration 236, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5106.860
START iteration 236, CKPT_AND_STOP: False
[2022-12-05 13:09:50.193881] Finished iteration 237, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5146.328
START iteration 237, CKPT_AND_STOP: False
[2022-12-05 13:09:54.342203] Finished iteration 238, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4148.322
START iteration 238, CKPT_AND_STOP: False
[2022-12-05 13:09:58.454066] Finished iteration 239, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4111.864
START iteration 239, CKPT_AND_STOP: False
[2022-12-05 13:10:02.546172] Finished iteration 240, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4092.105
START iteration 240, CKPT_AND_STOP: False
[2022-12-05 13:10:06.605644] Finished iteration 241, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4059.472
START iteration 241, CKPT_AND_STOP: False
[2022-12-05 13:10:10.661512] Finished iteration 242, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4055.869
START iteration 242, CKPT_AND_STOP: False
[2022-12-05 13:10:14.757913] Finished iteration 243, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4096.401
START iteration 243, CKPT_AND_STOP: False
[2022-12-05 13:10:18.871949] Finished iteration 244, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4114.036
START iteration 244, CKPT_AND_STOP: False
[2022-12-05 13:10:22.956777] Finished iteration 245, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4084.827
START iteration 245, CKPT_AND_STOP: False
[2022-12-05 13:10:27.100531] Finished iteration 246, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4143.755
START iteration 246, CKPT_AND_STOP: False
[2022-12-05 13:10:31.197755] Finished iteration 247, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4097.224
START iteration 247, CKPT_AND_STOP: False
[2022-12-05 13:10:35.311762] Finished iteration 248, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4114.007
START iteration 248, CKPT_AND_STOP: False
[2022-12-05 13:10:39.416487] Finished iteration 249, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4104.725
START iteration 249, CKPT_AND_STOP: False
[2022-12-05 13:10:43.545845] Finished iteration 250, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4129.358
START iteration 250, CKPT_AND_STOP: False
[2022-12-05 13:10:47.646504] Finished iteration 251, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4100.659
START iteration 251, CKPT_AND_STOP: False
[2022-12-05 13:10:51.698865] Finished iteration 252, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4052.362
START iteration 252, CKPT_AND_STOP: False
[2022-12-05 13:10:55.764123] Finished iteration 253, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4065.258
START iteration 253, CKPT_AND_STOP: False
[2022-12-05 13:10:59.796351] Finished iteration 254, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4032.228
START iteration 254, CKPT_AND_STOP: False
[2022-12-05 13:11:03.842596] Finished iteration 255, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4046.245
START iteration 255, CKPT_AND_STOP: False
[2022-12-05 13:11:07.929209] Finished iteration 256, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4086.613
START iteration 256, CKPT_AND_STOP: False
[2022-12-05 13:11:11.972040] Finished iteration 257, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4042.831
START iteration 257, CKPT_AND_STOP: False
[2022-12-05 13:11:16.105694] Finished iteration 258, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4133.653
START iteration 258, CKPT_AND_STOP: False
[2022-12-05 13:11:20.312198] Finished iteration 259, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4206.505
START iteration 259, CKPT_AND_STOP: False
[2022-12-05 13:11:24.442262] Finished iteration 260, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4130.064
START iteration 260, CKPT_AND_STOP: False
[2022-12-05 13:11:28.503992] Finished iteration 261, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4061.731
START iteration 261, CKPT_AND_STOP: False
[2022-12-05 13:11:32.585295] Finished iteration 262, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4081.301
START iteration 262, CKPT_AND_STOP: False
[2022-12-05 13:11:36.724581] Finished iteration 263, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4139.287
START iteration 263, CKPT_AND_STOP: False
[2022-12-05 13:11:40.780424] Finished iteration 264, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4055.844
START iteration 264, CKPT_AND_STOP: False
[2022-12-05 13:11:44.911442] Finished iteration 265, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4131.017
START iteration 265, CKPT_AND_STOP: False
[2022-12-05 13:11:48.989917] Finished iteration 266, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4078.475
START iteration 266, CKPT_AND_STOP: False
[2022-12-05 13:11:53.056962] Finished iteration 267, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4067.045
START iteration 267, CKPT_AND_STOP: False
[2022-12-05 13:11:57.142103] Finished iteration 268, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4085.140
START iteration 268, CKPT_AND_STOP: False
[2022-12-05 13:12:01.220188] Finished iteration 269, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4078.085
START iteration 269, CKPT_AND_STOP: False
[2022-12-05 13:12:05.330155] Finished iteration 270, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4109.967
START iteration 270, CKPT_AND_STOP: False
[2022-12-05 13:12:09.393849] Finished iteration 271, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4063.694
START iteration 271, CKPT_AND_STOP: False
[2022-12-05 13:12:13.483734] Finished iteration 272, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4089.884
START iteration 272, CKPT_AND_STOP: False
[2022-12-05 13:12:17.555598] Finished iteration 273, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4071.865
START iteration 273, CKPT_AND_STOP: False
[2022-12-05 13:12:21.607318] Finished iteration 274, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4051.720
START iteration 274, CKPT_AND_STOP: False
[2022-12-05 13:12:25.656104] Finished iteration 275, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4048.785
START iteration 275, CKPT_AND_STOP: False
[2022-12-05 13:12:29.754320] Finished iteration 276, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4098.215
START iteration 276, CKPT_AND_STOP: False
[2022-12-05 13:12:33.838655] Finished iteration 277, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4084.335
START iteration 277, CKPT_AND_STOP: False
[2022-12-05 13:12:37.951147] Finished iteration 278, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4112.492
START iteration 278, CKPT_AND_STOP: False
[2022-12-05 13:12:42.083098] Finished iteration 279, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4131.951
START iteration 279, CKPT_AND_STOP: False
[2022-12-05 13:12:46.153640] Finished iteration 280, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4070.544
START iteration 280, CKPT_AND_STOP: False
[2022-12-05 13:12:50.237110] Finished iteration 281, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4083.468
START iteration 281, CKPT_AND_STOP: False
[2022-12-05 13:12:54.433528] Finished iteration 282, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4196.418
START iteration 282, CKPT_AND_STOP: False
[2022-12-05 13:12:58.508923] Finished iteration 283, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4075.395
START iteration 283, CKPT_AND_STOP: False
[2022-12-05 13:13:02.625065] Finished iteration 284, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4116.142
START iteration 284, CKPT_AND_STOP: False
[2022-12-05 13:13:06.683321] Finished iteration 285, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4058.256
START iteration 285, CKPT_AND_STOP: False
[2022-12-05 13:13:10.748101] Finished iteration 286, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4064.780
START iteration 286, CKPT_AND_STOP: False
[2022-12-05 13:13:15.299839] Finished iteration 287, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4551.739
START iteration 287, CKPT_AND_STOP: False
[2022-12-05 13:13:19.372001] Finished iteration 288, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4072.161
START iteration 288, CKPT_AND_STOP: False
[2022-12-05 13:13:23.394990] Finished iteration 289, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4022.989
START iteration 289, CKPT_AND_STOP: False
[2022-12-05 13:13:27.550897] Finished iteration 290, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4155.907
START iteration 290, CKPT_AND_STOP: False
[2022-12-05 13:13:31.715650] Finished iteration 291, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4164.753
START iteration 291, CKPT_AND_STOP: False
[2022-12-05 13:13:35.862008] Finished iteration 292, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4146.359
START iteration 292, CKPT_AND_STOP: False
[2022-12-05 13:13:39.940560] Finished iteration 293, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4078.551
START iteration 293, CKPT_AND_STOP: False
[2022-12-05 13:13:43.935656] Finished iteration 294, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3995.096
START iteration 294, CKPT_AND_STOP: False
[2022-12-05 13:13:47.992698] Finished iteration 295, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4057.033
START iteration 295, CKPT_AND_STOP: False
[2022-12-05 13:13:52.127505] Finished iteration 296, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4134.817
START iteration 296, CKPT_AND_STOP: False
[2022-12-05 13:13:56.189848] Finished iteration 297, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4062.343
START iteration 297, CKPT_AND_STOP: False
[2022-12-05 13:14:01.064965] Finished iteration 298, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4875.117
START iteration 298, CKPT_AND_STOP: False
[2022-12-05 13:14:05.125436] Finished iteration 299, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4060.472
START iteration 299, CKPT_AND_STOP: False
[2022-12-05 13:14:09.242612] Finished iteration 300, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4117.175
START iteration 300, CKPT_AND_STOP: False
[2022-12-05 13:14:13.315662] Finished iteration 301, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4073.050
START iteration 301, CKPT_AND_STOP: False
[2022-12-05 13:14:17.511197] Finished iteration 302, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4195.535
START iteration 302, CKPT_AND_STOP: False
[2022-12-05 13:14:21.601630] Finished iteration 303, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4090.432
START iteration 303, CKPT_AND_STOP: False
[2022-12-05 13:14:25.698973] Finished iteration 304, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4097.343
START iteration 304, CKPT_AND_STOP: False
[2022-12-05 13:14:29.748575] Finished iteration 305, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4049.601
START iteration 305, CKPT_AND_STOP: False
[2022-12-05 13:14:33.826733] Finished iteration 306, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4078.159
START iteration 306, CKPT_AND_STOP: False
[2022-12-05 13:14:37.853252] Finished iteration 307, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4026.518
START iteration 307, CKPT_AND_STOP: False
[2022-12-05 13:14:41.950655] Finished iteration 308, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4097.404
START iteration 308, CKPT_AND_STOP: False
[2022-12-05 13:14:46.138380] Finished iteration 309, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4187.725
START iteration 309, CKPT_AND_STOP: False
[2022-12-05 13:14:50.209842] Finished iteration 310, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4071.463
START iteration 310, CKPT_AND_STOP: False
[2022-12-05 13:14:54.257766] Finished iteration 311, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4047.923
START iteration 311, CKPT_AND_STOP: False
[2022-12-05 13:14:58.417641] Finished iteration 312, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4159.876
START iteration 312, CKPT_AND_STOP: False
[2022-12-05 13:15:02.517391] Finished iteration 313, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4099.749
START iteration 313, CKPT_AND_STOP: False
[2022-12-05 13:15:06.607339] Finished iteration 314, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4089.948
START iteration 314, CKPT_AND_STOP: False
[2022-12-05 13:15:10.713578] Finished iteration 315, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4106.239
START iteration 315, CKPT_AND_STOP: False
[2022-12-05 13:15:14.843076] Finished iteration 316, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4129.498
START iteration 316, CKPT_AND_STOP: False
[2022-12-05 13:15:18.945189] Finished iteration 317, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4102.112
START iteration 317, CKPT_AND_STOP: False
[2022-12-05 13:15:23.010478] Finished iteration 318, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4065.290
START iteration 318, CKPT_AND_STOP: False
[2022-12-05 13:15:27.065878] Finished iteration 319, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4055.400
START iteration 319, CKPT_AND_STOP: False
[2022-12-05 13:15:31.147046] Finished iteration 320, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4081.168
START iteration 320, CKPT_AND_STOP: False
[2022-12-05 13:15:36.102136] Finished iteration 321, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4955.089
START iteration 321, CKPT_AND_STOP: False
[2022-12-05 13:15:40.106092] Finished iteration 322, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4003.958
START iteration 322, CKPT_AND_STOP: False
