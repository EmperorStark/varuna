Parent process ID: 3087 node: 172.31.23.137
24 cutpoints
Stages 1
Micro-bs 8 Max mem: 14622140211.200005
Predicted microbatch size for 1: 8
comm size 0
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 1 6 0 2350970.703125 0
End of simulation:  Mini-batch time (usec) = 4325616
Min send: 10000000, max send 0
Min long send: 10000000, max long send 0
Min fwd: 10000000, max fwd 0; min bwd 10000000, max bwd 0
Min long fwd: 140872, max long fwd 144458; min long bwd 182761, max long bwd 191040
Time taken by simulation: 60 microseconds

Stages 2
Micro-bs 8 Max mem: 7660942131.200001
Predicted microbatch size for 2: 8
comm size 4194304
WARNING: no send time found, 2 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 2 13 0 639521.4233398438 248719.58977934244
End of simulation:  Mini-batch time (usec) = 4315108
Min send: 10000000, max send 0
Min long send: 249051, max long send 271185
Min fwd: 78473, max fwd 86627; min bwd 87174, max bwd 96382
Min long fwd: 58383, max long fwd 64048; min long bwd 92410, max long bwd 98662
Time taken by simulation: 251 microseconds

Stages 3
Micro-bs 8 Max mem: 5497876480.0
Predicted microbatch size for 3: 8
comm size 4194304
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 19 0 455501.3732910156 248719.58977934244
End of simulation:  Mini-batch time (usec) = 4359024
Min send: 10000000, max send 0
Min long send: 248801, max long send 272408
Min fwd: 34386, max fwd 67951; min bwd 53743, max bwd 63367
Min long fwd: 37367, max long fwd 45094; min long bwd 64590, max long bwd 71935
Time taken by simulation: 638 microseconds

Stages 4
Micro-bs 8 Max mem: 4406266675.2
Predicted microbatch size for 4: 8
comm size 4194304
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 26 0 356986.63330078125 248719.58977934244
End of simulation:  Mini-batch time (usec) = 5178944
Min send: 10000000, max send 0
Min long send: 248907, max long send 273926
Min fwd: 22410, max fwd 60312; min bwd 37981, max bwd 50449
Min long fwd: 30741, max long fwd 37490; min long bwd 47928, max long bwd 56568
Time taken by simulation: 1215 microseconds

Stages 6
Micro-bs 8 Max mem: 3314656870.4
Predicted microbatch size for 6: 8
comm size 4194304
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 43 0 218394.13452148438 248719.58977934244
End of simulation:  Mini-batch time (usec) = 8069195
Min send: 10000000, max send 0
Min long send: 248801, max long send 275881
Min fwd: 11106, max fwd 44737; min bwd 22890, max bwd 36101
Min long fwd: 21913, max long fwd 30446; min long bwd 33725, max long bwd 41238
Time taken by simulation: 3162 microseconds

Stages 8
Micro-bs 8 Max mem: 2758774988.8
Predicted microbatch size for 8: 8
comm size 4194304
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 64 0 144488.12866210938 248719.58977934244
End of simulation:  Mini-batch time (usec) = 11599775
Min send: 10000000, max send 0
Min long send: 248735, max long send 283577
Min fwd: 5572, max fwd 41293; min bwd 15648, max bwd 28947
Min long fwd: 17804, max long fwd 28406; min long bwd 25411, max long bwd 32670
Time taken by simulation: 6703 microseconds

Stages 12
Micro-bs 8 Max mem: 2202893107.2
Predicted microbatch size for 12: 8
comm size 4194304
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 128 0 0 248719.58977934244
End of simulation:  Mini-batch time (usec) = 21673100
Min send: 10000000, max send 0
Min long send: 248719, max long send 288457
Min fwd: 673, max fwd 27541; min bwd 8696, max bwd 22046
Min long fwd: 7851, max long fwd 17781; min long bwd 16226, max long bwd 27833
Time taken by simulation: 21528 microseconds

{1: 4.325616, 2: 4.315108, 3: 4.359024, 4: 5.178944, 6: 8.069195, 8: 11.599775, 12: 21.6731}
{1: 8, 2: 8, 3: 8, 4: 8, 6: 8, 8: 8, 12: 8}
best config is: 2 8
expected time is 4.315108
10 per stage
20 servers!
20 20 I am of no use!
Parent process ID: 3446 node: 172.31.23.137
24 cutpoints
Stages 1
Micro-bs 8 Max mem: 14622140211.200005
Predicted microbatch size for 1: 8
comm size 0
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 1 6 0 2300677.490234375 0
End of simulation:  Mini-batch time (usec) = 4275323
Min send: 10000000, max send 0
Min long send: 10000000, max long send 0
Min fwd: 10000000, max fwd 0; min bwd 10000000, max bwd 0
Min long fwd: 140872, max long fwd 144458; min long bwd 182761, max long bwd 191040
Time taken by simulation: 58 microseconds

Stages 2
Micro-bs 8 Max mem: 7660942131.200001
Predicted microbatch size for 2: 8
comm size 4194304
WARNING: no send time found, 2 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 2 12 0 637508.1176757812 248719.58977934244
End of simulation:  Mini-batch time (usec) = 4128575
Min send: 10000000, max send 0
Min long send: 249051, max long send 271185
Min fwd: 78473, max fwd 86627; min bwd 87174, max bwd 96382
Min long fwd: 57100, max long fwd 64048; min long bwd 93560, max long bwd 98662
Time taken by simulation: 229 microseconds

Stages 3
Micro-bs 8 Max mem: 5497876480.0
Predicted microbatch size for 3: 8
comm size 4194304
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 19 0 455501.3732910156 248719.58977934244
End of simulation:  Mini-batch time (usec) = 4359024
Min send: 10000000, max send 0
Min long send: 248801, max long send 272408
Min fwd: 34386, max fwd 67951; min bwd 53743, max bwd 63367
Min long fwd: 37367, max long fwd 45094; min long bwd 64590, max long bwd 71935
Time taken by simulation: 600 microseconds

Stages 4
Micro-bs 8 Max mem: 4406266675.2
Predicted microbatch size for 4: 8
comm size 4194304
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 26 0 356986.63330078125 248719.58977934244
End of simulation:  Mini-batch time (usec) = 5178944
Min send: 10000000, max send 0
Min long send: 248907, max long send 273926
Min fwd: 22410, max fwd 60312; min bwd 37981, max bwd 50449
Min long fwd: 30741, max long fwd 37490; min long bwd 47928, max long bwd 56568
Time taken by simulation: 1177 microseconds

Stages 6
Micro-bs 8 Max mem: 3314656870.4
Predicted microbatch size for 6: 8
comm size 4194304
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 43 0 218394.13452148438 248719.58977934244
End of simulation:  Mini-batch time (usec) = 8069195
Min send: 10000000, max send 0
Min long send: 248801, max long send 275881
Min fwd: 11106, max fwd 44737; min bwd 22890, max bwd 36101
Min long fwd: 21913, max long fwd 30446; min long bwd 33725, max long bwd 41238
Time taken by simulation: 3245 microseconds

Stages 8
Micro-bs 8 Max mem: 2758774988.8
Predicted microbatch size for 8: 8
comm size 4194304
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 64 0 144488.12866210938 248719.58977934244
End of simulation:  Mini-batch time (usec) = 11599775
Min send: 10000000, max send 0
Min long send: 248735, max long send 283577
Min fwd: 5572, max fwd 41293; min bwd 15648, max bwd 28947
Min long fwd: 17804, max long fwd 28406; min long bwd 25411, max long bwd 32670
Time taken by simulation: 6792 microseconds

Stages 12
Micro-bs 8 Max mem: 2202893107.2
Predicted microbatch size for 12: 8
comm size 4194304
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 128 0 0 248719.58977934244
End of simulation:  Mini-batch time (usec) = 21673100
Min send: 10000000, max send 0
Min long send: 248719, max long send 288457
Min fwd: 673, max fwd 27541; min bwd 8696, max bwd 22046
Min long fwd: 7851, max long fwd 17781; min long bwd 16226, max long bwd 27833
Time taken by simulation: 21541 microseconds

{1: 4.275323, 2: 4.128575, 3: 4.359024, 4: 5.178944, 6: 8.069195, 8: 11.599775, 12: 21.6731}
{1: 8, 2: 8, 3: 8, 4: 8, 6: 8, 8: 8, 12: 8}
best config is: 2 8
expected time is 4.128575
11 per stage
22 servers!
Config:
ranks: range(20, 21)
train batch size: 1024
partitions: 2
chunk_size: 8
data depth: 11
stage to rank map: 0,2,4,6,8,10,12,14,16,18,20;1,3,5,7,9,11,13,15,17,19,21;
World size is 22
/opt/conda/envs/varuna/bin/python -u /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --rank=20 --chunk_size=8 --local_rank=0 --stage_to_rank_map=0,2,4,6,8,10,12,14,16,18,20;1,3,5,7,9,11,13,15,17,19,21; --batch-size=93 --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna --resume_step 77
device: cuda:0 n_gpu: 1, distributed training: True, 16-bits training: True
dry run time 0.007890462875366211
SHARED WEIGHTS ARE
[(0, 1)]
this rank  20 is part of pipeline replica  10
12 chunks
Begin to load checkpint from s3://spot-checkpoints/bert/ckpt_77.pt
2022-11-26 03:13:14.017898 resume step from  77
2022-11-26 03:14:10.413448 - Finished loading checkpoint, takes 56.363 secs
20 Overflow !!
20 : update_scale(): _has_overflow, dynamic. _loss_scale =  524288.0
[2022-11-26 03:14:24.016689] Finished iteration 77, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 9620.953
20 Overflow !!
20 : update_scale(): _has_overflow, dynamic. _loss_scale =  262144.0
[2022-11-26 03:14:26.631741] Finished iteration 78, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2614.765
20 Overflow !!
20 : update_scale(): _has_overflow, dynamic. _loss_scale =  131072.0
[2022-11-26 03:14:30.227831] Finished iteration 79, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3596.183
20 Overflow !!
20 : update_scale(): _has_overflow, dynamic. _loss_scale =  65536.0
[2022-11-26 03:14:32.811267] Finished iteration 80, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2583.256
20 Overflow !!
20 : update_scale(): _has_overflow, dynamic. _loss_scale =  32768.0
[2022-11-26 03:14:35.389069] Finished iteration 81, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2577.770
20 Overflow !!
20 : update_scale(): _has_overflow, dynamic. _loss_scale =  16384.0
[2022-11-26 03:14:38.001560] Finished iteration 82, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2612.467
20 Overflow !!
20 : update_scale(): _has_overflow, dynamic. _loss_scale =  8192.0
[2022-11-26 03:14:40.576284] Finished iteration 83, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2574.689
20 Overflow !!
20 : update_scale(): _has_overflow, dynamic. _loss_scale =  4096.0
[2022-11-26 03:14:43.140630] Finished iteration 84, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2564.358
20 Overflow !!
20 : update_scale(): _has_overflow, dynamic. _loss_scale =  2048.0
[2022-11-26 03:14:45.717353] Finished iteration 85, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2576.647
20 Overflow !!
20 : update_scale(): _has_overflow, dynamic. _loss_scale =  1024.0
[2022-11-26 03:14:48.318902] Finished iteration 86, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2601.542
20 Overflow !!
20 : update_scale(): _has_overflow, dynamic. _loss_scale =  512.0
[2022-11-26 03:14:50.885917] Finished iteration 87, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2566.961
20 Overflow !!
20 : update_scale(): _has_overflow, dynamic. _loss_scale =  256.0
[2022-11-26 03:14:53.432022] Finished iteration 88, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2546.049
20 Overflow !!
20 : update_scale(): _has_overflow, dynamic. _loss_scale =  128.0
[2022-11-26 03:14:55.996376] Finished iteration 89, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2564.323
20 Overflow !!
20 : update_scale(): _has_overflow, dynamic. _loss_scale =  64.0
[2022-11-26 03:14:58.570183] Finished iteration 90, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2573.888
20 Overflow !!
20 : update_scale(): _has_overflow, dynamic. _loss_scale =  32.0
[2022-11-26 03:15:01.126788] Finished iteration 91, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2556.483
20 Overflow !!
20 : update_scale(): _has_overflow, dynamic. _loss_scale =  16.0
[2022-11-26 03:15:03.713935] Finished iteration 92, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2587.083
20 Overflow !!
20 : update_scale(): _has_overflow, dynamic. _loss_scale =  8.0
[2022-11-26 03:15:06.292538] Finished iteration 93, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2578.572
20 Overflow !!
20 : update_scale(): _has_overflow, dynamic. _loss_scale =  4.0
[2022-11-26 03:15:08.842761] Finished iteration 94, CKPT_AND_STOP: False, flag: tensor([1], dtype=torch.int32), speed: 2550.255
2022-11-26 03:15:08.848110 Begin to save checkpont to s3://spot-checkpoints/bert and exit
Opt ckpt time 4.446753263473511
Process done with return code 0
Parent process ID: 4693 node: 172.31.23.137
24 cutpoints
Stages 1
Micro-bs 8 Max mem: 14622140211.200005
Predicted microbatch size for 1: 8
comm size 0
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 1 6 0 2325752.685546875 0
End of simulation:  Mini-batch time (usec) = 4300398
Min send: 10000000, max send 0
Min long send: 10000000, max long send 0
Min fwd: 10000000, max fwd 0; min bwd 10000000, max bwd 0
Min long fwd: 140872, max long fwd 144458; min long bwd 182761, max long bwd 191040
Time taken by simulation: 55 microseconds

Stages 2
Micro-bs 8 Max mem: 7660942131.200001
Predicted microbatch size for 2: 8
comm size 4194304
WARNING: no send time found, 2 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 2 12 0 637508.1176757812 248719.58977934244
End of simulation:  Mini-batch time (usec) = 4128575
Min send: 10000000, max send 0
Min long send: 249051, max long send 271185
Min fwd: 78473, max fwd 86627; min bwd 87174, max bwd 96382
Min long fwd: 57100, max long fwd 64048; min long bwd 93560, max long bwd 98662
Time taken by simulation: 260 microseconds

Stages 3
Micro-bs 8 Max mem: 5497876480.0
Predicted microbatch size for 3: 8
comm size 4194304
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 19 0 455501.3732910156 248719.58977934244
End of simulation:  Mini-batch time (usec) = 4359024
Min send: 10000000, max send 0
Min long send: 248801, max long send 272408
Min fwd: 34386, max fwd 67951; min bwd 53743, max bwd 63367
Min long fwd: 37367, max long fwd 45094; min long bwd 64590, max long bwd 71935
Time taken by simulation: 608 microseconds

Stages 4
Micro-bs 8 Max mem: 4406266675.2
Predicted microbatch size for 4: 8
comm size 4194304
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 26 0 356986.63330078125 248719.58977934244
End of simulation:  Mini-batch time (usec) = 5178944
Min send: 10000000, max send 0
Min long send: 248907, max long send 273926
Min fwd: 22410, max fwd 60312; min bwd 37981, max bwd 50449
Min long fwd: 30741, max long fwd 37490; min long bwd 47928, max long bwd 56568
Time taken by simulation: 1176 microseconds

Stages 6
Micro-bs 8 Max mem: 3314656870.4
Predicted microbatch size for 6: 8
comm size 4194304
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 43 0 218394.13452148438 248719.58977934244
End of simulation:  Mini-batch time (usec) = 8069195
Min send: 10000000, max send 0
Min long send: 248801, max long send 275881
Min fwd: 11106, max fwd 44737; min bwd 22890, max bwd 36101
Min long fwd: 21913, max long fwd 30446; min long bwd 33725, max long bwd 41238
Time taken by simulation: 3213 microseconds

Stages 8
Micro-bs 8 Max mem: 2758774988.8
Predicted microbatch size for 8: 8
comm size 4194304
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 64 0 144488.12866210938 248719.58977934244
End of simulation:  Mini-batch time (usec) = 11599775
Min send: 10000000, max send 0
Min long send: 248735, max long send 283577
Min fwd: 5572, max fwd 41293; min bwd 15648, max bwd 28947
Min long fwd: 17804, max long fwd 28406; min long bwd 25411, max long bwd 32670
Time taken by simulation: 6716 microseconds

Stages 12
Micro-bs 8 Max mem: 2202893107.2
Predicted microbatch size for 12: 8
comm size 4194304
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 128 0 0 248719.58977934244
End of simulation:  Mini-batch time (usec) = 21673100
Min send: 10000000, max send 0
Min long send: 248719, max long send 288457
Min fwd: 673, max fwd 27541; min bwd 8696, max bwd 22046
Min long fwd: 7851, max long fwd 17781; min long bwd 16226, max long bwd 27833
Time taken by simulation: 21560 microseconds

{1: 4.300398, 2: 4.128575, 3: 4.359024, 4: 5.178944, 6: 8.069195, 8: 11.599775, 12: 21.6731}
{1: 8, 2: 8, 3: 8, 4: 8, 6: 8, 8: 8, 12: 8}
best config is: 2 8
expected time is 4.128575
11 per stage
22 servers!
Config:
ranks: range(20, 21)
train batch size: 1024
partitions: 2
chunk_size: 8
data depth: 11
stage to rank map: 0,2,4,6,8,10,12,14,16,18,20;1,3,5,7,9,11,13,15,17,19,21;
World size is 22
/opt/conda/envs/varuna/bin/python -u /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --rank=20 --chunk_size=8 --local_rank=0 --stage_to_rank_map=0,2,4,6,8,10,12,14,16,18,20;1,3,5,7,9,11,13,15,17,19,21; --batch-size=93 --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna --resume_step 95
device: cuda:0 n_gpu: 1, distributed training: True, 16-bits training: True
dry run time 0.03906559944152832
SHARED WEIGHTS ARE
[(0, 1)]
this rank  20 is part of pipeline replica  10
12 chunks
Begin to load checkpint from s3://spot-checkpoints/bert/ckpt_95.pt
2022-11-26 03:15:42.431775 resume step from  95
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 20 signal handler called with signal 10
2022-11-26 03:16:31.309074 - Finished loading checkpoint, takes 48.848 secs
2022-11-26 03:16:44.906649 Begin to exit
Process done with return code 0
Parent process ID: 5882 node: 172.31.23.137
24 cutpoints
Stages 1
Micro-bs 8 Max mem: 14622140211.200005
Predicted microbatch size for 1: 8
comm size 0
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 1 6 0 2258812.98828125 0
End of simulation:  Mini-batch time (usec) = 4233458
Min send: 10000000, max send 0
Min long send: 10000000, max long send 0
Min fwd: 10000000, max fwd 0; min bwd 10000000, max bwd 0
Min long fwd: 140872, max long fwd 144458; min long bwd 182761, max long bwd 191040
Time taken by simulation: 53 microseconds

Stages 2
Micro-bs 8 Max mem: 7660942131.200001
Predicted microbatch size for 2: 8
comm size 4194304
WARNING: no send time found, 2 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 2 11 0 656490.9057617188 248719.58977934244
End of simulation:  Mini-batch time (usec) = 3966187
Min send: 10000000, max send 0
Min long send: 249051, max long send 264414
Min fwd: 78473, max fwd 86627; min bwd 87174, max bwd 96382
Min long fwd: 58631, max long fwd 64048; min long bwd 93560, max long bwd 98662
Time taken by simulation: 214 microseconds

Stages 3
Micro-bs 8 Max mem: 5497876480.0
Predicted microbatch size for 3: 8
comm size 4194304
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 16 0 458491.3635253906 248719.58977934244
End of simulation:  Mini-batch time (usec) = 4073233
Min send: 10000000, max send 0
Min long send: 248907, max long send 271185
Min fwd: 34639, max fwd 68075; min bwd 55135, max bwd 63761
Min long fwd: 38640, max long fwd 45018; min long bwd 64291, max long bwd 71935
Time taken by simulation: 515 microseconds

Stages 4
Micro-bs 8 Max mem: 4406266675.2
Predicted microbatch size for 4: 8
comm size 4194304
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 22 0 364029.9377441406 248719.58977934244
End of simulation:  Mini-batch time (usec) = 4679330
Min send: 10000000, max send 0
Min long send: 248907, max long send 274819
Min fwd: 21514, max fwd 60961; min bwd 37461, max bwd 50759
Min long fwd: 29330, max long fwd 37152; min long bwd 47928, max long bwd 55195
Time taken by simulation: 1011 microseconds

Stages 6
Micro-bs 8 Max mem: 3314656870.4
Predicted microbatch size for 6: 8
comm size 4194304
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 32 0 233226.318359375 248719.58977934244
End of simulation:  Mini-batch time (usec) = 6680183
Min send: 10000000, max send 0
Min long send: 248719, max long send 275881
Min fwd: 10965, max fwd 44004; min bwd 19992, max bwd 36467
Min long fwd: 22115, max long fwd 30954; min long bwd 32578, max long bwd 40795
Time taken by simulation: 2406 microseconds

Stages 8
Micro-bs 8 Max mem: 2758774988.8
Predicted microbatch size for 8: 8
comm size 4194304
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 43 0 178155.74645996094 248719.58977934244
End of simulation:  Mini-batch time (usec) = 9019309
Min send: 10000000, max send 0
Min long send: 248735, max long send 276940
Min fwd: 5776, max fwd 41014; min bwd 16548, max bwd 29492
Min long fwd: 17309, max long fwd 25772; min long bwd 25282, max long bwd 32088
Time taken by simulation: 4446 microseconds

Stages 12
Micro-bs 8 Max mem: 2202893107.2
Predicted microbatch size for 12: 8
comm size 4194304
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 64 0 117116.2109375 248719.58977934244
End of simulation:  Mini-batch time (usec) = 13687683
Min send: 10000000, max send 0
Min long send: 248720, max long send 280797
Min fwd: 141, max fwd 25024; min bwd 6433, max bwd 23373
Min long fwd: 7201, max long fwd 18161; min long bwd 16833, max long bwd 28389
Time taken by simulation: 10591 microseconds

{1: 4.233458, 2: 3.966187, 3: 4.073233, 4: 4.67933, 6: 6.680183, 8: 9.019309, 12: 13.687683}
{1: 8, 2: 8, 3: 8, 4: 8, 6: 8, 8: 8, 12: 8}
best config is: 2 8
expected time is 3.966187
12 per stage
24 servers!
Config:
ranks: range(20, 21)
train batch size: 1024
partitions: 2
chunk_size: 8
data depth: 12
stage to rank map: 0,2,4,6,8,10,12,14,16,18,20,22;1,3,5,7,9,11,13,15,17,19,21,23;
World size is 24
/opt/conda/envs/varuna/bin/python -u /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --rank=20 --chunk_size=8 --local_rank=0 --stage_to_rank_map=0,2,4,6,8,10,12,14,16,18,20,22;1,3,5,7,9,11,13,15,17,19,21,23; --batch-size=85 --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna --resume_step 95
device: cuda:0 n_gpu: 1, distributed training: True, 16-bits training: True
dry run time 0.004313945770263672
SHARED WEIGHTS ARE
[(0, 1)]
this rank  20 is part of pipeline replica  10
11 chunks
Begin to load checkpint from s3://spot-checkpoints/bert/ckpt_95.pt
2022-11-26 03:17:10.908495 resume step from  95
2022-11-26 03:18:04.182669 - Finished loading checkpoint, takes 53.244 secs
20 Overflow !!
20 : update_scale(): _has_overflow, dynamic. _loss_scale =  524288.0
[2022-11-26 03:18:18.057476] Finished iteration 95, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 8903.713
20 Overflow !!
20 : update_scale(): _has_overflow, dynamic. _loss_scale =  262144.0
[2022-11-26 03:18:21.541936] Finished iteration 96, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3484.153
20 Overflow !!
20 : update_scale(): _has_overflow, dynamic. _loss_scale =  131072.0
[2022-11-26 03:18:25.000902] Finished iteration 97, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3458.933
20 Overflow !!
20 : update_scale(): _has_overflow, dynamic. _loss_scale =  65536.0
[2022-11-26 03:18:28.449382] Finished iteration 98, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3448.452
20 Overflow !!
20 : update_scale(): _has_overflow, dynamic. _loss_scale =  32768.0
[2022-11-26 03:18:31.913811] Finished iteration 99, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3464.349
20 Overflow !!
20 : update_scale(): _has_overflow, dynamic. _loss_scale =  16384.0
[2022-11-26 03:18:34.420651] Finished iteration 100, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2506.702
20 Overflow !!
20 : update_scale(): _has_overflow, dynamic. _loss_scale =  8192.0
[2022-11-26 03:18:36.883654] Finished iteration 101, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2462.970
20 Overflow !!
20 : update_scale(): _has_overflow, dynamic. _loss_scale =  4096.0
[2022-11-26 03:18:39.356430] Finished iteration 102, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2472.752
20 Overflow !!
20 : update_scale(): _has_overflow, dynamic. _loss_scale =  2048.0
[2022-11-26 03:18:41.874995] Finished iteration 103, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2518.515
20 Overflow !!
20 : update_scale(): _has_overflow, dynamic. _loss_scale =  1024.0
[2022-11-26 03:18:44.360312] Finished iteration 104, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2485.283
20 Overflow !!
20 : update_scale(): _has_overflow, dynamic. _loss_scale =  512.0
[2022-11-26 03:18:46.829456] Finished iteration 105, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2469.121
20 Overflow !!
20 : update_scale(): _has_overflow, dynamic. _loss_scale =  256.0
[2022-11-26 03:18:49.360376] Finished iteration 106, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2531.066
20 Overflow !!
20 : update_scale(): _has_overflow, dynamic. _loss_scale =  128.0
[2022-11-26 03:18:51.849080] Finished iteration 107, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2488.489
20 Overflow !!
20 : update_scale(): _has_overflow, dynamic. _loss_scale =  64.0
[2022-11-26 03:18:54.319640] Finished iteration 108, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2470.574
20 Overflow !!
20 : update_scale(): _has_overflow, dynamic. _loss_scale =  32.0
[2022-11-26 03:18:56.817312] Finished iteration 109, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2497.596
20 Overflow !!
20 : update_scale(): _has_overflow, dynamic. _loss_scale =  16.0
[2022-11-26 03:18:59.256379] Finished iteration 110, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2439.033
20 Overflow !!
20 : update_scale(): _has_overflow, dynamic. _loss_scale =  8.0
[2022-11-26 03:19:01.762445] Finished iteration 111, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2506.034
20 Overflow !!
20 : update_scale(): _has_overflow, dynamic. _loss_scale =  4.0
[2022-11-26 03:19:04.219715] Finished iteration 112, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2457.284
20 Overflow !!
20 : update_scale(): _has_overflow, dynamic. _loss_scale =  2.0
[2022-11-26 03:19:06.659308] Finished iteration 113, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2439.501
20 Overflow !!
20 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 03:19:09.135539] Finished iteration 114, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2476.192
20 Overflow !!
20 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 03:19:11.597676] Finished iteration 115, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2462.100
20 Overflow !!
20 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 03:19:14.092586] Finished iteration 116, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2494.896
20 Overflow !!
20 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 03:19:16.586844] Finished iteration 117, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2494.257
20 Overflow !!
20 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 03:19:19.016384] Finished iteration 118, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2429.518
20 Overflow !!
20 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 03:19:21.462082] Finished iteration 119, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2445.612
20 Overflow !!
20 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 03:19:23.928844] Finished iteration 120, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2466.770
20 Overflow !!
20 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 03:19:26.388213] Finished iteration 121, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2459.299
20 Overflow !!
20 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 03:19:28.907812] Finished iteration 122, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2519.579
20 Overflow !!
20 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 03:19:31.343476] Finished iteration 123, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2435.625
20 Overflow !!
20 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 03:19:33.781127] Finished iteration 124, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2437.618
20 Overflow !!
20 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 03:19:36.272488] Finished iteration 125, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2491.330
20 Overflow !!
20 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 03:19:38.692390] Finished iteration 126, CKPT_AND_STOP: False, flag: tensor([1], dtype=torch.int32), speed: 2419.891
2022-11-26 03:19:38.697856 Begin to save checkpont to s3://spot-checkpoints/bert and exit
Opt ckpt time 3.9743218421936035
Process done with return code 0
