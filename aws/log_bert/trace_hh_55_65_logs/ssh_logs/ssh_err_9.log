Traceback (most recent call last):
  File "/home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py", line 846, in <module>
    args, final_loss, train_time_raw, global_step = main()
  File "/home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py", line 644, in main
    dist.all_reduce(flag)
  File "/opt/conda/envs/varuna/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 1321, in all_reduce
    work.wait()
RuntimeError: [/opt/conda/conda-bld/pytorch_1646755888534/work/third_party/gloo/gloo/transport/tcp/pair.cc:598] Connection closed by peer [172.31.28.236]:1198
Terminated
Traceback (most recent call last):
  File "/home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py", line 846, in <module>
    args, final_loss, train_time_raw, global_step = main()
  File "/home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py", line 644, in main
    dist.all_reduce(flag)
  File "/opt/conda/envs/varuna/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 1321, in all_reduce
    work.wait()
RuntimeError: [/opt/conda/conda-bld/pytorch_1646755888534/work/third_party/gloo/gloo/transport/tcp/pair.cc:598] Connection closed by peer [172.31.21.45]:927
launch_varuna.sh: line 1: 33254 User defined signal 1   /opt/conda/envs/varuna/bin/python -u -m varuna.launcher --ngpus_per_server 1 --node_rank 9 --nservers 32 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna --resume_step 221
