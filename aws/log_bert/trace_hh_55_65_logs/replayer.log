[2022-11-26 03:56:56.230714] Begin to replay trace traces/trace_hh_55_65.txt
[2022-11-26 03:56:56.230767] >>> [0.000] next_event: add at 0
[2022-11-26 03:56:56.230792] >>> [0.000]      node to be add: ['172.31.28.108', '172.31.20.223', '172.31.18.152', '172.31.27.216', '172.31.24.208', '172.31.30.99', '172.31.16.100', '172.31.22.229', '172.31.22.165', '172.31.31.40', '172.31.19.171', '172.31.17.44', '172.31.28.236', '172.31.21.45', '172.31.21.109', '172.31.19.112', '172.31.21.254', '172.31.24.191', '172.31.16.5', '172.31.30.133', '172.31.23.137', '172.31.21.137', '172.31.26.140', '172.31.28.143', '172.31.28.16', '172.31.17.209', '172.31.24.82', '172.31.29.147', '172.31.27.21', '172.31.30.89', '172.31.25.155', '172.31.27.155']
[2022-11-26 03:56:56.231790] >>> [0.001] nnodes: 32, message: 
[2022-11-26 03:56:56.231852]                remain nodes: ['172.31.28.108', '172.31.20.223', '172.31.18.152', '172.31.27.216', '172.31.24.208', '172.31.30.99', '172.31.16.100', '172.31.22.229', '172.31.22.165', '172.31.31.40', '172.31.19.171', '172.31.17.44', '172.31.28.236', '172.31.21.45', '172.31.21.109', '172.31.19.112', '172.31.21.254', '172.31.24.191', '172.31.16.5', '172.31.30.133', '172.31.23.137', '172.31.21.137', '172.31.26.140', '172.31.28.143', '172.31.28.16', '172.31.17.209', '172.31.24.82', '172.31.29.147', '172.31.27.21', '172.31.30.89', '172.31.25.155', '172.31.27.155']
[2022-11-26 03:56:56.231873] >>> [0.001] next_event: no-op at 60000
Container nvidia build = 
Warning! /hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ directory missing. Training cannot start
/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/
/home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json
Logs written to /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/bert_lamb_pretraining.pyt_bert_pretraining_phase1_fp16_gbs1024.log
+ '[' -z /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/bert_lamb_pretraining.pyt_bert_pretraining_phase1_fp16_gbs1024.log ']'
+ tee /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/bert_lamb_pretraining.pyt_bert_pretraining_phase1_fp16_gbs1024.log
+ /opt/conda/envs/varuna/bin/python -m varuna.run_varuna --profile_folder s3://spot-checkpoints/bert-profile --batch_size 1024 --chunk_size 8 --gpus_per_node 1 --machine_list /home/ubuntu/varuna/aws/hosts/available_machines.out /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna
reachable machines: ['172.31.28.108', '172.31.20.223', '172.31.18.152', '172.31.27.216', '172.31.24.208', '172.31.30.99', '172.31.16.100', '172.31.22.229', '172.31.22.165', '172.31.31.40', '172.31.19.171', '172.31.17.44', '172.31.28.236', '172.31.21.45', '172.31.21.109', '172.31.19.112', '172.31.21.254', '172.31.24.191', '172.31.16.5', '172.31.30.133', '172.31.23.137', '172.31.21.137', '172.31.26.140', '172.31.28.143', '172.31.28.16', '172.31.17.209', '172.31.24.82', '172.31.29.147', '172.31.27.21', '172.31.30.89', '172.31.25.155', '172.31.27.155']
/opt/conda/envs/varuna/bin/python -m varuna.morph_server /home/ubuntu/varuna/aws/hosts/available_machines.out /home/ubuntu/varuna/aws/hosts/varuna_current_machines 4200  > varuna_morph.out 2>varuna_morph.err &
/opt/conda/envs/varuna/bin/python -m varuna.catch_all /home/ubuntu/varuna/aws/hosts/varuna_current_machines 5000  > varuna_catch.out 2>varuna_catch.err &
ssh ubuntu@172.31.28.108 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 0 --nservers 32 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.20.223 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 1 --nservers 32 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.18.152 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 2 --nservers 32 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.27.216 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 3 --nservers 32 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.24.208 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 4 --nservers 32 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.30.99 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 5 --nservers 32 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.16.100 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 6 --nservers 32 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.22.229 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 7 --nservers 32 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.22.165 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 8 --nservers 32 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.31.40 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 9 --nservers 32 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.19.171 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 10 --nservers 32 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.17.44 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 11 --nservers 32 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.28.236 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 12 --nservers 32 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.21.45 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 13 --nservers 32 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.21.109 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 14 --nservers 32 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.19.112 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 15 --nservers 32 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.21.254 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 16 --nservers 32 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.24.191 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 17 --nservers 32 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.16.5 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 18 --nservers 32 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.30.133 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 19 --nservers 32 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.23.137 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 20 --nservers 32 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.21.137 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 21 --nservers 32 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.26.140 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 22 --nservers 32 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.28.143 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 23 --nservers 32 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.28.16 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 24 --nservers 32 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.17.209 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 25 --nservers 32 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.24.82 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 26 --nservers 32 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.29.147 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 27 --nservers 32 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.27.21 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 28 --nservers 32 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.30.89 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 29 --nservers 32 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.25.155 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 30 --nservers 32 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.27.155 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 31 --nservers 32 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
+ set +x
finished pretraining
[2022-11-26 03:57:56.290322] >>> [60.060] nnodes: 32, no morph
[2022-11-26 03:57:56.290399] >>> [60.060] next_event: no-op at 120000
[2022-11-26 03:58:56.237311] >>> [120.007] nnodes: 32, no morph
[2022-11-26 03:58:56.237407] >>> [120.007] next_event: remove at 180000
[2022-11-26 03:59:26.260810] >>> [150.030]      node to be remove: ['172.31.24.82', '172.31.31.40', '172.31.19.171']
[2022-11-26 03:59:26.261518] >>> [150.031] nnodes: 29, message: preempt 150.03052043914795
[2022-11-26 03:59:26.261579]                remain nodes: ['172.31.28.108', '172.31.20.223', '172.31.18.152', '172.31.27.216', '172.31.24.208', '172.31.30.99', '172.31.16.100', '172.31.22.229', '172.31.22.165', '172.31.17.44', '172.31.28.236', '172.31.21.45', '172.31.21.109', '172.31.19.112', '172.31.21.254', '172.31.24.191', '172.31.16.5', '172.31.30.133', '172.31.23.137', '172.31.21.137', '172.31.26.140', '172.31.28.143', '172.31.28.16', '172.31.17.209', '172.31.29.147', '172.31.27.21', '172.31.30.89', '172.31.25.155', '172.31.27.155']
[2022-11-26 03:59:56.260765] >>> [180.030] Remove node 172.31.24.82, CMD: ssh -q ubuntu@172.31.24.82 bash /home/ubuntu/varuna/aws/remove_node.sh
[2022-11-26 03:59:56.262440] >>> [180.032] Remove node 172.31.31.40, CMD: ssh -q ubuntu@172.31.31.40 bash /home/ubuntu/varuna/aws/remove_node.sh
[2022-11-26 03:59:56.263647] >>> [180.033] Remove node 172.31.19.171, CMD: ssh -q ubuntu@172.31.19.171 bash /home/ubuntu/varuna/aws/remove_node.sh
[2022-11-26 03:59:56.264860] >>> [180.034] next_event: no-op at 240000
[2022-11-26 04:00:56.290739] >>> [240.060] nnodes: 29, no morph
[2022-11-26 04:00:56.290789] >>> [240.060] next_event: remove at 300000
[2022-11-26 04:01:26.233428] >>> [270.003]      node to be remove: ['172.31.25.155', '172.31.19.112', '172.31.26.140']
[2022-11-26 04:01:26.234050] >>> [270.003] nnodes: 26, message: preempt 270.003137588501
[2022-11-26 04:01:26.234103]                remain nodes: ['172.31.28.108', '172.31.20.223', '172.31.18.152', '172.31.27.216', '172.31.24.208', '172.31.30.99', '172.31.16.100', '172.31.22.229', '172.31.22.165', '172.31.17.44', '172.31.28.236', '172.31.21.45', '172.31.21.109', '172.31.21.254', '172.31.24.191', '172.31.16.5', '172.31.30.133', '172.31.23.137', '172.31.21.137', '172.31.28.143', '172.31.28.16', '172.31.17.209', '172.31.29.147', '172.31.27.21', '172.31.30.89', '172.31.27.155']
[2022-11-26 04:01:56.260783] >>> [300.030] Remove node 172.31.25.155, CMD: ssh -q ubuntu@172.31.25.155 bash /home/ubuntu/varuna/aws/remove_node.sh
[2022-11-26 04:01:56.262506] >>> [300.032] Remove node 172.31.19.112, CMD: ssh -q ubuntu@172.31.19.112 bash /home/ubuntu/varuna/aws/remove_node.sh
[2022-11-26 04:01:56.263770] >>> [300.033] Remove node 172.31.26.140, CMD: ssh -q ubuntu@172.31.26.140 bash /home/ubuntu/varuna/aws/remove_node.sh
[2022-11-26 04:01:56.265035] >>> [300.034] next_event: no-op at 360000
[2022-11-26 04:02:56.290497] >>> [360.060] nnodes: 26, no morph
[2022-11-26 04:02:56.290673] >>> [360.060] next_event: remove at 420000
[2022-11-26 04:03:26.233176] >>> [390.002]      node to be remove: ['172.31.17.44']
[2022-11-26 04:03:26.233805] >>> [390.003] nnodes: 25, message: preempt 390.00286960601807
[2022-11-26 04:03:26.233866]                remain nodes: ['172.31.28.108', '172.31.20.223', '172.31.18.152', '172.31.27.216', '172.31.24.208', '172.31.30.99', '172.31.16.100', '172.31.22.229', '172.31.22.165', '172.31.28.236', '172.31.21.45', '172.31.21.109', '172.31.21.254', '172.31.24.191', '172.31.16.5', '172.31.30.133', '172.31.23.137', '172.31.21.137', '172.31.28.143', '172.31.28.16', '172.31.17.209', '172.31.29.147', '172.31.27.21', '172.31.30.89', '172.31.27.155']
[2022-11-26 04:03:56.260779] >>> [420.030] Remove node 172.31.17.44, CMD: ssh -q ubuntu@172.31.17.44 bash /home/ubuntu/varuna/aws/remove_node.sh
[2022-11-26 04:03:56.262502] >>> [420.032] next_event: no-op at 480000
[2022-11-26 04:04:56.240696] >>> [480.010] nnodes: 25, no morph
[2022-11-26 04:04:56.240772] >>> [480.010] next_event: no-op at 540000
[2022-11-26 04:05:56.286321] >>> [540.056] nnodes: 25, no morph
[2022-11-26 04:05:56.286367] >>> [540.056] next_event: no-op at 600000
[2022-11-26 04:06:56.290324] >>> [600.060] nnodes: 25, no morph
[2022-11-26 04:06:56.290386] >>> [600.060] next_event: remove at 660000
[2022-11-26 04:07:26.258356] >>> [630.028]      node to be remove: ['172.31.24.191', '172.31.21.137']
[2022-11-26 04:07:26.259023] >>> [630.028] nnodes: 23, message: preempt 630.0280656814575
[2022-11-26 04:07:26.259076]                remain nodes: ['172.31.28.108', '172.31.20.223', '172.31.18.152', '172.31.27.216', '172.31.24.208', '172.31.30.99', '172.31.16.100', '172.31.22.229', '172.31.22.165', '172.31.28.236', '172.31.21.45', '172.31.21.109', '172.31.21.254', '172.31.16.5', '172.31.30.133', '172.31.23.137', '172.31.28.143', '172.31.28.16', '172.31.17.209', '172.31.29.147', '172.31.27.21', '172.31.30.89', '172.31.27.155']
[2022-11-26 04:07:56.238956] >>> [660.008] Remove node 172.31.24.191, CMD: ssh -q ubuntu@172.31.24.191 bash /home/ubuntu/varuna/aws/remove_node.sh
[2022-11-26 04:07:56.240629] >>> [660.010] Remove node 172.31.21.137, CMD: ssh -q ubuntu@172.31.21.137 bash /home/ubuntu/varuna/aws/remove_node.sh
[2022-11-26 04:07:56.241894] >>> [660.011] next_event: no-op at 720000
[2022-11-26 04:08:56.256822] >>> [720.026] nnodes: 23, no morph
[2022-11-26 04:08:56.256872] >>> [720.026] next_event: remove at 780000
[2022-11-26 04:09:26.239664] >>> [750.009]      node to be remove: ['172.31.21.45']
[2022-11-26 04:09:26.240148] >>> [750.009] nnodes: 22, message: preempt 750.0092570781708
[2022-11-26 04:09:26.240189]                remain nodes: ['172.31.28.108', '172.31.20.223', '172.31.18.152', '172.31.27.216', '172.31.24.208', '172.31.30.99', '172.31.16.100', '172.31.22.229', '172.31.22.165', '172.31.28.236', '172.31.21.109', '172.31.21.254', '172.31.16.5', '172.31.30.133', '172.31.23.137', '172.31.28.143', '172.31.28.16', '172.31.17.209', '172.31.29.147', '172.31.27.21', '172.31.30.89', '172.31.27.155']
[2022-11-26 04:09:56.241297] >>> [780.011] Remove node 172.31.21.45, CMD: ssh -q ubuntu@172.31.21.45 bash /home/ubuntu/varuna/aws/remove_node.sh
[2022-11-26 04:09:56.242948] >>> [780.012] next_event: no-op at 840000
[2022-11-26 04:10:56.290769] >>> [840.060] nnodes: 22, no morph
[2022-11-26 04:10:56.290815] >>> [840.060] next_event: no-op at 900000
[2022-11-26 04:11:56.290340] >>> [900.060] nnodes: 22, no morph
[2022-11-26 04:11:56.290423] >>> [900.060] next_event: add at 960000
[2022-11-26 04:12:56.280566] >>> [960.050]      node to be add: ['172.31.24.82', '172.31.31.40']
[2022-11-26 04:12:56.281243] >>> [960.051] nnodes: 24, message: morph
[2022-11-26 04:12:56.281294]                remain nodes: ['172.31.28.108', '172.31.20.223', '172.31.18.152', '172.31.27.216', '172.31.24.208', '172.31.30.99', '172.31.16.100', '172.31.22.229', '172.31.22.165', '172.31.28.236', '172.31.21.109', '172.31.21.254', '172.31.16.5', '172.31.30.133', '172.31.23.137', '172.31.28.143', '172.31.28.16', '172.31.17.209', '172.31.29.147', '172.31.27.21', '172.31.30.89', '172.31.27.155', '172.31.24.82', '172.31.31.40']
[2022-11-26 04:12:56.281318] >>> [960.051] next_event: add at 1020000
[2022-11-26 04:13:56.268343] >>> [1020.038]      node to be add: ['172.31.19.171']
[2022-11-26 04:13:56.268840] >>> [1020.038] nnodes: 25, message: morph
[2022-11-26 04:13:56.268888]                remain nodes: ['172.31.28.108', '172.31.20.223', '172.31.18.152', '172.31.27.216', '172.31.24.208', '172.31.30.99', '172.31.16.100', '172.31.22.229', '172.31.22.165', '172.31.28.236', '172.31.21.109', '172.31.21.254', '172.31.16.5', '172.31.30.133', '172.31.23.137', '172.31.28.143', '172.31.28.16', '172.31.17.209', '172.31.29.147', '172.31.27.21', '172.31.30.89', '172.31.27.155', '172.31.24.82', '172.31.31.40', '172.31.19.171']
[2022-11-26 04:13:56.268910] >>> [1020.038] next_event: no-op at 1080000
[2022-11-26 04:14:56.290743] >>> [1080.060] nnodes: 25, no morph
[2022-11-26 04:14:56.290792] >>> [1080.060] next_event: remove at 1140000
[2022-11-26 04:15:26.242344] >>> [1110.012]      node to be remove: ['172.31.28.236', '172.31.30.99', '172.31.24.208', '172.31.21.254']
[2022-11-26 04:15:26.242834] >>> [1110.012] nnodes: 21, message: preempt 1110.0119500160217
[2022-11-26 04:15:26.242886]                remain nodes: ['172.31.28.108', '172.31.20.223', '172.31.18.152', '172.31.27.216', '172.31.16.100', '172.31.22.229', '172.31.22.165', '172.31.21.109', '172.31.16.5', '172.31.30.133', '172.31.23.137', '172.31.28.143', '172.31.28.16', '172.31.17.209', '172.31.29.147', '172.31.27.21', '172.31.30.89', '172.31.27.155', '172.31.24.82', '172.31.31.40', '172.31.19.171']
[2022-11-26 04:15:56.234372] >>> [1140.004] Remove node 172.31.28.236, CMD: ssh -q ubuntu@172.31.28.236 bash /home/ubuntu/varuna/aws/remove_node.sh
[2022-11-26 04:15:56.236004] >>> [1140.005] Remove node 172.31.30.99, CMD: ssh -q ubuntu@172.31.30.99 bash /home/ubuntu/varuna/aws/remove_node.sh
[2022-11-26 04:15:56.237235] >>> [1140.007] Remove node 172.31.24.208, CMD: ssh -q ubuntu@172.31.24.208 bash /home/ubuntu/varuna/aws/remove_node.sh
[2022-11-26 04:15:56.238519] >>> [1140.008] Remove node 172.31.21.254, CMD: ssh -q ubuntu@172.31.21.254 bash /home/ubuntu/varuna/aws/remove_node.sh
[2022-11-26 04:15:56.239885] >>> [1140.009] next_event: no-op at 1200000
[2022-11-26 04:16:56.290777] >>> [1200.060] nnodes: 21, no morph
[2022-11-26 04:16:56.290833] >>> [1200.060] next_event: remove at 1260000
[2022-11-26 04:17:26.235737] >>> [1230.005]      node to be remove: ['172.31.28.16']
[2022-11-26 04:17:26.236277] >>> [1230.006] nnodes: 20, message: preempt 1230.0053567886353
[2022-11-26 04:17:26.236322]                remain nodes: ['172.31.28.108', '172.31.20.223', '172.31.18.152', '172.31.27.216', '172.31.16.100', '172.31.22.229', '172.31.22.165', '172.31.21.109', '172.31.16.5', '172.31.30.133', '172.31.23.137', '172.31.28.143', '172.31.17.209', '172.31.29.147', '172.31.27.21', '172.31.30.89', '172.31.27.155', '172.31.24.82', '172.31.31.40', '172.31.19.171']
[2022-11-26 04:17:56.260783] >>> [1260.030] Remove node 172.31.28.16, CMD: ssh -q ubuntu@172.31.28.16 bash /home/ubuntu/varuna/aws/remove_node.sh
[2022-11-26 04:17:56.262478] >>> [1260.032] next_event: add at 1320000
[2022-11-26 04:18:56.243175] >>> [1320.012]      node to be add: ['172.31.25.155']
[2022-11-26 04:18:56.243681] >>> [1320.013] nnodes: 21, message: morph
[2022-11-26 04:18:56.243735]                remain nodes: ['172.31.28.108', '172.31.20.223', '172.31.18.152', '172.31.27.216', '172.31.16.100', '172.31.22.229', '172.31.22.165', '172.31.21.109', '172.31.16.5', '172.31.30.133', '172.31.23.137', '172.31.28.143', '172.31.17.209', '172.31.29.147', '172.31.27.21', '172.31.30.89', '172.31.27.155', '172.31.24.82', '172.31.31.40', '172.31.19.171', '172.31.25.155']
[2022-11-26 04:18:56.243762] >>> [1320.013] next_event: no-op at 1380000
[2022-11-26 04:19:56.237055] >>> [1380.006] nnodes: 21, no morph
[2022-11-26 04:19:56.237108] >>> [1380.006] next_event: no-op at 1440000
[2022-11-26 04:20:56.290331] >>> [1440.060] nnodes: 21, no morph
[2022-11-26 04:20:56.290402] >>> [1440.060] next_event: no-op at 1500000
[2022-11-26 04:21:56.290369] >>> [1500.060] nnodes: 21, no morph
[2022-11-26 04:21:56.290468] >>> [1500.060] next_event: no-op at 1560000
[2022-11-26 04:22:56.290337] >>> [1560.060] nnodes: 21, no morph
[2022-11-26 04:22:56.290410] >>> [1560.060] next_event: no-op at 1620000
[2022-11-26 04:23:56.290329] >>> [1620.060] nnodes: 21, no morph
[2022-11-26 04:23:56.290403] >>> [1620.060] next_event: add at 1680000
[2022-11-26 04:24:56.264882] >>> [1680.034]      node to be add: ['172.31.19.112', '172.31.26.140']
[2022-11-26 04:24:56.265505] >>> [1680.035] nnodes: 23, message: morph
[2022-11-26 04:24:56.265552]                remain nodes: ['172.31.28.108', '172.31.20.223', '172.31.18.152', '172.31.27.216', '172.31.16.100', '172.31.22.229', '172.31.22.165', '172.31.21.109', '172.31.16.5', '172.31.30.133', '172.31.23.137', '172.31.28.143', '172.31.17.209', '172.31.29.147', '172.31.27.21', '172.31.30.89', '172.31.27.155', '172.31.24.82', '172.31.31.40', '172.31.19.171', '172.31.25.155', '172.31.19.112', '172.31.26.140']
[2022-11-26 04:24:56.265575] >>> [1680.035] next_event: no-op at 1740000
[2022-11-26 04:25:56.290309] >>> [1740.060] nnodes: 23, no morph
[2022-11-26 04:25:56.290360] >>> [1740.060] next_event: no-op at 1800000
[2022-11-26 04:26:56.276824] >>> [1800.046] nnodes: 23, no morph
[2022-11-26 04:26:56.276907] >>> [1800.046] next_event: add at 1860000
[2022-11-26 04:27:56.290479] >>> [1860.060]      node to be add: ['172.31.17.44', '172.31.24.191', '172.31.21.137', '172.31.21.45', '172.31.28.236', '172.31.30.99', '172.31.24.208']
[2022-11-26 04:27:56.291604] >>> [1860.061] nnodes: 30, message: morph
[2022-11-26 04:27:56.291709]                remain nodes: ['172.31.28.108', '172.31.20.223', '172.31.18.152', '172.31.27.216', '172.31.16.100', '172.31.22.229', '172.31.22.165', '172.31.21.109', '172.31.16.5', '172.31.30.133', '172.31.23.137', '172.31.28.143', '172.31.17.209', '172.31.29.147', '172.31.27.21', '172.31.30.89', '172.31.27.155', '172.31.24.82', '172.31.31.40', '172.31.19.171', '172.31.25.155', '172.31.19.112', '172.31.26.140', '172.31.17.44', '172.31.24.191', '172.31.21.137', '172.31.21.45', '172.31.28.236', '172.31.30.99', '172.31.24.208']
[2022-11-26 04:27:56.291774] >>> [1860.061] next_event: add at 1920000
[2022-11-26 04:28:56.290325] >>> [1920.060]      node to be add: ['172.31.21.254', '172.31.28.16']
[2022-11-26 04:28:56.290723] >>> [1920.060] nnodes: 32, message: morph
[2022-11-26 04:28:56.290759]                remain nodes: ['172.31.28.108', '172.31.20.223', '172.31.18.152', '172.31.27.216', '172.31.16.100', '172.31.22.229', '172.31.22.165', '172.31.21.109', '172.31.16.5', '172.31.30.133', '172.31.23.137', '172.31.28.143', '172.31.17.209', '172.31.29.147', '172.31.27.21', '172.31.30.89', '172.31.27.155', '172.31.24.82', '172.31.31.40', '172.31.19.171', '172.31.25.155', '172.31.19.112', '172.31.26.140', '172.31.17.44', '172.31.24.191', '172.31.21.137', '172.31.21.45', '172.31.28.236', '172.31.30.99', '172.31.24.208', '172.31.21.254', '172.31.28.16']
[2022-11-26 04:28:56.290773] >>> [1920.060] next_event: no-op at 1980000
[2022-11-26 04:29:56.288214] >>> [1980.057] nnodes: 32, no morph
[2022-11-26 04:29:56.288275] >>> [1980.058] next_event: no-op at 2040000
[2022-11-26 04:30:56.290720] >>> [2040.060] nnodes: 32, no morph
[2022-11-26 04:30:56.290777] >>> [2040.060] next_event: no-op at 2100000
[2022-11-26 04:31:56.290616] >>> [2100.060] nnodes: 32, no morph
[2022-11-26 04:31:56.290942] >>> [2100.060] next_event: no-op at 2160000
[2022-11-26 04:32:56.290328] >>> [2160.060] nnodes: 32, no morph
[2022-11-26 04:32:56.290386] >>> [2160.060] next_event: no-op at 2220000
[2022-11-26 04:33:56.290352] >>> [2220.060] nnodes: 32, no morph
[2022-11-26 04:33:56.290481] >>> [2220.060] next_event: no-op at 2280000
[2022-11-26 04:34:56.290498] >>> [2280.060] nnodes: 32, no morph
[2022-11-26 04:34:56.290601] >>> [2280.060] next_event: remove at 2340000
[2022-11-26 04:35:26.260753] >>> [2310.030]      node to be remove: ['172.31.16.100']
[2022-11-26 04:35:26.261352] >>> [2310.031] nnodes: 31, message: preempt 2310.030419588089
[2022-11-26 04:35:26.261402]                remain nodes: ['172.31.28.108', '172.31.20.223', '172.31.18.152', '172.31.27.216', '172.31.22.229', '172.31.22.165', '172.31.21.109', '172.31.16.5', '172.31.30.133', '172.31.23.137', '172.31.28.143', '172.31.17.209', '172.31.29.147', '172.31.27.21', '172.31.30.89', '172.31.27.155', '172.31.24.82', '172.31.31.40', '172.31.19.171', '172.31.25.155', '172.31.19.112', '172.31.26.140', '172.31.17.44', '172.31.24.191', '172.31.21.137', '172.31.21.45', '172.31.28.236', '172.31.30.99', '172.31.24.208', '172.31.21.254', '172.31.28.16']
[2022-11-26 04:35:56.260763] >>> [2340.030] Remove node 172.31.16.100, CMD: ssh -q ubuntu@172.31.16.100 bash /home/ubuntu/varuna/aws/remove_node.sh
[2022-11-26 04:35:56.262445] >>> [2340.032] next_event: no-op at 2400000
[2022-11-26 04:36:56.290748] >>> [2400.060] nnodes: 31, no morph
[2022-11-26 04:36:56.290797] >>> [2400.060] next_event: add at 2460000
[2022-11-26 04:37:56.232221] >>> [2460.001]      node to be add: ['172.31.16.100']
[2022-11-26 04:37:56.232760] >>> [2460.002] nnodes: 32, message: morph
[2022-11-26 04:37:56.232806]                remain nodes: ['172.31.28.108', '172.31.20.223', '172.31.18.152', '172.31.27.216', '172.31.22.229', '172.31.22.165', '172.31.21.109', '172.31.16.5', '172.31.30.133', '172.31.23.137', '172.31.28.143', '172.31.17.209', '172.31.29.147', '172.31.27.21', '172.31.30.89', '172.31.27.155', '172.31.24.82', '172.31.31.40', '172.31.19.171', '172.31.25.155', '172.31.19.112', '172.31.26.140', '172.31.17.44', '172.31.24.191', '172.31.21.137', '172.31.21.45', '172.31.28.236', '172.31.30.99', '172.31.24.208', '172.31.21.254', '172.31.28.16', '172.31.16.100']
[2022-11-26 04:37:56.232829] >>> [2460.002] next_event: no-op at 2520000
[2022-11-26 04:38:56.290327] >>> [2520.060] nnodes: 32, no morph
[2022-11-26 04:38:56.290376] >>> [2520.060] next_event: no-op at 2580000
[2022-11-26 04:39:56.261879] >>> [2580.031] nnodes: 32, no morph
[2022-11-26 04:39:56.261934] >>> [2580.031] next_event: no-op at 2640000
[2022-11-26 04:40:56.272547] >>> [2640.042] nnodes: 32, no morph
[2022-11-26 04:40:56.272600] >>> [2640.042] next_event: no-op at 2700000
[2022-11-26 04:41:56.236766] >>> [2700.006] nnodes: 32, no morph
[2022-11-26 04:41:56.236836] >>> [2700.006] next_event: no-op at 2760000
[2022-11-26 04:42:56.290714] >>> [2760.060] nnodes: 32, no morph
[2022-11-26 04:42:56.290821] >>> [2760.060] next_event: remove at 2820000
[2022-11-26 04:43:26.258348] >>> [2790.028]      node to be remove: ['172.31.26.140', '172.31.19.112', '172.31.27.21']
[2022-11-26 04:43:26.258992] >>> [2790.028] nnodes: 29, message: preempt 2790.028035402298
[2022-11-26 04:43:26.259042]                remain nodes: ['172.31.28.108', '172.31.20.223', '172.31.18.152', '172.31.27.216', '172.31.22.229', '172.31.22.165', '172.31.21.109', '172.31.16.5', '172.31.30.133', '172.31.23.137', '172.31.28.143', '172.31.17.209', '172.31.29.147', '172.31.30.89', '172.31.27.155', '172.31.24.82', '172.31.31.40', '172.31.19.171', '172.31.25.155', '172.31.17.44', '172.31.24.191', '172.31.21.137', '172.31.21.45', '172.31.28.236', '172.31.30.99', '172.31.24.208', '172.31.21.254', '172.31.28.16', '172.31.16.100']
[2022-11-26 04:43:56.260758] >>> [2820.030] Remove node 172.31.26.140, CMD: ssh -q ubuntu@172.31.26.140 bash /home/ubuntu/varuna/aws/remove_node.sh
[2022-11-26 04:43:56.262356] >>> [2820.032] Remove node 172.31.19.112, CMD: ssh -q ubuntu@172.31.19.112 bash /home/ubuntu/varuna/aws/remove_node.sh
[2022-11-26 04:43:56.263689] >>> [2820.033] Remove node 172.31.27.21, CMD: ssh -q ubuntu@172.31.27.21 bash /home/ubuntu/varuna/aws/remove_node.sh
[2022-11-26 04:43:56.264945] >>> [2820.034] next_event: no-op at 2880000
[2022-11-26 04:44:56.290359] >>> [2880.060] nnodes: 29, no morph
[2022-11-26 04:44:56.290435] >>> [2880.060] next_event: no-op at 2940000
[2022-11-26 04:45:56.290356] >>> [2940.060] nnodes: 29, no morph
[2022-11-26 04:45:56.290436] >>> [2940.060] next_event: no-op at 3000000
[2022-11-26 04:46:56.290716] >>> [3000.060] nnodes: 29, no morph
[2022-11-26 04:47:56.291029] >>> [3060.060] nnodes: 29, message: preempt 3060.0601086616516
[2022-11-26 04:47:56.291070]           Finally kill all
