[2022-11-26 05:31:55.939095] Begin to replay trace traces/trace_hl_15_25.txt
[2022-11-26 05:31:55.939148] >>> [0.000] next_event: add at 0
[2022-11-26 05:31:55.939188] >>> [0.000]      node to be add: ['172.31.28.108', '172.31.20.223', '172.31.18.152', '172.31.27.216', '172.31.24.208', '172.31.30.99', '172.31.16.100', '172.31.22.229', '172.31.22.165', '172.31.31.40', '172.31.19.171', '172.31.17.44', '172.31.28.236', '172.31.21.45', '172.31.21.109', '172.31.19.112', '172.31.21.254', '172.31.24.191', '172.31.16.5', '172.31.30.133', '172.31.23.137', '172.31.21.137', '172.31.26.140', '172.31.28.143', '172.31.28.16', '172.31.17.209', '172.31.24.82']
[2022-11-26 05:31:55.940216] >>> [0.001] nnodes: 27, message: 
[2022-11-26 05:31:55.940281]                remain nodes: ['172.31.28.108', '172.31.20.223', '172.31.18.152', '172.31.27.216', '172.31.24.208', '172.31.30.99', '172.31.16.100', '172.31.22.229', '172.31.22.165', '172.31.31.40', '172.31.19.171', '172.31.17.44', '172.31.28.236', '172.31.21.45', '172.31.21.109', '172.31.19.112', '172.31.21.254', '172.31.24.191', '172.31.16.5', '172.31.30.133', '172.31.23.137', '172.31.21.137', '172.31.26.140', '172.31.28.143', '172.31.28.16', '172.31.17.209', '172.31.24.82']
[2022-11-26 05:31:55.940308] >>> [0.001] next_event: no-op at 60000
Container nvidia build = 
Warning! /hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ directory missing. Training cannot start
/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/
/home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json
Logs written to /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/bert_lamb_pretraining.pyt_bert_pretraining_phase1_fp16_gbs1024.log
+ '[' -z /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/bert_lamb_pretraining.pyt_bert_pretraining_phase1_fp16_gbs1024.log ']'
+ tee /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/bert_lamb_pretraining.pyt_bert_pretraining_phase1_fp16_gbs1024.log
+ /opt/conda/envs/varuna/bin/python -m varuna.run_varuna --profile_folder s3://spot-checkpoints/bert-profile --batch_size 1024 --chunk_size 8 --gpus_per_node 1 --machine_list /home/ubuntu/varuna/aws/hosts/available_machines.out /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna
reachable machines: ['172.31.28.108', '172.31.20.223', '172.31.18.152', '172.31.27.216', '172.31.24.208', '172.31.30.99', '172.31.16.100', '172.31.22.229', '172.31.22.165', '172.31.31.40', '172.31.19.171', '172.31.17.44', '172.31.28.236', '172.31.21.45', '172.31.21.109', '172.31.19.112', '172.31.21.254', '172.31.24.191', '172.31.16.5', '172.31.30.133', '172.31.23.137', '172.31.21.137', '172.31.26.140', '172.31.28.143', '172.31.28.16', '172.31.17.209', '172.31.24.82']
/opt/conda/envs/varuna/bin/python -m varuna.morph_server /home/ubuntu/varuna/aws/hosts/available_machines.out /home/ubuntu/varuna/aws/hosts/varuna_current_machines 4200  > varuna_morph.out 2>varuna_morph.err &
/opt/conda/envs/varuna/bin/python -m varuna.catch_all /home/ubuntu/varuna/aws/hosts/varuna_current_machines 5000  > varuna_catch.out 2>varuna_catch.err &
ssh ubuntu@172.31.28.108 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 0 --nservers 27 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.20.223 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 1 --nservers 27 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.18.152 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 2 --nservers 27 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.27.216 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 3 --nservers 27 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.24.208 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 4 --nservers 27 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.30.99 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 5 --nservers 27 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.16.100 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 6 --nservers 27 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.22.229 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 7 --nservers 27 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.22.165 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 8 --nservers 27 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.31.40 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 9 --nservers 27 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.19.171 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 10 --nservers 27 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.17.44 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 11 --nservers 27 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.28.236 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 12 --nservers 27 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.21.45 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 13 --nservers 27 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.21.109 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 14 --nservers 27 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.19.112 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 15 --nservers 27 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.21.254 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 16 --nservers 27 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.24.191 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 17 --nservers 27 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.16.5 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 18 --nservers 27 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.30.133 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 19 --nservers 27 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.23.137 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 20 --nservers 27 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.21.137 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 21 --nservers 27 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.26.140 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 22 --nservers 27 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.28.143 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 23 --nservers 27 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.28.16 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 24 --nservers 27 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.17.209 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 25 --nservers 27 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.24.82 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 26 --nservers 27 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
+ set +x
finished pretraining
[2022-11-26 05:32:55.998425] >>> [60.059] nnodes: 27, no morph
[2022-11-26 05:32:55.998495] >>> [60.059] next_event: no-op at 120000
[2022-11-26 05:33:55.998483] >>> [120.059] nnodes: 27, no morph
[2022-11-26 05:33:55.998563] >>> [120.059] next_event: no-op at 180000
[2022-11-26 05:34:55.998450] >>> [180.059] nnodes: 27, no morph
[2022-11-26 05:34:55.998597] >>> [180.059] next_event: no-op at 240000
[2022-11-26 05:35:55.998356] >>> [240.059] nnodes: 27, no morph
[2022-11-26 05:35:55.998448] >>> [240.059] next_event: no-op at 300000
[2022-11-26 05:36:55.998327] >>> [300.059] nnodes: 27, no morph
[2022-11-26 05:36:55.998393] >>> [300.059] next_event: add at 360000
[2022-11-26 05:37:55.998337] >>> [360.059]      node to be add: ['172.31.29.147']
[2022-11-26 05:37:55.999027] >>> [360.060] nnodes: 28, message: morph
[2022-11-26 05:37:55.999078]                remain nodes: ['172.31.28.108', '172.31.20.223', '172.31.18.152', '172.31.27.216', '172.31.24.208', '172.31.30.99', '172.31.16.100', '172.31.22.229', '172.31.22.165', '172.31.31.40', '172.31.19.171', '172.31.17.44', '172.31.28.236', '172.31.21.45', '172.31.21.109', '172.31.19.112', '172.31.21.254', '172.31.24.191', '172.31.16.5', '172.31.30.133', '172.31.23.137', '172.31.21.137', '172.31.26.140', '172.31.28.143', '172.31.28.16', '172.31.17.209', '172.31.24.82', '172.31.29.147']
[2022-11-26 05:37:55.999101] >>> [360.060] next_event: add at 420000
[2022-11-26 05:38:55.998350] >>> [420.059]      node to be add: ['172.31.27.21', '172.31.30.89', '172.31.25.155', '172.31.27.155']
[2022-11-26 05:38:55.998862] >>> [420.060] nnodes: 32, message: morph
[2022-11-26 05:38:55.998921]                remain nodes: ['172.31.28.108', '172.31.20.223', '172.31.18.152', '172.31.27.216', '172.31.24.208', '172.31.30.99', '172.31.16.100', '172.31.22.229', '172.31.22.165', '172.31.31.40', '172.31.19.171', '172.31.17.44', '172.31.28.236', '172.31.21.45', '172.31.21.109', '172.31.19.112', '172.31.21.254', '172.31.24.191', '172.31.16.5', '172.31.30.133', '172.31.23.137', '172.31.21.137', '172.31.26.140', '172.31.28.143', '172.31.28.16', '172.31.17.209', '172.31.24.82', '172.31.29.147', '172.31.27.21', '172.31.30.89', '172.31.25.155', '172.31.27.155']
[2022-11-26 05:38:55.998942] >>> [420.060] next_event: no-op at 480000
[2022-11-26 05:39:55.999098] >>> [480.060] nnodes: 32, no morph
[2022-11-26 05:39:55.999147] >>> [480.060] next_event: no-op at 540000
[2022-11-26 05:40:55.998319] >>> [540.059] nnodes: 32, no morph
[2022-11-26 05:40:55.998369] >>> [540.059] next_event: no-op at 600000
[2022-11-26 05:41:55.998801] >>> [600.060] nnodes: 32, no morph
[2022-11-26 05:41:55.998871] >>> [600.060] next_event: no-op at 660000
[2022-11-26 05:42:55.942322] >>> [660.003] nnodes: 32, no morph
[2022-11-26 05:42:55.942375] >>> [660.003] next_event: no-op at 720000
[2022-11-26 05:43:55.998320] >>> [720.059] nnodes: 32, no morph
[2022-11-26 05:43:55.998375] >>> [720.059] next_event: no-op at 780000
[2022-11-26 05:44:55.998325] >>> [780.059] nnodes: 32, no morph
[2022-11-26 05:44:55.998401] >>> [780.059] next_event: no-op at 840000
[2022-11-26 05:45:55.982492] >>> [840.043] nnodes: 32, no morph
[2022-11-26 05:45:55.982550] >>> [840.043] next_event: remove at 900000
[2022-11-26 05:46:25.950062] >>> [870.011]      node to be remove: ['172.31.28.143']
[2022-11-26 05:46:25.950642] >>> [870.012] nnodes: 31, message: preempt 870.0113387107849
[2022-11-26 05:46:25.950683]                remain nodes: ['172.31.28.108', '172.31.20.223', '172.31.18.152', '172.31.27.216', '172.31.24.208', '172.31.30.99', '172.31.16.100', '172.31.22.229', '172.31.22.165', '172.31.31.40', '172.31.19.171', '172.31.17.44', '172.31.28.236', '172.31.21.45', '172.31.21.109', '172.31.19.112', '172.31.21.254', '172.31.24.191', '172.31.16.5', '172.31.30.133', '172.31.23.137', '172.31.21.137', '172.31.26.140', '172.31.28.16', '172.31.17.209', '172.31.24.82', '172.31.29.147', '172.31.27.21', '172.31.30.89', '172.31.25.155', '172.31.27.155']
[2022-11-26 05:46:55.969162] >>> [900.030] Remove node 172.31.28.143, CMD: ssh -q ubuntu@172.31.28.143 bash /home/ubuntu/varuna/aws/remove_node.sh
[2022-11-26 05:46:55.970906] >>> [900.032] next_event: no-op at 960000
[2022-11-26 05:47:55.998316] >>> [960.059] nnodes: 31, no morph
[2022-11-26 05:47:55.998363] >>> [960.059] next_event: remove at 1020000
[2022-11-26 05:48:25.969119] >>> [990.030]      node to be remove: ['172.31.31.40']
[2022-11-26 05:48:25.969645] >>> [990.031] nnodes: 30, message: preempt 990.0303633213043
[2022-11-26 05:48:25.969698]                remain nodes: ['172.31.28.108', '172.31.20.223', '172.31.18.152', '172.31.27.216', '172.31.24.208', '172.31.30.99', '172.31.16.100', '172.31.22.229', '172.31.22.165', '172.31.19.171', '172.31.17.44', '172.31.28.236', '172.31.21.45', '172.31.21.109', '172.31.19.112', '172.31.21.254', '172.31.24.191', '172.31.16.5', '172.31.30.133', '172.31.23.137', '172.31.21.137', '172.31.26.140', '172.31.28.16', '172.31.17.209', '172.31.24.82', '172.31.29.147', '172.31.27.21', '172.31.30.89', '172.31.25.155', '172.31.27.155']
[2022-11-26 05:48:55.949470] >>> [1020.010] Remove node 172.31.31.40, CMD: ssh -q ubuntu@172.31.31.40 bash /home/ubuntu/varuna/aws/remove_node.sh
[2022-11-26 05:48:55.951231] >>> [1020.012] next_event: no-op at 1080000
[2022-11-26 05:49:55.999146] >>> [1080.060] nnodes: 30, no morph
[2022-11-26 05:49:55.999194] >>> [1080.060] next_event: no-op at 1140000
[2022-11-26 05:50:55.974326] >>> [1140.035] nnodes: 30, no morph
[2022-11-26 05:50:55.974392] >>> [1140.035] next_event: no-op at 1200000
[2022-11-26 05:51:55.999173] >>> [1200.060] nnodes: 30, no morph
[2022-11-26 05:51:55.999267] >>> [1200.060] next_event: no-op at 1260000
[2022-11-26 05:52:55.998351] >>> [1260.059] nnodes: 30, no morph
[2022-11-26 05:52:55.998420] >>> [1260.059] next_event: no-op at 1320000
[2022-11-26 05:53:55.998320] >>> [1320.059] nnodes: 30, no morph
[2022-11-26 05:53:55.998377] >>> [1320.059] next_event: no-op at 1380000
[2022-11-26 05:54:55.999105] >>> [1380.060] nnodes: 30, no morph
[2022-11-26 05:54:55.999161] >>> [1380.060] next_event: add at 1440000
[2022-11-26 05:55:55.998368] >>> [1440.059]      node to be add: ['172.31.28.143']
[2022-11-26 05:55:55.999076] >>> [1440.060] nnodes: 31, message: morph
[2022-11-26 05:55:55.999137]                remain nodes: ['172.31.28.108', '172.31.20.223', '172.31.18.152', '172.31.27.216', '172.31.24.208', '172.31.30.99', '172.31.16.100', '172.31.22.229', '172.31.22.165', '172.31.19.171', '172.31.17.44', '172.31.28.236', '172.31.21.45', '172.31.21.109', '172.31.19.112', '172.31.21.254', '172.31.24.191', '172.31.16.5', '172.31.30.133', '172.31.23.137', '172.31.21.137', '172.31.26.140', '172.31.28.16', '172.31.17.209', '172.31.24.82', '172.31.29.147', '172.31.27.21', '172.31.30.89', '172.31.25.155', '172.31.27.155', '172.31.28.143']
[2022-11-26 05:55:55.999165] >>> [1440.060] next_event: add at 1500000
[2022-11-26 05:56:55.951859] >>> [1500.013]      node to be add: ['172.31.31.40']
[2022-11-26 05:56:55.952264] >>> [1500.013] nnodes: 32, message: morph
[2022-11-26 05:56:55.952308]                remain nodes: ['172.31.28.108', '172.31.20.223', '172.31.18.152', '172.31.27.216', '172.31.24.208', '172.31.30.99', '172.31.16.100', '172.31.22.229', '172.31.22.165', '172.31.19.171', '172.31.17.44', '172.31.28.236', '172.31.21.45', '172.31.21.109', '172.31.19.112', '172.31.21.254', '172.31.24.191', '172.31.16.5', '172.31.30.133', '172.31.23.137', '172.31.21.137', '172.31.26.140', '172.31.28.16', '172.31.17.209', '172.31.24.82', '172.31.29.147', '172.31.27.21', '172.31.30.89', '172.31.25.155', '172.31.27.155', '172.31.28.143', '172.31.31.40']
[2022-11-26 05:56:55.952326] >>> [1500.013] next_event: no-op at 1560000
[2022-11-26 05:57:55.999149] >>> [1560.060] nnodes: 32, no morph
[2022-11-26 05:57:55.999212] >>> [1560.060] next_event: no-op at 1620000
[2022-11-26 05:58:55.998340] >>> [1620.059] nnodes: 32, no morph
[2022-11-26 05:58:55.998405] >>> [1620.059] next_event: no-op at 1680000
[2022-11-26 05:59:55.998327] >>> [1680.059] nnodes: 32, no morph
[2022-11-26 05:59:55.998404] >>> [1680.059] next_event: no-op at 1740000
[2022-11-26 06:00:55.998334] >>> [1740.059] nnodes: 32, no morph
[2022-11-26 06:00:55.998403] >>> [1740.059] next_event: no-op at 1800000
[2022-11-26 06:01:55.998419] >>> [1800.059] nnodes: 32, no morph
[2022-11-26 06:01:55.998544] >>> [1800.059] next_event: remove at 1860000
[2022-11-26 06:02:25.958366] >>> [1830.019]      node to be remove: ['172.31.21.254']
[2022-11-26 06:02:25.958878] >>> [1830.020] nnodes: 31, message: preempt 1830.0196232795715
[2022-11-26 06:02:25.958917]                remain nodes: ['172.31.28.108', '172.31.20.223', '172.31.18.152', '172.31.27.216', '172.31.24.208', '172.31.30.99', '172.31.16.100', '172.31.22.229', '172.31.22.165', '172.31.19.171', '172.31.17.44', '172.31.28.236', '172.31.21.45', '172.31.21.109', '172.31.19.112', '172.31.24.191', '172.31.16.5', '172.31.30.133', '172.31.23.137', '172.31.21.137', '172.31.26.140', '172.31.28.16', '172.31.17.209', '172.31.24.82', '172.31.29.147', '172.31.27.21', '172.31.30.89', '172.31.25.155', '172.31.27.155', '172.31.28.143', '172.31.31.40']
[2022-11-26 06:02:55.969151] >>> [1860.030] Remove node 172.31.21.254, CMD: ssh -q ubuntu@172.31.21.254 bash /home/ubuntu/varuna/aws/remove_node.sh
[2022-11-26 06:02:55.970737] >>> [1860.032] next_event: remove at 1920000
[2022-11-26 06:03:25.948039] >>> [1890.009]      node to be remove: ['172.31.16.5', '172.31.21.109', '172.31.21.45', '172.31.27.216', '172.31.22.165']
[2022-11-26 06:03:25.948537] >>> [1890.009] nnodes: 26, message: preempt 1890.009254693985
[2022-11-26 06:03:25.948590]                remain nodes: ['172.31.28.108', '172.31.20.223', '172.31.18.152', '172.31.24.208', '172.31.30.99', '172.31.16.100', '172.31.22.229', '172.31.19.171', '172.31.17.44', '172.31.28.236', '172.31.19.112', '172.31.24.191', '172.31.30.133', '172.31.23.137', '172.31.21.137', '172.31.26.140', '172.31.28.16', '172.31.17.209', '172.31.24.82', '172.31.29.147', '172.31.27.21', '172.31.30.89', '172.31.25.155', '172.31.27.155', '172.31.28.143', '172.31.31.40']
[2022-11-26 06:03:55.969160] >>> [1920.030] Remove node 172.31.16.5, CMD: ssh -q ubuntu@172.31.16.5 bash /home/ubuntu/varuna/aws/remove_node.sh
[2022-11-26 06:03:55.970871] >>> [1920.032] Remove node 172.31.21.109, CMD: ssh -q ubuntu@172.31.21.109 bash /home/ubuntu/varuna/aws/remove_node.sh
[2022-11-26 06:03:55.972157] >>> [1920.033] Remove node 172.31.21.45, CMD: ssh -q ubuntu@172.31.21.45 bash /home/ubuntu/varuna/aws/remove_node.sh
[2022-11-26 06:03:55.973419] >>> [1920.034] Remove node 172.31.27.216, CMD: ssh -q ubuntu@172.31.27.216 bash /home/ubuntu/varuna/aws/remove_node.sh
[2022-11-26 06:03:55.975017] >>> [1920.036] Remove node 172.31.22.165, CMD: ssh -q ubuntu@172.31.22.165 bash /home/ubuntu/varuna/aws/remove_node.sh
[2022-11-26 06:03:55.976571] >>> [1920.037] next_event: remove at 1980000
[2022-11-26 06:04:25.969147] >>> [1950.030]      node to be remove: ['172.31.17.44']
[2022-11-26 06:04:25.969648] >>> [1950.031] nnodes: 25, message: preempt 1950.0303745269775
[2022-11-26 06:04:25.969690]                remain nodes: ['172.31.28.108', '172.31.20.223', '172.31.18.152', '172.31.24.208', '172.31.30.99', '172.31.16.100', '172.31.22.229', '172.31.19.171', '172.31.28.236', '172.31.19.112', '172.31.24.191', '172.31.30.133', '172.31.23.137', '172.31.21.137', '172.31.26.140', '172.31.28.16', '172.31.17.209', '172.31.24.82', '172.31.29.147', '172.31.27.21', '172.31.30.89', '172.31.25.155', '172.31.27.155', '172.31.28.143', '172.31.31.40']
[2022-11-26 06:04:55.969134] >>> [1980.030] Remove node 172.31.17.44, CMD: ssh -q ubuntu@172.31.17.44 bash /home/ubuntu/varuna/aws/remove_node.sh
[2022-11-26 06:04:55.970950] >>> [1980.032] next_event: remove at 2040000
[2022-11-26 06:05:25.966336] >>> [2010.027]      node to be remove: ['172.31.17.209', '172.31.25.155']
[2022-11-26 06:05:25.966890] >>> [2010.028] nnodes: 23, message: preempt 2010.0276126861572
[2022-11-26 06:05:25.966939]                remain nodes: ['172.31.28.108', '172.31.20.223', '172.31.18.152', '172.31.24.208', '172.31.30.99', '172.31.16.100', '172.31.22.229', '172.31.19.171', '172.31.28.236', '172.31.19.112', '172.31.24.191', '172.31.30.133', '172.31.23.137', '172.31.21.137', '172.31.26.140', '172.31.28.16', '172.31.24.82', '172.31.29.147', '172.31.27.21', '172.31.30.89', '172.31.27.155', '172.31.28.143', '172.31.31.40']
[2022-11-26 06:05:55.969142] >>> [2040.030] Remove node 172.31.17.209, CMD: ssh -q ubuntu@172.31.17.209 bash /home/ubuntu/varuna/aws/remove_node.sh
[2022-11-26 06:05:55.970829] >>> [2040.032] Remove node 172.31.25.155, CMD: ssh -q ubuntu@172.31.25.155 bash /home/ubuntu/varuna/aws/remove_node.sh
[2022-11-26 06:05:55.972203] >>> [2040.033] next_event: no-op at 2100000
[2022-11-26 06:06:55.999131] >>> [2100.060] nnodes: 23, no morph
[2022-11-26 06:06:55.999186] >>> [2100.060] next_event: no-op at 2160000
[2022-11-26 06:07:55.999101] >>> [2160.060] nnodes: 23, no morph
[2022-11-26 06:07:55.999156] >>> [2160.060] next_event: no-op at 2220000
[2022-11-26 06:08:55.999101] >>> [2220.060] nnodes: 23, no morph
[2022-11-26 06:08:55.999156] >>> [2220.060] next_event: no-op at 2280000
[2022-11-26 06:09:55.998318] >>> [2280.059] nnodes: 23, no morph
[2022-11-26 06:09:55.998374] >>> [2280.059] next_event: no-op at 2340000
[2022-11-26 06:10:55.978683] >>> [2340.040] nnodes: 23, no morph
[2022-11-26 06:10:55.978736] >>> [2340.040] next_event: no-op at 2400000
[2022-11-26 06:11:55.963427] >>> [2400.024] nnodes: 23, no morph
[2022-11-26 06:12:55.957795] >>> [2460.019] nnodes: 23, message: preempt 2460.0185091495514
[2022-11-26 06:12:55.957836]           Finally kill all
