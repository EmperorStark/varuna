Parent process ID: 83581 node: 172.31.28.108
24 cutpoints
Stages 1
Micro-bs 8 Max mem: 14622140211.200005
Predicted microbatch size for 1: 8
comm size 0
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 1 5 0 2493369.62890625 0
End of simulation:  Mini-batch time (usec) = 4144382
Min send: 10000000, max send 0
Min long send: 10000000, max long send 0
Min fwd: 10000000, max fwd 0; min bwd 10000000, max bwd 0
Min long fwd: 141043, max long fwd 144458; min long bwd 184920, max long bwd 191040
Time taken by simulation: 48 microseconds

Stages 2
Micro-bs 8 Max mem: 7660942131.200001
Predicted microbatch size for 2: 8
comm size 4194304
WARNING: no send time found, 2 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 2 10 0 660629.9438476562 248719.58977934244
End of simulation:  Mini-batch time (usec) = 3225075
Min send: 10000000, max send 0
Min long send: 249051, max long send 264414
Min fwd: 78473, max fwd 86627; min bwd 87174, max bwd 96382
Min long fwd: 58631, max long fwd 64048; min long bwd 93560, max long bwd 98662
Time taken by simulation: 194 microseconds

Stages 3
Micro-bs 8 Max mem: 5497876480.0
Predicted microbatch size for 3: 8
comm size 4194304
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 15 0 476084.3811035156 248719.58977934244
End of simulation:  Mini-batch time (usec) = 3889823
Min send: 10000000, max send 0
Min long send: 248907, max long send 271185
Min fwd: 34426, max fwd 67951; min bwd 54355, max bwd 65681
Min long fwd: 38932, max long fwd 44034; min long bwd 64405, max long bwd 71935
Time taken by simulation: 493 microseconds

Stages 4
Micro-bs 8 Max mem: 4406266675.2
Predicted microbatch size for 4: 8
comm size 4194304
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 22 0 364029.9377441406 248719.58977934244
End of simulation:  Mini-batch time (usec) = 4679330
Min send: 10000000, max send 0
Min long send: 248907, max long send 274819
Min fwd: 21514, max fwd 60961; min bwd 37461, max bwd 50759
Min long fwd: 29330, max long fwd 37152; min long bwd 47928, max long bwd 55195
Time taken by simulation: 1068 microseconds

Stages 6
Micro-bs 8 Max mem: 3314656870.4
Predicted microbatch size for 6: 8
comm size 4194304
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 32 0 233226.318359375 248719.58977934244
End of simulation:  Mini-batch time (usec) = 6680183
Min send: 10000000, max send 0
Min long send: 248719, max long send 275881
Min fwd: 10965, max fwd 44004; min bwd 19992, max bwd 36467
Min long fwd: 22115, max long fwd 30954; min long bwd 32578, max long bwd 40795
Time taken by simulation: 2355 microseconds

Stages 8
Micro-bs 8 Max mem: 2758774988.8
Predicted microbatch size for 8: 8
comm size 4194304
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 43 0 178155.74645996094 248719.58977934244
End of simulation:  Mini-batch time (usec) = 9019309
Min send: 10000000, max send 0
Min long send: 248735, max long send 276940
Min fwd: 5776, max fwd 41014; min bwd 16548, max bwd 29492
Min long fwd: 17309, max long fwd 25772; min long bwd 25282, max long bwd 32088
Time taken by simulation: 4443 microseconds

Stages 12
Micro-bs 8 Max mem: 2202893107.2
Predicted microbatch size for 12: 8
comm size 4194304
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 64 0 117116.2109375 248719.58977934244
End of simulation:  Mini-batch time (usec) = 13687683
Min send: 10000000, max send 0
Min long send: 248720, max long send 280797
Min fwd: 141, max fwd 25024; min bwd 6433, max bwd 23373
Min long fwd: 7201, max long fwd 18161; min long bwd 16833, max long bwd 28389
Time taken by simulation: 10603 microseconds

{1: 4.144382, 2: 3.225075, 3: 3.889823, 4: 4.67933, 6: 6.680183, 8: 9.019309, 12: 13.687683}
{1: 8, 2: 8, 3: 8, 4: 8, 6: 8, 8: 8, 12: 8}
best config is: 2 8
expected time is 3.225075
13 per stage
26 servers!
Config:
ranks: range(0, 1)
train batch size: 1024
partitions: 2
chunk_size: 8
data depth: 13
stage to rank map: 0,2,4,6,8,10,12,14,16,18,20,22,24;1,3,5,7,9,11,13,15,17,19,21,23,25;
World size is 26
/opt/conda/envs/varuna/bin/python -u /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --rank=0 --chunk_size=8 --local_rank=0 --stage_to_rank_map=0,2,4,6,8,10,12,14,16,18,20,22,24;1,3,5,7,9,11,13,15,17,19,21,23,25; --batch-size=78 --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna
device: cuda:0 n_gpu: 1, distributed training: True, 16-bits training: True
DLL 2022-11-26 05:32:08.070316 - PARAMETER Config : ["Namespace(input_dir='/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/', config_file='bert_config.json', bert_model='bert-large-uncased', output_dir='s3://spot-checkpoints/bert', init_checkpoint=None, max_seq_length=128, max_predictions_per_seq=20, train_batch_size=78, learning_rate=0.006, num_train_epochs=3.0, max_steps=7038.0, warmup_proportion=0.2843, local_rank=0, seed=12439, gradient_accumulation_steps=1, fp16=True, amp=False, loss_scale=0.0, log_freq=1.0, checkpoint_activations=False, resume_from_checkpoint=False, resume_step=-1, num_steps_per_checkpoint=200, skip_checkpoint=False, phase2=False, allreduce_post_accumulation=False, allreduce_post_accumulation_fp16=False, phase1_end_step=7038, init_loss_scale=1048576, do_train=True, json_summary='/home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json', use_env=False, disable_progress_bar=False, steps_this_run=7038.0, varuna=True, stage_to_rank_map='0,2,4,6,8,10,12,14,16,18,20,22,24;1,3,5,7,9,11,13,15,17,19,21,23,25;', chunk_size=8, batch_size=78, rank=0, profiling=False, n_gpu=1)"] 
dry run time 0.2074131965637207
SHARED WEIGHTS ARE
[(0, 1)]
this rank  0 is part of pipeline replica  0
10 chunks
Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.

Defaults for this optimization level are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
DLL 2022-11-26 05:32:17.851857 - PARAMETER SEED : 12439 
DLL 2022-11-26 05:32:17.852006 - PARAMETER train_start : True 
DLL 2022-11-26 05:32:17.852084 - PARAMETER batch_size_per_gpu : 78 
DLL 2022-11-26 05:32:17.852164 - PARAMETER learning_rate : 0.006 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  524288.0
[2022-11-26 05:32:21.978320] Finished iteration 0, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4082.053
DLL 2022-11-26 05:32:21.989434 - Training Epoch: 0 Training Iteration: 1  average_loss : 11.24765682220459  step_loss : 11.24765682220459  learning_rate : 2.9986455118223097e-06 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  262144.0
[2022-11-26 05:32:24.370031] Finished iteration 1, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2391.572
DLL 2022-11-26 05:32:24.375361 - Training Epoch: 0 Training Iteration: 2  average_loss : nan  step_loss : nan  learning_rate : 5.9972910236446195e-06 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  131072.0
[2022-11-26 05:32:26.730458] Finished iteration 2, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2360.333
DLL 2022-11-26 05:32:26.735354 - Training Epoch: 0 Training Iteration: 3  average_loss : nan  step_loss : nan  learning_rate : 8.995936535466931e-06 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  65536.0
[2022-11-26 05:32:29.104982] Finished iteration 3, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2374.483
DLL 2022-11-26 05:32:29.109706 - Training Epoch: 0 Training Iteration: 4  average_loss : nan  step_loss : nan  learning_rate : 1.1994582047289239e-05 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  32768.0
[2022-11-26 05:32:31.505373] Finished iteration 4, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2400.360
DLL 2022-11-26 05:32:31.509910 - Training Epoch: 0 Training Iteration: 5  average_loss : nan  step_loss : nan  learning_rate : 1.499322755911155e-05 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  16384.0
[2022-11-26 05:32:34.276254] Finished iteration 5, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2770.880
DLL 2022-11-26 05:32:34.281362 - Training Epoch: 0 Training Iteration: 6  average_loss : nan  step_loss : nan  learning_rate : 1.7991873070933862e-05 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  8192.0
[2022-11-26 05:32:36.728967] Finished iteration 6, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2452.662
DLL 2022-11-26 05:32:36.733842 - Training Epoch: 0 Training Iteration: 7  average_loss : nan  step_loss : nan  learning_rate : 2.099051858275617e-05 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  4096.0
[2022-11-26 05:32:39.169760] Finished iteration 7, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2440.783
DLL 2022-11-26 05:32:39.175387 - Training Epoch: 0 Training Iteration: 8  average_loss : nan  step_loss : nan  learning_rate : 2.3989164094578478e-05 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  2048.0
[2022-11-26 05:32:41.688117] Finished iteration 8, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2518.309
DLL 2022-11-26 05:32:41.692842 - Training Epoch: 0 Training Iteration: 9  average_loss : nan  step_loss : nan  learning_rate : 2.698780960640079e-05 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1024.0
[2022-11-26 05:32:44.559240] Finished iteration 9, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2871.084
DLL 2022-11-26 05:32:44.564311 - Training Epoch: 0 Training Iteration: 10  average_loss : nan  step_loss : nan  learning_rate : 2.99864551182231e-05 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  512.0
[2022-11-26 05:32:46.903869] Finished iteration 10, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2344.616
DLL 2022-11-26 05:32:46.908993 - Training Epoch: 0 Training Iteration: 11  average_loss : nan  step_loss : nan  learning_rate : 3.298510063004541e-05 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  256.0
[2022-11-26 05:32:49.297196] Finished iteration 11, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2393.296
DLL 2022-11-26 05:32:49.302150 - Training Epoch: 0 Training Iteration: 12  average_loss : nan  step_loss : nan  learning_rate : 3.5983746141867724e-05 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  128.0
[2022-11-26 05:32:51.664232] Finished iteration 12, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2367.003
DLL 2022-11-26 05:32:51.669253 - Training Epoch: 0 Training Iteration: 13  average_loss : nan  step_loss : nan  learning_rate : 3.898239165369003e-05 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  64.0
[2022-11-26 05:32:54.069040] Finished iteration 13, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2404.781
DLL 2022-11-26 05:32:54.074163 - Training Epoch: 0 Training Iteration: 14  average_loss : nan  step_loss : nan  learning_rate : 4.198103716551234e-05 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  32.0
[2022-11-26 05:32:56.523422] Finished iteration 14, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2454.342
DLL 2022-11-26 05:32:56.528323 - Training Epoch: 0 Training Iteration: 15  average_loss : nan  step_loss : nan  learning_rate : 4.497968267733465e-05 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  16.0
[2022-11-26 05:32:58.923873] Finished iteration 15, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2400.436
DLL 2022-11-26 05:32:58.928654 - Training Epoch: 0 Training Iteration: 16  average_loss : nan  step_loss : nan  learning_rate : 4.7978328189156956e-05 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  8.0
[2022-11-26 05:33:01.404767] Finished iteration 16, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2480.865
DLL 2022-11-26 05:33:01.409717 - Training Epoch: 0 Training Iteration: 17  average_loss : nan  step_loss : nan  learning_rate : 5.097697370097927e-05 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  4.0
[2022-11-26 05:33:03.794772] Finished iteration 17, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2389.974
DLL 2022-11-26 05:33:03.799667 - Training Epoch: 0 Training Iteration: 18  average_loss : nan  step_loss : nan  learning_rate : 5.397561921280158e-05 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  2.0
[2022-11-26 05:33:06.252616] Finished iteration 18, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2457.820
DLL 2022-11-26 05:33:06.257453 - Training Epoch: 0 Training Iteration: 19  average_loss : nan  step_loss : nan  learning_rate : 5.697426472462389e-05 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:33:08.696775] Finished iteration 19, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2444.119
DLL 2022-11-26 05:33:08.701633 - Training Epoch: 0 Training Iteration: 20  average_loss : nan  step_loss : nan  learning_rate : 5.99729102364462e-05 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:33:11.096683] Finished iteration 20, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2399.886
DLL 2022-11-26 05:33:11.133745 - Training Epoch: 0 Training Iteration: 21  average_loss : nan  step_loss : nan  learning_rate : 6.297155574826851e-05 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:33:13.548264] Finished iteration 21, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2451.556
DLL 2022-11-26 05:33:13.553111 - Training Epoch: 0 Training Iteration: 22  average_loss : nan  step_loss : nan  learning_rate : 6.597020126009082e-05 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:33:15.950101] Finished iteration 22, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2401.854
DLL 2022-11-26 05:33:15.955081 - Training Epoch: 0 Training Iteration: 23  average_loss : nan  step_loss : nan  learning_rate : 6.896884677191313e-05 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:33:18.337770] Finished iteration 23, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2387.605
DLL 2022-11-26 05:33:18.342639 - Training Epoch: 0 Training Iteration: 24  average_loss : nan  step_loss : nan  learning_rate : 7.196749228373545e-05 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:33:20.713714] Finished iteration 24, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2375.891
DLL 2022-11-26 05:33:20.718434 - Training Epoch: 0 Training Iteration: 25  average_loss : nan  step_loss : nan  learning_rate : 7.496613779555775e-05 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:33:23.171885] Finished iteration 25, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2458.157
DLL 2022-11-26 05:33:23.176792 - Training Epoch: 0 Training Iteration: 26  average_loss : nan  step_loss : nan  learning_rate : 7.796478330738006e-05 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:33:25.533499] Finished iteration 26, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2361.580
DLL 2022-11-26 05:33:25.538317 - Training Epoch: 0 Training Iteration: 27  average_loss : nan  step_loss : nan  learning_rate : 8.096342881920237e-05 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:33:27.957998] Finished iteration 27, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2424.471
DLL 2022-11-26 05:33:27.962852 - Training Epoch: 0 Training Iteration: 28  average_loss : nan  step_loss : nan  learning_rate : 8.396207433102469e-05 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:33:30.351561] Finished iteration 28, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2393.534
DLL 2022-11-26 05:33:30.356374 - Training Epoch: 0 Training Iteration: 29  average_loss : nan  step_loss : nan  learning_rate : 8.696071984284699e-05 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:33:32.755078] Finished iteration 29, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2403.472
DLL 2022-11-26 05:33:32.759879 - Training Epoch: 0 Training Iteration: 30  average_loss : nan  step_loss : nan  learning_rate : 8.99593653546693e-05 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:33:35.164442] Finished iteration 30, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2409.352
DLL 2022-11-26 05:33:35.169700 - Training Epoch: 0 Training Iteration: 31  average_loss : nan  step_loss : nan  learning_rate : 9.29580108664916e-05 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:33:37.589889] Finished iteration 31, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2425.430
DLL 2022-11-26 05:33:37.595281 - Training Epoch: 0 Training Iteration: 32  average_loss : nan  step_loss : nan  learning_rate : 9.595665637831391e-05 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:33:40.010531] Finished iteration 32, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2420.593
DLL 2022-11-26 05:33:40.015353 - Training Epoch: 0 Training Iteration: 33  average_loss : nan  step_loss : nan  learning_rate : 9.895530189013622e-05 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:33:42.343147] Finished iteration 33, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2332.588
DLL 2022-11-26 05:33:42.347896 - Training Epoch: 0 Training Iteration: 34  average_loss : nan  step_loss : nan  learning_rate : 0.00010195394740195854 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:33:44.784379] Finished iteration 34, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2441.197
DLL 2022-11-26 05:33:44.789193 - Training Epoch: 0 Training Iteration: 35  average_loss : nan  step_loss : nan  learning_rate : 0.00010495259291378085 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:33:47.174889] Finished iteration 35, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2390.484
DLL 2022-11-26 05:33:47.179746 - Training Epoch: 0 Training Iteration: 36  average_loss : nan  step_loss : nan  learning_rate : 0.00010795123842560316 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:33:49.648311] Finished iteration 36, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2473.397
DLL 2022-11-26 05:33:49.653065 - Training Epoch: 0 Training Iteration: 37  average_loss : nan  step_loss : nan  learning_rate : 0.00011094988393742548 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:33:52.087124] Finished iteration 37, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2438.789
DLL 2022-11-26 05:33:52.092327 - Training Epoch: 0 Training Iteration: 38  average_loss : nan  step_loss : nan  learning_rate : 0.00011394852944924778 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:33:54.439890] Finished iteration 38, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2352.733
DLL 2022-11-26 05:33:54.444781 - Training Epoch: 0 Training Iteration: 39  average_loss : nan  step_loss : nan  learning_rate : 0.00011694717496107008 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:33:56.861985] Finished iteration 39, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2422.090
DLL 2022-11-26 05:33:56.867097 - Training Epoch: 0 Training Iteration: 40  average_loss : nan  step_loss : nan  learning_rate : 0.0001199458204728924 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:33:59.300789] Finished iteration 40, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2438.779
DLL 2022-11-26 05:33:59.305748 - Training Epoch: 0 Training Iteration: 41  average_loss : nan  step_loss : nan  learning_rate : 0.0001229444659847147 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:34:01.733409] Finished iteration 41, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2432.558
DLL 2022-11-26 05:34:01.738301 - Training Epoch: 0 Training Iteration: 42  average_loss : nan  step_loss : nan  learning_rate : 0.00012594311149653702 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:34:04.106696] Finished iteration 42, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2373.274
DLL 2022-11-26 05:34:04.111617 - Training Epoch: 0 Training Iteration: 43  average_loss : nan  step_loss : nan  learning_rate : 0.00012894175700835933 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:34:06.469466] Finished iteration 43, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2362.724
DLL 2022-11-26 05:34:06.474382 - Training Epoch: 0 Training Iteration: 44  average_loss : nan  step_loss : nan  learning_rate : 0.00013194040252018164 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:34:08.835887] Finished iteration 44, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2366.395
DLL 2022-11-26 05:34:08.841071 - Training Epoch: 0 Training Iteration: 45  average_loss : nan  step_loss : nan  learning_rate : 0.00013493904803200396 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:34:11.242975] Finished iteration 45, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2407.058
DLL 2022-11-26 05:34:11.247836 - Training Epoch: 0 Training Iteration: 46  average_loss : nan  step_loss : nan  learning_rate : 0.00013793769354382627 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:34:13.706805] Finished iteration 46, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2463.796
DLL 2022-11-26 05:34:13.711592 - Training Epoch: 0 Training Iteration: 47  average_loss : nan  step_loss : nan  learning_rate : 0.00014093633905564855 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:34:16.066849] Finished iteration 47, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2360.014
DLL 2022-11-26 05:34:16.071651 - Training Epoch: 0 Training Iteration: 48  average_loss : nan  step_loss : nan  learning_rate : 0.0001439349845674709 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:34:18.451399] Finished iteration 48, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2384.521
DLL 2022-11-26 05:34:18.456483 - Training Epoch: 0 Training Iteration: 49  average_loss : nan  step_loss : nan  learning_rate : 0.00014693363007929318 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:34:20.810902] Finished iteration 49, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2359.479
DLL 2022-11-26 05:34:20.816007 - Training Epoch: 0 Training Iteration: 50  average_loss : nan  step_loss : nan  learning_rate : 0.0001499322755911155 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:34:23.182668] Finished iteration 50, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2371.752
DLL 2022-11-26 05:34:23.187691 - Training Epoch: 0 Training Iteration: 51  average_loss : nan  step_loss : nan  learning_rate : 0.0001529309211029378 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:34:25.553124] Finished iteration 51, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2370.434
DLL 2022-11-26 05:34:25.558091 - Training Epoch: 0 Training Iteration: 52  average_loss : nan  step_loss : nan  learning_rate : 0.00015592956661476012 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:34:27.904432] Finished iteration 52, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2351.249
DLL 2022-11-26 05:34:27.909334 - Training Epoch: 0 Training Iteration: 53  average_loss : nan  step_loss : nan  learning_rate : 0.0001589282121265824 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:34:30.275866] Finished iteration 53, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2371.407
DLL 2022-11-26 05:34:30.280738 - Training Epoch: 0 Training Iteration: 54  average_loss : nan  step_loss : nan  learning_rate : 0.00016192685763840475 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:34:32.668186] Finished iteration 54, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2392.276
DLL 2022-11-26 05:34:32.673077 - Training Epoch: 0 Training Iteration: 55  average_loss : nan  step_loss : nan  learning_rate : 0.00016492550315022706 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:34:35.004678] Finished iteration 55, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2336.513
DLL 2022-11-26 05:34:35.009681 - Training Epoch: 0 Training Iteration: 56  average_loss : nan  step_loss : nan  learning_rate : 0.00016792414866204937 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:34:37.362514] Finished iteration 56, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2357.802
DLL 2022-11-26 05:34:37.367595 - Training Epoch: 0 Training Iteration: 57  average_loss : nan  step_loss : nan  learning_rate : 0.00017092279417387166 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:34:39.748666] Finished iteration 57, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2386.099
DLL 2022-11-26 05:34:39.753569 - Training Epoch: 0 Training Iteration: 58  average_loss : nan  step_loss : nan  learning_rate : 0.00017392143968569397 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:34:42.150069] Finished iteration 58, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2401.405
DLL 2022-11-26 05:34:42.155143 - Training Epoch: 0 Training Iteration: 59  average_loss : nan  step_loss : nan  learning_rate : 0.0001769200851975163 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:34:44.526676] Finished iteration 59, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2376.560
DLL 2022-11-26 05:34:44.532017 - Training Epoch: 0 Training Iteration: 60  average_loss : nan  step_loss : nan  learning_rate : 0.0001799187307093386 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:34:46.946613] Finished iteration 60, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2419.910
DLL 2022-11-26 05:34:46.951458 - Training Epoch: 0 Training Iteration: 61  average_loss : nan  step_loss : nan  learning_rate : 0.00018291737622116094 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:34:49.357819] Finished iteration 61, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2411.166
DLL 2022-11-26 05:34:49.362667 - Training Epoch: 0 Training Iteration: 62  average_loss : nan  step_loss : nan  learning_rate : 0.0001859160217329832 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:34:51.754697] Finished iteration 62, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2396.857
DLL 2022-11-26 05:34:51.759518 - Training Epoch: 0 Training Iteration: 63  average_loss : nan  step_loss : nan  learning_rate : 0.00018891466724480554 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:34:54.167004] Finished iteration 63, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2412.250
DLL 2022-11-26 05:34:54.171885 - Training Epoch: 0 Training Iteration: 64  average_loss : nan  step_loss : nan  learning_rate : 0.00019191331275662782 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:34:56.534492] Finished iteration 64, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2367.446
DLL 2022-11-26 05:34:56.539287 - Training Epoch: 0 Training Iteration: 65  average_loss : nan  step_loss : nan  learning_rate : 0.00019491195826845016 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:34:58.947889] Finished iteration 65, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2413.381
DLL 2022-11-26 05:34:58.952635 - Training Epoch: 0 Training Iteration: 66  average_loss : nan  step_loss : nan  learning_rate : 0.00019791060378027245 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:35:01.287682] Finished iteration 66, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2339.767
DLL 2022-11-26 05:35:01.292773 - Training Epoch: 0 Training Iteration: 67  average_loss : nan  step_loss : nan  learning_rate : 0.00020090924929209476 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:35:03.676340] Finished iteration 67, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2388.623
DLL 2022-11-26 05:35:03.681467 - Training Epoch: 0 Training Iteration: 68  average_loss : nan  step_loss : nan  learning_rate : 0.00020390789480391708 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:35:06.082483] Finished iteration 68, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2406.155
DLL 2022-11-26 05:35:06.087913 - Training Epoch: 0 Training Iteration: 69  average_loss : nan  step_loss : nan  learning_rate : 0.0002069065403157394 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:35:08.410701] Finished iteration 69, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2328.127
DLL 2022-11-26 05:35:08.415502 - Training Epoch: 0 Training Iteration: 70  average_loss : nan  step_loss : nan  learning_rate : 0.0002099051858275617 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:35:10.809090] Finished iteration 70, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2398.369
DLL 2022-11-26 05:35:10.814191 - Training Epoch: 0 Training Iteration: 71  average_loss : nan  step_loss : nan  learning_rate : 0.00021290383133938402 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:35:13.202434] Finished iteration 71, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2393.313
DLL 2022-11-26 05:35:13.207090 - Training Epoch: 0 Training Iteration: 72  average_loss : nan  step_loss : nan  learning_rate : 0.00021590247685120633 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:35:15.564492] Finished iteration 72, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2362.037
DLL 2022-11-26 05:35:15.569242 - Training Epoch: 0 Training Iteration: 73  average_loss : nan  step_loss : nan  learning_rate : 0.00021890112236302861 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:35:17.904894] Finished iteration 73, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2340.397
DLL 2022-11-26 05:35:17.909826 - Training Epoch: 0 Training Iteration: 74  average_loss : nan  step_loss : nan  learning_rate : 0.00022189976787485096 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:35:20.249437] Finished iteration 74, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2344.470
DLL 2022-11-26 05:35:20.254745 - Training Epoch: 0 Training Iteration: 75  average_loss : nan  step_loss : nan  learning_rate : 0.00022489841338667327 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:35:22.607396] Finished iteration 75, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2357.937
DLL 2022-11-26 05:35:22.612549 - Training Epoch: 0 Training Iteration: 76  average_loss : nan  step_loss : nan  learning_rate : 0.00022789705889849555 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:35:24.980361] Finished iteration 76, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2372.932
DLL 2022-11-26 05:35:24.984947 - Training Epoch: 0 Training Iteration: 77  average_loss : nan  step_loss : nan  learning_rate : 0.00023089570441031787 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:35:27.396969] Finished iteration 77, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2416.587
DLL 2022-11-26 05:35:27.402026 - Training Epoch: 0 Training Iteration: 78  average_loss : nan  step_loss : nan  learning_rate : 0.00023389434992214015 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:35:29.723089] Finished iteration 78, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2326.088
DLL 2022-11-26 05:35:29.727922 - Training Epoch: 0 Training Iteration: 79  average_loss : nan  step_loss : nan  learning_rate : 0.00023689299543396247 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:35:32.158832] Finished iteration 79, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2435.704
DLL 2022-11-26 05:35:32.163560 - Training Epoch: 0 Training Iteration: 80  average_loss : nan  step_loss : nan  learning_rate : 0.0002398916409457848 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:35:34.609238] Finished iteration 80, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2450.387
DLL 2022-11-26 05:35:34.614397 - Training Epoch: 0 Training Iteration: 81  average_loss : nan  step_loss : nan  learning_rate : 0.00024289028645760712 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:35:37.019119] Finished iteration 81, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2409.855
DLL 2022-11-26 05:35:37.024193 - Training Epoch: 0 Training Iteration: 82  average_loss : nan  step_loss : nan  learning_rate : 0.0002458889319694294 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:35:39.374489] Finished iteration 82, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2355.342
DLL 2022-11-26 05:35:39.379528 - Training Epoch: 0 Training Iteration: 83  average_loss : nan  step_loss : nan  learning_rate : 0.0002488875774812517 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:35:42.411028] Finished iteration 83, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3036.512
DLL 2022-11-26 05:35:42.415926 - Training Epoch: 0 Training Iteration: 84  average_loss : nan  step_loss : nan  learning_rate : 0.00025188622299307403 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:35:44.904355] Finished iteration 84, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2493.287
DLL 2022-11-26 05:35:44.909393 - Training Epoch: 0 Training Iteration: 85  average_loss : nan  step_loss : nan  learning_rate : 0.00025488486850489635 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:35:47.366244] Finished iteration 85, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2461.924
DLL 2022-11-26 05:35:47.371413 - Training Epoch: 0 Training Iteration: 86  average_loss : nan  step_loss : nan  learning_rate : 0.00025788351401671866 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:35:50.656009] Finished iteration 86, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3289.686
DLL 2022-11-26 05:35:50.660899 - Training Epoch: 0 Training Iteration: 87  average_loss : nan  step_loss : nan  learning_rate : 0.00026088215952854097 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:35:53.023131] Finished iteration 87, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2367.123
DLL 2022-11-26 05:35:53.028245 - Training Epoch: 0 Training Iteration: 88  average_loss : nan  step_loss : nan  learning_rate : 0.0002638808050403633 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:35:55.364413] Finished iteration 88, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2341.231
DLL 2022-11-26 05:35:55.369668 - Training Epoch: 0 Training Iteration: 89  average_loss : nan  step_loss : nan  learning_rate : 0.0002668794505521856 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:35:57.773403] Finished iteration 89, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2408.936
DLL 2022-11-26 05:35:57.778251 - Training Epoch: 0 Training Iteration: 90  average_loss : nan  step_loss : nan  learning_rate : 0.0002698780960640079 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:36:00.119853] Finished iteration 90, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2346.434
DLL 2022-11-26 05:36:00.124910 - Training Epoch: 0 Training Iteration: 91  average_loss : nan  step_loss : nan  learning_rate : 0.00027287674157583017 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:36:02.519889] Finished iteration 91, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2400.023
DLL 2022-11-26 05:36:02.524876 - Training Epoch: 0 Training Iteration: 92  average_loss : nan  step_loss : nan  learning_rate : 0.00027587538708765254 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:36:04.883352] Finished iteration 92, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2363.441
DLL 2022-11-26 05:36:04.888393 - Training Epoch: 0 Training Iteration: 93  average_loss : nan  step_loss : nan  learning_rate : 0.00027887403259947485 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:36:07.317350] Finished iteration 93, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2433.944
DLL 2022-11-26 05:36:07.322114 - Training Epoch: 0 Training Iteration: 94  average_loss : nan  step_loss : nan  learning_rate : 0.0002818726781112971 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:36:09.685667] Finished iteration 94, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2368.291
DLL 2022-11-26 05:36:09.690850 - Training Epoch: 0 Training Iteration: 95  average_loss : nan  step_loss : nan  learning_rate : 0.0002848713236231194 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:36:12.042876] Finished iteration 95, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2357.176
DLL 2022-11-26 05:36:12.047675 - Training Epoch: 0 Training Iteration: 96  average_loss : nan  step_loss : nan  learning_rate : 0.0002878699691349418 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:36:14.430614] Finished iteration 96, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2387.710
DLL 2022-11-26 05:36:14.435240 - Training Epoch: 0 Training Iteration: 97  average_loss : nan  step_loss : nan  learning_rate : 0.00029086861464676405 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:36:16.772856] Finished iteration 97, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2342.211
DLL 2022-11-26 05:36:16.777931 - Training Epoch: 0 Training Iteration: 98  average_loss : nan  step_loss : nan  learning_rate : 0.00029386726015858636 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:36:19.182973] Finished iteration 98, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2410.106
DLL 2022-11-26 05:36:19.187931 - Training Epoch: 0 Training Iteration: 99  average_loss : nan  step_loss : nan  learning_rate : 0.0002968659056704087 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:36:21.543346] Finished iteration 99, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2360.313
DLL 2022-11-26 05:36:21.548119 - Training Epoch: 0 Training Iteration: 100  average_loss : nan  step_loss : nan  learning_rate : 0.000299864551182231 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:36:23.903423] Finished iteration 100, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2360.059
DLL 2022-11-26 05:36:23.908148 - Training Epoch: 0 Training Iteration: 101  average_loss : nan  step_loss : nan  learning_rate : 0.0003028631966940533 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:36:26.268410] Finished iteration 101, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2364.959
DLL 2022-11-26 05:36:26.273530 - Training Epoch: 0 Training Iteration: 102  average_loss : nan  step_loss : nan  learning_rate : 0.0003058618422058756 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:36:28.646956] Finished iteration 102, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2378.527
DLL 2022-11-26 05:36:28.651782 - Training Epoch: 0 Training Iteration: 103  average_loss : nan  step_loss : nan  learning_rate : 0.000308860487717698 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:36:31.066448] Finished iteration 103, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2419.449
DLL 2022-11-26 05:36:31.071303 - Training Epoch: 0 Training Iteration: 104  average_loss : nan  step_loss : nan  learning_rate : 0.00031185913322952024 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:36:33.480403] Finished iteration 104, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2413.925
DLL 2022-11-26 05:36:33.485277 - Training Epoch: 0 Training Iteration: 105  average_loss : nan  step_loss : nan  learning_rate : 0.0003148577787413425 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:36:35.866198] Finished iteration 105, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2385.798
DLL 2022-11-26 05:36:35.870992 - Training Epoch: 0 Training Iteration: 106  average_loss : nan  step_loss : nan  learning_rate : 0.0003178564242531648 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:36:38.298139] Finished iteration 106, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2431.935
DLL 2022-11-26 05:36:38.303007 - Training Epoch: 0 Training Iteration: 107  average_loss : nan  step_loss : nan  learning_rate : 0.0003208550697649872 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:36:40.698588] Finished iteration 107, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2400.386
DLL 2022-11-26 05:36:40.703991 - Training Epoch: 0 Training Iteration: 108  average_loss : nan  step_loss : nan  learning_rate : 0.0003238537152768095 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:36:43.081351] Finished iteration 108, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2382.740
DLL 2022-11-26 05:36:43.086210 - Training Epoch: 0 Training Iteration: 109  average_loss : nan  step_loss : nan  learning_rate : 0.0003268523607886318 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:36:45.494460] Finished iteration 109, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2413.043
DLL 2022-11-26 05:36:45.499582 - Training Epoch: 0 Training Iteration: 110  average_loss : nan  step_loss : nan  learning_rate : 0.0003298510063004541 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:36:47.900877] Finished iteration 110, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2406.401
DLL 2022-11-26 05:36:47.905557 - Training Epoch: 0 Training Iteration: 111  average_loss : nan  step_loss : nan  learning_rate : 0.00033284965181227643 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:36:50.232911] Finished iteration 111, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2332.008
DLL 2022-11-26 05:36:50.238246 - Training Epoch: 0 Training Iteration: 112  average_loss : nan  step_loss : nan  learning_rate : 0.00033584829732409875 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:36:52.649152] Finished iteration 112, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2416.209
DLL 2022-11-26 05:36:52.654416 - Training Epoch: 0 Training Iteration: 113  average_loss : nan  step_loss : nan  learning_rate : 0.000338846942835921 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:36:55.046212] Finished iteration 113, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2397.063
DLL 2022-11-26 05:36:55.051468 - Training Epoch: 0 Training Iteration: 114  average_loss : nan  step_loss : nan  learning_rate : 0.0003418455883477433 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:36:57.436920] Finished iteration 114, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2390.636
DLL 2022-11-26 05:36:57.442080 - Training Epoch: 0 Training Iteration: 115  average_loss : nan  step_loss : nan  learning_rate : 0.0003448442338595657 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:36:59.856185] Finished iteration 115, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2419.250
DLL 2022-11-26 05:36:59.861230 - Training Epoch: 0 Training Iteration: 116  average_loss : nan  step_loss : nan  learning_rate : 0.00034784287937138794 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:37:02.287520] Finished iteration 116, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2431.308
DLL 2022-11-26 05:37:02.292328 - Training Epoch: 0 Training Iteration: 117  average_loss : nan  step_loss : nan  learning_rate : 0.00035084152488321026 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:37:04.768908] Finished iteration 117, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2481.352
DLL 2022-11-26 05:37:04.773878 - Training Epoch: 0 Training Iteration: 118  average_loss : nan  step_loss : nan  learning_rate : 0.0003538401703950326 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:37:07.118525] Finished iteration 118, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2349.591
DLL 2022-11-26 05:37:07.123806 - Training Epoch: 0 Training Iteration: 119  average_loss : nan  step_loss : nan  learning_rate : 0.0003568388159068549 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:37:09.498413] Finished iteration 119, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2379.864
DLL 2022-11-26 05:37:09.503323 - Training Epoch: 0 Training Iteration: 120  average_loss : nan  step_loss : nan  learning_rate : 0.0003598374614186772 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:37:11.977880] Finished iteration 120, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2479.432
DLL 2022-11-26 05:37:11.983189 - Training Epoch: 0 Training Iteration: 121  average_loss : nan  step_loss : nan  learning_rate : 0.00036283610693049946 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:37:14.334307] Finished iteration 121, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2356.414
DLL 2022-11-26 05:37:14.339405 - Training Epoch: 0 Training Iteration: 122  average_loss : nan  step_loss : nan  learning_rate : 0.0003658347524423219 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:37:16.742290] Finished iteration 122, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2407.939
DLL 2022-11-26 05:37:16.747112 - Training Epoch: 0 Training Iteration: 123  average_loss : nan  step_loss : nan  learning_rate : 0.00036883339795414414 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:37:19.059609] Finished iteration 123, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2317.297
DLL 2022-11-26 05:37:19.064577 - Training Epoch: 0 Training Iteration: 124  average_loss : nan  step_loss : nan  learning_rate : 0.0003718320434659664 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:37:21.410567] Finished iteration 124, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2350.944
DLL 2022-11-26 05:37:21.415659 - Training Epoch: 0 Training Iteration: 125  average_loss : nan  step_loss : nan  learning_rate : 0.00037483068897778876 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:37:23.779529] Finished iteration 125, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2368.912
DLL 2022-11-26 05:37:23.784345 - Training Epoch: 0 Training Iteration: 126  average_loss : nan  step_loss : nan  learning_rate : 0.0003778293344896111 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:37:26.151080] Finished iteration 126, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2371.518
DLL 2022-11-26 05:37:26.155878 - Training Epoch: 0 Training Iteration: 127  average_loss : nan  step_loss : nan  learning_rate : 0.0003808279800014334 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:37:28.560814] Finished iteration 127, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2409.739
DLL 2022-11-26 05:37:28.565874 - Training Epoch: 0 Training Iteration: 128  average_loss : nan  step_loss : nan  learning_rate : 0.00038382662551325565 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:37:30.945289] Finished iteration 128, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2384.430
DLL 2022-11-26 05:37:30.950386 - Training Epoch: 0 Training Iteration: 129  average_loss : nan  step_loss : nan  learning_rate : 0.00038682527102507796 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:37:33.340817] Finished iteration 129, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2395.470
DLL 2022-11-26 05:37:33.345517 - Training Epoch: 0 Training Iteration: 130  average_loss : nan  step_loss : nan  learning_rate : 0.00038982391653690033 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:37:35.917020] Finished iteration 130, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2576.181
DLL 2022-11-26 05:37:35.922202 - Training Epoch: 0 Training Iteration: 131  average_loss : nan  step_loss : nan  learning_rate : 0.0003928225620487226 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:37:38.233337] Finished iteration 131, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2316.316
DLL 2022-11-26 05:37:38.238398 - Training Epoch: 0 Training Iteration: 132  average_loss : nan  step_loss : nan  learning_rate : 0.0003958212075605449 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:37:40.576202] Finished iteration 132, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2342.822
DLL 2022-11-26 05:37:40.581478 - Training Epoch: 0 Training Iteration: 133  average_loss : nan  step_loss : nan  learning_rate : 0.00039881985307236727 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:37:43.033168] Finished iteration 133, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2456.951
DLL 2022-11-26 05:37:43.038456 - Training Epoch: 0 Training Iteration: 134  average_loss : nan  step_loss : nan  learning_rate : 0.0004018184985841895 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:37:45.541299] Finished iteration 134, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2508.093
DLL 2022-11-26 05:37:45.546593 - Training Epoch: 0 Training Iteration: 135  average_loss : nan  step_loss : nan  learning_rate : 0.00040481714409601184 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:37:47.925392] Finished iteration 135, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2384.056
DLL 2022-11-26 05:37:47.930307 - Training Epoch: 0 Training Iteration: 136  average_loss : nan  step_loss : nan  learning_rate : 0.00040781578960783415 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:37:50.280109] Finished iteration 136, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2354.683
DLL 2022-11-26 05:37:50.285140 - Training Epoch: 0 Training Iteration: 137  average_loss : nan  step_loss : nan  learning_rate : 0.0004108144351196565 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:37:52.707657] Finished iteration 137, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2427.532
DLL 2022-11-26 05:37:52.712600 - Training Epoch: 0 Training Iteration: 138  average_loss : nan  step_loss : nan  learning_rate : 0.0004138130806314788 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:37:55.169714] Finished iteration 138, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2462.014
DLL 2022-11-26 05:37:55.174442 - Training Epoch: 0 Training Iteration: 139  average_loss : nan  step_loss : nan  learning_rate : 0.00041681172614330104 
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 0 signal handler called with signal 10
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:37:57.485660] Finished iteration 139, CKPT_AND_STOP: True, flag: tensor([1], dtype=torch.int32), speed: 2315.996
DLL 2022-11-26 05:37:57.493256 - Training Epoch: 0 Training Iteration: 140  average_loss : nan  step_loss : nan  learning_rate : 0.0004198103716551234 
2022-11-26 05:37:57.493604 Begin to save checkpont to s3://spot-checkpoints/bert and exit
DLL 2022-11-26 05:37:57.493651 - PARAMETER checkpoint_step : 140 
Opt ckpt time 10.27311396598816
Process done with return code 0
Parent process ID: 84983 node: 172.31.28.108
24 cutpoints
Stages 1
Micro-bs 8 Max mem: 14622140211.200005
Predicted microbatch size for 1: 8
comm size 0
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 1 5 0 2493369.62890625 0
End of simulation:  Mini-batch time (usec) = 4144382
Min send: 10000000, max send 0
Min long send: 10000000, max long send 0
Min fwd: 10000000, max fwd 0; min bwd 10000000, max bwd 0
Min long fwd: 141043, max long fwd 144458; min long bwd 184920, max long bwd 191040
Time taken by simulation: 46 microseconds

Stages 2
Micro-bs 8 Max mem: 7660942131.200001
Predicted microbatch size for 2: 8
comm size 4194304
WARNING: no send time found, 2 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 2 10 0 892117.1264648438 248719.58977934244
End of simulation:  Mini-batch time (usec) = 3456563
Min send: 10000000, max send 0
Min long send: 249051, max long send 264414
Min fwd: 78473, max fwd 86627; min bwd 87174, max bwd 96382
Min long fwd: 58631, max long fwd 64048; min long bwd 93560, max long bwd 98662
Time taken by simulation: 196 microseconds

Stages 3
Micro-bs 8 Max mem: 5497876480.0
Predicted microbatch size for 3: 8
comm size 4194304
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 15 0 476084.3811035156 248719.58977934244
End of simulation:  Mini-batch time (usec) = 3889823
Min send: 10000000, max send 0
Min long send: 248907, max long send 271185
Min fwd: 34426, max fwd 67951; min bwd 54355, max bwd 65681
Min long fwd: 38932, max long fwd 44034; min long bwd 64405, max long bwd 71935
Time taken by simulation: 512 microseconds

Stages 4
Micro-bs 8 Max mem: 4406266675.2
Predicted microbatch size for 4: 8
comm size 4194304
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 19 0 352272.7355957031 248719.58977934244
End of simulation:  Mini-batch time (usec) = 4275253
Min send: 10000000, max send 0
Min long send: 248773, max long send 273424
Min fwd: 22410, max fwd 61283; min bwd 39748, max bwd 51303
Min long fwd: 29385, max long fwd 37648; min long bwd 47928, max long bwd 54735
Time taken by simulation: 865 microseconds

Stages 6
Micro-bs 8 Max mem: 3314656870.4
Predicted microbatch size for 6: 8
comm size 4194304
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 32 0 233226.318359375 248719.58977934244
End of simulation:  Mini-batch time (usec) = 6680183
Min send: 10000000, max send 0
Min long send: 248719, max long send 275881
Min fwd: 10965, max fwd 44004; min bwd 19992, max bwd 36467
Min long fwd: 22115, max long fwd 30954; min long bwd 32578, max long bwd 40795
Time taken by simulation: 2334 microseconds

Stages 8
Micro-bs 8 Max mem: 2758774988.8
Predicted microbatch size for 8: 8
comm size 4194304
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 43 0 178155.74645996094 248719.58977934244
End of simulation:  Mini-batch time (usec) = 9019309
Min send: 10000000, max send 0
Min long send: 248735, max long send 276940
Min fwd: 5776, max fwd 41014; min bwd 16548, max bwd 29492
Min long fwd: 17309, max long fwd 25772; min long bwd 25282, max long bwd 32088
Time taken by simulation: 4563 microseconds

Stages 12
Micro-bs 8 Max mem: 2202893107.2
Predicted microbatch size for 12: 8
comm size 4194304
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 64 0 117116.2109375 248719.58977934244
End of simulation:  Mini-batch time (usec) = 13687683
Min send: 10000000, max send 0
Min long send: 248720, max long send 280797
Min fwd: 141, max fwd 25024; min bwd 6433, max bwd 23373
Min long fwd: 7201, max long fwd 18161; min long bwd 16833, max long bwd 28389
Time taken by simulation: 10778 microseconds

{1: 4.144382, 2: 3.456563, 3: 3.889823, 4: 4.275253, 6: 6.680183, 8: 9.019309, 12: 13.687683}
{1: 8, 2: 8, 3: 8, 4: 8, 6: 8, 8: 8, 12: 8}
best config is: 2 8
expected time is 3.456563
14 per stage
28 servers!
Config:
ranks: range(0, 1)
train batch size: 1024
partitions: 2
chunk_size: 8
data depth: 14
stage to rank map: 0,2,4,6,8,10,12,14,16,18,20,22,24,26;1,3,5,7,9,11,13,15,17,19,21,23,25,27;
World size is 28
/opt/conda/envs/varuna/bin/python -u /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --rank=0 --chunk_size=8 --local_rank=0 --stage_to_rank_map=0,2,4,6,8,10,12,14,16,18,20,22,24,26;1,3,5,7,9,11,13,15,17,19,21,23,25,27; --batch-size=73 --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna --resume_step 140
device: cuda:0 n_gpu: 1, distributed training: True, 16-bits training: True
DLL 2022-11-26 05:38:24.114428 - PARAMETER Config : ["Namespace(input_dir='/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/', config_file='bert_config.json', bert_model='bert-large-uncased', output_dir='s3://spot-checkpoints/bert', init_checkpoint=None, max_seq_length=128, max_predictions_per_seq=20, train_batch_size=73, learning_rate=0.006, num_train_epochs=3.0, max_steps=7038.0, warmup_proportion=0.2843, local_rank=0, seed=12439, gradient_accumulation_steps=1, fp16=True, amp=False, loss_scale=0.0, log_freq=1.0, checkpoint_activations=False, resume_from_checkpoint=True, resume_step=140, num_steps_per_checkpoint=200, skip_checkpoint=False, phase2=False, allreduce_post_accumulation=False, allreduce_post_accumulation_fp16=False, phase1_end_step=7038, init_loss_scale=1048576, do_train=True, json_summary='/home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json', use_env=False, disable_progress_bar=False, steps_this_run=7038.0, varuna=True, stage_to_rank_map='0,2,4,6,8,10,12,14,16,18,20,22,24,26;1,3,5,7,9,11,13,15,17,19,21,23,25,27;', chunk_size=8, batch_size=73, rank=0, profiling=False, n_gpu=1)"] 
dry run time 0.19508767127990723
SHARED WEIGHTS ARE
[(0, 1)]
this rank  0 is part of pipeline replica  0
10 chunks
Begin to load checkpint from s3://spot-checkpoints/bert/ckpt_140.pt
2022-11-26 05:38:34.569293 resume step from  140
Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.

Defaults for this optimization level are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 0 signal handler called with signal 10
2022-11-26 05:39:29.385462 - Finished loading checkpoint, takes 54.788 secs
DLL 2022-11-26 05:39:29.386400 - PARAMETER SEED : 12439 
DLL 2022-11-26 05:39:29.386521 - PARAMETER train_start : True 
DLL 2022-11-26 05:39:29.386573 - PARAMETER batch_size_per_gpu : 73 
DLL 2022-11-26 05:39:29.386630 - PARAMETER learning_rate : 0.006 
2022-11-26 05:39:51.021350 Begin to exit
Process done with return code 0
Parent process ID: 86532 node: 172.31.28.108
24 cutpoints
Stages 1
Micro-bs 8 Max mem: 14622140211.200005
Predicted microbatch size for 1: 8
comm size 0
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 1 4 0 3598379.5166015625 0
End of simulation:  Mini-batch time (usec) = 4923429
Min send: 10000000, max send 0
Min long send: 10000000, max long send 0
Min fwd: 10000000, max fwd 0; min bwd 10000000, max bwd 0
Min long fwd: 142174, max long fwd 144458; min long bwd 186536, max long bwd 191040
Time taken by simulation: 47 microseconds

Stages 2
Micro-bs 8 Max mem: 7660942131.200001
Predicted microbatch size for 2: 8
comm size 4194304
WARNING: no send time found, 2 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 2 8 0 954047.119140625 248719.58977934244
End of simulation:  Mini-batch time (usec) = 3096062
Min send: 10000000, max send 0
Min long send: 249051, max long send 268766
Min fwd: 79507, max fwd 86627; min bwd 88131, max bwd 94131
Min long fwd: 58556, max long fwd 63385; min long bwd 92867, max long bwd 97582
Time taken by simulation: 209 microseconds

Stages 3
Micro-bs 8 Max mem: 5497876480.0
Predicted microbatch size for 3: 8
comm size 4194304
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 13 0 485476.6540527344 248719.58977934244
End of simulation:  Mini-batch time (usec) = 3469734
Min send: 10000000, max send 0
Min long send: 248801, max long send 271185
Min fwd: 34426, max fwd 67951; min bwd 53890, max bwd 64826
Min long fwd: 37108, max long fwd 45662; min long bwd 64919, max long bwd 72155
Time taken by simulation: 454 microseconds

Stages 4
Micro-bs 8 Max mem: 4406266675.2
Predicted microbatch size for 4: 8
comm size 4194304
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 16 0 364488.09814453125 248719.58977934244
End of simulation:  Mini-batch time (usec) = 3900556
Min send: 10000000, max send 0
Min long send: 248773, max long send 273424
Min fwd: 20622, max fwd 60312; min bwd 40311, max bwd 50179
Min long fwd: 29744, max long fwd 36491; min long bwd 47928, max long bwd 56568
Time taken by simulation: 852 microseconds

Stages 6
Micro-bs 8 Max mem: 3314656870.4
Predicted microbatch size for 6: 8
comm size 4194304
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 26 0 254962.82958984375 248719.58977934244
End of simulation:  Mini-batch time (usec) = 5944030
Min send: 10000000, max send 0
Min long send: 248735, max long send 278723
Min fwd: 10836, max fwd 44441; min bwd 24199, max bwd 35953
Min long fwd: 21303, max long fwd 29429; min long bwd 33298, max long bwd 40795
Time taken by simulation: 1893 microseconds

Stages 8
Micro-bs 8 Max mem: 2758774988.8
Predicted microbatch size for 8: 8
comm size 4194304
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 32 0 244280.30395507812 248719.58977934244
End of simulation:  Mini-batch time (usec) = 7674225
Min send: 10000000, max send 0
Min long send: 248719, max long send 278723
Min fwd: 6779, max fwd 41103; min bwd 15994, max bwd 28589
Min long fwd: 18906, max long fwd 26091; min long bwd 25267, max long bwd 32480
Time taken by simulation: 3565 microseconds

Stages 12
Micro-bs 8 Max mem: 2202893107.2
Predicted microbatch size for 12: 8
comm size 4194304
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 64 0 117116.2109375 248719.58977934244
End of simulation:  Mini-batch time (usec) = 13687683
Min send: 10000000, max send 0
Min long send: 248720, max long send 280797
Min fwd: 141, max fwd 25024; min bwd 6433, max bwd 23373
Min long fwd: 7201, max long fwd 18161; min long bwd 16833, max long bwd 28389
Time taken by simulation: 11868 microseconds

{1: 4.923429, 2: 3.096062, 3: 3.469734, 4: 3.900556, 6: 5.94403, 8: 7.674225, 12: 13.687683}
{1: 8, 2: 8, 3: 8, 4: 8, 6: 8, 8: 8, 12: 8}
best config is: 2 8
expected time is 3.096062
16 per stage
32 servers!
Config:
ranks: range(0, 1)
train batch size: 1024
partitions: 2
chunk_size: 8
data depth: 16
stage to rank map: 0,2,4,6,8,10,12,14,16,18,20,22,24,26,28,30;1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31;
World size is 32
/opt/conda/envs/varuna/bin/python -u /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --rank=0 --chunk_size=8 --local_rank=0 --stage_to_rank_map=0,2,4,6,8,10,12,14,16,18,20,22,24,26,28,30;1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31; --batch-size=64 --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna --resume_step 140
device: cuda:0 n_gpu: 1, distributed training: True, 16-bits training: True
DLL 2022-11-26 05:40:01.872979 - PARAMETER Config : ["Namespace(input_dir='/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/', config_file='bert_config.json', bert_model='bert-large-uncased', output_dir='s3://spot-checkpoints/bert', init_checkpoint=None, max_seq_length=128, max_predictions_per_seq=20, train_batch_size=64, learning_rate=0.006, num_train_epochs=3.0, max_steps=7038.0, warmup_proportion=0.2843, local_rank=0, seed=12439, gradient_accumulation_steps=1, fp16=True, amp=False, loss_scale=0.0, log_freq=1.0, checkpoint_activations=False, resume_from_checkpoint=True, resume_step=140, num_steps_per_checkpoint=200, skip_checkpoint=False, phase2=False, allreduce_post_accumulation=False, allreduce_post_accumulation_fp16=False, phase1_end_step=7038, init_loss_scale=1048576, do_train=True, json_summary='/home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json', use_env=False, disable_progress_bar=False, steps_this_run=7038.0, varuna=True, stage_to_rank_map='0,2,4,6,8,10,12,14,16,18,20,22,24,26,28,30;1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31;', chunk_size=8, batch_size=64, rank=0, profiling=False, n_gpu=1)"] 
dry run time 0.18262887001037598
SHARED WEIGHTS ARE
[(0, 1)]
this rank  0 is part of pipeline replica  0
8 chunks
Begin to load checkpint from s3://spot-checkpoints/bert/ckpt_140.pt
2022-11-26 05:40:12.480441 resume step from  140
Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.

Defaults for this optimization level are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
2022-11-26 05:41:04.205865 - Finished loading checkpoint, takes 51.698 secs
DLL 2022-11-26 05:41:04.206820 - PARAMETER SEED : 12439 
DLL 2022-11-26 05:41:04.206943 - PARAMETER train_start : True 
DLL 2022-11-26 05:41:04.207007 - PARAMETER batch_size_per_gpu : 64 
DLL 2022-11-26 05:41:04.207044 - PARAMETER learning_rate : 0.006 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  524288.0
[2022-11-26 05:41:49.173755] Finished iteration 140, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5427.696
DLL 2022-11-26 05:41:49.179920 - Training Epoch: 0 Training Iteration: 141  average_loss : nan  step_loss : nan  learning_rate : 0.0004228090171669457 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  262144.0
[2022-11-26 05:41:52.497319] Finished iteration 141, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3323.379
DLL 2022-11-26 05:41:52.502586 - Training Epoch: 0 Training Iteration: 142  average_loss : nan  step_loss : nan  learning_rate : 0.00042580766267876803 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  131072.0
[2022-11-26 05:41:55.678149] Finished iteration 142, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3180.799
DLL 2022-11-26 05:41:55.683198 - Training Epoch: 0 Training Iteration: 143  average_loss : nan  step_loss : nan  learning_rate : 0.0004288063081905903 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  65536.0
[2022-11-26 05:41:58.890694] Finished iteration 143, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3212.493
DLL 2022-11-26 05:41:58.895860 - Training Epoch: 0 Training Iteration: 144  average_loss : nan  step_loss : nan  learning_rate : 0.00043180495370241266 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  32768.0
[2022-11-26 05:42:02.109557] Finished iteration 144, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3218.849
DLL 2022-11-26 05:42:02.115163 - Training Epoch: 0 Training Iteration: 145  average_loss : nan  step_loss : nan  learning_rate : 0.00043480359921423497 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  16384.0
[2022-11-26 05:42:04.310798] Finished iteration 145, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2201.163
DLL 2022-11-26 05:42:04.315748 - Training Epoch: 0 Training Iteration: 146  average_loss : nan  step_loss : nan  learning_rate : 0.00043780224472605723 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  8192.0
[2022-11-26 05:42:06.504870] Finished iteration 146, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2194.043
DLL 2022-11-26 05:42:06.509932 - Training Epoch: 0 Training Iteration: 147  average_loss : nan  step_loss : nan  learning_rate : 0.0004408008902378796 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  4096.0
[2022-11-26 05:42:08.666217] Finished iteration 147, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2161.350
DLL 2022-11-26 05:42:08.671322 - Training Epoch: 0 Training Iteration: 148  average_loss : nan  step_loss : nan  learning_rate : 0.0004437995357497019 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  2048.0
[2022-11-26 05:42:10.830248] Finished iteration 148, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2163.993
DLL 2022-11-26 05:42:10.836392 - Training Epoch: 0 Training Iteration: 149  average_loss : nan  step_loss : nan  learning_rate : 0.0004467981812615243 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1024.0
[2022-11-26 05:42:12.992841] Finished iteration 149, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2162.532
DLL 2022-11-26 05:42:12.997796 - Training Epoch: 0 Training Iteration: 150  average_loss : nan  step_loss : nan  learning_rate : 0.00044979682677334654 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  512.0
[2022-11-26 05:42:15.203386] Finished iteration 150, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2210.525
DLL 2022-11-26 05:42:15.208212 - Training Epoch: 0 Training Iteration: 151  average_loss : nan  step_loss : nan  learning_rate : 0.0004527954722851688 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  256.0
[2022-11-26 05:42:17.419720] Finished iteration 151, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2216.305
DLL 2022-11-26 05:42:17.425166 - Training Epoch: 0 Training Iteration: 152  average_loss : nan  step_loss : nan  learning_rate : 0.0004557941177969911 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  128.0
[2022-11-26 05:42:19.594818] Finished iteration 152, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2175.061
DLL 2022-11-26 05:42:19.600143 - Training Epoch: 0 Training Iteration: 153  average_loss : nan  step_loss : nan  learning_rate : 0.00045879276330881337 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  64.0
[2022-11-26 05:42:21.767560] Finished iteration 153, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2172.711
DLL 2022-11-26 05:42:21.772990 - Training Epoch: 0 Training Iteration: 154  average_loss : nan  step_loss : nan  learning_rate : 0.00046179140882063573 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  32.0
[2022-11-26 05:42:23.936914] Finished iteration 154, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2169.314
DLL 2022-11-26 05:42:23.941816 - Training Epoch: 0 Training Iteration: 155  average_loss : nan  step_loss : nan  learning_rate : 0.00046479005433245805 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  16.0
[2022-11-26 05:42:26.102411] Finished iteration 155, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2165.473
DLL 2022-11-26 05:42:26.107399 - Training Epoch: 0 Training Iteration: 156  average_loss : nan  step_loss : nan  learning_rate : 0.0004677886998442803 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  8.0
[2022-11-26 05:42:28.264807] Finished iteration 156, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2162.370
DLL 2022-11-26 05:42:28.269822 - Training Epoch: 0 Training Iteration: 157  average_loss : nan  step_loss : nan  learning_rate : 0.0004707873453561027 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  4.0
[2022-11-26 05:42:30.447988] Finished iteration 157, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2183.151
DLL 2022-11-26 05:42:30.453273 - Training Epoch: 0 Training Iteration: 158  average_loss : nan  step_loss : nan  learning_rate : 0.00047378599086792493 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  2.0
[2022-11-26 05:42:32.664472] Finished iteration 158, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2216.450
DLL 2022-11-26 05:42:32.669462 - Training Epoch: 0 Training Iteration: 159  average_loss : nan  step_loss : nan  learning_rate : 0.0004767846363797473 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:42:34.854135] Finished iteration 159, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2189.681
DLL 2022-11-26 05:42:34.860044 - Training Epoch: 0 Training Iteration: 160  average_loss : nan  step_loss : nan  learning_rate : 0.0004797832818915696 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:42:37.067770] Finished iteration 160, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2213.559
DLL 2022-11-26 05:42:37.072795 - Training Epoch: 0 Training Iteration: 161  average_loss : nan  step_loss : nan  learning_rate : 0.00048278192740339187 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:42:39.303186] Finished iteration 161, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2235.386
DLL 2022-11-26 05:42:39.308205 - Training Epoch: 0 Training Iteration: 162  average_loss : nan  step_loss : nan  learning_rate : 0.00048578057291521424 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:42:41.478181] Finished iteration 162, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2175.005
DLL 2022-11-26 05:42:41.483431 - Training Epoch: 0 Training Iteration: 163  average_loss : nan  step_loss : nan  learning_rate : 0.0004887792184270365 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:42:43.632412] Finished iteration 163, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2154.214
DLL 2022-11-26 05:42:43.639875 - Training Epoch: 0 Training Iteration: 164  average_loss : nan  step_loss : nan  learning_rate : 0.0004917778639388588 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:42:45.839276] Finished iteration 164, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2206.761
DLL 2022-11-26 05:42:45.844240 - Training Epoch: 0 Training Iteration: 165  average_loss : nan  step_loss : nan  learning_rate : 0.0004947765094506812 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:42:48.022693] Finished iteration 165, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2183.410
DLL 2022-11-26 05:42:48.028117 - Training Epoch: 0 Training Iteration: 166  average_loss : nan  step_loss : nan  learning_rate : 0.0004977751549625034 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:42:50.308192] Finished iteration 166, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2285.461
DLL 2022-11-26 05:42:50.313123 - Training Epoch: 0 Training Iteration: 167  average_loss : nan  step_loss : nan  learning_rate : 0.0005007738004743258 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:42:53.577735] Finished iteration 167, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3269.514
DLL 2022-11-26 05:42:53.583219 - Training Epoch: 0 Training Iteration: 168  average_loss : nan  step_loss : nan  learning_rate : 0.0005037724459861481 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:42:55.850117] Finished iteration 168, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2272.395
DLL 2022-11-26 05:42:55.855988 - Training Epoch: 0 Training Iteration: 169  average_loss : nan  step_loss : nan  learning_rate : 0.0005067710914979704 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:42:58.012462] Finished iteration 169, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2162.281
DLL 2022-11-26 05:42:58.017361 - Training Epoch: 0 Training Iteration: 170  average_loss : nan  step_loss : nan  learning_rate : 0.0005097697370097927 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:43:00.232526] Finished iteration 170, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2220.100
DLL 2022-11-26 05:43:00.237972 - Training Epoch: 0 Training Iteration: 171  average_loss : nan  step_loss : nan  learning_rate : 0.0005127683825216149 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:43:02.448348] Finished iteration 171, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2215.709
DLL 2022-11-26 05:43:02.453262 - Training Epoch: 0 Training Iteration: 172  average_loss : nan  step_loss : nan  learning_rate : 0.0005157670280334373 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:43:04.655434] Finished iteration 172, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2207.052
DLL 2022-11-26 05:43:04.660432 - Training Epoch: 0 Training Iteration: 173  average_loss : nan  step_loss : nan  learning_rate : 0.0005187656735452596 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:43:06.871935] Finished iteration 173, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2216.466
DLL 2022-11-26 05:43:06.877071 - Training Epoch: 0 Training Iteration: 174  average_loss : nan  step_loss : nan  learning_rate : 0.0005217643190570819 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:43:09.081709] Finished iteration 174, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2209.734
DLL 2022-11-26 05:43:09.087307 - Training Epoch: 0 Training Iteration: 175  average_loss : nan  step_loss : nan  learning_rate : 0.0005247629645689043 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:43:11.263067] Finished iteration 175, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2181.337
DLL 2022-11-26 05:43:11.268078 - Training Epoch: 0 Training Iteration: 176  average_loss : nan  step_loss : nan  learning_rate : 0.0005277616100807266 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:43:13.464406] Finished iteration 176, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2201.344
DLL 2022-11-26 05:43:13.469505 - Training Epoch: 0 Training Iteration: 177  average_loss : nan  step_loss : nan  learning_rate : 0.0005307602555925489 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:43:15.635277] Finished iteration 177, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2170.810
DLL 2022-11-26 05:43:15.640217 - Training Epoch: 0 Training Iteration: 178  average_loss : nan  step_loss : nan  learning_rate : 0.0005337589011043712 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:43:17.816863] Finished iteration 178, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2181.591
DLL 2022-11-26 05:43:17.823861 - Training Epoch: 0 Training Iteration: 179  average_loss : nan  step_loss : nan  learning_rate : 0.0005367575466161935 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:43:20.032734] Finished iteration 179, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2215.793
DLL 2022-11-26 05:43:20.037841 - Training Epoch: 0 Training Iteration: 180  average_loss : nan  step_loss : nan  learning_rate : 0.0005397561921280158 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:43:22.179635] Finished iteration 180, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2146.882
DLL 2022-11-26 05:43:22.185060 - Training Epoch: 0 Training Iteration: 181  average_loss : nan  step_loss : nan  learning_rate : 0.0005427548376398381 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:43:24.381710] Finished iteration 181, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2202.036
DLL 2022-11-26 05:43:24.386789 - Training Epoch: 0 Training Iteration: 182  average_loss : nan  step_loss : nan  learning_rate : 0.0005457534831516603 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:43:26.569794] Finished iteration 182, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2188.060
DLL 2022-11-26 05:43:26.574785 - Training Epoch: 0 Training Iteration: 183  average_loss : nan  step_loss : nan  learning_rate : 0.0005487521286634827 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:43:28.743610] Finished iteration 183, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2173.801
DLL 2022-11-26 05:43:28.748619 - Training Epoch: 0 Training Iteration: 184  average_loss : nan  step_loss : nan  learning_rate : 0.0005517507741753051 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:43:30.878552] Finished iteration 184, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2134.887
DLL 2022-11-26 05:43:30.883753 - Training Epoch: 0 Training Iteration: 185  average_loss : nan  step_loss : nan  learning_rate : 0.0005547494196871273 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:43:33.055622] Finished iteration 185, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2177.068
DLL 2022-11-26 05:43:33.061011 - Training Epoch: 0 Training Iteration: 186  average_loss : nan  step_loss : nan  learning_rate : 0.0005577480651989497 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:43:35.216169] Finished iteration 186, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2160.512
DLL 2022-11-26 05:43:35.221407 - Training Epoch: 0 Training Iteration: 187  average_loss : nan  step_loss : nan  learning_rate : 0.000560746710710772 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:43:37.395210] Finished iteration 187, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2179.031
DLL 2022-11-26 05:43:37.400153 - Training Epoch: 0 Training Iteration: 188  average_loss : nan  step_loss : nan  learning_rate : 0.0005637453562225942 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:43:39.582687] Finished iteration 188, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2187.440
DLL 2022-11-26 05:43:39.587938 - Training Epoch: 0 Training Iteration: 189  average_loss : nan  step_loss : nan  learning_rate : 0.0005667440017344166 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:43:41.764014] Finished iteration 189, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2181.282
DLL 2022-11-26 05:43:41.769082 - Training Epoch: 0 Training Iteration: 190  average_loss : nan  step_loss : nan  learning_rate : 0.0005697426472462388 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:43:43.986825] Finished iteration 190, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2222.812
DLL 2022-11-26 05:43:43.992509 - Training Epoch: 0 Training Iteration: 191  average_loss : nan  step_loss : nan  learning_rate : 0.0005727412927580613 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:43:46.148755] Finished iteration 191, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2161.859
DLL 2022-11-26 05:43:46.154038 - Training Epoch: 0 Training Iteration: 192  average_loss : nan  step_loss : nan  learning_rate : 0.0005757399382698836 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:43:48.337083] Finished iteration 192, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2188.304
DLL 2022-11-26 05:43:48.342490 - Training Epoch: 0 Training Iteration: 193  average_loss : nan  step_loss : nan  learning_rate : 0.0005787385837817058 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:43:50.495165] Finished iteration 193, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2158.053
DLL 2022-11-26 05:43:50.500680 - Training Epoch: 0 Training Iteration: 194  average_loss : nan  step_loss : nan  learning_rate : 0.0005817372292935281 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:43:52.706148] Finished iteration 194, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2210.971
DLL 2022-11-26 05:43:52.711479 - Training Epoch: 0 Training Iteration: 195  average_loss : nan  step_loss : nan  learning_rate : 0.0005847358748053504 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:43:54.899203] Finished iteration 195, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2193.005
DLL 2022-11-26 05:43:54.904580 - Training Epoch: 0 Training Iteration: 196  average_loss : nan  step_loss : nan  learning_rate : 0.0005877345203171727 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:43:57.055212] Finished iteration 196, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2155.979
DLL 2022-11-26 05:43:57.060354 - Training Epoch: 0 Training Iteration: 197  average_loss : nan  step_loss : nan  learning_rate : 0.000590733165828995 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:43:59.239133] Finished iteration 197, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2183.885
DLL 2022-11-26 05:43:59.244278 - Training Epoch: 0 Training Iteration: 198  average_loss : nan  step_loss : nan  learning_rate : 0.0005937318113408173 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:44:01.424340] Finished iteration 198, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2185.196
DLL 2022-11-26 05:44:01.429792 - Training Epoch: 0 Training Iteration: 199  average_loss : nan  step_loss : nan  learning_rate : 0.0005967304568526397 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:44:03.634518] Finished iteration 199, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2210.122
DLL 2022-11-26 05:44:03.639702 - Training Epoch: 0 Training Iteration: 200  average_loss : nan  step_loss : nan  learning_rate : 0.000599729102364462 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:44:05.851473] Finished iteration 200, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2216.937
DLL 2022-11-26 05:44:05.856151 - Training Epoch: 0 Training Iteration: 201  average_loss : nan  step_loss : nan  learning_rate : 0.0006027277478762843 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:44:08.433389] Finished iteration 201, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2581.879
DLL 2022-11-26 05:44:08.438939 - Training Epoch: 0 Training Iteration: 202  average_loss : nan  step_loss : nan  learning_rate : 0.0006057263933881066 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:44:10.747707] Finished iteration 202, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2314.291
DLL 2022-11-26 05:44:10.753201 - Training Epoch: 0 Training Iteration: 203  average_loss : nan  step_loss : nan  learning_rate : 0.0006087250388999289 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:44:12.938557] Finished iteration 203, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2190.887
DLL 2022-11-26 05:44:12.945881 - Training Epoch: 0 Training Iteration: 204  average_loss : nan  step_loss : nan  learning_rate : 0.0006117236844117512 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:44:15.121442] Finished iteration 204, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2182.765
DLL 2022-11-26 05:44:15.126406 - Training Epoch: 0 Training Iteration: 205  average_loss : nan  step_loss : nan  learning_rate : 0.0006147223299235735 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:44:17.307607] Finished iteration 205, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2186.147
DLL 2022-11-26 05:44:17.312528 - Training Epoch: 0 Training Iteration: 206  average_loss : nan  step_loss : nan  learning_rate : 0.000617720975435396 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:44:19.513222] Finished iteration 206, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2205.587
DLL 2022-11-26 05:44:19.518237 - Training Epoch: 0 Training Iteration: 207  average_loss : nan  step_loss : nan  learning_rate : 0.0006207196209472182 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:44:21.706999] Finished iteration 207, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2193.757
DLL 2022-11-26 05:44:21.711992 - Training Epoch: 0 Training Iteration: 208  average_loss : nan  step_loss : nan  learning_rate : 0.0006237182664590405 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:44:24.225377] Finished iteration 208, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2518.333
DLL 2022-11-26 05:44:24.230448 - Training Epoch: 0 Training Iteration: 209  average_loss : nan  step_loss : nan  learning_rate : 0.0006267169119708628 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:44:26.914190] Finished iteration 209, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2688.815
DLL 2022-11-26 05:44:26.919356 - Training Epoch: 0 Training Iteration: 210  average_loss : nan  step_loss : nan  learning_rate : 0.000629715557482685 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:44:29.145654] Finished iteration 210, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2231.405
DLL 2022-11-26 05:44:29.150845 - Training Epoch: 0 Training Iteration: 211  average_loss : nan  step_loss : nan  learning_rate : 0.0006327142029945074 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:44:31.356201] Finished iteration 211, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2210.517
DLL 2022-11-26 05:44:31.361645 - Training Epoch: 0 Training Iteration: 212  average_loss : nan  step_loss : nan  learning_rate : 0.0006357128485063296 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:44:33.567067] Finished iteration 212, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2210.848
DLL 2022-11-26 05:44:33.572025 - Training Epoch: 0 Training Iteration: 213  average_loss : nan  step_loss : nan  learning_rate : 0.000638711494018152 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:44:35.765387] Finished iteration 213, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2198.308
DLL 2022-11-26 05:44:35.770374 - Training Epoch: 0 Training Iteration: 214  average_loss : nan  step_loss : nan  learning_rate : 0.0006417101395299744 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:44:37.946231] Finished iteration 214, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2180.803
DLL 2022-11-26 05:44:37.951266 - Training Epoch: 0 Training Iteration: 215  average_loss : nan  step_loss : nan  learning_rate : 0.0006447087850417966 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:44:40.160326] Finished iteration 215, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2214.047
DLL 2022-11-26 05:44:40.165848 - Training Epoch: 0 Training Iteration: 216  average_loss : nan  step_loss : nan  learning_rate : 0.000647707430553619 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:44:42.370081] Finished iteration 216, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2209.762
DLL 2022-11-26 05:44:42.375462 - Training Epoch: 0 Training Iteration: 217  average_loss : nan  step_loss : nan  learning_rate : 0.0006507060760654413 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:44:44.530441] Finished iteration 217, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2160.292
DLL 2022-11-26 05:44:44.535761 - Training Epoch: 0 Training Iteration: 218  average_loss : nan  step_loss : nan  learning_rate : 0.0006537047215772636 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:44:46.717861] Finished iteration 218, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2187.403
DLL 2022-11-26 05:44:46.723148 - Training Epoch: 0 Training Iteration: 219  average_loss : nan  step_loss : nan  learning_rate : 0.0006567033670890859 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:44:48.884056] Finished iteration 219, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2166.140
DLL 2022-11-26 05:44:48.888942 - Training Epoch: 0 Training Iteration: 220  average_loss : nan  step_loss : nan  learning_rate : 0.0006597020126009082 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:44:51.061171] Finished iteration 220, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2177.126
DLL 2022-11-26 05:44:51.066299 - Training Epoch: 0 Training Iteration: 221  average_loss : nan  step_loss : nan  learning_rate : 0.0006627006581127306 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:44:53.198945] Finished iteration 221, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2137.716
DLL 2022-11-26 05:44:53.203961 - Training Epoch: 0 Training Iteration: 222  average_loss : nan  step_loss : nan  learning_rate : 0.0006656993036245529 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:44:55.412323] Finished iteration 222, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2213.375
DLL 2022-11-26 05:44:55.417363 - Training Epoch: 0 Training Iteration: 223  average_loss : nan  step_loss : nan  learning_rate : 0.0006686979491363751 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:44:57.597100] Finished iteration 223, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2184.722
DLL 2022-11-26 05:44:57.602512 - Training Epoch: 0 Training Iteration: 224  average_loss : nan  step_loss : nan  learning_rate : 0.0006716965946481975 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:44:59.829663] Finished iteration 224, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2232.542
DLL 2022-11-26 05:44:59.834720 - Training Epoch: 0 Training Iteration: 225  average_loss : nan  step_loss : nan  learning_rate : 0.0006746952401600198 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:45:02.053761] Finished iteration 225, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2224.079
DLL 2022-11-26 05:45:02.059182 - Training Epoch: 0 Training Iteration: 226  average_loss : nan  step_loss : nan  learning_rate : 0.000677693885671842 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:45:04.279783] Finished iteration 226, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2225.971
DLL 2022-11-26 05:45:04.284893 - Training Epoch: 0 Training Iteration: 227  average_loss : nan  step_loss : nan  learning_rate : 0.0006806925311836643 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:45:06.497348] Finished iteration 227, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2217.533
DLL 2022-11-26 05:45:06.502370 - Training Epoch: 0 Training Iteration: 228  average_loss : nan  step_loss : nan  learning_rate : 0.0006836911766954866 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:45:08.674295] Finished iteration 228, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2176.939
DLL 2022-11-26 05:45:08.679332 - Training Epoch: 0 Training Iteration: 229  average_loss : nan  step_loss : nan  learning_rate : 0.0006866898222073091 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:45:10.847554] Finished iteration 229, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2173.200
DLL 2022-11-26 05:45:10.853024 - Training Epoch: 0 Training Iteration: 230  average_loss : nan  step_loss : nan  learning_rate : 0.0006896884677191314 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:45:13.013380] Finished iteration 230, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2165.815
DLL 2022-11-26 05:45:13.018577 - Training Epoch: 0 Training Iteration: 231  average_loss : nan  step_loss : nan  learning_rate : 0.0006926871132309536 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:45:15.206069] Finished iteration 231, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2192.707
DLL 2022-11-26 05:45:15.211073 - Training Epoch: 0 Training Iteration: 232  average_loss : nan  step_loss : nan  learning_rate : 0.0006956857587427759 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:45:17.398289] Finished iteration 232, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2192.132
DLL 2022-11-26 05:45:17.403285 - Training Epoch: 0 Training Iteration: 233  average_loss : nan  step_loss : nan  learning_rate : 0.0006986844042545982 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:45:19.556859] Finished iteration 233, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2158.546
DLL 2022-11-26 05:45:19.562199 - Training Epoch: 0 Training Iteration: 234  average_loss : nan  step_loss : nan  learning_rate : 0.0007016830497664205 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:45:21.738300] Finished iteration 234, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2181.397
DLL 2022-11-26 05:45:21.743562 - Training Epoch: 0 Training Iteration: 235  average_loss : nan  step_loss : nan  learning_rate : 0.0007046816952782429 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:45:23.887638] Finished iteration 235, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2149.335
DLL 2022-11-26 05:45:23.892590 - Training Epoch: 0 Training Iteration: 236  average_loss : nan  step_loss : nan  learning_rate : 0.0007076803407900652 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:45:26.065362] Finished iteration 236, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2177.754
DLL 2022-11-26 05:45:26.070820 - Training Epoch: 0 Training Iteration: 237  average_loss : nan  step_loss : nan  learning_rate : 0.0007106789863018875 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:45:28.273800] Finished iteration 237, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2208.364
DLL 2022-11-26 05:45:28.279161 - Training Epoch: 0 Training Iteration: 238  average_loss : nan  step_loss : nan  learning_rate : 0.0007136776318137098 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:45:30.463186] Finished iteration 238, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2189.342
DLL 2022-11-26 05:45:30.468639 - Training Epoch: 0 Training Iteration: 239  average_loss : nan  step_loss : nan  learning_rate : 0.0007166762773255321 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:45:32.639436] Finished iteration 239, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2176.186
DLL 2022-11-26 05:45:32.644605 - Training Epoch: 0 Training Iteration: 240  average_loss : nan  step_loss : nan  learning_rate : 0.0007196749228373544 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:45:34.835118] Finished iteration 240, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2195.664
DLL 2022-11-26 05:45:34.840499 - Training Epoch: 0 Training Iteration: 241  average_loss : nan  step_loss : nan  learning_rate : 0.0007226735683491767 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:45:37.041187] Finished iteration 241, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2206.033
DLL 2022-11-26 05:45:37.046799 - Training Epoch: 0 Training Iteration: 242  average_loss : nan  step_loss : nan  learning_rate : 0.0007256722138609989 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:45:39.247654] Finished iteration 242, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2206.444
DLL 2022-11-26 05:45:39.252596 - Training Epoch: 0 Training Iteration: 243  average_loss : nan  step_loss : nan  learning_rate : 0.0007286708593728212 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:45:41.464349] Finished iteration 243, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2216.662
DLL 2022-11-26 05:45:41.469150 - Training Epoch: 0 Training Iteration: 244  average_loss : nan  step_loss : nan  learning_rate : 0.0007316695048846438 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:45:43.634501] Finished iteration 244, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2170.114
DLL 2022-11-26 05:45:43.639549 - Training Epoch: 0 Training Iteration: 245  average_loss : nan  step_loss : nan  learning_rate : 0.000734668150396466 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:45:45.772319] Finished iteration 245, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2137.805
DLL 2022-11-26 05:45:45.777726 - Training Epoch: 0 Training Iteration: 246  average_loss : nan  step_loss : nan  learning_rate : 0.0007376667959082883 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:45:48.039664] Finished iteration 246, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2267.309
DLL 2022-11-26 05:45:48.044795 - Training Epoch: 0 Training Iteration: 247  average_loss : nan  step_loss : nan  learning_rate : 0.0007406654414201106 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:45:50.233332] Finished iteration 247, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2193.636
DLL 2022-11-26 05:45:50.238596 - Training Epoch: 0 Training Iteration: 248  average_loss : nan  step_loss : nan  learning_rate : 0.0007436640869319328 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:45:52.449124] Finished iteration 248, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2215.801
DLL 2022-11-26 05:45:52.454000 - Training Epoch: 0 Training Iteration: 249  average_loss : nan  step_loss : nan  learning_rate : 0.0007466627324437552 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:45:54.690177] Finished iteration 249, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2241.010
DLL 2022-11-26 05:45:54.695365 - Training Epoch: 0 Training Iteration: 250  average_loss : nan  step_loss : nan  learning_rate : 0.0007496613779555775 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:45:57.170913] Finished iteration 250, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2480.709
DLL 2022-11-26 05:45:57.175852 - Training Epoch: 0 Training Iteration: 251  average_loss : nan  step_loss : nan  learning_rate : 0.0007526600234673998 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:45:59.522224] Finished iteration 251, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2351.287
DLL 2022-11-26 05:45:59.527305 - Training Epoch: 0 Training Iteration: 252  average_loss : nan  step_loss : nan  learning_rate : 0.0007556586689792222 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:46:01.661496] Finished iteration 252, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2139.228
DLL 2022-11-26 05:46:01.666370 - Training Epoch: 0 Training Iteration: 253  average_loss : nan  step_loss : nan  learning_rate : 0.0007586573144910444 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:46:03.855812] Finished iteration 253, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2194.269
DLL 2022-11-26 05:46:03.860922 - Training Epoch: 0 Training Iteration: 254  average_loss : nan  step_loss : nan  learning_rate : 0.0007616559600028668 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:46:06.221077] Finished iteration 254, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2365.220
DLL 2022-11-26 05:46:06.226156 - Training Epoch: 0 Training Iteration: 255  average_loss : nan  step_loss : nan  learning_rate : 0.0007646546055146891 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:46:08.435030] Finished iteration 255, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2213.955
DLL 2022-11-26 05:46:08.440260 - Training Epoch: 0 Training Iteration: 256  average_loss : nan  step_loss : nan  learning_rate : 0.0007676532510265113 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:46:10.596354] Finished iteration 256, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2161.307
DLL 2022-11-26 05:46:10.601893 - Training Epoch: 0 Training Iteration: 257  average_loss : nan  step_loss : nan  learning_rate : 0.0007706518965383336 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:46:12.774567] Finished iteration 257, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2178.186
DLL 2022-11-26 05:46:12.780129 - Training Epoch: 0 Training Iteration: 258  average_loss : nan  step_loss : nan  learning_rate : 0.0007736505420501559 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:46:14.965555] Finished iteration 258, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2190.951
DLL 2022-11-26 05:46:14.971099 - Training Epoch: 0 Training Iteration: 259  average_loss : nan  step_loss : nan  learning_rate : 0.0007766491875619783 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:46:17.140009] Finished iteration 259, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2174.402
DLL 2022-11-26 05:46:17.145338 - Training Epoch: 0 Training Iteration: 260  average_loss : nan  step_loss : nan  learning_rate : 0.0007796478330738007 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:46:19.286246] Finished iteration 260, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2146.261
DLL 2022-11-26 05:46:19.291257 - Training Epoch: 0 Training Iteration: 261  average_loss : nan  step_loss : nan  learning_rate : 0.0007826464785856229 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:46:21.468312] Finished iteration 261, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2182.014
DLL 2022-11-26 05:46:21.473367 - Training Epoch: 0 Training Iteration: 262  average_loss : nan  step_loss : nan  learning_rate : 0.0007856451240974452 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:46:23.674405] Finished iteration 262, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2206.067
DLL 2022-11-26 05:46:23.679541 - Training Epoch: 0 Training Iteration: 263  average_loss : nan  step_loss : nan  learning_rate : 0.0007886437696092675 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:46:25.847357] Finished iteration 263, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2172.921
DLL 2022-11-26 05:46:25.852260 - Training Epoch: 0 Training Iteration: 264  average_loss : nan  step_loss : nan  learning_rate : 0.0007916424151210898 
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 0 signal handler called with signal 10
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:46:28.013857] Finished iteration 264, CKPT_AND_STOP: True, flag: tensor([2], dtype=torch.int32), speed: 2166.449
DLL 2022-11-26 05:46:28.019228 - Training Epoch: 0 Training Iteration: 265  average_loss : nan  step_loss : nan  learning_rate : 0.0007946410606329121 
2022-11-26 05:46:28.019357 Begin to save checkpont to s3://spot-checkpoints/bert and exit
DLL 2022-11-26 05:46:28.019375 - PARAMETER checkpoint_step : 265 
Opt ckpt time 7.284298658370972
Process done with return code 0
Parent process ID: 89073 node: 172.31.28.108
24 cutpoints
Stages 1
Micro-bs 8 Max mem: 14622140211.200005
Predicted microbatch size for 1: 8
comm size 0
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 1 5 0 2493369.62890625 0
End of simulation:  Mini-batch time (usec) = 4144382
Min send: 10000000, max send 0
Min long send: 10000000, max long send 0
Min fwd: 10000000, max fwd 0; min bwd 10000000, max bwd 0
Min long fwd: 141043, max long fwd 144458; min long bwd 184920, max long bwd 191040
Time taken by simulation: 43 microseconds

Stages 2
Micro-bs 8 Max mem: 7660942131.200001
Predicted microbatch size for 2: 8
comm size 4194304
WARNING: no send time found, 2 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 2 9 0 970375.4272460938 248719.58977934244
End of simulation:  Mini-batch time (usec) = 3283515
Min send: 10000000, max send 0
Min long send: 249051, max long send 268766
Min fwd: 79750, max fwd 86627; min bwd 87708, max bwd 94754
Min long fwd: 58189, max long fwd 63385; min long bwd 92867, max long bwd 97330
Time taken by simulation: 184 microseconds

Stages 3
Micro-bs 8 Max mem: 5497876480.0
Predicted microbatch size for 3: 8
comm size 4194304
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 13 0 485476.6540527344 248719.58977934244
End of simulation:  Mini-batch time (usec) = 3469734
Min send: 10000000, max send 0
Min long send: 248801, max long send 271185
Min fwd: 34426, max fwd 67951; min bwd 53890, max bwd 64826
Min long fwd: 37108, max long fwd 45662; min long bwd 64919, max long bwd 72155
Time taken by simulation: 431 microseconds

Stages 4
Micro-bs 8 Max mem: 4406266675.2
Predicted microbatch size for 4: 8
comm size 4194304
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 19 0 352272.7355957031 248719.58977934244
End of simulation:  Mini-batch time (usec) = 4275253
Min send: 10000000, max send 0
Min long send: 248773, max long send 273424
Min fwd: 22410, max fwd 61283; min bwd 39748, max bwd 51303
Min long fwd: 29385, max long fwd 37648; min long bwd 47928, max long bwd 54735
Time taken by simulation: 910 microseconds

Stages 6
Micro-bs 8 Max mem: 3314656870.4
Predicted microbatch size for 6: 8
comm size 4194304
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 26 0 254962.82958984375 248719.58977934244
End of simulation:  Mini-batch time (usec) = 5944030
Min send: 10000000, max send 0
Min long send: 248735, max long send 278723
Min fwd: 10836, max fwd 44441; min bwd 24199, max bwd 35953
Min long fwd: 21303, max long fwd 29429; min long bwd 33298, max long bwd 40795
Time taken by simulation: 2015 microseconds

Stages 8
Micro-bs 8 Max mem: 2758774988.8
Predicted microbatch size for 8: 8
comm size 4194304
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 43 0 178155.74645996094 248719.58977934244
End of simulation:  Mini-batch time (usec) = 9019309
Min send: 10000000, max send 0
Min long send: 248735, max long send 276940
Min fwd: 5776, max fwd 41014; min bwd 16548, max bwd 29492
Min long fwd: 17309, max long fwd 25772; min long bwd 25282, max long bwd 32088
Time taken by simulation: 4658 microseconds

Stages 12
Micro-bs 8 Max mem: 2202893107.2
Predicted microbatch size for 12: 8
comm size 4194304
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 64 0 117116.2109375 248719.58977934244
End of simulation:  Mini-batch time (usec) = 13687683
Min send: 10000000, max send 0
Min long send: 248720, max long send 280797
Min fwd: 141, max fwd 25024; min bwd 6433, max bwd 23373
Min long fwd: 7201, max long fwd 18161; min long bwd 16833, max long bwd 28389
Time taken by simulation: 11163 microseconds

{1: 4.144382, 2: 3.283515, 3: 3.469734, 4: 4.275253, 6: 5.94403, 8: 9.019309, 12: 13.687683}
{1: 8, 2: 8, 3: 8, 4: 8, 6: 8, 8: 8, 12: 8}
best config is: 2 8
expected time is 3.283515
15 per stage
30 servers!
Config:
ranks: range(0, 1)
train batch size: 1024
partitions: 2
chunk_size: 8
data depth: 15
stage to rank map: 0,2,4,6,8,10,12,14,16,18,20,22,24,26,28;1,3,5,7,9,11,13,15,17,19,21,23,25,27,29;
World size is 30
/opt/conda/envs/varuna/bin/python -u /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --rank=0 --chunk_size=8 --local_rank=0 --stage_to_rank_map=0,2,4,6,8,10,12,14,16,18,20,22,24,26,28;1,3,5,7,9,11,13,15,17,19,21,23,25,27,29; --batch-size=68 --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna --resume_step 265
device: cuda:0 n_gpu: 1, distributed training: True, 16-bits training: True
DLL 2022-11-26 05:47:27.462528 - PARAMETER Config : ["Namespace(input_dir='/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/', config_file='bert_config.json', bert_model='bert-large-uncased', output_dir='s3://spot-checkpoints/bert', init_checkpoint=None, max_seq_length=128, max_predictions_per_seq=20, train_batch_size=68, learning_rate=0.006, num_train_epochs=3.0, max_steps=7038.0, warmup_proportion=0.2843, local_rank=0, seed=12439, gradient_accumulation_steps=1, fp16=True, amp=False, loss_scale=0.0, log_freq=1.0, checkpoint_activations=False, resume_from_checkpoint=True, resume_step=265, num_steps_per_checkpoint=200, skip_checkpoint=False, phase2=False, allreduce_post_accumulation=False, allreduce_post_accumulation_fp16=False, phase1_end_step=7038, init_loss_scale=1048576, do_train=True, json_summary='/home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json', use_env=False, disable_progress_bar=False, steps_this_run=7038.0, varuna=True, stage_to_rank_map='0,2,4,6,8,10,12,14,16,18,20,22,24,26,28;1,3,5,7,9,11,13,15,17,19,21,23,25,27,29;', chunk_size=8, batch_size=68, rank=0, profiling=False, n_gpu=1)"] 
dry run time 0.17995738983154297
SHARED WEIGHTS ARE
[(0, 1)]
this rank  0 is part of pipeline replica  0
9 chunks
Begin to load checkpint from s3://spot-checkpoints/bert/ckpt_265.pt
2022-11-26 05:47:37.904708 resume step from  265
Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.

Defaults for this optimization level are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 0 signal handler called with signal 10
2022-11-26 05:48:38.636225 - Finished loading checkpoint, takes 60.704 secs
DLL 2022-11-26 05:48:38.637106 - PARAMETER SEED : 12439 
DLL 2022-11-26 05:48:38.637227 - PARAMETER train_start : True 
DLL 2022-11-26 05:48:38.637282 - PARAMETER batch_size_per_gpu : 68 
DLL 2022-11-26 05:48:38.637357 - PARAMETER learning_rate : 0.006 
Process done with return code 1
Parent process ID: 90874 node: 172.31.28.108
24 cutpoints
Stages 1
Micro-bs 8 Max mem: 14622140211.200005
Predicted microbatch size for 1: 8
comm size 0
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 1 5 0 2493369.62890625 0
End of simulation:  Mini-batch time (usec) = 4144382
Min send: 10000000, max send 0
Min long send: 10000000, max long send 0
Min fwd: 10000000, max fwd 0; min bwd 10000000, max bwd 0
Min long fwd: 141043, max long fwd 144458; min long bwd 184920, max long bwd 191040
Time taken by simulation: 49 microseconds

Stages 2
Micro-bs 8 Max mem: 7660942131.200001
Predicted microbatch size for 2: 8
comm size 4194304
WARNING: no send time found, 2 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 2 9 0 970375.4272460938 248719.58977934244
End of simulation:  Mini-batch time (usec) = 3283515
Min send: 10000000, max send 0
Min long send: 249051, max long send 268766
Min fwd: 79750, max fwd 86627; min bwd 87708, max bwd 94754
Min long fwd: 58189, max long fwd 63385; min long bwd 92867, max long bwd 97330
Time taken by simulation: 186 microseconds

Stages 3
Micro-bs 8 Max mem: 5497876480.0
Predicted microbatch size for 3: 8
comm size 4194304
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 13 0 485476.6540527344 248719.58977934244
End of simulation:  Mini-batch time (usec) = 3469734
Min send: 10000000, max send 0
Min long send: 248801, max long send 271185
Min fwd: 34426, max fwd 67951; min bwd 53890, max bwd 64826
Min long fwd: 37108, max long fwd 45662; min long bwd 64919, max long bwd 72155
Time taken by simulation: 428 microseconds

Stages 4
Micro-bs 8 Max mem: 4406266675.2
Predicted microbatch size for 4: 8
comm size 4194304
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 19 0 352272.7355957031 248719.58977934244
End of simulation:  Mini-batch time (usec) = 4275253
Min send: 10000000, max send 0
Min long send: 248773, max long send 273424
Min fwd: 22410, max fwd 61283; min bwd 39748, max bwd 51303
Min long fwd: 29385, max long fwd 37648; min long bwd 47928, max long bwd 54735
Time taken by simulation: 864 microseconds

Stages 6
Micro-bs 8 Max mem: 3314656870.4
Predicted microbatch size for 6: 8
comm size 4194304
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 26 0 254962.82958984375 248719.58977934244
End of simulation:  Mini-batch time (usec) = 5944030
Min send: 10000000, max send 0
Min long send: 248735, max long send 278723
Min fwd: 10836, max fwd 44441; min bwd 24199, max bwd 35953
Min long fwd: 21303, max long fwd 29429; min long bwd 33298, max long bwd 40795
Time taken by simulation: 2042 microseconds

Stages 8
Micro-bs 8 Max mem: 2758774988.8
Predicted microbatch size for 8: 8
comm size 4194304
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 43 0 178155.74645996094 248719.58977934244
End of simulation:  Mini-batch time (usec) = 9019309
Min send: 10000000, max send 0
Min long send: 248735, max long send 276940
Min fwd: 5776, max fwd 41014; min bwd 16548, max bwd 29492
Min long fwd: 17309, max long fwd 25772; min long bwd 25282, max long bwd 32088
Time taken by simulation: 4502 microseconds

Stages 12
Micro-bs 8 Max mem: 2202893107.2
Predicted microbatch size for 12: 8
comm size 4194304
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 64 0 117116.2109375 248719.58977934244
End of simulation:  Mini-batch time (usec) = 13687683
Min send: 10000000, max send 0
Min long send: 248720, max long send 280797
Min fwd: 141, max fwd 25024; min bwd 6433, max bwd 23373
Min long fwd: 7201, max long fwd 18161; min long bwd 16833, max long bwd 28389
Time taken by simulation: 10709 microseconds

{1: 4.144382, 2: 3.283515, 3: 3.469734, 4: 4.275253, 6: 5.94403, 8: 9.019309, 12: 13.687683}
{1: 8, 2: 8, 3: 8, 4: 8, 6: 8, 8: 8, 12: 8}
best config is: 2 8
expected time is 3.283515
15 per stage
30 servers!
Config:
ranks: range(0, 1)
train batch size: 1024
partitions: 2
chunk_size: 8
data depth: 15
stage to rank map: 0,2,4,6,8,10,12,14,16,18,20,22,24,26,28;1,3,5,7,9,11,13,15,17,19,21,23,25,27,29;
World size is 30
/opt/conda/envs/varuna/bin/python -u /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --rank=0 --chunk_size=8 --local_rank=0 --stage_to_rank_map=0,2,4,6,8,10,12,14,16,18,20,22,24,26,28;1,3,5,7,9,11,13,15,17,19,21,23,25,27,29; --batch-size=68 --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna --resume_step 265
device: cuda:0 n_gpu: 1, distributed training: True, 16-bits training: True
DLL 2022-11-26 05:49:44.620050 - PARAMETER Config : ["Namespace(input_dir='/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/', config_file='bert_config.json', bert_model='bert-large-uncased', output_dir='s3://spot-checkpoints/bert', init_checkpoint=None, max_seq_length=128, max_predictions_per_seq=20, train_batch_size=68, learning_rate=0.006, num_train_epochs=3.0, max_steps=7038.0, warmup_proportion=0.2843, local_rank=0, seed=12439, gradient_accumulation_steps=1, fp16=True, amp=False, loss_scale=0.0, log_freq=1.0, checkpoint_activations=False, resume_from_checkpoint=True, resume_step=265, num_steps_per_checkpoint=200, skip_checkpoint=False, phase2=False, allreduce_post_accumulation=False, allreduce_post_accumulation_fp16=False, phase1_end_step=7038, init_loss_scale=1048576, do_train=True, json_summary='/home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json', use_env=False, disable_progress_bar=False, steps_this_run=7038.0, varuna=True, stage_to_rank_map='0,2,4,6,8,10,12,14,16,18,20,22,24,26,28;1,3,5,7,9,11,13,15,17,19,21,23,25,27,29;', chunk_size=8, batch_size=68, rank=0, profiling=False, n_gpu=1)"] 
dry run time 0.1871941089630127
SHARED WEIGHTS ARE
[(0, 1)]
this rank  0 is part of pipeline replica  0
9 chunks
Begin to load checkpint from s3://spot-checkpoints/bert/ckpt_265.pt
2022-11-26 05:49:54.975815 resume step from  265
Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.

Defaults for this optimization level are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
2022-11-26 05:50:51.989086 - Finished loading checkpoint, takes 56.987 secs
DLL 2022-11-26 05:50:51.990124 - PARAMETER SEED : 12439 
DLL 2022-11-26 05:50:51.990241 - PARAMETER train_start : True 
DLL 2022-11-26 05:50:51.990345 - PARAMETER batch_size_per_gpu : 68 
DLL 2022-11-26 05:50:51.990401 - PARAMETER learning_rate : 0.006 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  524288.0
[2022-11-26 05:51:19.649763] Finished iteration 265, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5620.345
DLL 2022-11-26 05:51:19.732616 - Training Epoch: 0 Training Iteration: 266  average_loss : nan  step_loss : nan  learning_rate : 0.0007976397061447345 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  262144.0
[2022-11-26 05:51:22.955525] Finished iteration 266, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3305.613
DLL 2022-11-26 05:51:22.960795 - Training Epoch: 0 Training Iteration: 267  average_loss : nan  step_loss : nan  learning_rate : 0.0008006383516565567 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  131072.0
[2022-11-26 05:51:25.506387] Finished iteration 267, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2550.746
DLL 2022-11-26 05:51:25.511225 - Training Epoch: 0 Training Iteration: 268  average_loss : nan  step_loss : nan  learning_rate : 0.000803636997168379 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  65536.0
[2022-11-26 05:51:27.722434] Finished iteration 268, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2216.032
DLL 2022-11-26 05:51:27.727781 - Training Epoch: 0 Training Iteration: 269  average_loss : nan  step_loss : nan  learning_rate : 0.0008066356426802014 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  32768.0
[2022-11-26 05:51:29.945168] Finished iteration 269, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2222.695
DLL 2022-11-26 05:51:29.950516 - Training Epoch: 0 Training Iteration: 270  average_loss : nan  step_loss : nan  learning_rate : 0.0008096342881920237 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  16384.0
[2022-11-26 05:51:32.212109] Finished iteration 270, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2266.941
DLL 2022-11-26 05:51:32.217153 - Training Epoch: 0 Training Iteration: 271  average_loss : nan  step_loss : nan  learning_rate : 0.000812632933703846 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  8192.0
[2022-11-26 05:51:34.442119] Finished iteration 271, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2229.993
DLL 2022-11-26 05:51:34.447419 - Training Epoch: 0 Training Iteration: 272  average_loss : nan  step_loss : nan  learning_rate : 0.0008156315792156683 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  4096.0
[2022-11-26 05:51:36.690630] Finished iteration 272, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2248.457
DLL 2022-11-26 05:51:36.695641 - Training Epoch: 0 Training Iteration: 273  average_loss : nan  step_loss : nan  learning_rate : 0.0008186302247274905 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  2048.0
[2022-11-26 05:51:38.871358] Finished iteration 273, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2180.696
DLL 2022-11-26 05:51:38.876302 - Training Epoch: 0 Training Iteration: 274  average_loss : nan  step_loss : nan  learning_rate : 0.000821628870239313 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1024.0
[2022-11-26 05:51:41.090971] Finished iteration 274, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2219.568
DLL 2022-11-26 05:51:41.096078 - Training Epoch: 0 Training Iteration: 275  average_loss : nan  step_loss : nan  learning_rate : 0.0008246275157511352 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  512.0
[2022-11-26 05:51:43.341805] Finished iteration 275, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2250.840
DLL 2022-11-26 05:51:43.347017 - Training Epoch: 0 Training Iteration: 276  average_loss : nan  step_loss : nan  learning_rate : 0.0008276261612629576 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  256.0
[2022-11-26 05:51:45.618692] Finished iteration 276, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2276.840
DLL 2022-11-26 05:51:45.624173 - Training Epoch: 0 Training Iteration: 277  average_loss : nan  step_loss : nan  learning_rate : 0.0008306248067747799 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  128.0
[2022-11-26 05:51:47.852431] Finished iteration 277, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2233.705
DLL 2022-11-26 05:51:47.857377 - Training Epoch: 0 Training Iteration: 278  average_loss : nan  step_loss : nan  learning_rate : 0.0008336234522866021 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  64.0
[2022-11-26 05:51:50.621418] Finished iteration 278, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2768.963
DLL 2022-11-26 05:51:50.626887 - Training Epoch: 0 Training Iteration: 279  average_loss : nan  step_loss : nan  learning_rate : 0.0008366220977984245 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  32.0
[2022-11-26 05:51:52.849544] Finished iteration 279, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2228.084
DLL 2022-11-26 05:51:52.854815 - Training Epoch: 0 Training Iteration: 280  average_loss : nan  step_loss : nan  learning_rate : 0.0008396207433102468 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  16.0
[2022-11-26 05:51:55.101210] Finished iteration 280, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2251.645
DLL 2022-11-26 05:51:55.106017 - Training Epoch: 0 Training Iteration: 281  average_loss : nan  step_loss : nan  learning_rate : 0.000842619388822069 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  8.0
[2022-11-26 05:51:57.327945] Finished iteration 281, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2226.723
DLL 2022-11-26 05:51:57.333496 - Training Epoch: 0 Training Iteration: 282  average_loss : nan  step_loss : nan  learning_rate : 0.0008456180343338914 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  4.0
[2022-11-26 05:51:59.561325] Finished iteration 282, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2233.331
DLL 2022-11-26 05:51:59.566246 - Training Epoch: 0 Training Iteration: 283  average_loss : nan  step_loss : nan  learning_rate : 0.0008486166798457137 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  2.0
[2022-11-26 05:52:01.874631] Finished iteration 283, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2313.281
DLL 2022-11-26 05:52:01.879954 - Training Epoch: 0 Training Iteration: 284  average_loss : nan  step_loss : nan  learning_rate : 0.0008516153253575361 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:52:04.148533] Finished iteration 284, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2273.859
DLL 2022-11-26 05:52:04.153438 - Training Epoch: 0 Training Iteration: 285  average_loss : nan  step_loss : nan  learning_rate : 0.0008546139708693584 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:52:06.429684] Finished iteration 285, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2281.124
DLL 2022-11-26 05:52:06.434830 - Training Epoch: 0 Training Iteration: 286  average_loss : nan  step_loss : nan  learning_rate : 0.0008576126163811806 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:52:08.717535] Finished iteration 286, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2287.833
DLL 2022-11-26 05:52:08.722975 - Training Epoch: 0 Training Iteration: 287  average_loss : nan  step_loss : nan  learning_rate : 0.000860611261893003 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:52:10.942928] Finished iteration 287, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2225.362
DLL 2022-11-26 05:52:10.947798 - Training Epoch: 0 Training Iteration: 288  average_loss : nan  step_loss : nan  learning_rate : 0.0008636099074048253 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:52:13.214038] Finished iteration 288, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2271.077
DLL 2022-11-26 05:52:13.218956 - Training Epoch: 0 Training Iteration: 289  average_loss : nan  step_loss : nan  learning_rate : 0.0008666085529166475 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:52:15.482093] Finished iteration 289, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2268.028
DLL 2022-11-26 05:52:15.487061 - Training Epoch: 0 Training Iteration: 290  average_loss : nan  step_loss : nan  learning_rate : 0.0008696071984284699 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:52:17.733973] Finished iteration 290, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2251.827
DLL 2022-11-26 05:52:17.739010 - Training Epoch: 0 Training Iteration: 291  average_loss : nan  step_loss : nan  learning_rate : 0.0008726058439402921 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:52:19.983599] Finished iteration 291, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2249.592
DLL 2022-11-26 05:52:19.988865 - Training Epoch: 0 Training Iteration: 292  average_loss : nan  step_loss : nan  learning_rate : 0.0008756044894521145 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:52:22.276290] Finished iteration 292, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2292.667
DLL 2022-11-26 05:52:22.281352 - Training Epoch: 0 Training Iteration: 293  average_loss : nan  step_loss : nan  learning_rate : 0.0008786031349639369 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:52:24.510448] Finished iteration 293, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2234.125
DLL 2022-11-26 05:52:24.515633 - Training Epoch: 0 Training Iteration: 294  average_loss : nan  step_loss : nan  learning_rate : 0.0008816017804757592 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:52:26.790329] Finished iteration 294, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2279.842
DLL 2022-11-26 05:52:26.795685 - Training Epoch: 0 Training Iteration: 295  average_loss : nan  step_loss : nan  learning_rate : 0.0008846004259875814 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:52:29.093863] Finished iteration 295, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2303.520
DLL 2022-11-26 05:52:29.098861 - Training Epoch: 0 Training Iteration: 296  average_loss : nan  step_loss : nan  learning_rate : 0.0008875990714994038 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:52:31.325113] Finished iteration 296, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2231.240
DLL 2022-11-26 05:52:31.330231 - Training Epoch: 0 Training Iteration: 297  average_loss : nan  step_loss : nan  learning_rate : 0.0008905977170112259 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:52:33.573817] Finished iteration 297, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2248.660
DLL 2022-11-26 05:52:33.579367 - Training Epoch: 0 Training Iteration: 298  average_loss : nan  step_loss : nan  learning_rate : 0.0008935963625230486 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:52:35.801140] Finished iteration 298, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2227.288
DLL 2022-11-26 05:52:35.805996 - Training Epoch: 0 Training Iteration: 299  average_loss : nan  step_loss : nan  learning_rate : 0.0008965950080348708 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:52:38.038171] Finished iteration 299, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2237.049
DLL 2022-11-26 05:52:38.043411 - Training Epoch: 0 Training Iteration: 300  average_loss : nan  step_loss : nan  learning_rate : 0.0008995936535466931 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:52:40.278421] Finished iteration 300, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2240.178
DLL 2022-11-26 05:52:40.283428 - Training Epoch: 0 Training Iteration: 301  average_loss : nan  step_loss : nan  learning_rate : 0.0009025922990585153 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:52:42.585459] Finished iteration 301, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2306.998
DLL 2022-11-26 05:52:42.590520 - Training Epoch: 0 Training Iteration: 302  average_loss : nan  step_loss : nan  learning_rate : 0.0009055909445703376 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:52:44.818044] Finished iteration 302, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2232.554
DLL 2022-11-26 05:52:44.823010 - Training Epoch: 0 Training Iteration: 303  average_loss : nan  step_loss : nan  learning_rate : 0.00090858959008216 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:52:47.087741] Finished iteration 303, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2269.636
DLL 2022-11-26 05:52:47.092669 - Training Epoch: 0 Training Iteration: 304  average_loss : nan  step_loss : nan  learning_rate : 0.0009115882355939822 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:52:49.571404] Finished iteration 304, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2483.636
DLL 2022-11-26 05:52:49.576632 - Training Epoch: 0 Training Iteration: 305  average_loss : nan  step_loss : nan  learning_rate : 0.0009145868811058045 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:52:51.804740] Finished iteration 305, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2233.315
DLL 2022-11-26 05:52:51.810165 - Training Epoch: 0 Training Iteration: 306  average_loss : nan  step_loss : nan  learning_rate : 0.0009175855266176267 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:52:54.085338] Finished iteration 306, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2280.558
DLL 2022-11-26 05:52:54.090369 - Training Epoch: 0 Training Iteration: 307  average_loss : nan  step_loss : nan  learning_rate : 0.0009205841721294492 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:52:56.325932] Finished iteration 307, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2240.566
DLL 2022-11-26 05:52:56.331227 - Training Epoch: 0 Training Iteration: 308  average_loss : nan  step_loss : nan  learning_rate : 0.0009235828176412715 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:52:58.561067] Finished iteration 308, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2235.175
DLL 2022-11-26 05:52:58.568155 - Training Epoch: 0 Training Iteration: 309  average_loss : nan  step_loss : nan  learning_rate : 0.0009265814631530939 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:53:00.819842] Finished iteration 309, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2258.658
DLL 2022-11-26 05:53:00.824986 - Training Epoch: 0 Training Iteration: 310  average_loss : nan  step_loss : nan  learning_rate : 0.0009295801086649161 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:53:03.065701] Finished iteration 310, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2245.845
DLL 2022-11-26 05:53:03.071274 - Training Epoch: 0 Training Iteration: 311  average_loss : nan  step_loss : nan  learning_rate : 0.0009325787541767384 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:53:05.377791] Finished iteration 311, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2312.053
DLL 2022-11-26 05:53:05.382461 - Training Epoch: 0 Training Iteration: 312  average_loss : nan  step_loss : nan  learning_rate : 0.0009355773996885606 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:53:07.985930] Finished iteration 312, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2608.126
DLL 2022-11-26 05:53:07.991281 - Training Epoch: 0 Training Iteration: 313  average_loss : nan  step_loss : nan  learning_rate : 0.0009385760452003831 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:53:10.180328] Finished iteration 313, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2194.365
DLL 2022-11-26 05:53:10.185391 - Training Epoch: 0 Training Iteration: 314  average_loss : nan  step_loss : nan  learning_rate : 0.0009415746907122053 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:53:12.449988] Finished iteration 314, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2269.609
DLL 2022-11-26 05:53:12.454911 - Training Epoch: 0 Training Iteration: 315  average_loss : nan  step_loss : nan  learning_rate : 0.0009445733362240278 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:53:14.691017] Finished iteration 315, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2241.024
DLL 2022-11-26 05:53:14.696148 - Training Epoch: 0 Training Iteration: 316  average_loss : nan  step_loss : nan  learning_rate : 0.0009475719817358499 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:53:16.966350] Finished iteration 316, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2275.321
DLL 2022-11-26 05:53:16.971424 - Training Epoch: 0 Training Iteration: 317  average_loss : nan  step_loss : nan  learning_rate : 0.0009505706272476723 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:53:19.230915] Finished iteration 317, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2264.540
DLL 2022-11-26 05:53:19.235966 - Training Epoch: 0 Training Iteration: 318  average_loss : nan  step_loss : nan  learning_rate : 0.0009535692727594946 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:53:22.485975] Finished iteration 318, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3254.994
DLL 2022-11-26 05:53:22.490527 - Training Epoch: 0 Training Iteration: 319  average_loss : nan  step_loss : nan  learning_rate : 0.0009565679182713168 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:53:25.325901] Finished iteration 319, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2839.908
DLL 2022-11-26 05:53:25.331183 - Training Epoch: 0 Training Iteration: 320  average_loss : nan  step_loss : nan  learning_rate : 0.0009595665637831392 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:53:27.568101] Finished iteration 320, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2242.170
DLL 2022-11-26 05:53:27.573095 - Training Epoch: 0 Training Iteration: 321  average_loss : nan  step_loss : nan  learning_rate : 0.0009625652092949614 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:53:29.897377] Finished iteration 321, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2329.240
DLL 2022-11-26 05:53:29.902159 - Training Epoch: 0 Training Iteration: 322  average_loss : nan  step_loss : nan  learning_rate : 0.0009655638548067837 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:53:32.113549] Finished iteration 322, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2216.146
DLL 2022-11-26 05:53:32.119029 - Training Epoch: 0 Training Iteration: 323  average_loss : nan  step_loss : nan  learning_rate : 0.0009685625003186062 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:53:34.354628] Finished iteration 323, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2241.053
DLL 2022-11-26 05:53:34.360038 - Training Epoch: 0 Training Iteration: 324  average_loss : nan  step_loss : nan  learning_rate : 0.0009715611458304285 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:53:36.665127] Finished iteration 324, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2310.457
DLL 2022-11-26 05:53:36.670406 - Training Epoch: 0 Training Iteration: 325  average_loss : nan  step_loss : nan  learning_rate : 0.0009745597913422507 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:53:38.954143] Finished iteration 325, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2289.047
DLL 2022-11-26 05:53:38.959650 - Training Epoch: 0 Training Iteration: 326  average_loss : nan  step_loss : nan  learning_rate : 0.000977558436854073 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:53:41.158927] Finished iteration 326, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2204.710
DLL 2022-11-26 05:53:41.164074 - Training Epoch: 0 Training Iteration: 327  average_loss : nan  step_loss : nan  learning_rate : 0.0009805570823658953 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:53:43.434542] Finished iteration 327, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2275.580
DLL 2022-11-26 05:53:43.439758 - Training Epoch: 0 Training Iteration: 328  average_loss : nan  step_loss : nan  learning_rate : 0.0009835557278777176 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:53:45.666232] Finished iteration 328, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2231.704
DLL 2022-11-26 05:53:45.671423 - Training Epoch: 0 Training Iteration: 329  average_loss : nan  step_loss : nan  learning_rate : 0.00098655437338954 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:53:47.917831] Finished iteration 329, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2251.519
DLL 2022-11-26 05:53:47.923061 - Training Epoch: 0 Training Iteration: 330  average_loss : nan  step_loss : nan  learning_rate : 0.0009895530189013625 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:53:50.199148] Finished iteration 330, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2281.299
DLL 2022-11-26 05:53:50.204178 - Training Epoch: 0 Training Iteration: 331  average_loss : nan  step_loss : nan  learning_rate : 0.0009925516644131846 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:53:52.486989] Finished iteration 331, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2287.817
DLL 2022-11-26 05:53:52.492091 - Training Epoch: 0 Training Iteration: 332  average_loss : nan  step_loss : nan  learning_rate : 0.0009955503099250069 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:53:54.707156] Finished iteration 332, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2220.135
DLL 2022-11-26 05:53:54.712439 - Training Epoch: 0 Training Iteration: 333  average_loss : nan  step_loss : nan  learning_rate : 0.0009985489554368292 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:53:56.933470] Finished iteration 333, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2226.283
DLL 2022-11-26 05:53:56.938585 - Training Epoch: 0 Training Iteration: 334  average_loss : nan  step_loss : nan  learning_rate : 0.0010015476009486515 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:53:59.180885] Finished iteration 334, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2247.371
DLL 2022-11-26 05:53:59.185969 - Training Epoch: 0 Training Iteration: 335  average_loss : nan  step_loss : nan  learning_rate : 0.0010045462464604738 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:54:01.445794] Finished iteration 335, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2264.908
DLL 2022-11-26 05:54:01.450893 - Training Epoch: 0 Training Iteration: 336  average_loss : nan  step_loss : nan  learning_rate : 0.0010075448919722961 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:54:03.684868] Finished iteration 336, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2239.051
DLL 2022-11-26 05:54:03.689868 - Training Epoch: 0 Training Iteration: 337  average_loss : nan  step_loss : nan  learning_rate : 0.0010105435374841184 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:54:05.939638] Finished iteration 337, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2254.732
DLL 2022-11-26 05:54:05.945202 - Training Epoch: 0 Training Iteration: 338  average_loss : nan  step_loss : nan  learning_rate : 0.0010135421829959408 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:54:08.161723] Finished iteration 338, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2222.048
DLL 2022-11-26 05:54:08.166729 - Training Epoch: 0 Training Iteration: 339  average_loss : nan  step_loss : nan  learning_rate : 0.001016540828507763 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:54:10.418426] Finished iteration 339, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2256.662
DLL 2022-11-26 05:54:10.423497 - Training Epoch: 0 Training Iteration: 340  average_loss : nan  step_loss : nan  learning_rate : 0.0010195394740195854 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:54:12.671128] Finished iteration 340, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2252.691
DLL 2022-11-26 05:54:12.676302 - Training Epoch: 0 Training Iteration: 341  average_loss : nan  step_loss : nan  learning_rate : 0.0010225381195314077 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:54:15.029503] Finished iteration 341, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2358.343
DLL 2022-11-26 05:54:15.034947 - Training Epoch: 0 Training Iteration: 342  average_loss : nan  step_loss : nan  learning_rate : 0.0010255367650432298 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:54:17.308007] Finished iteration 342, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2278.471
DLL 2022-11-26 05:54:17.313212 - Training Epoch: 0 Training Iteration: 343  average_loss : nan  step_loss : nan  learning_rate : 0.0010285354105550523 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:54:19.566359] Finished iteration 343, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2258.339
DLL 2022-11-26 05:54:19.571484 - Training Epoch: 0 Training Iteration: 344  average_loss : nan  step_loss : nan  learning_rate : 0.0010315340560668746 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:54:22.028816] Finished iteration 344, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2462.421
DLL 2022-11-26 05:54:22.034100 - Training Epoch: 0 Training Iteration: 345  average_loss : nan  step_loss : nan  learning_rate : 0.001034532701578697 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:54:24.836834] Finished iteration 345, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2807.978
DLL 2022-11-26 05:54:24.842167 - Training Epoch: 0 Training Iteration: 346  average_loss : nan  step_loss : nan  learning_rate : 0.0010375313470905193 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:54:27.064170] Finished iteration 346, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2227.304
DLL 2022-11-26 05:54:27.069167 - Training Epoch: 0 Training Iteration: 347  average_loss : nan  step_loss : nan  learning_rate : 0.0010405299926023416 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:54:29.308852] Finished iteration 347, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2244.654
DLL 2022-11-26 05:54:29.313822 - Training Epoch: 0 Training Iteration: 348  average_loss : nan  step_loss : nan  learning_rate : 0.0010435286381141639 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:54:31.585322] Finished iteration 348, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2276.466
DLL 2022-11-26 05:54:31.590389 - Training Epoch: 0 Training Iteration: 349  average_loss : nan  step_loss : nan  learning_rate : 0.0010465272836259862 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:54:33.865682] Finished iteration 349, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2280.310
DLL 2022-11-26 05:54:33.870810 - Training Epoch: 0 Training Iteration: 350  average_loss : nan  step_loss : nan  learning_rate : 0.0010495259291378085 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:54:36.414476] Finished iteration 350, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2548.777
DLL 2022-11-26 05:54:36.419325 - Training Epoch: 0 Training Iteration: 351  average_loss : nan  step_loss : nan  learning_rate : 0.0010525245746496306 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:54:39.213594] Finished iteration 351, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2799.074
DLL 2022-11-26 05:54:39.218710 - Training Epoch: 0 Training Iteration: 352  average_loss : nan  step_loss : nan  learning_rate : 0.0010555232201614531 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:54:41.441129] Finished iteration 352, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2227.503
DLL 2022-11-26 05:54:41.446348 - Training Epoch: 0 Training Iteration: 353  average_loss : nan  step_loss : nan  learning_rate : 0.0010585218656732755 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:54:43.685571] Finished iteration 353, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2244.415
DLL 2022-11-26 05:54:43.690829 - Training Epoch: 0 Training Iteration: 354  average_loss : nan  step_loss : nan  learning_rate : 0.0010615205111850978 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:54:46.523739] Finished iteration 354, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2838.130
DLL 2022-11-26 05:54:46.529052 - Training Epoch: 0 Training Iteration: 355  average_loss : nan  step_loss : nan  learning_rate : 0.00106451915669692 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:54:49.098767] Finished iteration 355, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2575.007
DLL 2022-11-26 05:54:49.104252 - Training Epoch: 0 Training Iteration: 356  average_loss : nan  step_loss : nan  learning_rate : 0.0010675178022087424 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:54:51.380681] Finished iteration 356, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2281.892
DLL 2022-11-26 05:54:51.385706 - Training Epoch: 0 Training Iteration: 357  average_loss : nan  step_loss : nan  learning_rate : 0.0010705164477205647 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:54:53.621759] Finished iteration 357, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2241.045
DLL 2022-11-26 05:54:53.627041 - Training Epoch: 0 Training Iteration: 358  average_loss : nan  step_loss : nan  learning_rate : 0.001073515093232387 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:54:55.899033] Finished iteration 358, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2277.242
DLL 2022-11-26 05:54:55.903869 - Training Epoch: 0 Training Iteration: 359  average_loss : nan  step_loss : nan  learning_rate : 0.0010765137387442093 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:54:58.163045] Finished iteration 359, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2263.972
DLL 2022-11-26 05:54:58.167950 - Training Epoch: 0 Training Iteration: 360  average_loss : nan  step_loss : nan  learning_rate : 0.0010795123842560316 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:55:00.443807] Finished iteration 360, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2280.748
DLL 2022-11-26 05:55:00.449384 - Training Epoch: 0 Training Iteration: 361  average_loss : nan  step_loss : nan  learning_rate : 0.0010825110297678537 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:55:02.735660] Finished iteration 361, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2291.827
DLL 2022-11-26 05:55:02.740826 - Training Epoch: 0 Training Iteration: 362  average_loss : nan  step_loss : nan  learning_rate : 0.0010855096752796763 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:55:05.036918] Finished iteration 362, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2301.227
DLL 2022-11-26 05:55:05.041848 - Training Epoch: 0 Training Iteration: 363  average_loss : nan  step_loss : nan  learning_rate : 0.0010885083207914986 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:55:07.279487] Finished iteration 363, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2242.537
DLL 2022-11-26 05:55:07.284934 - Training Epoch: 0 Training Iteration: 364  average_loss : nan  step_loss : nan  learning_rate : 0.0010915069663033207 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:55:09.546851] Finished iteration 364, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2267.320
DLL 2022-11-26 05:55:09.552234 - Training Epoch: 0 Training Iteration: 365  average_loss : nan  step_loss : nan  learning_rate : 0.0010945056118151432 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:55:11.866053] Finished iteration 365, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2319.236
DLL 2022-11-26 05:55:11.871081 - Training Epoch: 0 Training Iteration: 366  average_loss : nan  step_loss : nan  learning_rate : 0.0010975042573269653 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:55:14.140703] Finished iteration 366, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2274.569
DLL 2022-11-26 05:55:14.145681 - Training Epoch: 0 Training Iteration: 367  average_loss : nan  step_loss : nan  learning_rate : 0.0011005029028387878 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:55:16.348153] Finished iteration 367, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2207.420
DLL 2022-11-26 05:55:16.353124 - Training Epoch: 0 Training Iteration: 368  average_loss : nan  step_loss : nan  learning_rate : 0.0011035015483506101 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:55:18.606869] Finished iteration 368, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2258.691
DLL 2022-11-26 05:55:18.611836 - Training Epoch: 0 Training Iteration: 369  average_loss : nan  step_loss : nan  learning_rate : 0.0011065001938624325 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:55:20.931209] Finished iteration 369, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2324.301
DLL 2022-11-26 05:55:20.936109 - Training Epoch: 0 Training Iteration: 370  average_loss : nan  step_loss : nan  learning_rate : 0.0011094988393742546 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:55:23.234627] Finished iteration 370, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2303.399
DLL 2022-11-26 05:55:23.239894 - Training Epoch: 0 Training Iteration: 371  average_loss : nan  step_loss : nan  learning_rate : 0.001112497484886077 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:55:25.486221] Finished iteration 371, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2251.609
DLL 2022-11-26 05:55:25.491589 - Training Epoch: 0 Training Iteration: 372  average_loss : nan  step_loss : nan  learning_rate : 0.0011154961303978994 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:55:27.737840] Finished iteration 372, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2251.554
DLL 2022-11-26 05:55:27.743082 - Training Epoch: 0 Training Iteration: 373  average_loss : nan  step_loss : nan  learning_rate : 0.0011184947759097215 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:55:30.007706] Finished iteration 373, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2269.840
DLL 2022-11-26 05:55:30.013001 - Training Epoch: 0 Training Iteration: 374  average_loss : nan  step_loss : nan  learning_rate : 0.001121493421421544 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:55:32.218010] Finished iteration 374, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2210.279
DLL 2022-11-26 05:55:32.223327 - Training Epoch: 0 Training Iteration: 375  average_loss : nan  step_loss : nan  learning_rate : 0.0011244920669333661 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:55:34.468207] Finished iteration 375, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2250.170
DLL 2022-11-26 05:55:34.473180 - Training Epoch: 0 Training Iteration: 376  average_loss : nan  step_loss : nan  learning_rate : 0.0011274907124451884 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:55:36.772941] Finished iteration 376, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2304.715
DLL 2022-11-26 05:55:36.778094 - Training Epoch: 0 Training Iteration: 377  average_loss : nan  step_loss : nan  learning_rate : 0.0011304893579570108 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:55:39.064723] Finished iteration 377, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2291.728
DLL 2022-11-26 05:55:39.069868 - Training Epoch: 0 Training Iteration: 378  average_loss : nan  step_loss : nan  learning_rate : 0.0011334880034688333 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:55:41.335759] Finished iteration 378, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2271.010
DLL 2022-11-26 05:55:41.341180 - Training Epoch: 0 Training Iteration: 379  average_loss : nan  step_loss : nan  learning_rate : 0.0011364866489806554 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:55:43.561299] Finished iteration 379, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2225.517
DLL 2022-11-26 05:55:43.566512 - Training Epoch: 0 Training Iteration: 380  average_loss : nan  step_loss : nan  learning_rate : 0.0011394852944924777 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:55:45.792095] Finished iteration 380, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2230.761
DLL 2022-11-26 05:55:45.797008 - Training Epoch: 0 Training Iteration: 381  average_loss : nan  step_loss : nan  learning_rate : 0.0011424839400043 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:55:48.113046] Finished iteration 381, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2320.920
DLL 2022-11-26 05:55:48.118094 - Training Epoch: 0 Training Iteration: 382  average_loss : nan  step_loss : nan  learning_rate : 0.0011454825855161225 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:55:50.327931] Finished iteration 382, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2214.859
DLL 2022-11-26 05:55:50.332967 - Training Epoch: 0 Training Iteration: 383  average_loss : nan  step_loss : nan  learning_rate : 0.0011484812310279446 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:55:52.559802] Finished iteration 383, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2231.840
DLL 2022-11-26 05:55:52.564783 - Training Epoch: 0 Training Iteration: 384  average_loss : nan  step_loss : nan  learning_rate : 0.0011514798765397672 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:55:54.834767] Finished iteration 384, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2274.929
DLL 2022-11-26 05:55:54.839937 - Training Epoch: 0 Training Iteration: 385  average_loss : nan  step_loss : nan  learning_rate : 0.0011544785220515893 
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 0 signal handler called with signal 10
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 05:55:57.128286] Finished iteration 385, CKPT_AND_STOP: True, flag: tensor([1], dtype=torch.int32), speed: 2293.489
DLL 2022-11-26 05:55:57.133679 - Training Epoch: 0 Training Iteration: 386  average_loss : nan  step_loss : nan  learning_rate : 0.0011574771675634116 
2022-11-26 05:55:57.133798 Begin to save checkpont to s3://spot-checkpoints/bert and exit
DLL 2022-11-26 05:55:57.133823 - PARAMETER checkpoint_step : 386 
Opt ckpt time 8.31177568435669
Process done with return code 0
Parent process ID: 93362 node: 172.31.28.108
24 cutpoints
Stages 1
Micro-bs 8 Max mem: 14622140211.200005
Predicted microbatch size for 1: 8
comm size 0
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 1 5 0 2493369.62890625 0
End of simulation:  Mini-batch time (usec) = 4144382
Min send: 10000000, max send 0
Min long send: 10000000, max long send 0
Min fwd: 10000000, max fwd 0; min bwd 10000000, max bwd 0
Min long fwd: 141043, max long fwd 144458; min long bwd 184920, max long bwd 191040
Time taken by simulation: 51 microseconds

Stages 2
Micro-bs 8 Max mem: 7660942131.200001
Predicted microbatch size for 2: 8
comm size 4194304
WARNING: no send time found, 2 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 2 9 0 970375.4272460938 248719.58977934244
End of simulation:  Mini-batch time (usec) = 3283515
Min send: 10000000, max send 0
Min long send: 249051, max long send 268766
Min fwd: 79750, max fwd 86627; min bwd 87708, max bwd 94754
Min long fwd: 58189, max long fwd 63385; min long bwd 92867, max long bwd 97330
Time taken by simulation: 253 microseconds

Stages 3
Micro-bs 8 Max mem: 5497876480.0
Predicted microbatch size for 3: 8
comm size 4194304
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 13 0 485476.6540527344 248719.58977934244
End of simulation:  Mini-batch time (usec) = 3469734
Min send: 10000000, max send 0
Min long send: 248801, max long send 271185
Min fwd: 34426, max fwd 67951; min bwd 53890, max bwd 64826
Min long fwd: 37108, max long fwd 45662; min long bwd 64919, max long bwd 72155
Time taken by simulation: 522 microseconds

Stages 4
Micro-bs 8 Max mem: 4406266675.2
Predicted microbatch size for 4: 8
comm size 4194304
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 19 0 352272.7355957031 248719.58977934244
End of simulation:  Mini-batch time (usec) = 4275253
Min send: 10000000, max send 0
Min long send: 248773, max long send 273424
Min fwd: 22410, max fwd 61283; min bwd 39748, max bwd 51303
Min long fwd: 29385, max long fwd 37648; min long bwd 47928, max long bwd 54735
Time taken by simulation: 857 microseconds

Stages 6
Micro-bs 8 Max mem: 3314656870.4
Predicted microbatch size for 6: 8
comm size 4194304
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 26 0 254962.82958984375 248719.58977934244
End of simulation:  Mini-batch time (usec) = 5944030
Min send: 10000000, max send 0
Min long send: 248735, max long send 278723
Min fwd: 10836, max fwd 44441; min bwd 24199, max bwd 35953
Min long fwd: 21303, max long fwd 29429; min long bwd 33298, max long bwd 40795
Time taken by simulation: 1956 microseconds

Stages 8
Micro-bs 8 Max mem: 2758774988.8
Predicted microbatch size for 8: 8
comm size 4194304
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 43 0 178155.74645996094 248719.58977934244
End of simulation:  Mini-batch time (usec) = 9019309
Min send: 10000000, max send 0
Min long send: 248735, max long send 276940
Min fwd: 5776, max fwd 41014; min bwd 16548, max bwd 29492
Min long fwd: 17309, max long fwd 25772; min long bwd 25282, max long bwd 32088
Time taken by simulation: 4420 microseconds

Stages 12
Micro-bs 8 Max mem: 2202893107.2
Predicted microbatch size for 12: 8
comm size 4194304
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 64 0 117116.2109375 248719.58977934244
End of simulation:  Mini-batch time (usec) = 13687683
Min send: 10000000, max send 0
Min long send: 248720, max long send 280797
Min fwd: 141, max fwd 25024; min bwd 6433, max bwd 23373
Min long fwd: 7201, max long fwd 18161; min long bwd 16833, max long bwd 28389
Time taken by simulation: 10952 microseconds

{1: 4.144382, 2: 3.283515, 3: 3.469734, 4: 4.275253, 6: 5.94403, 8: 9.019309, 12: 13.687683}
{1: 8, 2: 8, 3: 8, 4: 8, 6: 8, 8: 8, 12: 8}
best config is: 2 8
expected time is 3.283515
15 per stage
30 servers!
Config:
ranks: range(0, 1)
train batch size: 1024
partitions: 2
chunk_size: 8
data depth: 15
stage to rank map: 0,2,4,6,8,10,12,14,16,18,20,22,24,26,28;1,3,5,7,9,11,13,15,17,19,21,23,25,27,29;
World size is 30
/opt/conda/envs/varuna/bin/python -u /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --rank=0 --chunk_size=8 --local_rank=0 --stage_to_rank_map=0,2,4,6,8,10,12,14,16,18,20,22,24,26,28;1,3,5,7,9,11,13,15,17,19,21,23,25,27,29; --batch-size=68 --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna --resume_step 386
device: cuda:0 n_gpu: 1, distributed training: True, 16-bits training: True
DLL 2022-11-26 05:56:26.446818 - PARAMETER Config : ["Namespace(input_dir='/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/', config_file='bert_config.json', bert_model='bert-large-uncased', output_dir='s3://spot-checkpoints/bert', init_checkpoint=None, max_seq_length=128, max_predictions_per_seq=20, train_batch_size=68, learning_rate=0.006, num_train_epochs=3.0, max_steps=7038.0, warmup_proportion=0.2843, local_rank=0, seed=12439, gradient_accumulation_steps=1, fp16=True, amp=False, loss_scale=0.0, log_freq=1.0, checkpoint_activations=False, resume_from_checkpoint=True, resume_step=386, num_steps_per_checkpoint=200, skip_checkpoint=False, phase2=False, allreduce_post_accumulation=False, allreduce_post_accumulation_fp16=False, phase1_end_step=7038, init_loss_scale=1048576, do_train=True, json_summary='/home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json', use_env=False, disable_progress_bar=False, steps_this_run=7038.0, varuna=True, stage_to_rank_map='0,2,4,6,8,10,12,14,16,18,20,22,24,26,28;1,3,5,7,9,11,13,15,17,19,21,23,25,27,29;', chunk_size=8, batch_size=68, rank=0, profiling=False, n_gpu=1)"] 
dry run time 0.13636040687561035
SHARED WEIGHTS ARE
[(0, 1)]
this rank  0 is part of pipeline replica  0
9 chunks
Begin to load checkpint from s3://spot-checkpoints/bert/ckpt_386.pt
2022-11-26 05:56:36.954967 resume step from  386
Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.

Defaults for this optimization level are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 0 signal handler called with signal 10
2022-11-26 05:57:33.144131 - Finished loading checkpoint, takes 56.162 secs
DLL 2022-11-26 05:57:33.144974 - PARAMETER SEED : 12439 
DLL 2022-11-26 05:57:33.145088 - PARAMETER train_start : True 
DLL 2022-11-26 05:57:33.145149 - PARAMETER batch_size_per_gpu : 68 
DLL 2022-11-26 05:57:33.145185 - PARAMETER learning_rate : 0.006 
2022-11-26 05:58:00.583509 Begin to exit
Process done with return code 0
Parent process ID: 94942 node: 172.31.28.108
24 cutpoints
Stages 1
Micro-bs 8 Max mem: 14622140211.200005
Predicted microbatch size for 1: 8
comm size 0
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 1 4 0 3598379.5166015625 0
End of simulation:  Mini-batch time (usec) = 4923429
Min send: 10000000, max send 0
Min long send: 10000000, max long send 0
Min fwd: 10000000, max fwd 0; min bwd 10000000, max bwd 0
Min long fwd: 142174, max long fwd 144458; min long bwd 186536, max long bwd 191040
Time taken by simulation: 40 microseconds

Stages 2
Micro-bs 8 Max mem: 7660942131.200001
Predicted microbatch size for 2: 8
comm size 4194304
WARNING: no send time found, 2 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 2 8 0 954047.119140625 248719.58977934244
End of simulation:  Mini-batch time (usec) = 3096062
Min send: 10000000, max send 0
Min long send: 249051, max long send 268766
Min fwd: 79507, max fwd 86627; min bwd 88131, max bwd 94131
Min long fwd: 58556, max long fwd 63385; min long bwd 92867, max long bwd 97582
Time taken by simulation: 168 microseconds

Stages 3
Micro-bs 8 Max mem: 5497876480.0
Predicted microbatch size for 3: 8
comm size 4194304
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 13 0 485476.6540527344 248719.58977934244
End of simulation:  Mini-batch time (usec) = 3469734
Min send: 10000000, max send 0
Min long send: 248801, max long send 271185
Min fwd: 34426, max fwd 67951; min bwd 53890, max bwd 64826
Min long fwd: 37108, max long fwd 45662; min long bwd 64919, max long bwd 72155
Time taken by simulation: 475 microseconds

Stages 4
Micro-bs 8 Max mem: 4406266675.2
Predicted microbatch size for 4: 8
comm size 4194304
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 16 0 364488.09814453125 248719.58977934244
End of simulation:  Mini-batch time (usec) = 3900556
Min send: 10000000, max send 0
Min long send: 248773, max long send 273424
Min fwd: 20622, max fwd 60312; min bwd 40311, max bwd 50179
Min long fwd: 29744, max long fwd 36491; min long bwd 47928, max long bwd 56568
Time taken by simulation: 769 microseconds

Stages 6
Micro-bs 8 Max mem: 3314656870.4
Predicted microbatch size for 6: 8
comm size 4194304
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 26 0 254962.82958984375 248719.58977934244
End of simulation:  Mini-batch time (usec) = 5944030
Min send: 10000000, max send 0
Min long send: 248735, max long send 278723
Min fwd: 10836, max fwd 44441; min bwd 24199, max bwd 35953
Min long fwd: 21303, max long fwd 29429; min long bwd 33298, max long bwd 40795
Time taken by simulation: 1965 microseconds

Stages 8
Micro-bs 8 Max mem: 2758774988.8
Predicted microbatch size for 8: 8
comm size 4194304
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 32 0 244280.30395507812 248719.58977934244
End of simulation:  Mini-batch time (usec) = 7674225
Min send: 10000000, max send 0
Min long send: 248719, max long send 278723
Min fwd: 6779, max fwd 41103; min bwd 15994, max bwd 28589
Min long fwd: 18906, max long fwd 26091; min long bwd 25267, max long bwd 32480
Time taken by simulation: 3370 microseconds

Stages 12
Micro-bs 8 Max mem: 2202893107.2
Predicted microbatch size for 12: 8
comm size 4194304
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 64 0 117116.2109375 248719.58977934244
End of simulation:  Mini-batch time (usec) = 13687683
Min send: 10000000, max send 0
Min long send: 248720, max long send 280797
Min fwd: 141, max fwd 25024; min bwd 6433, max bwd 23373
Min long fwd: 7201, max long fwd 18161; min long bwd 16833, max long bwd 28389
Time taken by simulation: 11284 microseconds

{1: 4.923429, 2: 3.096062, 3: 3.469734, 4: 3.900556, 6: 5.94403, 8: 7.674225, 12: 13.687683}
{1: 8, 2: 8, 3: 8, 4: 8, 6: 8, 8: 8, 12: 8}
best config is: 2 8
expected time is 3.096062
16 per stage
32 servers!
Config:
ranks: range(0, 1)
train batch size: 1024
partitions: 2
chunk_size: 8
data depth: 16
stage to rank map: 0,2,4,6,8,10,12,14,16,18,20,22,24,26,28,30;1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31;
World size is 32
/opt/conda/envs/varuna/bin/python -u /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --rank=0 --chunk_size=8 --local_rank=0 --stage_to_rank_map=0,2,4,6,8,10,12,14,16,18,20,22,24,26,28,30;1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31; --batch-size=64 --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna --resume_step 386
device: cuda:0 n_gpu: 1, distributed training: True, 16-bits training: True
DLL 2022-11-26 05:58:11.266109 - PARAMETER Config : ["Namespace(input_dir='/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/', config_file='bert_config.json', bert_model='bert-large-uncased', output_dir='s3://spot-checkpoints/bert', init_checkpoint=None, max_seq_length=128, max_predictions_per_seq=20, train_batch_size=64, learning_rate=0.006, num_train_epochs=3.0, max_steps=7038.0, warmup_proportion=0.2843, local_rank=0, seed=12439, gradient_accumulation_steps=1, fp16=True, amp=False, loss_scale=0.0, log_freq=1.0, checkpoint_activations=False, resume_from_checkpoint=True, resume_step=386, num_steps_per_checkpoint=200, skip_checkpoint=False, phase2=False, allreduce_post_accumulation=False, allreduce_post_accumulation_fp16=False, phase1_end_step=7038, init_loss_scale=1048576, do_train=True, json_summary='/home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json', use_env=False, disable_progress_bar=False, steps_this_run=7038.0, varuna=True, stage_to_rank_map='0,2,4,6,8,10,12,14,16,18,20,22,24,26,28,30;1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31;', chunk_size=8, batch_size=64, rank=0, profiling=False, n_gpu=1)"] 
dry run time 0.17689800262451172
SHARED WEIGHTS ARE
[(0, 1)]
this rank  0 is part of pipeline replica  0
8 chunks
Begin to load checkpint from s3://spot-checkpoints/bert/ckpt_386.pt
2022-11-26 05:58:21.715396 resume step from  386
Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.

Defaults for this optimization level are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
2022-11-26 05:59:16.245509 - Finished loading checkpoint, takes 54.502 secs
DLL 2022-11-26 05:59:16.246404 - PARAMETER SEED : 12439 
DLL 2022-11-26 05:59:16.246523 - PARAMETER train_start : True 
DLL 2022-11-26 05:59:16.246584 - PARAMETER batch_size_per_gpu : 64 
DLL 2022-11-26 05:59:16.246619 - PARAMETER learning_rate : 0.006 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  524288.0
[2022-11-26 05:59:39.102840] Finished iteration 386, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5373.503
DLL 2022-11-26 05:59:39.108672 - Training Epoch: 0 Training Iteration: 387  average_loss : nan  step_loss : nan  learning_rate : 0.001160475813075234 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  262144.0
[2022-11-26 05:59:42.301155] Finished iteration 387, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3198.136
DLL 2022-11-26 05:59:42.306711 - Training Epoch: 0 Training Iteration: 388  average_loss : nan  step_loss : nan  learning_rate : 0.0011634744585870562 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  131072.0
[2022-11-26 05:59:45.487072] Finished iteration 388, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3185.807
DLL 2022-11-26 05:59:45.492847 - Training Epoch: 0 Training Iteration: 389  average_loss : nan  step_loss : nan  learning_rate : 0.0011664731040988785 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  65536.0
[2022-11-26 05:59:48.989482] Finished iteration 389, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3502.370
DLL 2022-11-26 05:59:48.995380 - Training Epoch: 0 Training Iteration: 390  average_loss : nan  step_loss : nan  learning_rate : 0.0011694717496107008 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  32768.0
[2022-11-26 05:59:52.211386] Finished iteration 390, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3221.888
DLL 2022-11-26 05:59:52.216980 - Training Epoch: 0 Training Iteration: 391  average_loss : nan  step_loss : nan  learning_rate : 0.0011724703951225231 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  16384.0
[2022-11-26 05:59:55.319193] Finished iteration 391, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3107.716
DLL 2022-11-26 05:59:55.327766 - Training Epoch: 0 Training Iteration: 392  average_loss : nan  step_loss : nan  learning_rate : 0.0011754690406343454 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  8192.0
[2022-11-26 05:59:58.792548] Finished iteration 392, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3473.325
DLL 2022-11-26 05:59:58.797724 - Training Epoch: 0 Training Iteration: 393  average_loss : nan  step_loss : nan  learning_rate : 0.001178467686146168 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  4096.0
[2022-11-26 06:00:01.806348] Finished iteration 393, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3013.776
DLL 2022-11-26 06:00:01.811896 - Training Epoch: 0 Training Iteration: 394  average_loss : nan  step_loss : nan  learning_rate : 0.00118146633165799 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  2048.0
[2022-11-26 06:00:04.456600] Finished iteration 394, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2650.290
DLL 2022-11-26 06:00:04.466330 - Training Epoch: 0 Training Iteration: 395  average_loss : nan  step_loss : nan  learning_rate : 0.0011844649771698124 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1024.0
[2022-11-26 06:00:07.064229] Finished iteration 395, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2607.520
DLL 2022-11-26 06:00:07.069790 - Training Epoch: 0 Training Iteration: 396  average_loss : nan  step_loss : nan  learning_rate : 0.0011874636226816347 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  512.0
[2022-11-26 06:00:09.307469] Finished iteration 396, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2243.226
DLL 2022-11-26 06:00:09.312810 - Training Epoch: 0 Training Iteration: 397  average_loss : nan  step_loss : nan  learning_rate : 0.0011904622681934572 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  256.0
[2022-11-26 06:00:11.465966] Finished iteration 397, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2158.461
DLL 2022-11-26 06:00:11.471138 - Training Epoch: 0 Training Iteration: 398  average_loss : nan  step_loss : nan  learning_rate : 0.0011934609137052793 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  128.0
[2022-11-26 06:00:13.651977] Finished iteration 398, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2185.961
DLL 2022-11-26 06:00:13.657293 - Training Epoch: 0 Training Iteration: 399  average_loss : nan  step_loss : nan  learning_rate : 0.0011964595592171016 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  64.0
[2022-11-26 06:00:15.842677] Finished iteration 399, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2190.658
DLL 2022-11-26 06:00:15.848223 - Training Epoch: 0 Training Iteration: 400  average_loss : nan  step_loss : nan  learning_rate : 0.001199458204728924 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  32.0
[2022-11-26 06:00:18.032877] Finished iteration 400, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2190.184
DLL 2022-11-26 06:00:18.038301 - Training Epoch: 0 Training Iteration: 401  average_loss : nan  step_loss : nan  learning_rate : 0.0012024568502407463 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  16.0
[2022-11-26 06:00:20.192598] Finished iteration 401, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2159.722
DLL 2022-11-26 06:00:20.198003 - Training Epoch: 0 Training Iteration: 402  average_loss : nan  step_loss : nan  learning_rate : 0.0012054554957525686 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  8.0
[2022-11-26 06:00:22.374975] Finished iteration 402, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2182.342
DLL 2022-11-26 06:00:22.380099 - Training Epoch: 0 Training Iteration: 403  average_loss : nan  step_loss : nan  learning_rate : 0.001208454141264391 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  4.0
[2022-11-26 06:00:24.595818] Finished iteration 403, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2220.786
DLL 2022-11-26 06:00:24.601112 - Training Epoch: 0 Training Iteration: 404  average_loss : nan  step_loss : nan  learning_rate : 0.0012114527867762132 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  2.0
[2022-11-26 06:00:26.765482] Finished iteration 404, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2169.621
DLL 2022-11-26 06:00:26.770723 - Training Epoch: 0 Training Iteration: 405  average_loss : nan  step_loss : nan  learning_rate : 0.0012144514322880353 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 06:00:28.996055] Finished iteration 405, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2230.554
DLL 2022-11-26 06:00:29.001131 - Training Epoch: 0 Training Iteration: 406  average_loss : nan  step_loss : nan  learning_rate : 0.0012174500777998578 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 06:00:31.224226] Finished iteration 406, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2228.146
DLL 2022-11-26 06:00:31.229348 - Training Epoch: 0 Training Iteration: 407  average_loss : nan  step_loss : nan  learning_rate : 0.0012204487233116801 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 06:00:33.415510] Finished iteration 407, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2191.249
DLL 2022-11-26 06:00:33.420601 - Training Epoch: 0 Training Iteration: 408  average_loss : nan  step_loss : nan  learning_rate : 0.0012234473688235025 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 06:00:35.609555] Finished iteration 408, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2194.016
DLL 2022-11-26 06:00:35.614951 - Training Epoch: 0 Training Iteration: 409  average_loss : nan  step_loss : nan  learning_rate : 0.0012264460143353248 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 06:00:37.823385] Finished iteration 409, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2213.793
DLL 2022-11-26 06:00:37.828801 - Training Epoch: 0 Training Iteration: 410  average_loss : nan  step_loss : nan  learning_rate : 0.001229444659847147 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 06:00:40.019629] Finished iteration 410, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2196.223
DLL 2022-11-26 06:00:40.024749 - Training Epoch: 0 Training Iteration: 411  average_loss : nan  step_loss : nan  learning_rate : 0.0012324433053589694 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 06:00:42.246998] Finished iteration 411, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2227.339
DLL 2022-11-26 06:00:42.251965 - Training Epoch: 0 Training Iteration: 412  average_loss : nan  step_loss : nan  learning_rate : 0.001235441950870792 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 06:00:44.463743] Finished iteration 412, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2216.721
DLL 2022-11-26 06:00:44.469381 - Training Epoch: 0 Training Iteration: 413  average_loss : nan  step_loss : nan  learning_rate : 0.001238440596382614 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 06:00:46.668036] Finished iteration 413, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2204.265
DLL 2022-11-26 06:00:46.673179 - Training Epoch: 0 Training Iteration: 414  average_loss : nan  step_loss : nan  learning_rate : 0.0012414392418944363 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 06:00:48.914917] Finished iteration 414, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2246.886
DLL 2022-11-26 06:00:48.920599 - Training Epoch: 0 Training Iteration: 415  average_loss : nan  step_loss : nan  learning_rate : 0.0012444378874062586 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 06:00:51.206195] Finished iteration 415, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2291.252
DLL 2022-11-26 06:00:51.211505 - Training Epoch: 0 Training Iteration: 416  average_loss : nan  step_loss : nan  learning_rate : 0.001247436532918081 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 06:00:53.417101] Finished iteration 416, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2210.833
DLL 2022-11-26 06:00:53.422650 - Training Epoch: 0 Training Iteration: 417  average_loss : nan  step_loss : nan  learning_rate : 0.0012504351784299033 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 06:00:55.618037] Finished iteration 417, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2200.904
DLL 2022-11-26 06:00:55.623573 - Training Epoch: 0 Training Iteration: 418  average_loss : nan  step_loss : nan  learning_rate : 0.0012534338239417256 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 06:00:57.888291] Finished iteration 418, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2270.201
DLL 2022-11-26 06:00:57.893459 - Training Epoch: 0 Training Iteration: 419  average_loss : nan  step_loss : nan  learning_rate : 0.001256432469453548 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 06:01:00.078686] Finished iteration 419, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2190.357
DLL 2022-11-26 06:01:00.084196 - Training Epoch: 0 Training Iteration: 420  average_loss : nan  step_loss : nan  learning_rate : 0.00125943111496537 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 06:01:02.278809] Finished iteration 420, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2200.102
DLL 2022-11-26 06:01:02.284437 - Training Epoch: 0 Training Iteration: 421  average_loss : nan  step_loss : nan  learning_rate : 0.0012624297604771925 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 06:01:04.473428] Finished iteration 421, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2194.595
DLL 2022-11-26 06:01:04.478662 - Training Epoch: 0 Training Iteration: 422  average_loss : nan  step_loss : nan  learning_rate : 0.0012654284059890148 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 06:01:06.673412] Finished iteration 422, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2199.955
DLL 2022-11-26 06:01:06.678679 - Training Epoch: 0 Training Iteration: 423  average_loss : nan  step_loss : nan  learning_rate : 0.0012684270515008372 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 06:01:08.898213] Finished iteration 423, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2224.810
DLL 2022-11-26 06:01:08.903406 - Training Epoch: 0 Training Iteration: 424  average_loss : nan  step_loss : nan  learning_rate : 0.0012714256970126593 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 06:01:11.095459] Finished iteration 424, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2197.184
DLL 2022-11-26 06:01:11.100670 - Training Epoch: 0 Training Iteration: 425  average_loss : nan  step_loss : nan  learning_rate : 0.0012744243425244818 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 06:01:13.327118] Finished iteration 425, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2231.645
DLL 2022-11-26 06:01:13.332260 - Training Epoch: 0 Training Iteration: 426  average_loss : nan  step_loss : nan  learning_rate : 0.001277422988036304 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 06:01:15.547061] Finished iteration 426, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2219.912
DLL 2022-11-26 06:01:15.552250 - Training Epoch: 0 Training Iteration: 427  average_loss : nan  step_loss : nan  learning_rate : 0.0012804216335481264 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 06:01:17.749004] Finished iteration 427, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2201.900
DLL 2022-11-26 06:01:17.754359 - Training Epoch: 0 Training Iteration: 428  average_loss : nan  step_loss : nan  learning_rate : 0.0012834202790599487 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 06:01:19.953469] Finished iteration 428, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2204.433
DLL 2022-11-26 06:01:19.958963 - Training Epoch: 0 Training Iteration: 429  average_loss : nan  step_loss : nan  learning_rate : 0.001286418924571771 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 06:01:22.845889] Finished iteration 429, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2892.385
DLL 2022-11-26 06:01:22.851254 - Training Epoch: 0 Training Iteration: 430  average_loss : nan  step_loss : nan  learning_rate : 0.0012894175700835931 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 06:01:25.092269] Finished iteration 430, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2246.361
DLL 2022-11-26 06:01:25.097882 - Training Epoch: 0 Training Iteration: 431  average_loss : nan  step_loss : nan  learning_rate : 0.0012924162155954157 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 06:01:27.945476] Finished iteration 431, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2853.173
DLL 2022-11-26 06:01:27.950783 - Training Epoch: 0 Training Iteration: 432  average_loss : nan  step_loss : nan  learning_rate : 0.001295414861107238 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 06:01:30.209352] Finished iteration 432, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2263.856
DLL 2022-11-26 06:01:30.214516 - Training Epoch: 0 Training Iteration: 433  average_loss : nan  step_loss : nan  learning_rate : 0.00129841350661906 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 06:01:32.410978] Finished iteration 433, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2201.610
DLL 2022-11-26 06:01:32.416136 - Training Epoch: 0 Training Iteration: 434  average_loss : nan  step_loss : nan  learning_rate : 0.0013014121521308826 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 06:01:34.640056] Finished iteration 434, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2229.021
DLL 2022-11-26 06:01:34.645401 - Training Epoch: 0 Training Iteration: 435  average_loss : nan  step_loss : nan  learning_rate : 0.0013044107976427047 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 06:01:36.832149] Finished iteration 435, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2192.079
DLL 2022-11-26 06:01:36.837457 - Training Epoch: 0 Training Iteration: 436  average_loss : nan  step_loss : nan  learning_rate : 0.0013074094431545272 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 06:01:39.040860] Finished iteration 436, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2208.678
DLL 2022-11-26 06:01:39.046310 - Training Epoch: 0 Training Iteration: 437  average_loss : nan  step_loss : nan  learning_rate : 0.0013104080886663495 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 06:01:41.205714] Finished iteration 437, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2164.828
DLL 2022-11-26 06:01:41.211300 - Training Epoch: 0 Training Iteration: 438  average_loss : nan  step_loss : nan  learning_rate : 0.0013134067341781719 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 06:01:43.421050] Finished iteration 438, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2215.308
DLL 2022-11-26 06:01:43.426327 - Training Epoch: 0 Training Iteration: 439  average_loss : nan  step_loss : nan  learning_rate : 0.001316405379689994 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 06:01:45.617775] Finished iteration 439, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2196.676
DLL 2022-11-26 06:01:45.623092 - Training Epoch: 0 Training Iteration: 440  average_loss : nan  step_loss : nan  learning_rate : 0.0013194040252018165 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 06:01:47.863507] Finished iteration 440, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2245.720
DLL 2022-11-26 06:01:47.869239 - Training Epoch: 0 Training Iteration: 441  average_loss : nan  step_loss : nan  learning_rate : 0.0013224026707136386 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 06:01:50.092960] Finished iteration 441, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2229.424
DLL 2022-11-26 06:01:50.098104 - Training Epoch: 0 Training Iteration: 442  average_loss : nan  step_loss : nan  learning_rate : 0.001325401316225461 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 06:01:52.283699] Finished iteration 442, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2190.710
DLL 2022-11-26 06:01:52.288954 - Training Epoch: 0 Training Iteration: 443  average_loss : nan  step_loss : nan  learning_rate : 0.0013283999617372834 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 06:01:54.472000] Finished iteration 443, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2188.278
DLL 2022-11-26 06:01:54.477765 - Training Epoch: 0 Training Iteration: 444  average_loss : nan  step_loss : nan  learning_rate : 0.0013313986072491057 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 06:01:56.674525] Finished iteration 444, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2202.479
DLL 2022-11-26 06:01:56.679948 - Training Epoch: 0 Training Iteration: 445  average_loss : nan  step_loss : nan  learning_rate : 0.001334397252760928 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 06:01:58.867221] Finished iteration 445, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2192.681
DLL 2022-11-26 06:01:58.872700 - Training Epoch: 0 Training Iteration: 446  average_loss : nan  step_loss : nan  learning_rate : 0.0013373958982727501 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 06:02:01.013525] Finished iteration 446, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2146.278
DLL 2022-11-26 06:02:01.019147 - Training Epoch: 0 Training Iteration: 447  average_loss : nan  step_loss : nan  learning_rate : 0.0013403945437845727 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 06:02:03.210092] Finished iteration 447, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2196.577
DLL 2022-11-26 06:02:03.215368 - Training Epoch: 0 Training Iteration: 448  average_loss : nan  step_loss : nan  learning_rate : 0.001343393189296395 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 06:02:05.375771] Finished iteration 448, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2165.614
DLL 2022-11-26 06:02:05.381063 - Training Epoch: 0 Training Iteration: 449  average_loss : nan  step_loss : nan  learning_rate : 0.001346391834808217 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 06:02:07.582331] Finished iteration 449, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2206.514
DLL 2022-11-26 06:02:07.587949 - Training Epoch: 0 Training Iteration: 450  average_loss : nan  step_loss : nan  learning_rate : 0.0013493904803200396 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 06:02:10.925991] Finished iteration 450, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3343.646
DLL 2022-11-26 06:02:10.931222 - Training Epoch: 0 Training Iteration: 451  average_loss : nan  step_loss : nan  learning_rate : 0.0013523891258318617 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 06:02:13.492166] Finished iteration 451, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2566.181
DLL 2022-11-26 06:02:13.497212 - Training Epoch: 0 Training Iteration: 452  average_loss : nan  step_loss : nan  learning_rate : 0.001355387771343684 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 06:02:16.906847] Finished iteration 452, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3414.619
DLL 2022-11-26 06:02:16.912199 - Training Epoch: 0 Training Iteration: 453  average_loss : nan  step_loss : nan  learning_rate : 0.0013583864168555065 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 06:02:19.890673] Finished iteration 453, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2983.797
DLL 2022-11-26 06:02:19.896039 - Training Epoch: 0 Training Iteration: 454  average_loss : nan  step_loss : nan  learning_rate : 0.0013613850623673286 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 06:02:23.196075] Finished iteration 454, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3305.360
DLL 2022-11-26 06:02:23.201173 - Training Epoch: 0 Training Iteration: 455  average_loss : nan  step_loss : nan  learning_rate : 0.0013643837078791512 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 06:02:25.746001] Finished iteration 455, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2549.945
DLL 2022-11-26 06:02:25.751304 - Training Epoch: 0 Training Iteration: 456  average_loss : nan  step_loss : nan  learning_rate : 0.0013673823533909733 
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 0 signal handler called with signal 10
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-26 06:02:28.001235] Finished iteration 456, CKPT_AND_STOP: True, flag: tensor([2], dtype=torch.int32), speed: 2255.152
DLL 2022-11-26 06:02:28.007375 - Training Epoch: 0 Training Iteration: 457  average_loss : nan  step_loss : nan  learning_rate : 0.0013703809989027958 
2022-11-26 06:02:28.007500 Begin to save checkpont to s3://spot-checkpoints/bert and exit
DLL 2022-11-26 06:02:28.007529 - PARAMETER checkpoint_step : 457 
Opt ckpt time 7.3381054401397705
Process done with return code 0
Parent process ID: 97258 node: 172.31.28.108
24 cutpoints
Stages 1
Micro-bs 8 Max mem: 14622140211.200005
Predicted microbatch size for 1: 8
comm size 0
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 1 5 0 2493369.62890625 0
End of simulation:  Mini-batch time (usec) = 4144382
Min send: 10000000, max send 0
Min long send: 10000000, max long send 0
Min fwd: 10000000, max fwd 0; min bwd 10000000, max bwd 0
Min long fwd: 141043, max long fwd 144458; min long bwd 184920, max long bwd 191040
Time taken by simulation: 43 microseconds

Stages 2
Micro-bs 8 Max mem: 7660942131.200001
Predicted microbatch size for 2: 8
comm size 4194304
WARNING: no send time found, 2 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 2 9 0 970375.4272460938 248719.58977934244
End of simulation:  Mini-batch time (usec) = 3283515
Min send: 10000000, max send 0
Min long send: 249051, max long send 268766
Min fwd: 79750, max fwd 86627; min bwd 87708, max bwd 94754
Min long fwd: 58189, max long fwd 63385; min long bwd 92867, max long bwd 97330
Time taken by simulation: 215 microseconds

Stages 3
Micro-bs 8 Max mem: 5497876480.0
Predicted microbatch size for 3: 8
comm size 4194304
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 13 0 485476.6540527344 248719.58977934244
End of simulation:  Mini-batch time (usec) = 3469734
Min send: 10000000, max send 0
Min long send: 248801, max long send 271185
Min fwd: 34426, max fwd 67951; min bwd 53890, max bwd 64826
Min long fwd: 37108, max long fwd 45662; min long bwd 64919, max long bwd 72155
Time taken by simulation: 460 microseconds

Stages 4
Micro-bs 8 Max mem: 4406266675.2
Predicted microbatch size for 4: 8
comm size 4194304
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 19 0 352272.7355957031 248719.58977934244
End of simulation:  Mini-batch time (usec) = 4275253
Min send: 10000000, max send 0
Min long send: 248773, max long send 273424
Min fwd: 22410, max fwd 61283; min bwd 39748, max bwd 51303
Min long fwd: 29385, max long fwd 37648; min long bwd 47928, max long bwd 54735
Time taken by simulation: 908 microseconds

Stages 6
Micro-bs 8 Max mem: 3314656870.4
Predicted microbatch size for 6: 8
comm size 4194304
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 26 0 254962.82958984375 248719.58977934244
End of simulation:  Mini-batch time (usec) = 5944030
Min send: 10000000, max send 0
Min long send: 248735, max long send 278723
Min fwd: 10836, max fwd 44441; min bwd 24199, max bwd 35953
Min long fwd: 21303, max long fwd 29429; min long bwd 33298, max long bwd 40795
Time taken by simulation: 1980 microseconds

Stages 8
Micro-bs 8 Max mem: 2758774988.8
Predicted microbatch size for 8: 8
comm size 4194304
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 43 0 178155.74645996094 248719.58977934244
End of simulation:  Mini-batch time (usec) = 9019309
Min send: 10000000, max send 0
Min long send: 248735, max long send 276940
Min fwd: 5776, max fwd 41014; min bwd 16548, max bwd 29492
Min long fwd: 17309, max long fwd 25772; min long bwd 25282, max long bwd 32088
Time taken by simulation: 4665 microseconds

Stages 12
Micro-bs 8 Max mem: 2202893107.2
Predicted microbatch size for 12: 8
comm size 4194304
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 64 0 117116.2109375 248719.58977934244
End of simulation:  Mini-batch time (usec) = 13687683
Min send: 10000000, max send 0
Min long send: 248720, max long send 280797
Min fwd: 141, max fwd 25024; min bwd 6433, max bwd 23373
Min long fwd: 7201, max long fwd 18161; min long bwd 16833, max long bwd 28389
Time taken by simulation: 10725 microseconds

{1: 4.144382, 2: 3.283515, 3: 3.469734, 4: 4.275253, 6: 5.94403, 8: 9.019309, 12: 13.687683}
{1: 8, 2: 8, 3: 8, 4: 8, 6: 8, 8: 8, 12: 8}
best config is: 2 8
expected time is 3.283515
15 per stage
30 servers!
Config:
ranks: range(0, 1)
train batch size: 1024
partitions: 2
chunk_size: 8
data depth: 15
stage to rank map: 0,2,4,6,8,10,12,14,16,18,20,22,24,26,28;1,3,5,7,9,11,13,15,17,19,21,23,25,27,29;
World size is 30
/opt/conda/envs/varuna/bin/python -u /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --rank=0 --chunk_size=8 --local_rank=0 --stage_to_rank_map=0,2,4,6,8,10,12,14,16,18,20,22,24,26,28;1,3,5,7,9,11,13,15,17,19,21,23,25,27,29; --batch-size=68 --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna --resume_step 457
Signal handler called with signal 10


 STOPPING VARUNA !!



