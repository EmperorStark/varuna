Traceback (most recent call last):
  File "/home/ubuntu/varuna_examples/Megatron-LM/pretrain_gpt2.py", line 170, in <module>
    pretrain(train_valid_test_datasets_provider, model_provider, forward_step,
  File "/home/ubuntu/varuna_examples/Megatron-LM/megatron/training.py", line 131, in pretrain
    iteration = train(forward_step_func if not args.varuna else varuna_step_func,
  File "/home/ubuntu/varuna_examples/Megatron-LM/megatron/training.py", line 519, in train
    save_checkpoint(iteration, model, optimizer, lr_scheduler)
  File "/home/ubuntu/varuna_examples/Megatron-LM/megatron/checkpointing.py", line 141, in save_checkpoint
    torch.distributed.barrier()
  File "/opt/conda/envs/varuna/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 2783, in barrier
    work.wait()
RuntimeError: [/opt/conda/conda-bld/pytorch_1646755888534/work/third_party/gloo/gloo/transport/tcp/pair.cc:598] Connection closed by peer [172.31.19.171]:29080
Traceback (most recent call last):
  File "/home/ubuntu/varuna_examples/Megatron-LM/pretrain_gpt2.py", line 170, in <module>
    pretrain(train_valid_test_datasets_provider, model_provider, forward_step,
  File "/home/ubuntu/varuna_examples/Megatron-LM/megatron/training.py", line 103, in pretrain
    model, optimizer, lr_scheduler = setup_model_and_optimizer(model_provider, get_batch_fn)
  File "/home/ubuntu/varuna_examples/Megatron-LM/megatron/training.py", line 280, in setup_model_and_optimizer
    args.iteration = load_checkpoint(model, optimizer, lr_scheduler)
  File "/home/ubuntu/varuna_examples/Megatron-LM/megatron/checkpointing.py", line 285, in load_checkpoint
    torch.distributed.barrier()
  File "/opt/conda/envs/varuna/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 2783, in barrier
    work.wait()
RuntimeError: [/opt/conda/conda-bld/pytorch_1646755888534/work/third_party/gloo/gloo/transport/tcp/pair.cc:598] Connection closed by peer [172.31.28.236]:23971
Traceback (most recent call last):
  File "/home/ubuntu/varuna_examples/Megatron-LM/pretrain_gpt2.py", line 170, in <module>
    pretrain(train_valid_test_datasets_provider, model_provider, forward_step,
  File "/home/ubuntu/varuna_examples/Megatron-LM/megatron/training.py", line 90, in pretrain
    initialize_megatron(extra_args_provider=extra_args_provider,
  File "/home/ubuntu/varuna_examples/Megatron-LM/megatron/initialize.py", line 48, in initialize_megatron
    set_global_variables(extra_args_provider=extra_args_provider,
  File "/home/ubuntu/varuna_examples/Megatron-LM/megatron/global_vars.py", line 70, in set_global_variables
    _ = _build_tokenizer(args)
  File "/home/ubuntu/varuna_examples/Megatron-LM/megatron/global_vars.py", line 91, in _build_tokenizer
    _GLOBAL_TOKENIZER = build_tokenizer(args)
  File "/home/ubuntu/varuna_examples/Megatron-LM/megatron/tokenizer/tokenizer.py", line 41, in build_tokenizer
    tokenizer = _GPT2BPETokenizer(args.vocab_file, args.merge_file)
  File "/home/ubuntu/varuna_examples/Megatron-LM/megatron/tokenizer/tokenizer.py", line 196, in __init__
    self.tokenizer = GPT2Tokenizer(vocab_file, merge_file, errors='replace',
  File "/home/ubuntu/varuna_examples/Megatron-LM/megatron/tokenizer/gpt2_tokenization.py", line 164, in __init__
    bpe_data = open(merges_file, encoding='utf-8').read().split('\n')[1:-1]
  File "/home/ubuntu/varuna_examples/Megatron-LM/pretrain_gpt2.py", line 164, in handler
    print('Rank', torch.distributed.get_rank(), 'signal handler called with signal', signum, flush=True)
  File "/opt/conda/envs/varuna/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 844, in get_rank
    default_pg = _get_default_group()
  File "/opt/conda/envs/varuna/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 429, in _get_default_group
    raise RuntimeError(
RuntimeError: Default process group has not been initialized, please make sure to call init_process_group.
