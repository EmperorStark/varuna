Parent process ID: 18861 node: 172.31.19.112
32 cutpoints
Stages 1
Micro-bs 1 Max mem: 128933453516.80006
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 64530397593.59998
Predicted microbatch size for 2: -1
Stages 4
Micro-bs 1 Max mem: 34529746124.799995
Predicted microbatch size for 4: -1
Stages 8
Micro-bs 1 Max mem: 19529420390.4
Predicted microbatch size for 8: -1
Stages 16
Micro-bs 1 Max mem: 12029257523.2
Predicted microbatch size for 16: 1
comm size 4194304
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 64 0 0 97573.47158206406
End of simulation:  Mini-batch time (usec) = 9027729
Min send: 10000000, max send 0
Min long send: 97573, max long send 127662
Min fwd: 6433, max fwd 20013; min bwd 37432, max bwd 53429
Min long fwd: 15602, max long fwd 25495; min long bwd 46790, max long bwd 57770
Time taken by simulation: 14425 microseconds

{1: inf, 2: inf, 4: inf, 8: inf, 16: 9.027729}
{1: -1, 2: -1, 4: -1, 8: -1, 16: 1}
best config is: 16 1
expected time is 9.027729
1 per stage
16 servers!
Config:
ranks: range(15, 16)
train batch size: 64
partitions: 16
chunk_size: 1
data depth: 1
stage to rank map: 0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;
World size is 16
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=15 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15; --batch-size=64 --num-layers 32 --hidden-size 4096 --num-attention-heads 32 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16
dry run time 4.84439754486084
SHARED WEIGHTS ARE
[(0, 15)]
this rank  15 is part of pipeline replica  0
64 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
 > finished loading checkpoint in 0.198 seconds
START iteration 0, CKPT_AND_STOP: False
Finished iteration 1, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 1, CKPT_AND_STOP: False
Finished iteration 2, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 2, CKPT_AND_STOP: False
Finished iteration 3, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 3, CKPT_AND_STOP: False
Finished iteration 4, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 4, CKPT_AND_STOP: False
Finished iteration 5, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 5, CKPT_AND_STOP: False
Finished iteration 6, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 6, CKPT_AND_STOP: False
Finished iteration 7, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 7, CKPT_AND_STOP: False
Finished iteration 8, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 8, CKPT_AND_STOP: False
Finished iteration 9, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 9, CKPT_AND_STOP: False
Finished iteration 10, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 10, CKPT_AND_STOP: False
Finished iteration 11, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 11, CKPT_AND_STOP: False
Finished iteration 12, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 12, CKPT_AND_STOP: False
Finished iteration 13, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 13, CKPT_AND_STOP: False
Finished iteration 14, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 14, CKPT_AND_STOP: False
Finished iteration 15, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 15, CKPT_AND_STOP: False
Finished iteration 16, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 16, CKPT_AND_STOP: False
Finished iteration 17, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 17, CKPT_AND_STOP: False
Finished iteration 18, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 18, CKPT_AND_STOP: False
Finished iteration 19, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 19, CKPT_AND_STOP: False
Finished iteration 20, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 20, CKPT_AND_STOP: False
Finished iteration 21, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 21, CKPT_AND_STOP: False
Finished iteration 22, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 22, CKPT_AND_STOP: False
Finished iteration 23, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 23, CKPT_AND_STOP: False
Finished iteration 24, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 24, CKPT_AND_STOP: False
Finished iteration 25, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 25, CKPT_AND_STOP: False
Finished iteration 26, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 26, CKPT_AND_STOP: False
Finished iteration 27, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 27, CKPT_AND_STOP: False
Finished iteration 28, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 28, CKPT_AND_STOP: False
Finished iteration 29, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 29, CKPT_AND_STOP: False
Finished iteration 30, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 30, CKPT_AND_STOP: False
Finished iteration 31, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 31, CKPT_AND_STOP: False
Finished iteration 32, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 32, CKPT_AND_STOP: False
Finished iteration 33, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 33, CKPT_AND_STOP: False
Finished iteration 34, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 34, CKPT_AND_STOP: False
Finished iteration 35, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 35, CKPT_AND_STOP: False
Finished iteration 36, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 36, CKPT_AND_STOP: False
Finished iteration 37, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 37, CKPT_AND_STOP: False
Finished iteration 38, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 38, CKPT_AND_STOP: False
Finished iteration 39, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 39, CKPT_AND_STOP: False
Finished iteration 40, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 40, CKPT_AND_STOP: False
Finished iteration 41, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 41, CKPT_AND_STOP: False
Finished iteration 42, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 42, CKPT_AND_STOP: False
Finished iteration 43, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 43, CKPT_AND_STOP: False
Finished iteration 44, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 44, CKPT_AND_STOP: False
Finished iteration 45, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 45, CKPT_AND_STOP: False
Finished iteration 46, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 46, CKPT_AND_STOP: False
Finished iteration 47, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 47, CKPT_AND_STOP: False
Finished iteration 48, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 48, CKPT_AND_STOP: False
Finished iteration 49, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 49, CKPT_AND_STOP: False
Finished iteration 50, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 50, CKPT_AND_STOP: False
Finished iteration 51, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 51, CKPT_AND_STOP: False
Finished iteration 52, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 52, CKPT_AND_STOP: False
Finished iteration 53, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 53, CKPT_AND_STOP: False
Finished iteration 54, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 54, CKPT_AND_STOP: False
Finished iteration 55, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 55, CKPT_AND_STOP: False
Finished iteration 56, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 56, CKPT_AND_STOP: False
Finished iteration 57, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 57, CKPT_AND_STOP: False
Finished iteration 58, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 58, CKPT_AND_STOP: False
Finished iteration 59, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 59, CKPT_AND_STOP: False
Finished iteration 60, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 60, CKPT_AND_STOP: False
Finished iteration 61, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 61, CKPT_AND_STOP: False
Finished iteration 62, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 62, CKPT_AND_STOP: False
Finished iteration 63, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32)
START iteration 63, CKPT_AND_STOP: False
Finished iteration 64, CKPT_AND_STOP: False, flag: tensor([2], dtype=torch.int32)
Begin to save checkpont and exit
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 15 signal handler called with signal 10
Opt ckpt time 78.3452832698822
Process done with return code 0
Parent process ID: 19404 node: 172.31.19.112
32 cutpoints
Stages 1
Micro-bs 1 Max mem: 128933453516.80006
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 64530397593.59998
Predicted microbatch size for 2: -1
Stages 4
Micro-bs 1 Max mem: 34529746124.799995
Predicted microbatch size for 4: -1
Stages 8
Micro-bs 1 Max mem: 19529420390.4
Predicted microbatch size for 8: -1
Stages 16
Micro-bs 1 Max mem: 12029257523.2
Predicted microbatch size for 16: 1
comm size 4194304
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 64 0 0 97573.47158206406
End of simulation:  Mini-batch time (usec) = 9027729
Min send: 10000000, max send 0
Min long send: 97573, max long send 127662
Min fwd: 6433, max fwd 20013; min bwd 37432, max bwd 53429
Min long fwd: 15602, max long fwd 25495; min long bwd 46790, max long bwd 57770
Time taken by simulation: 14339 microseconds

{1: inf, 2: inf, 4: inf, 8: inf, 16: 9.027729}
{1: -1, 2: -1, 4: -1, 8: -1, 16: 1}
best config is: 16 1
expected time is 9.027729
1 per stage
16 servers!
Config:
ranks: range(15, 16)
train batch size: 64
partitions: 16
chunk_size: 1
data depth: 1
stage to rank map: 0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;
World size is 16
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=15 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15; --batch-size=64 --num-layers 32 --hidden-size 4096 --num-attention-heads 32 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 64
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 15 signal handler called with signal 10
dry run time 3.526606321334839
SHARED WEIGHTS ARE
[(0, 15)]
this rank  15 is part of pipeline replica  0
64 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
 > finished loading checkpoint in 56.591 seconds
Process done with return code 0
Parent process ID: 19858 node: 172.31.19.112
32 cutpoints
Stages 1
Micro-bs 1 Max mem: 128933453516.80006
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 64530397593.59998
Predicted microbatch size for 2: -1
Stages 4
Micro-bs 1 Max mem: 34529746124.799995
Predicted microbatch size for 4: -1
Stages 8
Micro-bs 1 Max mem: 19529420390.4
Predicted microbatch size for 8: -1
Stages 16
Micro-bs 1 Max mem: 12029257523.2
Predicted microbatch size for 16: 1
comm size 4194304
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 64 0 0 97573.47158206406
End of simulation:  Mini-batch time (usec) = 9027729
Min send: 10000000, max send 0
Min long send: 97573, max long send 127662
Min fwd: 6433, max fwd 20013; min bwd 37432, max bwd 53429
Min long fwd: 15602, max long fwd 25495; min long bwd 46790, max long bwd 57770
Time taken by simulation: 14279 microseconds

{1: inf, 2: inf, 4: inf, 8: inf, 16: 9.027729}
{1: -1, 2: -1, 4: -1, 8: -1, 16: 1}
best config is: 16 1
expected time is 9.027729
1 per stage
16 servers!
Config:
ranks: range(15, 16)
train batch size: 64
partitions: 16
chunk_size: 1
data depth: 1
stage to rank map: 0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;
World size is 16
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=15 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15; --batch-size=64 --num-layers 32 --hidden-size 4096 --num-attention-heads 32 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 64
dry run time 3.5269434452056885
SHARED WEIGHTS ARE
[(0, 15)]
this rank  15 is part of pipeline replica  0
64 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
 > finished loading checkpoint in 55.811 seconds
Process done with return code 0
Parent process ID: 20308 node: 172.31.19.112
32 cutpoints
Stages 1
Micro-bs 1 Max mem: 128933453516.80006
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 64530397593.59998
Predicted microbatch size for 2: -1
Stages 4
Micro-bs 1 Max mem: 34529746124.799995
Predicted microbatch size for 4: -1
Stages 8
Micro-bs 1 Max mem: 19529420390.4
Predicted microbatch size for 8: -1
Stages 16
Micro-bs 1 Max mem: 12029257523.2
Predicted microbatch size for 16: 1
comm size 4194304
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 64 0 0 97573.47158206406
End of simulation:  Mini-batch time (usec) = 9027729
Min send: 10000000, max send 0
Min long send: 97573, max long send 127662
Min fwd: 6433, max fwd 20013; min bwd 37432, max bwd 53429
Min long fwd: 15602, max long fwd 25495; min long bwd 46790, max long bwd 57770
Time taken by simulation: 14314 microseconds

{1: inf, 2: inf, 4: inf, 8: inf, 16: 9.027729}
{1: -1, 2: -1, 4: -1, 8: -1, 16: 1}
best config is: 16 1
expected time is 9.027729
1 per stage
16 servers!
Config:
ranks: range(15, 16)
train batch size: 64
partitions: 16
chunk_size: 1
data depth: 1
stage to rank map: 0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;
World size is 16
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=15 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15; --batch-size=64 --num-layers 32 --hidden-size 4096 --num-attention-heads 32 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 64
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 15 signal handler called with signal 10
dry run time 3.829220771789551
SHARED WEIGHTS ARE
[(0, 15)]
this rank  15 is part of pipeline replica  0
64 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
 > finished loading checkpoint in 55.552 seconds
Process done with return code 0
Parent process ID: 20757 node: 172.31.19.112
32 cutpoints
Stages 1
Micro-bs 1 Max mem: 128933453516.80006
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 64530397593.59998
Predicted microbatch size for 2: -1
Stages 4
Micro-bs 1 Max mem: 34529746124.799995
Predicted microbatch size for 4: -1
Stages 8
Micro-bs 1 Max mem: 19529420390.4
Predicted microbatch size for 8: -1
Stages 16
Micro-bs 1 Max mem: 12029257523.2
Predicted microbatch size for 16: 1
comm size 4194304
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 64 0 0 97573.47158206406
End of simulation:  Mini-batch time (usec) = 9027729
Min send: 10000000, max send 0
Min long send: 97573, max long send 127662
Min fwd: 6433, max fwd 20013; min bwd 37432, max bwd 53429
Min long fwd: 15602, max long fwd 25495; min long bwd 46790, max long bwd 57770
Time taken by simulation: 14254 microseconds

{1: inf, 2: inf, 4: inf, 8: inf, 16: 9.027729}
{1: -1, 2: -1, 4: -1, 8: -1, 16: 1}
best config is: 16 1
expected time is 9.027729
1 per stage
16 servers!
Config:
ranks: range(15, 16)
train batch size: 64
partitions: 16
chunk_size: 1
data depth: 1
stage to rank map: 0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;
World size is 16
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=15 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15; --batch-size=64 --num-layers 32 --hidden-size 4096 --num-attention-heads 32 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 64
Parent process ID: 21020 node: 172.31.19.112
32 cutpoints
Stages 1
Micro-bs 1 Max mem: 128933453516.80006
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 64530397593.59998
Predicted microbatch size for 2: -1
Stages 4
Micro-bs 1 Max mem: 34529746124.799995
Predicted microbatch size for 4: -1
Stages 8
Micro-bs 1 Max mem: 19529420390.4
Predicted microbatch size for 8: -1
Stages 16
Micro-bs 1 Max mem: 12029257523.2
Predicted microbatch size for 16: 1
comm size 4194304
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 64 0 0 97573.47158206406
End of simulation:  Mini-batch time (usec) = 9027729
Min send: 10000000, max send 0
Min long send: 97573, max long send 127662
Min fwd: 6433, max fwd 20013; min bwd 37432, max bwd 53429
Min long fwd: 15602, max long fwd 25495; min long bwd 46790, max long bwd 57770
Time taken by simulation: 14263 microseconds

{1: inf, 2: inf, 4: inf, 8: inf, 16: 9.027729}
{1: -1, 2: -1, 4: -1, 8: -1, 16: 1}
best config is: 16 1
expected time is 9.027729
1 per stage
16 servers!
Config:
ranks: range(15, 16)
train batch size: 64
partitions: 16
chunk_size: 1
data depth: 1
stage to rank map: 0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;
World size is 16
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=15 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15; --batch-size=64 --num-layers 32 --hidden-size 4096 --num-attention-heads 32 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 64
dry run time 4.745951175689697
SHARED WEIGHTS ARE
[(0, 15)]
this rank  15 is part of pipeline replica  0
64 chunks
Begin to load checkpoint from global store s3://spot-checkpoints/gpt
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 15 signal handler called with signal 10
Process done with return code 1
Parent process ID: 23772 node: 172.31.30.133
32 cutpoints
Stages 1
Micro-bs 1 Max mem: 128933453516.80006
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 64530397593.59998
Predicted microbatch size for 2: -1
Stages 4
Micro-bs 1 Max mem: 34529746124.799995
Predicted microbatch size for 4: -1
Stages 8
Micro-bs 1 Max mem: 19529420390.4
Predicted microbatch size for 8: -1
Stages 16
Micro-bs 1 Max mem: 12029257523.2
Predicted microbatch size for 16: 1
comm size 4194304
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 64 0 0 97573.47158206406
End of simulation:  Mini-batch time (usec) = 9027729
Min send: 10000000, max send 0
Min long send: 97573, max long send 127662
Min fwd: 6433, max fwd 20013; min bwd 37432, max bwd 53429
Min long fwd: 15602, max long fwd 25495; min long bwd 46790, max long bwd 57770
Time taken by simulation: 14435 microseconds

{1: inf, 2: inf, 4: inf, 8: inf, 16: 9.027729}
{1: -1, 2: -1, 4: -1, 8: -1, 16: 1}
best config is: 16 1
expected time is 9.027729
1 per stage
16 servers!
Config:
ranks: range(15, 16)
train batch size: 64
partitions: 16
chunk_size: 1
data depth: 1
stage to rank map: 0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;
World size is 16
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=15 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15; --batch-size=64 --num-layers 32 --hidden-size 4096 --num-attention-heads 32 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 64
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 15 signal handler called with signal 10
dry run time 4.520827054977417
SHARED WEIGHTS ARE
[(0, 15)]
this rank  15 is part of pipeline replica  0
64 chunks
Parent process ID: 21665 node: 172.31.28.143
32 cutpoints
Stages 1
Micro-bs 1 Max mem: 128933453516.80006
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 64530397593.59998
Predicted microbatch size for 2: -1
Stages 4
Micro-bs 1 Max mem: 34529746124.799995
Predicted microbatch size for 4: -1
Stages 8
Micro-bs 1 Max mem: 19529420390.4
Predicted microbatch size for 8: -1
Stages 16
Micro-bs 1 Max mem: 12029257523.2
Predicted microbatch size for 16: 1
comm size 4194304
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 64 0 0 97573.47158206406
End of simulation:  Mini-batch time (usec) = 9027729
Min send: 10000000, max send 0
Min long send: 97573, max long send 127662
Min fwd: 6433, max fwd 20013; min bwd 37432, max bwd 53429
Min long fwd: 15602, max long fwd 25495; min long bwd 46790, max long bwd 57770
Time taken by simulation: 14426 microseconds

{1: inf, 2: inf, 4: inf, 8: inf, 16: 9.027729}
{1: -1, 2: -1, 4: -1, 8: -1, 16: 1}
best config is: 16 1
expected time is 9.027729
1 per stage
16 servers!
Config:
ranks: range(15, 16)
train batch size: 64
partitions: 16
chunk_size: 1
data depth: 1
stage to rank map: 0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;
World size is 16
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=15 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15; --batch-size=64 --num-layers 32 --hidden-size 4096 --num-attention-heads 32 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 64
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 15 signal handler called with signal 10
Process done with return code 1
Parent process ID: 20488 node: 172.31.24.191
32 cutpoints
Stages 1
Micro-bs 1 Max mem: 128933453516.80006
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 64530397593.59998
Predicted microbatch size for 2: -1
Stages 4
Micro-bs 1 Max mem: 34529746124.799995
Predicted microbatch size for 4: -1
Stages 8
Micro-bs 1 Max mem: 19529420390.4
Predicted microbatch size for 8: -1
Stages 16
Micro-bs 1 Max mem: 12029257523.2
Predicted microbatch size for 16: 1
comm size 4194304
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 64 0 0 97573.47158206406
End of simulation:  Mini-batch time (usec) = 9027729
Min send: 10000000, max send 0
Min long send: 97573, max long send 127662
Min fwd: 6433, max fwd 20013; min bwd 37432, max bwd 53429
Min long fwd: 15602, max long fwd 25495; min long bwd 46790, max long bwd 57770
Time taken by simulation: 14248 microseconds

{1: inf, 2: inf, 4: inf, 8: inf, 16: 9.027729}
{1: -1, 2: -1, 4: -1, 8: -1, 16: 1}
best config is: 16 1
expected time is 9.027729
1 per stage
16 servers!
Config:
ranks: range(15, 16)
train batch size: 64
partitions: 16
chunk_size: 1
data depth: 1
stage to rank map: 0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;
World size is 16
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=15 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15; --batch-size=64 --num-layers 32 --hidden-size 4096 --num-attention-heads 32 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 307
Process done with return code 1
Parent process ID: 20746 node: 172.31.24.191
32 cutpoints
Stages 1
Micro-bs 1 Max mem: 128933453516.80006
Predicted microbatch size for 1: -1
Stages 2
Micro-bs 1 Max mem: 64530397593.59998
Predicted microbatch size for 2: -1
Stages 4
Micro-bs 1 Max mem: 34529746124.799995
Predicted microbatch size for 4: -1
Stages 8
Micro-bs 1 Max mem: 19529420390.4
Predicted microbatch size for 8: -1
Stages 16
Micro-bs 1 Max mem: 12029257523.2
Predicted microbatch size for 16: 1
comm size 4194304
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 64 0 0 97573.47158206406
End of simulation:  Mini-batch time (usec) = 9027729
Min send: 10000000, max send 0
Min long send: 97573, max long send 127662
Min fwd: 6433, max fwd 20013; min bwd 37432, max bwd 53429
Min long fwd: 15602, max long fwd 25495; min long bwd 46790, max long bwd 57770
Time taken by simulation: 14284 microseconds

{1: inf, 2: inf, 4: inf, 8: inf, 16: 9.027729}
{1: -1, 2: -1, 4: -1, 8: -1, 16: 1}
best config is: 16 1
expected time is 9.027729
1 per stage
16 servers!
Config:
ranks: range(15, 16)
train batch size: 64
partitions: 16
chunk_size: 1
data depth: 1
stage to rank map: 0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;
World size is 16
/opt/conda/envs/varuna/bin/python -u pretrain_gpt2.py --rank=15 --chunk_size=1 --local_rank=0 --stage_to_rank_map=0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15; --batch-size=64 --num-layers 32 --hidden-size 4096 --num-attention-heads 32 --seq-length 1024 --max-position-embeddings 1024 --train-iters 18750 --lr-decay-iters 18750 --save s3://spot-checkpoints/gpt --load s3://spot-checkpoints/gpt --vocab-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/vocab.json --merge-file /home/ubuntu/SpotDL-DeesSpeed/megatron/Megatron-LM-v1.1.5-3D_parallelism/data/gpt2/merges.txt --data-impl mmap --split 949,50,1 --distributed-backend gloo --lr 0.00015 --min-lr 1.0e-5 --lr-decay-style cosine --weight-decay 1e-2 --clip-grad 1.0 --warmup .01 --log-interval 1 --exit-interval 10000 --save-interval 500 --eval-interval 10000 --use-cpu-initialization --synthetic --eval-iters 10 --varuna --fp16 --resume_step 307
Process done with return code 1
