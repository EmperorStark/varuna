[2022-11-24 13:52:43.542810] Begin to replay trace traces/trace_hl_15_25.txt
[2022-11-24 13:52:43.542872] >>> [0.000] next_event: add at 0
[2022-11-24 13:52:43.542900] >>> [0.000]      node to be add: ['172.31.28.108', '172.31.20.223', '172.31.18.152', '172.31.27.216', '172.31.24.208', '172.31.30.99', '172.31.16.100', '172.31.22.229', '172.31.22.165', '172.31.31.40', '172.31.19.171', '172.31.17.44', '172.31.28.236', '172.31.21.45', '172.31.21.109', '172.31.19.112', '172.31.21.254', '172.31.24.191', '172.31.16.5', '172.31.30.133', '172.31.23.137', '172.31.21.137', '172.31.26.140', '172.31.28.143', '172.31.28.16', '172.31.17.209', '172.31.24.82']
[2022-11-24 13:52:43.544011] >>> [0.001] nnodes: 27, message: 
[2022-11-24 13:52:43.544083]                remain nodes: ['172.31.28.108', '172.31.20.223', '172.31.18.152', '172.31.27.216', '172.31.24.208', '172.31.30.99', '172.31.16.100', '172.31.22.229', '172.31.22.165', '172.31.31.40', '172.31.19.171', '172.31.17.44', '172.31.28.236', '172.31.21.45', '172.31.21.109', '172.31.19.112', '172.31.21.254', '172.31.24.191', '172.31.16.5', '172.31.30.133', '172.31.23.137', '172.31.21.137', '172.31.26.140', '172.31.28.143', '172.31.28.16', '172.31.17.209', '172.31.24.82']
[2022-11-24 13:52:43.544105] >>> [0.001] next_event: no-op at 60000
Container nvidia build = 
Warning! /hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ directory missing. Training cannot start
/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/
/home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json
Logs written to /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/bert_lamb_pretraining.pyt_bert_pretraining_phase1_fp16_gbs1024.log
+ '[' -z /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/bert_lamb_pretraining.pyt_bert_pretraining_phase1_fp16_gbs1024.log ']'
+ tee /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/bert_lamb_pretraining.pyt_bert_pretraining_phase1_fp16_gbs1024.log
+ /opt/conda/envs/varuna/bin/python -m varuna.run_varuna --profile_folder s3://spot-checkpoints/bert-profile --batch_size 1024 --chunk_size 8 --gpus_per_node 1 --machine_list /home/ubuntu/varuna/aws/hosts/available_machines.out /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna
reachable machines: ['172.31.28.108', '172.31.20.223', '172.31.18.152', '172.31.27.216', '172.31.24.208', '172.31.30.99', '172.31.16.100', '172.31.22.229', '172.31.22.165', '172.31.31.40', '172.31.19.171', '172.31.17.44', '172.31.28.236', '172.31.21.45', '172.31.21.109', '172.31.19.112', '172.31.21.254', '172.31.24.191', '172.31.16.5', '172.31.30.133', '172.31.23.137', '172.31.21.137', '172.31.26.140', '172.31.28.143', '172.31.28.16', '172.31.17.209', '172.31.24.82']
/opt/conda/envs/varuna/bin/python -m varuna.morph_server /home/ubuntu/varuna/aws/hosts/available_machines.out /home/ubuntu/varuna/aws/hosts/varuna_current_machines 4200  > varuna_morph.out 2>varuna_morph.err &
/opt/conda/envs/varuna/bin/python -m varuna.catch_all /home/ubuntu/varuna/aws/hosts/varuna_current_machines 5000  > varuna_catch.out 2>varuna_catch.err &
ssh ubuntu@172.31.28.108 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 0 --nservers 27 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.20.223 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 1 --nservers 27 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.18.152 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 2 --nservers 27 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.27.216 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 3 --nservers 27 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.24.208 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 4 --nservers 27 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.30.99 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 5 --nservers 27 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.16.100 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 6 --nservers 27 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.22.229 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 7 --nservers 27 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.22.165 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 8 --nservers 27 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.31.40 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 9 --nservers 27 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.19.171 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 10 --nservers 27 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.17.44 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 11 --nservers 27 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.28.236 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 12 --nservers 27 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.21.45 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 13 --nservers 27 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.21.109 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 14 --nservers 27 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.19.112 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 15 --nservers 27 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.21.254 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 16 --nservers 27 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.24.191 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 17 --nservers 27 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.16.5 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 18 --nservers 27 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.30.133 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 19 --nservers 27 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.23.137 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 20 --nservers 27 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.21.137 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 21 --nservers 27 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.26.140 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 22 --nservers 27 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.28.143 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 23 --nservers 27 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.28.16 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 24 --nservers 27 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.17.209 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 25 --nservers 27 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.24.82 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 26 --nservers 27 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --profile_folder s3://spot-checkpoints/bert-profile /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
+ set +x
finished pretraining
[2022-11-24 13:53:43.600529] >>> [60.058] nnodes: 27, no morph
[2022-11-24 13:53:43.600616] >>> [60.058] next_event: no-op at 120000
[2022-11-24 13:54:43.600597] >>> [120.058] nnodes: 27, no morph
[2022-11-24 13:54:43.600744] >>> [120.058] next_event: no-op at 180000
[2022-11-24 13:55:43.600630] >>> [180.058] nnodes: 27, no morph
[2022-11-24 13:55:43.600777] >>> [180.058] next_event: no-op at 240000
[2022-11-24 13:56:43.602127] >>> [240.059] nnodes: 27, no morph
[2022-11-24 13:56:43.602192] >>> [240.059] next_event: no-op at 300000
[2022-11-24 13:57:43.600533] >>> [300.058] nnodes: 27, no morph
[2022-11-24 13:57:43.600613] >>> [300.058] next_event: add at 360000
[2022-11-24 13:58:43.600554] >>> [360.058]      node to be add: ['172.31.29.147']
[2022-11-24 13:58:43.601341] >>> [360.059] nnodes: 28, message: morph
[2022-11-24 13:58:43.601396]                remain nodes: ['172.31.28.108', '172.31.20.223', '172.31.18.152', '172.31.27.216', '172.31.24.208', '172.31.30.99', '172.31.16.100', '172.31.22.229', '172.31.22.165', '172.31.31.40', '172.31.19.171', '172.31.17.44', '172.31.28.236', '172.31.21.45', '172.31.21.109', '172.31.19.112', '172.31.21.254', '172.31.24.191', '172.31.16.5', '172.31.30.133', '172.31.23.137', '172.31.21.137', '172.31.26.140', '172.31.28.143', '172.31.28.16', '172.31.17.209', '172.31.24.82', '172.31.29.147']
[2022-11-24 13:58:43.601416] >>> [360.059] next_event: add at 420000
[2022-11-24 13:59:43.554065] >>> [420.011]      node to be add: ['172.31.27.21', '172.31.30.89', '172.31.25.155', '172.31.27.155']
[2022-11-24 13:59:43.554638] >>> [420.012] nnodes: 32, message: morph
[2022-11-24 13:59:43.554696]                remain nodes: ['172.31.28.108', '172.31.20.223', '172.31.18.152', '172.31.27.216', '172.31.24.208', '172.31.30.99', '172.31.16.100', '172.31.22.229', '172.31.22.165', '172.31.31.40', '172.31.19.171', '172.31.17.44', '172.31.28.236', '172.31.21.45', '172.31.21.109', '172.31.19.112', '172.31.21.254', '172.31.24.191', '172.31.16.5', '172.31.30.133', '172.31.23.137', '172.31.21.137', '172.31.26.140', '172.31.28.143', '172.31.28.16', '172.31.17.209', '172.31.24.82', '172.31.29.147', '172.31.27.21', '172.31.30.89', '172.31.25.155', '172.31.27.155']
[2022-11-24 13:59:43.554723] >>> [420.012] next_event: no-op at 480000
[2022-11-24 14:00:43.602913] >>> [480.060] nnodes: 32, no morph
[2022-11-24 14:00:43.602999] >>> [480.060] next_event: no-op at 540000
[2022-11-24 14:01:43.600526] >>> [540.058] nnodes: 32, no morph
[2022-11-24 14:01:43.600602] >>> [540.058] next_event: no-op at 600000
[2022-11-24 14:02:43.600555] >>> [600.058] nnodes: 32, no morph
[2022-11-24 14:02:43.600655] >>> [600.058] next_event: no-op at 660000
[2022-11-24 14:03:43.600579] >>> [660.058] nnodes: 32, no morph
[2022-11-24 14:03:43.600767] >>> [660.058] next_event: no-op at 720000
[2022-11-24 14:04:43.600637] >>> [720.058] nnodes: 32, no morph
[2022-11-24 14:04:43.600779] >>> [720.058] next_event: no-op at 780000
[2022-11-24 14:05:43.600527] >>> [780.058] nnodes: 32, no morph
[2022-11-24 14:05:43.600597] >>> [780.058] next_event: no-op at 840000
[2022-11-24 14:06:43.601080] >>> [840.058] nnodes: 32, no morph
[2022-11-24 14:06:43.601266] >>> [840.058] next_event: remove at 900000
[2022-11-24 14:07:13.572569] >>> [870.030]      node to be remove: ['172.31.28.143']
[2022-11-24 14:07:13.573466] >>> [870.031] nnodes: 31, message: preempt 870.0303826332092
[2022-11-24 14:07:13.573504]                remain nodes: ['172.31.28.108', '172.31.20.223', '172.31.18.152', '172.31.27.216', '172.31.24.208', '172.31.30.99', '172.31.16.100', '172.31.22.229', '172.31.22.165', '172.31.31.40', '172.31.19.171', '172.31.17.44', '172.31.28.236', '172.31.21.45', '172.31.21.109', '172.31.19.112', '172.31.21.254', '172.31.24.191', '172.31.16.5', '172.31.30.133', '172.31.23.137', '172.31.21.137', '172.31.26.140', '172.31.28.16', '172.31.17.209', '172.31.24.82', '172.31.29.147', '172.31.27.21', '172.31.30.89', '172.31.25.155', '172.31.27.155']
[2022-11-24 14:07:43.572572] >>> [900.030] Remove node 172.31.28.143, CMD: ssh -q ubuntu@172.31.28.143 bash /home/ubuntu/varuna/aws/remove_node.sh
[2022-11-24 14:07:43.574422] >>> [900.032] next_event: no-op at 960000
[2022-11-24 14:08:43.600643] >>> [960.058] nnodes: 31, no morph
[2022-11-24 14:08:43.600716] >>> [960.058] next_event: remove at 1020000
[2022-11-24 14:09:13.546944] >>> [990.004]      node to be remove: ['172.31.31.40']
[2022-11-24 14:09:13.547452] >>> [990.005] nnodes: 30, message: preempt 990.0044496059418
[2022-11-24 14:09:13.547510]                remain nodes: ['172.31.28.108', '172.31.20.223', '172.31.18.152', '172.31.27.216', '172.31.24.208', '172.31.30.99', '172.31.16.100', '172.31.22.229', '172.31.22.165', '172.31.19.171', '172.31.17.44', '172.31.28.236', '172.31.21.45', '172.31.21.109', '172.31.19.112', '172.31.21.254', '172.31.24.191', '172.31.16.5', '172.31.30.133', '172.31.23.137', '172.31.21.137', '172.31.26.140', '172.31.28.16', '172.31.17.209', '172.31.24.82', '172.31.29.147', '172.31.27.21', '172.31.30.89', '172.31.25.155', '172.31.27.155']
[2022-11-24 14:09:43.572881] >>> [1020.030] Remove node 172.31.31.40, CMD: ssh -q ubuntu@172.31.31.40 bash /home/ubuntu/varuna/aws/remove_node.sh
[2022-11-24 14:09:43.574551] >>> [1020.032] next_event: no-op at 1080000
/home/ubuntu/varuna/aws/remove_node.sh: line 2: [: too many arguments
[2022-11-24 14:10:43.602883] >>> [1080.060] nnodes: 30, no morph
[2022-11-24 14:10:43.602960] >>> [1080.060] next_event: no-op at 1140000
[2022-11-24 14:11:43.592528] >>> [1140.050] nnodes: 30, no morph
[2022-11-24 14:11:43.592584] >>> [1140.050] next_event: no-op at 1200000
[2022-11-24 14:12:43.600565] >>> [1200.058] nnodes: 30, no morph
[2022-11-24 14:12:43.600671] >>> [1200.058] next_event: no-op at 1260000
[2022-11-24 14:13:43.592552] >>> [1260.050] nnodes: 30, no morph
[2022-11-24 14:13:43.592616] >>> [1260.050] next_event: no-op at 1320000
[2022-11-24 14:14:43.600522] >>> [1320.058] nnodes: 30, no morph
[2022-11-24 14:14:43.600598] >>> [1320.058] next_event: add at 1380000
[2022-11-24 14:15:43.602839] >>> [1380.060]      node to be add: ['172.31.28.143']
[2022-11-24 14:15:43.603412] >>> [1380.061] nnodes: 31, message: morph
[2022-11-24 14:15:43.603457]                remain nodes: ['172.31.28.108', '172.31.20.223', '172.31.18.152', '172.31.27.216', '172.31.24.208', '172.31.30.99', '172.31.16.100', '172.31.22.229', '172.31.22.165', '172.31.19.171', '172.31.17.44', '172.31.28.236', '172.31.21.45', '172.31.21.109', '172.31.19.112', '172.31.21.254', '172.31.24.191', '172.31.16.5', '172.31.30.133', '172.31.23.137', '172.31.21.137', '172.31.26.140', '172.31.28.16', '172.31.17.209', '172.31.24.82', '172.31.29.147', '172.31.27.21', '172.31.30.89', '172.31.25.155', '172.31.27.155', '172.31.28.143']
[2022-11-24 14:15:43.603477] >>> [1380.061] next_event: add at 1440000
[2022-11-24 14:16:43.592534] >>> [1440.050]      node to be add: ['172.31.31.40']
[2022-11-24 14:16:43.593018] >>> [1440.050] nnodes: 32, message: morph
[2022-11-24 14:16:43.593065]                remain nodes: ['172.31.28.108', '172.31.20.223', '172.31.18.152', '172.31.27.216', '172.31.24.208', '172.31.30.99', '172.31.16.100', '172.31.22.229', '172.31.22.165', '172.31.19.171', '172.31.17.44', '172.31.28.236', '172.31.21.45', '172.31.21.109', '172.31.19.112', '172.31.21.254', '172.31.24.191', '172.31.16.5', '172.31.30.133', '172.31.23.137', '172.31.21.137', '172.31.26.140', '172.31.28.16', '172.31.17.209', '172.31.24.82', '172.31.29.147', '172.31.27.21', '172.31.30.89', '172.31.25.155', '172.31.27.155', '172.31.28.143', '172.31.31.40']
[2022-11-24 14:16:43.593084] >>> [1440.050] next_event: no-op at 1500000
[2022-11-24 14:17:43.560539] >>> [1500.018] nnodes: 32, no morph
[2022-11-24 14:17:43.560595] >>> [1500.018] next_event: no-op at 1560000
[2022-11-24 14:18:43.548515] >>> [1560.006] nnodes: 32, no morph
[2022-11-24 14:18:43.548571] >>> [1560.006] next_event: no-op at 1620000
[2022-11-24 14:19:43.602873] >>> [1620.060] nnodes: 32, no morph
[2022-11-24 14:19:43.602935] >>> [1620.060] next_event: no-op at 1680000
[2022-11-24 14:20:43.572539] >>> [1680.030] nnodes: 32, no morph
[2022-11-24 14:20:43.572615] >>> [1680.030] next_event: no-op at 1740000
[2022-11-24 14:21:43.585714] >>> [1740.043] nnodes: 32, no morph
[2022-11-24 14:21:43.585773] >>> [1740.043] next_event: remove at 1800000
[2022-11-24 14:22:13.572533] >>> [1770.030]      node to be remove: ['172.31.21.254']
[2022-11-24 14:22:13.573034] >>> [1770.030] nnodes: 31, message: preempt 1770.0300414562225
[2022-11-24 14:22:13.573071]                remain nodes: ['172.31.28.108', '172.31.20.223', '172.31.18.152', '172.31.27.216', '172.31.24.208', '172.31.30.99', '172.31.16.100', '172.31.22.229', '172.31.22.165', '172.31.19.171', '172.31.17.44', '172.31.28.236', '172.31.21.45', '172.31.21.109', '172.31.19.112', '172.31.24.191', '172.31.16.5', '172.31.30.133', '172.31.23.137', '172.31.21.137', '172.31.26.140', '172.31.28.16', '172.31.17.209', '172.31.24.82', '172.31.29.147', '172.31.27.21', '172.31.30.89', '172.31.25.155', '172.31.27.155', '172.31.28.143', '172.31.31.40']
[2022-11-24 14:22:43.572872] >>> [1800.030] Remove node 172.31.21.254, CMD: ssh -q ubuntu@172.31.21.254 bash /home/ubuntu/varuna/aws/remove_node.sh
[2022-11-24 14:22:43.575218] >>> [1800.032] next_event: remove at 1860000
/home/ubuntu/varuna/aws/remove_node.sh: line 2: [: too many arguments
[2022-11-24 14:23:13.572886] >>> [1830.030]      node to be remove: ['172.31.16.5', '172.31.21.109', '172.31.21.45', '172.31.27.216', '172.31.22.165']
[2022-11-24 14:23:13.573453] >>> [1830.031] nnodes: 26, message: preempt 1830.0304367542267
[2022-11-24 14:23:13.573512]                remain nodes: ['172.31.28.108', '172.31.20.223', '172.31.18.152', '172.31.24.208', '172.31.30.99', '172.31.16.100', '172.31.22.229', '172.31.19.171', '172.31.17.44', '172.31.28.236', '172.31.19.112', '172.31.24.191', '172.31.30.133', '172.31.23.137', '172.31.21.137', '172.31.26.140', '172.31.28.16', '172.31.17.209', '172.31.24.82', '172.31.29.147', '172.31.27.21', '172.31.30.89', '172.31.25.155', '172.31.27.155', '172.31.28.143', '172.31.31.40']
[2022-11-24 14:23:43.546632] >>> [1860.004] Remove node 172.31.16.5, CMD: ssh -q ubuntu@172.31.16.5 bash /home/ubuntu/varuna/aws/remove_node.sh
[2022-11-24 14:23:43.548327] >>> [1860.006] Remove node 172.31.21.109, CMD: ssh -q ubuntu@172.31.21.109 bash /home/ubuntu/varuna/aws/remove_node.sh
[2022-11-24 14:23:43.549730] >>> [1860.007] Remove node 172.31.21.45, CMD: ssh -q ubuntu@172.31.21.45 bash /home/ubuntu/varuna/aws/remove_node.sh
[2022-11-24 14:23:43.551091] >>> [1860.008] Remove node 172.31.27.216, CMD: ssh -q ubuntu@172.31.27.216 bash /home/ubuntu/varuna/aws/remove_node.sh
[2022-11-24 14:23:43.552636] >>> [1860.010] Remove node 172.31.22.165, CMD: ssh -q ubuntu@172.31.22.165 bash /home/ubuntu/varuna/aws/remove_node.sh
[2022-11-24 14:23:43.554535] >>> [1860.012] next_event: remove at 1920000
/home/ubuntu/varuna/aws/remove_node.sh: line 2: [: too many arguments
/home/ubuntu/varuna/aws/remove_node.sh: line 2: [: too many arguments
/home/ubuntu/varuna/aws/remove_node.sh: line 2: [: too many arguments
/home/ubuntu/varuna/aws/remove_node.sh: line 2: [: too many arguments
/home/ubuntu/varuna/aws/remove_node.sh: line 2: [: too many arguments
[2022-11-24 14:24:13.572895] >>> [1890.030]      node to be remove: ['172.31.17.44']
[2022-11-24 14:24:13.573424] >>> [1890.031] nnodes: 25, message: preempt 1890.030416727066
[2022-11-24 14:24:13.573468]                remain nodes: ['172.31.28.108', '172.31.20.223', '172.31.18.152', '172.31.24.208', '172.31.30.99', '172.31.16.100', '172.31.22.229', '172.31.19.171', '172.31.28.236', '172.31.19.112', '172.31.24.191', '172.31.30.133', '172.31.23.137', '172.31.21.137', '172.31.26.140', '172.31.28.16', '172.31.17.209', '172.31.24.82', '172.31.29.147', '172.31.27.21', '172.31.30.89', '172.31.25.155', '172.31.27.155', '172.31.28.143', '172.31.31.40']
[2022-11-24 14:24:43.572786] >>> [1920.030] Remove node 172.31.17.44, CMD: ssh -q ubuntu@172.31.17.44 bash /home/ubuntu/varuna/aws/remove_node.sh
[2022-11-24 14:24:43.574603] >>> [1920.032] next_event: remove at 1980000
/home/ubuntu/varuna/aws/remove_node.sh: line 2: [: too many arguments
[2022-11-24 14:25:13.572881] >>> [1950.030]      node to be remove: ['172.31.17.209', '172.31.25.155']
[2022-11-24 14:25:13.573438] >>> [1950.031] nnodes: 23, message: preempt 1950.0304260253906
[2022-11-24 14:25:13.573490]                remain nodes: ['172.31.28.108', '172.31.20.223', '172.31.18.152', '172.31.24.208', '172.31.30.99', '172.31.16.100', '172.31.22.229', '172.31.19.171', '172.31.28.236', '172.31.19.112', '172.31.24.191', '172.31.30.133', '172.31.23.137', '172.31.21.137', '172.31.26.140', '172.31.28.16', '172.31.24.82', '172.31.29.147', '172.31.27.21', '172.31.30.89', '172.31.27.155', '172.31.28.143', '172.31.31.40']
[2022-11-24 14:25:43.572892] >>> [1980.030] Remove node 172.31.17.209, CMD: ssh -q ubuntu@172.31.17.209 bash /home/ubuntu/varuna/aws/remove_node.sh
[2022-11-24 14:25:43.574604] >>> [1980.032] Remove node 172.31.25.155, CMD: ssh -q ubuntu@172.31.25.155 bash /home/ubuntu/varuna/aws/remove_node.sh
[2022-11-24 14:25:43.575962] >>> [1980.033] next_event: no-op at 2040000
/home/ubuntu/varuna/aws/remove_node.sh: line 2: [: too many arguments
/home/ubuntu/varuna/aws/remove_node.sh: line 2: [: too many arguments
[2022-11-24 14:26:43.546168] >>> [2040.003] nnodes: 23, no morph
[2022-11-24 14:26:43.546226] >>> [2040.003] next_event: no-op at 2100000
[2022-11-24 14:27:43.549994] >>> [2100.007] nnodes: 23, no morph
[2022-11-24 14:27:43.550051] >>> [2100.007] next_event: no-op at 2160000
[2022-11-24 14:28:43.552739] >>> [2160.010] nnodes: 23, no morph
[2022-11-24 14:28:43.552794] >>> [2160.010] next_event: no-op at 2220000
[2022-11-24 14:29:43.602900] >>> [2220.060] nnodes: 23, no morph
[2022-11-24 14:29:43.602986] >>> [2220.060] next_event: no-op at 2280000
[2022-11-24 14:30:43.602863] >>> [2280.060] nnodes: 23, no morph
[2022-11-24 14:30:43.602952] >>> [2280.060] next_event: no-op at 2340000
[2022-11-24 14:31:43.543187] >>> [2340.000] nnodes: 23, no morph
[2022-11-24 14:32:43.584120] >>> [2400.041] nnodes: 23, message: preempt 2400.0411002635956
[2022-11-24 14:32:43.584173]           Finally kill all
