Parent process ID: 8764 node: 172.31.24.82
24 cutpoints
Stages 1
13 20868437708.800007
7 13915698585.599995
10 17153729331.199993
8 14622140211.200005
9 15846820659.199995
Predicted microbatch size for 1: 8
comm size 0
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 1 5 0 1286522.0947265625 0
End of simulation:  Mini-batch time (usec) = 2905085
Min send: 10000000, max send 0
Min long send: 10000000, max long send 0
Min fwd: 10000000, max fwd 0; min bwd 10000000, max bwd 0
Min long fwd: 126283, max long fwd 129698; min long bwd 193190, max long bwd 199310
Time taken by simulation: 42 microseconds

Stages 2
13 10987980083.2
19 14996390399.999996
22 16963644723.199997
20 15631126630.400002
Predicted microbatch size for 2: 19
comm size 9961472
WARNING: no send time found, 2 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 2 5 0 635506.6528320312 542254.6839368516
End of simulation:  Mini-batch time (usec) = 3634860
Min send: 10000000, max send 0
Min long send: 542586, max long send 558986
Min fwd: 106816, max fwd 113936; min bwd 154625, max bwd 157669
Min long fwd: 134083, max long fwd 138081; min long bwd 169664, max long bwd 173713
Time taken by simulation: 118 microseconds

Stages 3
13 7832942284.800001
19 10697074380.8
22 12097432473.599998
23 12575272243.2
24 13035207577.6
Predicted microbatch size for 3: 24
comm size 12582912
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 5 0 443515.80810546875 663682.2411979454
End of simulation:  Mini-batch time (usec) = 4988556
Min send: 10000000, max send 0
Min long send: 664014, max long send 679713
Min fwd: 72258, max fwd 88035; min bwd 119079, max bwd 130804
Min long fwd: 107414, max long fwd 112703; min long bwd 150032, max long bwd 153679
Time taken by simulation: 211 microseconds

Stages 4
13 6255423385.6
19 8547416371.2
22 9664326348.8
23 10045446451.2
24 10412856422.4
Predicted microbatch size for 4: 24
comm size 12582912
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 8 0 326449.15771484375 663682.2411979454
End of simulation:  Mini-batch time (usec) = 6677364
Min send: 10000000, max send 0
Min long send: 663870, max long send 686148
Min fwd: 51765, max fwd 66948; min bwd 85303, max bwd 98547
Min long fwd: 83336, max long fwd 91250; min long bwd 118529, max long bwd 127083
Time taken by simulation: 368 microseconds

Stages 6
13 4698582732.8
19 6397758361.599999
22 7231220224.0
23 7515620659.2
24 7790505267.2
Predicted microbatch size for 6: 24
comm size 12582912
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 11 0 240705.6121826172 663682.2411979454
End of simulation:  Mini-batch time (usec) = 9735715
Min send: 10000000, max send 0
Min long send: 663764, max long send 689782
Min fwd: 32942, max fwd 48168; min bwd 55337, max bwd 68897
Min long fwd: 65982, max long fwd 73316; min long bwd 85277, max long bwd 90311
Time taken by simulation: 771 microseconds

Stages 8
13 3930501529.6000004
19 5322929356.799999
22 6014667161.6
23 6250707763.2
24 6479329689.6
Predicted microbatch size for 8: 24
comm size 12582912
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 15 0 176039.7491455078 663682.2411979454
End of simulation:  Mini-batch time (usec) = 13724566
Min send: 10000000, max send 0
Min long send: 663736, max long send 690844
Min fwd: 22801, max fwd 38139; min bwd 36151, max bwd 55503
Min long fwd: 51106, max long fwd 59884; min long bwd 68124, max long bwd 75476
Time taken by simulation: 1446 microseconds

Stages 12
13 3141742080.0
19 4248100352.0
22 4798114099.200001
23 4985794867.2
24 5168154112.0
Predicted microbatch size for 12: 24
comm size 12582912
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 22 0 97192.52014160156 663682.2411979454
End of simulation:  Mini-batch time (usec) = 21189724
Min send: 10000000, max send 0
Min long send: 663682, max long send 690844
Min fwd: 10724, max fwd 28920; min bwd 23319, max bwd 41964
Min long fwd: 40826, max long fwd 50474; min long bwd 49192, max long bwd 58811
Time taken by simulation: 3350 microseconds

{1: 2.905085, 2: 3.63486, 3: 4.988556, 4: 6.677364, 6: 9.735715, 8: 13.724566, 12: 21.189724}
{1: 8, 2: 19, 3: 24, 4: 24, 6: 24, 8: 24, 12: 24}
best config is: 2 19
expected time is 3.63486
13 per stage
26 servers!
26 26 I am of no use!
Parent process ID: 9098 node: 172.31.24.82
24 cutpoints
Stages 1
13 20868437708.800007
7 13915698585.599995
10 17153729331.199993
8 14622140211.200005
9 15846820659.199995
Predicted microbatch size for 1: 8
comm size 0
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 1 5 0 1286522.0947265625 0
End of simulation:  Mini-batch time (usec) = 2905085
Min send: 10000000, max send 0
Min long send: 10000000, max long send 0
Min fwd: 10000000, max fwd 0; min bwd 10000000, max bwd 0
Min long fwd: 126283, max long fwd 129698; min long bwd 193190, max long bwd 199310
Time taken by simulation: 49 microseconds

Stages 2
13 10987980083.2
19 14996390399.999996
22 16963644723.199997
20 15631126630.400002
Predicted microbatch size for 2: 19
comm size 9961472
WARNING: no send time found, 2 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 2 4 0 645340.8203125 542254.6839368516
End of simulation:  Mini-batch time (usec) = 3338780
Min send: 10000000, max send 0
Min long send: 542586, max long send 555338
Min fwd: 107744, max fwd 113936; min bwd 155753, max bwd 158782
Min long fwd: 131842, max long fwd 138676; min long bwd 169332, max long bwd 173300
Time taken by simulation: 95 microseconds

Stages 3
13 7832942284.800001
19 10697074380.8
22 12097432473.599998
23 12575272243.2
24 13035207577.6
Predicted microbatch size for 3: 24
comm size 12582912
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 5 0 443515.80810546875 663682.2411979454
End of simulation:  Mini-batch time (usec) = 4988556
Min send: 10000000, max send 0
Min long send: 664014, max long send 679713
Min fwd: 72258, max fwd 88035; min bwd 119079, max bwd 130804
Min long fwd: 107414, max long fwd 112703; min long bwd 150032, max long bwd 153679
Time taken by simulation: 168 microseconds

Stages 4
13 6255423385.6
19 8547416371.2
22 9664326348.8
23 10045446451.2
24 10412856422.4
Predicted microbatch size for 4: 24
comm size 12582912
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 7 0 358221.00830078125 663682.2411979454
End of simulation:  Mini-batch time (usec) = 6464795
Min send: 10000000, max send 0
Min long send: 663870, max long send 683729
Min fwd: 53924, max fwd 67812; min bwd 83975, max bwd 97299
Min long fwd: 86081, max long fwd 91318; min long bwd 118237, max long bwd 121834
Time taken by simulation: 317 microseconds

Stages 6
13 4698582732.8
19 6397758361.599999
22 7231220224.0
23 7515620659.2
24 7790505267.2
Predicted microbatch size for 6: 24
comm size 12582912
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 11 0 240705.6121826172 663682.2411979454
End of simulation:  Mini-batch time (usec) = 9735715
Min send: 10000000, max send 0
Min long send: 663764, max long send 689782
Min fwd: 32942, max fwd 48168; min bwd 55337, max bwd 68897
Min long fwd: 65982, max long fwd 73316; min long bwd 85277, max long bwd 90311
Time taken by simulation: 878 microseconds

Stages 8
13 3930501529.6000004
19 5322929356.799999
22 6014667161.6
23 6250707763.2
24 6479329689.6
Predicted microbatch size for 8: 24
comm size 12582912
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 15 0 176039.7491455078 663682.2411979454
End of simulation:  Mini-batch time (usec) = 13724566
Min send: 10000000, max send 0
Min long send: 663736, max long send 690844
Min fwd: 22801, max fwd 38139; min bwd 36151, max bwd 55503
Min long fwd: 51106, max long fwd 59884; min long bwd 68124, max long bwd 75476
Time taken by simulation: 1457 microseconds

Stages 12
13 3141742080.0
19 4248100352.0
22 4798114099.200001
23 4985794867.2
24 5168154112.0
Predicted microbatch size for 12: 24
comm size 12582912
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 22 0 97192.52014160156 663682.2411979454
End of simulation:  Mini-batch time (usec) = 21189724
Min send: 10000000, max send 0
Min long send: 663682, max long send 690844
Min fwd: 10724, max fwd 28920; min bwd 23319, max bwd 41964
Min long fwd: 40826, max long fwd 50474; min long bwd 49192, max long bwd 58811
Time taken by simulation: 3476 microseconds

{1: 2.905085, 2: 3.33878, 3: 4.988556, 4: 6.464795, 6: 9.735715, 8: 13.724566, 12: 21.189724}
{1: 8, 2: 19, 3: 24, 4: 24, 6: 24, 8: 24, 12: 24}
best config is: 2 19
expected time is 3.33878
14 per stage
28 servers!
Config:
ranks: range(26, 27)
train batch size: 1024
partitions: 2
chunk_size: 19
data depth: 14
stage to rank map: 0,2,4,6,8,10,12,14,16,18,20,22,24,26;1,3,5,7,9,11,13,15,17,19,21,23,25,27;
World size is 28
/opt/conda/envs/varuna/bin/python -u /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --rank=26 --chunk_size=19 --local_rank=0 --stage_to_rank_map=0,2,4,6,8,10,12,14,16,18,20,22,24,26;1,3,5,7,9,11,13,15,17,19,21,23,25,27; --batch-size=73 --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna --resume_step 144
device: cuda:0 n_gpu: 1, distributed training: True, 16-bits training: True
dry run time 0.22637224197387695
SHARED WEIGHTS ARE
[(0, 1)]
this rank  26 is part of pipeline replica  13
4 chunks
Begin to load checkpint from s3://spot-checkpoints/bert/ckpt_144.pt
2022-11-24 13:59:22.766221 resume step from  144
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 26 signal handler called with signal 10
2022-11-24 14:00:18.390093 - Finished loading checkpoint, takes 55.477 secs
2022-11-24 14:00:31.372631 Begin to exit
Process done with return code 0
Parent process ID: 10384 node: 172.31.24.82
24 cutpoints
Stages 1
13 20868437708.800007
7 13915698585.599995
10 17153729331.199993
8 14622140211.200005
9 15846820659.199995
Predicted microbatch size for 1: 8
comm size 0
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 1 4 0 3150942.3828125 0
End of simulation:  Mini-batch time (usec) = 4450032
Min send: 10000000, max send 0
Min long send: 10000000, max long send 0
Min fwd: 10000000, max fwd 0; min bwd 10000000, max bwd 0
Min long fwd: 127414, max long fwd 129698; min long bwd 194806, max long bwd 199310
Time taken by simulation: 44 microseconds

Stages 2
13 10987980083.2
19 14996390399.999996
22 16963644723.199997
20 15631126630.400002
Predicted microbatch size for 2: 19
comm size 9961472
WARNING: no send time found, 2 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 2 4 0 673273.3154296875 542254.6839368516
End of simulation:  Mini-batch time (usec) = 3366713
Min send: 10000000, max send 0
Min long send: 542586, max long send 555338
Min fwd: 107744, max fwd 113936; min bwd 155753, max bwd 158782
Min long fwd: 131842, max long fwd 138676; min long bwd 169332, max long bwd 173300
Time taken by simulation: 119 microseconds

Stages 3
13 7832942284.800001
19 10697074380.8
22 12097432473.599998
23 12575272243.2
24 13035207577.6
Predicted microbatch size for 3: 24
comm size 12582912
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 5 0 448996.58203125 663682.2411979454
End of simulation:  Mini-batch time (usec) = 4994037
Min send: 10000000, max send 0
Min long send: 664014, max long send 679713
Min fwd: 72258, max fwd 88035; min bwd 119079, max bwd 130804
Min long fwd: 107414, max long fwd 112703; min long bwd 150032, max long bwd 153679
Time taken by simulation: 172 microseconds

Stages 4
13 6255423385.6
19 8547416371.2
22 9664326348.8
23 10045446451.2
24 10412856422.4
Predicted microbatch size for 4: 24
comm size 12582912
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 6 0 375752.13623046875 663682.2411979454
End of simulation:  Mini-batch time (usec) = 6314108
Min send: 10000000, max send 0
Min long send: 663764, max long send 688387
Min fwd: 53924, max fwd 66948; min bwd 83975, max bwd 98046
Min long fwd: 84759, max long fwd 91250; min long bwd 120659, max long bwd 125455
Time taken by simulation: 276 microseconds

Stages 6
13 4698582732.8
19 6397758361.599999
22 7231220224.0
23 7515620659.2
24 7790505267.2
Predicted microbatch size for 6: 24
comm size 12582912
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 9 0 241996.6583251953 663682.2411979454
End of simulation:  Mini-batch time (usec) = 9164548
Min send: 10000000, max send 0
Min long send: 663736, max long send 687371
Min fwd: 33746, max fwd 47347; min bwd 54554, max bwd 72477
Min long fwd: 65864, max long fwd 73316; min long bwd 84274, max long bwd 89413
Time taken by simulation: 620 microseconds

Stages 8
13 3930501529.6000004
19 5322929356.799999
22 6014667161.6
23 6250707763.2
24 6479329689.6
Predicted microbatch size for 8: 24
comm size 12582912
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 11 0 214379.08935546875 663682.2411979454
End of simulation:  Mini-batch time (usec) = 12421079
Min send: 10000000, max send 0
Min long send: 663682, max long send 689782
Min fwd: 22992, max fwd 37161; min bwd 37517, max bwd 55449
Min long fwd: 51419, max long fwd 57045; min long bwd 68935, max long bwd 77274
Time taken by simulation: 1039 microseconds

Stages 12
13 3141742080.0
19 4248100352.0
22 4798114099.200001
23 4985794867.2
24 5168154112.0
Predicted microbatch size for 12: 24
comm size 12582912
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 22 0 97192.52014160156 663682.2411979454
End of simulation:  Mini-batch time (usec) = 21189724
Min send: 10000000, max send 0
Min long send: 663682, max long send 690844
Min fwd: 10724, max fwd 28920; min bwd 23319, max bwd 41964
Min long fwd: 40826, max long fwd 50474; min long bwd 49192, max long bwd 58811
Time taken by simulation: 3346 microseconds

{1: 4.450032, 2: 3.366713, 3: 4.994037, 4: 6.314108, 6: 9.164548, 8: 12.421079, 12: 21.189724}
{1: 8, 2: 19, 3: 24, 4: 24, 6: 24, 8: 24, 12: 24}
best config is: 2 19
expected time is 3.366713
16 per stage
32 servers!
Config:
ranks: range(26, 27)
train batch size: 1024
partitions: 2
chunk_size: 19
data depth: 16
stage to rank map: 0,2,4,6,8,10,12,14,16,18,20,22,24,26,28,30;1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31;
World size is 32
/opt/conda/envs/varuna/bin/python -u /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --rank=26 --chunk_size=19 --local_rank=0 --stage_to_rank_map=0,2,4,6,8,10,12,14,16,18,20,22,24,26,28,30;1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31; --batch-size=64 --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna --resume_step 144
device: cuda:0 n_gpu: 1, distributed training: True, 16-bits training: True
dry run time 0.14778494834899902
SHARED WEIGHTS ARE
[(0, 1)]
this rank  26 is part of pipeline replica  13
4 chunks
Begin to load checkpint from s3://spot-checkpoints/bert/ckpt_144.pt
2022-11-24 14:00:52.848838 resume step from  144
2022-11-24 14:01:52.774058 - Finished loading checkpoint, takes 59.783 secs
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  524288.0
[2022-11-24 14:02:26.488669] Finished iteration 144, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5710.912
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  262144.0
[2022-11-24 14:02:29.715336] Finished iteration 145, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3226.380
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  131072.0
[2022-11-24 14:02:32.848125] Finished iteration 146, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3132.768
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  65536.0
[2022-11-24 14:02:35.990750] Finished iteration 147, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3142.583
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  32768.0
[2022-11-24 14:02:39.100540] Finished iteration 148, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3109.718
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  16384.0
[2022-11-24 14:02:41.199758] Finished iteration 149, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2099.163
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  8192.0
[2022-11-24 14:02:43.335325] Finished iteration 150, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2135.523
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  4096.0
[2022-11-24 14:02:45.388267] Finished iteration 151, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2052.907
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  2048.0
[2022-11-24 14:02:47.489797] Finished iteration 152, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2101.635
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1024.0
[2022-11-24 14:02:49.607421] Finished iteration 153, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2117.441
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  512.0
[2022-11-24 14:02:51.707306] Finished iteration 154, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2099.864
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  256.0
[2022-11-24 14:02:53.785284] Finished iteration 155, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2077.953
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  128.0
[2022-11-24 14:02:55.938015] Finished iteration 156, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2152.875
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  64.0
[2022-11-24 14:02:58.043110] Finished iteration 157, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2104.851
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  32.0
[2022-11-24 14:03:00.147262] Finished iteration 158, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2104.136
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  16.0
[2022-11-24 14:03:02.261574] Finished iteration 159, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2114.276
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  8.0
[2022-11-24 14:03:04.353763] Finished iteration 160, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2092.170
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  4.0
[2022-11-24 14:03:06.507034] Finished iteration 161, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2153.229
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  2.0
[2022-11-24 14:03:08.601090] Finished iteration 162, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2094.012
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:11.887271] Finished iteration 163, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3286.166
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:14.005359] Finished iteration 164, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2118.192
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:16.133430] Finished iteration 165, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2127.859
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:18.234147] Finished iteration 166, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2100.858
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:20.375717] Finished iteration 167, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2141.362
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:22.443319] Finished iteration 168, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2067.548
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:24.589317] Finished iteration 169, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2145.972
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:26.735619] Finished iteration 170, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2146.424
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:28.897400] Finished iteration 171, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2161.587
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:31.039932] Finished iteration 172, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2142.502
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:33.200677] Finished iteration 173, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2160.697
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:35.285205] Finished iteration 174, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2084.524
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:37.400725] Finished iteration 175, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2115.478
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:39.477442] Finished iteration 176, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2076.690
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:41.591449] Finished iteration 177, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2114.097
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:43.753723] Finished iteration 178, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2162.116
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:45.953491] Finished iteration 179, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2199.723
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:48.048890] Finished iteration 180, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2095.363
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:50.179106] Finished iteration 181, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2130.180
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:52.293840] Finished iteration 182, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2114.699
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:54.409625] Finished iteration 183, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2115.752
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:56.555193] Finished iteration 184, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2145.546
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:58.642090] Finished iteration 185, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2086.890
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:00.754263] Finished iteration 186, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2112.129
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:02.902531] Finished iteration 187, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2148.231
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:04.987280] Finished iteration 188, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2084.708
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:07.122358] Finished iteration 189, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2135.078
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:09.249966] Finished iteration 190, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2127.577
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:11.352276] Finished iteration 191, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2102.247
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:13.485872] Finished iteration 192, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2133.575
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:15.596482] Finished iteration 193, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2110.573
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:17.697041] Finished iteration 194, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2100.523
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:19.826389] Finished iteration 195, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2129.328
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:21.955005] Finished iteration 196, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2128.584
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:24.111683] Finished iteration 197, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2156.684
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:26.180197] Finished iteration 198, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2068.438
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:28.230039] Finished iteration 199, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2049.980
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:30.355593] Finished iteration 200, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2125.352
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:32.470538] Finished iteration 201, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2114.906
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:34.590402] Finished iteration 202, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2119.843
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:36.704508] Finished iteration 203, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2114.086
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:38.816684] Finished iteration 204, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2112.138
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:41.276605] Finished iteration 205, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2459.881
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:43.727323] Finished iteration 206, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2450.691
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:45.867524] Finished iteration 207, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2140.326
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:49.105409] Finished iteration 208, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3237.686
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:51.566304] Finished iteration 209, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2460.869
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:53.751605] Finished iteration 210, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2185.261
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:55.854309] Finished iteration 211, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2102.673
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:57.913997] Finished iteration 212, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2059.695
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:00.057707] Finished iteration 213, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2143.644
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:02.197762] Finished iteration 214, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2140.032
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:04.275145] Finished iteration 215, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2077.345
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:06.409726] Finished iteration 216, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2134.560
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:08.541979] Finished iteration 217, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2132.251
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:10.631298] Finished iteration 218, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2089.259
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:12.759579] Finished iteration 219, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2128.250
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:14.888216] Finished iteration 220, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2128.615
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:16.965261] Finished iteration 221, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2077.012
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:19.082668] Finished iteration 222, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2117.380
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:21.197256] Finished iteration 223, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2114.558
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:23.320752] Finished iteration 224, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2123.463
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:25.454207] Finished iteration 225, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2133.442
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:27.574253] Finished iteration 226, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2120.007
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:29.672190] Finished iteration 227, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2097.916
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:31.830764] Finished iteration 228, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2158.574
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:33.995648] Finished iteration 229, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2164.827
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:36.150042] Finished iteration 230, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2154.407
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:38.252236] Finished iteration 231, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2102.139
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:40.368176] Finished iteration 232, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2116.015
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:42.483039] Finished iteration 233, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2114.696
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:44.595323] Finished iteration 234, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2112.245
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:46.745307] Finished iteration 235, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2149.951
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:48.839533] Finished iteration 236, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2094.381
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:50.951844] Finished iteration 237, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2112.103
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:53.031306] Finished iteration 238, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2079.575
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:55.130391] Finished iteration 239, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2098.886
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:57.222992] Finished iteration 240, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2092.586
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:00.132711] Finished iteration 241, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2909.689
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:02.245980] Finished iteration 242, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2113.276
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:04.371543] Finished iteration 243, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2125.470
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:06.467505] Finished iteration 244, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2095.938
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:08.569054] Finished iteration 245, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2101.528
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:10.729093] Finished iteration 246, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2160.006
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:12.785152] Finished iteration 247, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2056.030
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:14.888694] Finished iteration 248, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2103.663
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:17.010946] Finished iteration 249, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2122.058
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:19.117143] Finished iteration 250, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2106.195
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:21.217120] Finished iteration 251, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2099.922
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:23.338380] Finished iteration 252, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2121.231
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:25.426658] Finished iteration 253, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2088.253
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:27.533506] Finished iteration 254, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2106.818
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:29.638285] Finished iteration 255, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2104.742
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:31.759184] Finished iteration 256, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2120.857
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:33.948874] Finished iteration 257, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2189.662
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:36.045434] Finished iteration 258, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2096.548
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:38.097790] Finished iteration 259, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2052.321
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:40.171371] Finished iteration 260, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2073.569
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:42.337175] Finished iteration 261, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2165.740
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:44.434376] Finished iteration 262, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2097.203
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:46.528105] Finished iteration 263, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2093.704
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:48.622363] Finished iteration 264, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2094.201
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:50.763662] Finished iteration 265, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2141.282
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:52.905403] Finished iteration 266, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2141.685
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:54.999883] Finished iteration 267, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2094.453
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:57.068236] Finished iteration 268, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2068.327
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:59.208002] Finished iteration 269, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2139.733
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:07:01.334110] Finished iteration 270, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2126.118
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:07:03.423168] Finished iteration 271, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2088.985
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:07:05.551988] Finished iteration 272, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2128.791
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:07:07.618325] Finished iteration 273, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2066.325
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:07:09.659926] Finished iteration 274, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2041.555
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:07:11.775042] Finished iteration 275, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2115.091
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:07:13.950418] Finished iteration 276, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2175.379
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:07:16.756862] Finished iteration 277, CKPT_AND_STOP: False, flag: tensor([2], dtype=torch.int32), speed: 2806.429
2022-11-24 14:07:16.761332 Begin to save checkpont to s3://spot-checkpoints/bert and exit
Opt ckpt time 4.04499888420105
Process done with return code 0
Parent process ID: 11323 node: 172.31.29.147
24 cutpoints
Stages 1
13 20868437708.800007
7 13915698585.599995
10 17153729331.199993
8 14622140211.200005
9 15846820659.199995
Predicted microbatch size for 1: 8
comm size 0
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 1 5 0 1286522.0947265625 0
End of simulation:  Mini-batch time (usec) = 2905085
Min send: 10000000, max send 0
Min long send: 10000000, max long send 0
Min fwd: 10000000, max fwd 0; min bwd 10000000, max bwd 0
Min long fwd: 126283, max long fwd 129698; min long bwd 193190, max long bwd 199310
Time taken by simulation: 45 microseconds

Stages 2
13 10987980083.2
19 14996390399.999996
22 16963644723.199997
20 15631126630.400002
Predicted microbatch size for 2: 19
comm size 9961472
WARNING: no send time found, 2 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 2 4 0 638222.2290039062 542254.6839368516
End of simulation:  Mini-batch time (usec) = 3331662
Min send: 10000000, max send 0
Min long send: 542586, max long send 555338
Min fwd: 107744, max fwd 113936; min bwd 155753, max bwd 158782
Min long fwd: 131842, max long fwd 138676; min long bwd 169332, max long bwd 173300
Time taken by simulation: 96 microseconds

Stages 3
13 7832942284.800001
19 10697074380.8
22 12097432473.599998
23 12575272243.2
24 13035207577.6
Predicted microbatch size for 3: 24
comm size 12582912
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 5 0 448996.58203125 663682.2411979454
End of simulation:  Mini-batch time (usec) = 4994037
Min send: 10000000, max send 0
Min long send: 664014, max long send 679713
Min fwd: 72258, max fwd 88035; min bwd 119079, max bwd 130804
Min long fwd: 107414, max long fwd 112703; min long bwd 150032, max long bwd 153679
Time taken by simulation: 170 microseconds

Stages 4
13 6255423385.6
19 8547416371.2
22 9664326348.8
23 10045446451.2
24 10412856422.4
Predicted microbatch size for 4: 24
comm size 12582912
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 7 0 358221.00830078125 663682.2411979454
End of simulation:  Mini-batch time (usec) = 6464795
Min send: 10000000, max send 0
Min long send: 663870, max long send 683729
Min fwd: 53924, max fwd 67812; min bwd 83975, max bwd 97299
Min long fwd: 86081, max long fwd 91318; min long bwd 118237, max long bwd 121834
Time taken by simulation: 318 microseconds

Stages 6
13 4698582732.8
19 6397758361.599999
22 7231220224.0
23 7515620659.2
24 7790505267.2
Predicted microbatch size for 6: 24
comm size 12582912
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 9 0 241996.6583251953 663682.2411979454
End of simulation:  Mini-batch time (usec) = 9164548
Min send: 10000000, max send 0
Min long send: 663736, max long send 687371
Min fwd: 33746, max fwd 47347; min bwd 54554, max bwd 72477
Min long fwd: 65864, max long fwd 73316; min long bwd 84274, max long bwd 89413
Time taken by simulation: 671 microseconds

Stages 8
13 3930501529.6000004
19 5322929356.799999
22 6014667161.6
23 6250707763.2
24 6479329689.6
Predicted microbatch size for 8: 24
comm size 12582912
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 15 0 176039.7491455078 663682.2411979454
End of simulation:  Mini-batch time (usec) = 13724566
Min send: 10000000, max send 0
Min long send: 663736, max long send 690844
Min fwd: 22801, max fwd 38139; min bwd 36151, max bwd 55503
Min long fwd: 51106, max long fwd 59884; min long bwd 68124, max long bwd 75476
Time taken by simulation: 1456 microseconds

Stages 12
13 3141742080.0
19 4248100352.0
22 4798114099.200001
23 4985794867.2
24 5168154112.0
Predicted microbatch size for 12: 24
comm size 12582912
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 22 0 97192.52014160156 663682.2411979454
End of simulation:  Mini-batch time (usec) = 21189724
Min send: 10000000, max send 0
Min long send: 663682, max long send 690844
Min fwd: 10724, max fwd 28920; min bwd 23319, max bwd 41964
Min long fwd: 40826, max long fwd 50474; min long bwd 49192, max long bwd 58811
Time taken by simulation: 3407 microseconds

{1: 2.905085, 2: 3.331662, 3: 4.994037, 4: 6.464795, 6: 9.164548, 8: 13.724566, 12: 21.189724}
{1: 8, 2: 19, 3: 24, 4: 24, 6: 24, 8: 24, 12: 24}
best config is: 2 19
expected time is 3.331662
15 per stage
30 servers!
Config:
ranks: range(26, 27)
train batch size: 1024
partitions: 2
chunk_size: 19
data depth: 15
stage to rank map: 0,2,4,6,8,10,12,14,16,18,20,22,24,26,28;1,3,5,7,9,11,13,15,17,19,21,23,25,27,29;
World size is 30
/opt/conda/envs/varuna/bin/python -u /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --rank=26 --chunk_size=19 --local_rank=0 --stage_to_rank_map=0,2,4,6,8,10,12,14,16,18,20,22,24,26,28;1,3,5,7,9,11,13,15,17,19,21,23,25,27,29; --batch-size=68 --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna --resume_step 278
device: cuda:0 n_gpu: 1, distributed training: True, 16-bits training: True
dry run time 0.14756512641906738
SHARED WEIGHTS ARE
[(0, 1)]
this rank  26 is part of pipeline replica  13
4 chunks
Begin to load checkpint from s3://spot-checkpoints/bert/ckpt_278.pt
2022-11-24 14:08:27.188662 resume step from  278
2022-11-24 14:09:32.855617 - Finished loading checkpoint, takes 65.482 secs
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 26 signal handler called with signal 10
Process done with return code 1
Parent process ID: 11347 node: 172.31.27.21
24 cutpoints
Stages 1
13 20868437708.800007
7 13915698585.599995
10 17153729331.199993
8 14622140211.200005
9 15846820659.199995
Predicted microbatch size for 1: 8
comm size 0
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 1 5 0 1286522.0947265625 0
End of simulation:  Mini-batch time (usec) = 2905085
Min send: 10000000, max send 0
Min long send: 10000000, max long send 0
Min fwd: 10000000, max fwd 0; min bwd 10000000, max bwd 0
Min long fwd: 126283, max long fwd 129698; min long bwd 193190, max long bwd 199310
Time taken by simulation: 51 microseconds

Stages 2
13 10987980083.2
19 14996390399.999996
22 16963644723.199997
20 15631126630.400002
Predicted microbatch size for 2: 19
comm size 9961472
WARNING: no send time found, 2 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 2 4 0 638222.2290039062 542254.6839368516
End of simulation:  Mini-batch time (usec) = 3331662
Min send: 10000000, max send 0
Min long send: 542586, max long send 555338
Min fwd: 107744, max fwd 113936; min bwd 155753, max bwd 158782
Min long fwd: 131842, max long fwd 138676; min long bwd 169332, max long bwd 173300
Time taken by simulation: 94 microseconds

Stages 3
13 7832942284.800001
19 10697074380.8
22 12097432473.599998
23 12575272243.2
24 13035207577.6
Predicted microbatch size for 3: 24
comm size 12582912
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 5 0 448996.58203125 663682.2411979454
End of simulation:  Mini-batch time (usec) = 4994037
Min send: 10000000, max send 0
Min long send: 664014, max long send 679713
Min fwd: 72258, max fwd 88035; min bwd 119079, max bwd 130804
Min long fwd: 107414, max long fwd 112703; min long bwd 150032, max long bwd 153679
Time taken by simulation: 167 microseconds

Stages 4
13 6255423385.6
19 8547416371.2
22 9664326348.8
23 10045446451.2
24 10412856422.4
Predicted microbatch size for 4: 24
comm size 12582912
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 7 0 358221.00830078125 663682.2411979454
End of simulation:  Mini-batch time (usec) = 6464795
Min send: 10000000, max send 0
Min long send: 663870, max long send 683729
Min fwd: 53924, max fwd 67812; min bwd 83975, max bwd 97299
Min long fwd: 86081, max long fwd 91318; min long bwd 118237, max long bwd 121834
Time taken by simulation: 319 microseconds

Stages 6
13 4698582732.8
19 6397758361.599999
22 7231220224.0
23 7515620659.2
24 7790505267.2
Predicted microbatch size for 6: 24
comm size 12582912
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 9 0 241996.6583251953 663682.2411979454
End of simulation:  Mini-batch time (usec) = 9164548
Min send: 10000000, max send 0
Min long send: 663736, max long send 687371
Min fwd: 33746, max fwd 47347; min bwd 54554, max bwd 72477
Min long fwd: 65864, max long fwd 73316; min long bwd 84274, max long bwd 89413
Time taken by simulation: 643 microseconds

Stages 8
13 3930501529.6000004
19 5322929356.799999
22 6014667161.6
23 6250707763.2
24 6479329689.6
Predicted microbatch size for 8: 24
comm size 12582912
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 15 0 176039.7491455078 663682.2411979454
End of simulation:  Mini-batch time (usec) = 13724566
Min send: 10000000, max send 0
Min long send: 663736, max long send 690844
Min fwd: 22801, max fwd 38139; min bwd 36151, max bwd 55503
Min long fwd: 51106, max long fwd 59884; min long bwd 68124, max long bwd 75476
Time taken by simulation: 1456 microseconds

Stages 12
13 3141742080.0
19 4248100352.0
22 4798114099.200001
23 4985794867.2
24 5168154112.0
Predicted microbatch size for 12: 24
comm size 12582912
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 22 0 97192.52014160156 663682.2411979454
End of simulation:  Mini-batch time (usec) = 21189724
Min send: 10000000, max send 0
Min long send: 663682, max long send 690844
Min fwd: 10724, max fwd 28920; min bwd 23319, max bwd 41964
Min long fwd: 40826, max long fwd 50474; min long bwd 49192, max long bwd 58811
Time taken by simulation: 3439 microseconds

{1: 2.905085, 2: 3.331662, 3: 4.994037, 4: 6.464795, 6: 9.164548, 8: 13.724566, 12: 21.189724}
{1: 8, 2: 19, 3: 24, 4: 24, 6: 24, 8: 24, 12: 24}
best config is: 2 19
expected time is 3.331662
15 per stage
30 servers!
Config:
ranks: range(26, 27)
train batch size: 1024
partitions: 2
chunk_size: 19
data depth: 15
stage to rank map: 0,2,4,6,8,10,12,14,16,18,20,22,24,26,28;1,3,5,7,9,11,13,15,17,19,21,23,25,27,29;
World size is 30
/opt/conda/envs/varuna/bin/python -u /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --rank=26 --chunk_size=19 --local_rank=0 --stage_to_rank_map=0,2,4,6,8,10,12,14,16,18,20,22,24,26,28;1,3,5,7,9,11,13,15,17,19,21,23,25,27,29; --batch-size=68 --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna --resume_step 278
device: cuda:0 n_gpu: 1, distributed training: True, 16-bits training: True
dry run time 0.16708040237426758
SHARED WEIGHTS ARE
[(0, 1)]
this rank  26 is part of pipeline replica  13
4 chunks
Begin to load checkpint from s3://spot-checkpoints/bert/ckpt_278.pt
2022-11-24 14:10:37.964207 resume step from  278
2022-11-24 14:11:43.537613 - Finished loading checkpoint, takes 65.471 secs
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  524288.0
[2022-11-24 14:12:03.154402] Finished iteration 278, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4741.931
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  262144.0
[2022-11-24 14:12:06.359605] Finished iteration 279, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3204.984
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  131072.0
[2022-11-24 14:12:09.536924] Finished iteration 280, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3177.449
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  65536.0
[2022-11-24 14:12:12.677636] Finished iteration 281, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3140.517
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  32768.0
[2022-11-24 14:12:16.116148] Finished iteration 282, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3438.420
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  16384.0
[2022-11-24 14:12:18.255569] Finished iteration 283, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2139.328
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  8192.0
[2022-11-24 14:12:20.398599] Finished iteration 284, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2143.017
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  4096.0
[2022-11-24 14:12:22.521864] Finished iteration 285, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2123.242
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  2048.0
[2022-11-24 14:12:24.632384] Finished iteration 286, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2110.502
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1024.0
[2022-11-24 14:12:26.721687] Finished iteration 287, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2089.245
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  512.0
[2022-11-24 14:12:28.847444] Finished iteration 288, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2125.737
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  256.0
[2022-11-24 14:12:30.956073] Finished iteration 289, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2108.751
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  128.0
[2022-11-24 14:12:33.121859] Finished iteration 290, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2165.579
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  64.0
[2022-11-24 14:12:35.259134] Finished iteration 291, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2137.236
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  32.0
[2022-11-24 14:12:37.397988] Finished iteration 292, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2138.818
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  16.0
[2022-11-24 14:12:39.492516] Finished iteration 293, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2094.493
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  8.0
[2022-11-24 14:12:41.580573] Finished iteration 294, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2088.038
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  4.0
[2022-11-24 14:12:43.733149] Finished iteration 295, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2152.533
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  2.0
[2022-11-24 14:12:45.876123] Finished iteration 296, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2142.923
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:12:47.975629] Finished iteration 297, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2099.457
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:12:50.112484] Finished iteration 298, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2136.826
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:12:52.261118] Finished iteration 299, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2148.579
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:12:54.432464] Finished iteration 300, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2171.321
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:12:56.559310] Finished iteration 301, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2126.813
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:12:58.732168] Finished iteration 302, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2172.832
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:00.848919] Finished iteration 303, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2116.726
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:03.002582] Finished iteration 304, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2153.645
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:05.144093] Finished iteration 305, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2141.482
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:07.618127] Finished iteration 306, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2473.981
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:10.007175] Finished iteration 307, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2389.007
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:12.157529] Finished iteration 308, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2150.320
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:14.272279] Finished iteration 309, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2114.721
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:16.431996] Finished iteration 310, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2159.699
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:18.552394] Finished iteration 311, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2120.546
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:20.683093] Finished iteration 312, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2130.509
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:22.796102] Finished iteration 313, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2112.943
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:24.956850] Finished iteration 314, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2160.717
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:27.094389] Finished iteration 315, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2137.518
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:29.284434] Finished iteration 316, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2190.026
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:31.382560] Finished iteration 317, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2098.078
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:33.514389] Finished iteration 318, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2131.835
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:35.775061] Finished iteration 319, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2260.803
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:37.928382] Finished iteration 320, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2153.090
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:40.073523] Finished iteration 321, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2145.104
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:42.229735] Finished iteration 322, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2156.181
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:44.366689] Finished iteration 323, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2136.917
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:46.492091] Finished iteration 324, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2125.509
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:48.746984] Finished iteration 325, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2254.703
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:50.869796] Finished iteration 326, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2122.803
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:53.718043] Finished iteration 327, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2848.211
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:55.850455] Finished iteration 328, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2132.517
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:58.034885] Finished iteration 329, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2184.251
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:00.143146] Finished iteration 330, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2108.237
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:02.238427] Finished iteration 331, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2095.387
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:04.394717] Finished iteration 332, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2156.101
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:06.515608] Finished iteration 333, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2120.853
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:08.636850] Finished iteration 334, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2121.354
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:10.767851] Finished iteration 335, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2130.955
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:12.888677] Finished iteration 336, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2120.792
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:15.025362] Finished iteration 337, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2136.494
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:17.189285] Finished iteration 338, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2163.918
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:19.318023] Finished iteration 339, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2128.675
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:21.433050] Finished iteration 340, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2114.996
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:23.595682] Finished iteration 341, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2162.597
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:25.752816] Finished iteration 342, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2157.105
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:27.890792] Finished iteration 343, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2137.943
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:30.033683] Finished iteration 344, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2142.898
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:32.181941] Finished iteration 345, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2148.208
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:34.318781] Finished iteration 346, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2136.817
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:36.416862] Finished iteration 347, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2098.041
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:38.596684] Finished iteration 348, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2179.844
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:40.705881] Finished iteration 349, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2109.139
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:42.901157] Finished iteration 350, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2195.196
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:45.033775] Finished iteration 351, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2132.757
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:47.163944] Finished iteration 352, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2129.964
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:49.264053] Finished iteration 353, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2100.047
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:51.412154] Finished iteration 354, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2148.096
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:53.606240] Finished iteration 355, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2194.050
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:55.727548] Finished iteration 356, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2121.253
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:57.843846] Finished iteration 357, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2116.272
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:59.951719] Finished iteration 358, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2107.849
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:02.084187] Finished iteration 359, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2132.413
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:04.205856] Finished iteration 360, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2121.635
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:06.370868] Finished iteration 361, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2164.980
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:08.533032] Finished iteration 362, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2162.133
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:10.688262] Finished iteration 363, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2155.196
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:12.884489] Finished iteration 364, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2196.210
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:14.999973] Finished iteration 365, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2115.423
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:17.106739] Finished iteration 366, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2106.870
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:19.274100] Finished iteration 367, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2167.229
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:21.392785] Finished iteration 368, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2118.623
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:23.545319] Finished iteration 369, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2152.467
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:25.704957] Finished iteration 370, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2159.754
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:27.855771] Finished iteration 371, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2150.625
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:29.967803] Finished iteration 372, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2112.001
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:32.106238] Finished iteration 373, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2138.561
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:34.268382] Finished iteration 374, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2161.939
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:36.393038] Finished iteration 375, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2124.634
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:38.515748] Finished iteration 376, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2122.676
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:40.697928] Finished iteration 377, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2182.149
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:42.815879] Finished iteration 378, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2117.925
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:44.957099] Finished iteration 379, CKPT_AND_STOP: False, flag: tensor([1], dtype=torch.int32), speed: 2141.215
2022-11-24 14:15:44.962151 Begin to save checkpont to s3://spot-checkpoints/bert and exit
Opt ckpt time 4.984451532363892
Process done with return code 0
Parent process ID: 13062 node: 172.31.27.21
24 cutpoints
Stages 1
13 20868437708.800007
7 13915698585.599995
10 17153729331.199993
8 14622140211.200005
9 15846820659.199995
Predicted microbatch size for 1: 8
comm size 0
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 1 5 0 1286522.0947265625 0
End of simulation:  Mini-batch time (usec) = 2905085
Min send: 10000000, max send 0
Min long send: 10000000, max long send 0
Min fwd: 10000000, max fwd 0; min bwd 10000000, max bwd 0
Min long fwd: 126283, max long fwd 129698; min long bwd 193190, max long bwd 199310
Time taken by simulation: 45 microseconds

Stages 2
13 10987980083.2
19 14996390399.999996
22 16963644723.199997
20 15631126630.400002
Predicted microbatch size for 2: 19
comm size 9961472
WARNING: no send time found, 2 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 2 4 0 638222.2290039062 542254.6839368516
End of simulation:  Mini-batch time (usec) = 3331662
Min send: 10000000, max send 0
Min long send: 542586, max long send 555338
Min fwd: 107744, max fwd 113936; min bwd 155753, max bwd 158782
Min long fwd: 131842, max long fwd 138676; min long bwd 169332, max long bwd 173300
Time taken by simulation: 95 microseconds

Stages 3
13 7832942284.800001
19 10697074380.8
22 12097432473.599998
23 12575272243.2
24 13035207577.6
Predicted microbatch size for 3: 24
comm size 12582912
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 5 0 448996.58203125 663682.2411979454
End of simulation:  Mini-batch time (usec) = 4994037
Min send: 10000000, max send 0
Min long send: 664014, max long send 679713
Min fwd: 72258, max fwd 88035; min bwd 119079, max bwd 130804
Min long fwd: 107414, max long fwd 112703; min long bwd 150032, max long bwd 153679
Time taken by simulation: 170 microseconds

Stages 4
13 6255423385.6
19 8547416371.2
22 9664326348.8
23 10045446451.2
24 10412856422.4
Predicted microbatch size for 4: 24
comm size 12582912
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 7 0 358221.00830078125 663682.2411979454
End of simulation:  Mini-batch time (usec) = 6464795
Min send: 10000000, max send 0
Min long send: 663870, max long send 683729
Min fwd: 53924, max fwd 67812; min bwd 83975, max bwd 97299
Min long fwd: 86081, max long fwd 91318; min long bwd 118237, max long bwd 121834
Time taken by simulation: 352 microseconds

Stages 6
13 4698582732.8
19 6397758361.599999
22 7231220224.0
23 7515620659.2
24 7790505267.2
Predicted microbatch size for 6: 24
comm size 12582912
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 9 0 241996.6583251953 663682.2411979454
End of simulation:  Mini-batch time (usec) = 9164548
Min send: 10000000, max send 0
Min long send: 663736, max long send 687371
Min fwd: 33746, max fwd 47347; min bwd 54554, max bwd 72477
Min long fwd: 65864, max long fwd 73316; min long bwd 84274, max long bwd 89413
Time taken by simulation: 627 microseconds

Stages 8
13 3930501529.6000004
19 5322929356.799999
22 6014667161.6
23 6250707763.2
24 6479329689.6
Predicted microbatch size for 8: 24
comm size 12582912
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 15 0 176039.7491455078 663682.2411979454
End of simulation:  Mini-batch time (usec) = 13724566
Min send: 10000000, max send 0
Min long send: 663736, max long send 690844
Min fwd: 22801, max fwd 38139; min bwd 36151, max bwd 55503
Min long fwd: 51106, max long fwd 59884; min long bwd 68124, max long bwd 75476
Time taken by simulation: 1487 microseconds

Stages 12
13 3141742080.0
19 4248100352.0
22 4798114099.200001
23 4985794867.2
24 5168154112.0
Predicted microbatch size for 12: 24
comm size 12582912
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 22 0 97192.52014160156 663682.2411979454
End of simulation:  Mini-batch time (usec) = 21189724
Min send: 10000000, max send 0
Min long send: 663682, max long send 690844
Min fwd: 10724, max fwd 28920; min bwd 23319, max bwd 41964
Min long fwd: 40826, max long fwd 50474; min long bwd 49192, max long bwd 58811
Time taken by simulation: 3409 microseconds

{1: 2.905085, 2: 3.331662, 3: 4.994037, 4: 6.464795, 6: 9.164548, 8: 13.724566, 12: 21.189724}
{1: 8, 2: 19, 3: 24, 4: 24, 6: 24, 8: 24, 12: 24}
best config is: 2 19
expected time is 3.331662
15 per stage
30 servers!
Config:
ranks: range(26, 27)
train batch size: 1024
partitions: 2
chunk_size: 19
data depth: 15
stage to rank map: 0,2,4,6,8,10,12,14,16,18,20,22,24,26,28;1,3,5,7,9,11,13,15,17,19,21,23,25,27,29;
World size is 30
/opt/conda/envs/varuna/bin/python -u /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --rank=26 --chunk_size=19 --local_rank=0 --stage_to_rank_map=0,2,4,6,8,10,12,14,16,18,20,22,24,26,28;1,3,5,7,9,11,13,15,17,19,21,23,25,27,29; --batch-size=68 --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna --resume_step 380
device: cuda:0 n_gpu: 1, distributed training: True, 16-bits training: True
dry run time 1.23883056640625
SHARED WEIGHTS ARE
[(0, 1)]
this rank  26 is part of pipeline replica  13
4 chunks
Begin to load checkpint from s3://spot-checkpoints/bert/ckpt_380.pt
2022-11-24 14:16:31.999962 resume step from  380
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 26 signal handler called with signal 10
2022-11-24 14:17:36.871892 - Finished loading checkpoint, takes 64.836 secs
2022-11-24 14:17:54.289685 Begin to exit
Process done with return code 0
Parent process ID: 14457 node: 172.31.27.21
24 cutpoints
Stages 1
13 20868437708.800007
7 13915698585.599995
10 17153729331.199993
8 14622140211.200005
9 15846820659.199995
Predicted microbatch size for 1: 8
comm size 0
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 1 4 0 3150942.3828125 0
End of simulation:  Mini-batch time (usec) = 4450032
Min send: 10000000, max send 0
Min long send: 10000000, max long send 0
Min fwd: 10000000, max fwd 0; min bwd 10000000, max bwd 0
Min long fwd: 127414, max long fwd 129698; min long bwd 194806, max long bwd 199310
Time taken by simulation: 44 microseconds

Stages 2
13 10987980083.2
19 14996390399.999996
22 16963644723.199997
20 15631126630.400002
Predicted microbatch size for 2: 19
comm size 9961472
WARNING: no send time found, 2 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 2 4 0 673273.3154296875 542254.6839368516
End of simulation:  Mini-batch time (usec) = 3366713
Min send: 10000000, max send 0
Min long send: 542586, max long send 555338
Min fwd: 107744, max fwd 113936; min bwd 155753, max bwd 158782
Min long fwd: 131842, max long fwd 138676; min long bwd 169332, max long bwd 173300
Time taken by simulation: 100 microseconds

Stages 3
13 7832942284.800001
19 10697074380.8
22 12097432473.599998
23 12575272243.2
24 13035207577.6
Predicted microbatch size for 3: 24
comm size 12582912
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 5 0 448996.58203125 663682.2411979454
End of simulation:  Mini-batch time (usec) = 4994037
Min send: 10000000, max send 0
Min long send: 664014, max long send 679713
Min fwd: 72258, max fwd 88035; min bwd 119079, max bwd 130804
Min long fwd: 107414, max long fwd 112703; min long bwd 150032, max long bwd 153679
Time taken by simulation: 172 microseconds

Stages 4
13 6255423385.6
19 8547416371.2
22 9664326348.8
23 10045446451.2
24 10412856422.4
Predicted microbatch size for 4: 24
comm size 12582912
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 6 0 375752.13623046875 663682.2411979454
End of simulation:  Mini-batch time (usec) = 6314108
Min send: 10000000, max send 0
Min long send: 663764, max long send 688387
Min fwd: 53924, max fwd 66948; min bwd 83975, max bwd 98046
Min long fwd: 84759, max long fwd 91250; min long bwd 120659, max long bwd 125455
Time taken by simulation: 273 microseconds

Stages 6
13 4698582732.8
19 6397758361.599999
22 7231220224.0
23 7515620659.2
24 7790505267.2
Predicted microbatch size for 6: 24
comm size 12582912
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 9 0 241996.6583251953 663682.2411979454
End of simulation:  Mini-batch time (usec) = 9164548
Min send: 10000000, max send 0
Min long send: 663736, max long send 687371
Min fwd: 33746, max fwd 47347; min bwd 54554, max bwd 72477
Min long fwd: 65864, max long fwd 73316; min long bwd 84274, max long bwd 89413
Time taken by simulation: 624 microseconds

Stages 8
13 3930501529.6000004
19 5322929356.799999
22 6014667161.6
23 6250707763.2
24 6479329689.6
Predicted microbatch size for 8: 24
comm size 12582912
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 11 0 214379.08935546875 663682.2411979454
End of simulation:  Mini-batch time (usec) = 12421079
Min send: 10000000, max send 0
Min long send: 663682, max long send 689782
Min fwd: 22992, max fwd 37161; min bwd 37517, max bwd 55449
Min long fwd: 51419, max long fwd 57045; min long bwd 68935, max long bwd 77274
Time taken by simulation: 1101 microseconds

Stages 12
13 3141742080.0
19 4248100352.0
22 4798114099.200001
23 4985794867.2
24 5168154112.0
Predicted microbatch size for 12: 24
comm size 12582912
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 22 0 97192.52014160156 663682.2411979454
End of simulation:  Mini-batch time (usec) = 21189724
Min send: 10000000, max send 0
Min long send: 663682, max long send 690844
Min fwd: 10724, max fwd 28920; min bwd 23319, max bwd 41964
Min long fwd: 40826, max long fwd 50474; min long bwd 49192, max long bwd 58811
Time taken by simulation: 3400 microseconds

{1: 4.450032, 2: 3.366713, 3: 4.994037, 4: 6.314108, 6: 9.164548, 8: 12.421079, 12: 21.189724}
{1: 8, 2: 19, 3: 24, 4: 24, 6: 24, 8: 24, 12: 24}
best config is: 2 19
expected time is 3.366713
16 per stage
32 servers!
Config:
ranks: range(26, 27)
train batch size: 1024
partitions: 2
chunk_size: 19
data depth: 16
stage to rank map: 0,2,4,6,8,10,12,14,16,18,20,22,24,26,28,30;1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31;
World size is 32
/opt/conda/envs/varuna/bin/python -u /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --rank=26 --chunk_size=19 --local_rank=0 --stage_to_rank_map=0,2,4,6,8,10,12,14,16,18,20,22,24,26,28,30;1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31; --batch-size=64 --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna --resume_step 380
device: cuda:0 n_gpu: 1, distributed training: True, 16-bits training: True
dry run time 0.11309123039245605
SHARED WEIGHTS ARE
[(0, 1)]
this rank  26 is part of pipeline replica  13
4 chunks
Begin to load checkpint from s3://spot-checkpoints/bert/ckpt_380.pt
2022-11-24 14:18:15.770437 resume step from  380
2022-11-24 14:19:28.692533 - Finished loading checkpoint, takes 67.892 secs
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  524288.0
[2022-11-24 14:19:34.548050] Finished iteration 380, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5718.729
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  262144.0
[2022-11-24 14:19:37.742015] Finished iteration 381, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3193.681
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  131072.0
[2022-11-24 14:19:40.910326] Finished iteration 382, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3168.251
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  65536.0
[2022-11-24 14:19:44.059542] Finished iteration 383, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3149.197
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  32768.0
[2022-11-24 14:19:47.213220] Finished iteration 384, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3153.580
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  16384.0
[2022-11-24 14:19:49.554435] Finished iteration 385, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2341.147
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  8192.0
[2022-11-24 14:19:51.663785] Finished iteration 386, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2109.324
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  4096.0
[2022-11-24 14:19:53.812813] Finished iteration 387, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2149.029
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  2048.0
[2022-11-24 14:19:55.880885] Finished iteration 388, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2068.014
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1024.0
[2022-11-24 14:19:57.960436] Finished iteration 389, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2079.538
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  512.0
[2022-11-24 14:20:00.060030] Finished iteration 390, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2099.682
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  256.0
[2022-11-24 14:20:02.202175] Finished iteration 391, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2141.947
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  128.0
[2022-11-24 14:20:05.146863] Finished iteration 392, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2944.656
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  64.0
[2022-11-24 14:20:07.256461] Finished iteration 393, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2109.602
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  32.0
[2022-11-24 14:20:09.350717] Finished iteration 394, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2094.167
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  16.0
[2022-11-24 14:20:12.386570] Finished iteration 395, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3035.819
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  8.0
[2022-11-24 14:20:14.477867] Finished iteration 396, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2091.269
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  4.0
[2022-11-24 14:20:16.549818] Finished iteration 397, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2071.929
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  2.0
[2022-11-24 14:20:18.634806] Finished iteration 398, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2085.113
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:20.685655] Finished iteration 399, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2050.637
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:22.760698] Finished iteration 400, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2075.061
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:24.876251] Finished iteration 401, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2115.500
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:26.989528] Finished iteration 402, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2113.363
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:29.632171] Finished iteration 403, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2642.450
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:31.801134] Finished iteration 404, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2168.922
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:33.878609] Finished iteration 405, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2077.436
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:35.998038] Finished iteration 406, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2119.404
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:38.094574] Finished iteration 407, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2096.505
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:40.229656] Finished iteration 408, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2135.051
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:42.294921] Finished iteration 409, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2065.240
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:44.369511] Finished iteration 410, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2074.568
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:46.484559] Finished iteration 411, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2115.049
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:48.569661] Finished iteration 412, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2085.078
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:50.665816] Finished iteration 413, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2096.214
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:52.758018] Finished iteration 414, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2092.010
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:54.901471] Finished iteration 415, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2143.427
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:56.952320] Finished iteration 416, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2050.822
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:59.109323] Finished iteration 417, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2156.980
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:01.190931] Finished iteration 418, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2081.570
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:03.269493] Finished iteration 419, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2078.531
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:05.377699] Finished iteration 420, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2108.188
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:07.450802] Finished iteration 421, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2073.201
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:09.588571] Finished iteration 422, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2137.640
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:11.679017] Finished iteration 423, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2090.362
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:13.804464] Finished iteration 424, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2125.436
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:15.914860] Finished iteration 425, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2110.343
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:18.013893] Finished iteration 426, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2098.989
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:20.075810] Finished iteration 427, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2061.883
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:22.179449] Finished iteration 428, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2103.592
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:24.228923] Finished iteration 429, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2049.446
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:26.328055] Finished iteration 430, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2099.252
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:28.393535] Finished iteration 431, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2065.288
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:30.481594] Finished iteration 432, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2088.001
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:32.558046] Finished iteration 433, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2076.422
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:34.699171] Finished iteration 434, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2141.084
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:36.858469] Finished iteration 435, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2159.263
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:39.030129] Finished iteration 436, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2171.625
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:41.155470] Finished iteration 437, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2125.337
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:43.343708] Finished iteration 438, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2188.180
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:45.442377] Finished iteration 439, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2098.636
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:47.579556] Finished iteration 440, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2137.143
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:49.676111] Finished iteration 441, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2096.516
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:51.805976] Finished iteration 442, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2129.853
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:53.888330] Finished iteration 443, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2082.324
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:56.014631] Finished iteration 444, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2126.284
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:58.110429] Finished iteration 445, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2095.747
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:00.204363] Finished iteration 446, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2093.903
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:02.252586] Finished iteration 447, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2048.234
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:04.359444] Finished iteration 448, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2106.763
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:06.471530] Finished iteration 449, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2112.235
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:08.545968] Finished iteration 450, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2074.201
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:10.653211] Finished iteration 451, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2107.373
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:12.832615] Finished iteration 452, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2179.224
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:14.931995] Finished iteration 453, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2099.325
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:17.058313] Finished iteration 454, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2126.290
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:19.116551] Finished iteration 455, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2058.380
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:21.192954] Finished iteration 456, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2076.181
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:24.179443] Finished iteration 457, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2986.447
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:26.272607] Finished iteration 458, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2093.182
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:28.309081] Finished iteration 459, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2036.403
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:30.383755] Finished iteration 460, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2074.796
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:32.482750] Finished iteration 461, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2098.985
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:34.586052] Finished iteration 462, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2103.079
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:36.651768] Finished iteration 463, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2065.675
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:38.782778] Finished iteration 464, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2130.963
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:40.821042] Finished iteration 465, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2038.194
26 Overflow !!
26 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:42.940972] Finished iteration 466, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2119.911
26 Overflow !!
