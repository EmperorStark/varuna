Parent process ID: 16172 node: 172.31.22.229
24 cutpoints
Stages 1
13 20868437708.800007
7 13915698585.599995
10 17153729331.199993
8 14622140211.200005
9 15846820659.199995
Predicted microbatch size for 1: 8
comm size 0
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 1 5 0 1286522.0947265625 0
End of simulation:  Mini-batch time (usec) = 2905085
Min send: 10000000, max send 0
Min long send: 10000000, max long send 0
Min fwd: 10000000, max fwd 0; min bwd 10000000, max bwd 0
Min long fwd: 126283, max long fwd 129698; min long bwd 193190, max long bwd 199310
Time taken by simulation: 88 microseconds

Stages 2
13 10987980083.2
19 14996390399.999996
22 16963644723.199997
20 15631126630.400002
Predicted microbatch size for 2: 19
comm size 9961472
WARNING: no send time found, 2 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 2 5 0 635506.6528320312 542254.6839368516
End of simulation:  Mini-batch time (usec) = 3634860
Min send: 10000000, max send 0
Min long send: 542586, max long send 558986
Min fwd: 106816, max fwd 113936; min bwd 154625, max bwd 157669
Min long fwd: 134083, max long fwd 138081; min long bwd 169664, max long bwd 173713
Time taken by simulation: 117 microseconds

Stages 3
13 7832942284.800001
19 10697074380.8
22 12097432473.599998
23 12575272243.2
24 13035207577.6
Predicted microbatch size for 3: 24
comm size 12582912
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 5 0 443515.80810546875 663682.2411979454
End of simulation:  Mini-batch time (usec) = 4988556
Min send: 10000000, max send 0
Min long send: 664014, max long send 679713
Min fwd: 72258, max fwd 88035; min bwd 119079, max bwd 130804
Min long fwd: 107414, max long fwd 112703; min long bwd 150032, max long bwd 153679
Time taken by simulation: 172 microseconds

Stages 4
13 6255423385.6
19 8547416371.2
22 9664326348.8
23 10045446451.2
24 10412856422.4
Predicted microbatch size for 4: 24
comm size 12582912
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 8 0 326449.15771484375 663682.2411979454
End of simulation:  Mini-batch time (usec) = 6677364
Min send: 10000000, max send 0
Min long send: 663870, max long send 686148
Min fwd: 51765, max fwd 66948; min bwd 85303, max bwd 98547
Min long fwd: 83336, max long fwd 91250; min long bwd 118529, max long bwd 127083
Time taken by simulation: 361 microseconds

Stages 6
13 4698582732.8
19 6397758361.599999
22 7231220224.0
23 7515620659.2
24 7790505267.2
Predicted microbatch size for 6: 24
comm size 12582912
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 11 0 240705.6121826172 663682.2411979454
End of simulation:  Mini-batch time (usec) = 9735715
Min send: 10000000, max send 0
Min long send: 663764, max long send 689782
Min fwd: 32942, max fwd 48168; min bwd 55337, max bwd 68897
Min long fwd: 65982, max long fwd 73316; min long bwd 85277, max long bwd 90311
Time taken by simulation: 808 microseconds

Stages 8
13 3930501529.6000004
19 5322929356.799999
22 6014667161.6
23 6250707763.2
24 6479329689.6
Predicted microbatch size for 8: 24
comm size 12582912
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 15 0 176039.7491455078 663682.2411979454
End of simulation:  Mini-batch time (usec) = 13724566
Min send: 10000000, max send 0
Min long send: 663736, max long send 690844
Min fwd: 22801, max fwd 38139; min bwd 36151, max bwd 55503
Min long fwd: 51106, max long fwd 59884; min long bwd 68124, max long bwd 75476
Time taken by simulation: 1496 microseconds

Stages 12
13 3141742080.0
19 4248100352.0
22 4798114099.200001
23 4985794867.2
24 5168154112.0
Predicted microbatch size for 12: 24
comm size 12582912
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 22 0 97192.52014160156 663682.2411979454
End of simulation:  Mini-batch time (usec) = 21189724
Min send: 10000000, max send 0
Min long send: 663682, max long send 690844
Min fwd: 10724, max fwd 28920; min bwd 23319, max bwd 41964
Min long fwd: 40826, max long fwd 50474; min long bwd 49192, max long bwd 58811
Time taken by simulation: 3362 microseconds

{1: 2.905085, 2: 3.63486, 3: 4.988556, 4: 6.677364, 6: 9.735715, 8: 13.724566, 12: 21.189724}
{1: 8, 2: 19, 3: 24, 4: 24, 6: 24, 8: 24, 12: 24}
best config is: 2 19
expected time is 3.63486
13 per stage
26 servers!
Config:
ranks: range(7, 8)
train batch size: 1024
partitions: 2
chunk_size: 19
data depth: 13
stage to rank map: 0,2,4,6,8,10,12,14,16,18,20,22,24;1,3,5,7,9,11,13,15,17,19,21,23,25;
World size is 26
/opt/conda/envs/varuna/bin/python -u /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --rank=7 --chunk_size=19 --local_rank=0 --stage_to_rank_map=0,2,4,6,8,10,12,14,16,18,20,22,24;1,3,5,7,9,11,13,15,17,19,21,23,25; --batch-size=78 --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna
device: cuda:0 n_gpu: 1, distributed training: True, 16-bits training: True
dry run time 0.06298613548278809
SHARED WEIGHTS ARE
[(0, 1)]
this rank  7 is part of pipeline replica  3
5 chunks
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  524288.0
[2022-11-24 13:53:10.906868] Finished iteration 0, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5378.097
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  262144.0
[2022-11-24 13:53:13.228327] Finished iteration 1, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2321.132
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  131072.0
[2022-11-24 13:53:16.604334] Finished iteration 2, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3376.193
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  65536.0
[2022-11-24 13:53:18.983470] Finished iteration 3, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2379.000
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  32768.0
[2022-11-24 13:53:22.306988] Finished iteration 4, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3323.542
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  16384.0
[2022-11-24 13:53:24.667422] Finished iteration 5, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2360.159
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  8192.0
[2022-11-24 13:53:26.926737] Finished iteration 6, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2259.288
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  4096.0
[2022-11-24 13:53:29.276106] Finished iteration 7, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2349.491
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  2048.0
[2022-11-24 13:53:31.595744] Finished iteration 8, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2319.588
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1024.0
[2022-11-24 13:53:33.929303] Finished iteration 9, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2333.524
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  512.0
[2022-11-24 13:53:36.247435] Finished iteration 10, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2317.917
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  256.0
[2022-11-24 13:53:38.524061] Finished iteration 11, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2276.596
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  128.0
[2022-11-24 13:53:40.863622] Finished iteration 12, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2339.532
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  64.0
[2022-11-24 13:53:43.162966] Finished iteration 13, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2299.318
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  32.0
[2022-11-24 13:53:45.445805] Finished iteration 14, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2282.949
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  16.0
[2022-11-24 13:53:47.777735] Finished iteration 15, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2331.732
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  8.0
[2022-11-24 13:53:50.046407] Finished iteration 16, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2268.806
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  4.0
[2022-11-24 13:53:52.350910] Finished iteration 17, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2304.435
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  2.0
[2022-11-24 13:53:54.691811] Finished iteration 18, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2340.718
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:53:56.996869] Finished iteration 19, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2305.177
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:53:59.273845] Finished iteration 20, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2276.778
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:01.600206] Finished iteration 21, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2326.385
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:03.912506] Finished iteration 22, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2312.207
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:06.194652] Finished iteration 23, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2282.295
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:08.482597] Finished iteration 24, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2287.719
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:10.773567] Finished iteration 25, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2290.942
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:13.099622] Finished iteration 26, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2326.030
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:15.417055] Finished iteration 27, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2317.441
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:17.758989] Finished iteration 28, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2342.010
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:20.936694] Finished iteration 29, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3177.505
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:23.194363] Finished iteration 30, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2257.675
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:25.537171] Finished iteration 31, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2342.741
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:27.808406] Finished iteration 32, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2271.202
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:30.121849] Finished iteration 33, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2313.572
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:32.460126] Finished iteration 34, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2338.083
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:34.755987] Finished iteration 35, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2295.970
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:37.088405] Finished iteration 36, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2332.384
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:39.416640] Finished iteration 37, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2328.189
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:41.744303] Finished iteration 38, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2327.596
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:44.090879] Finished iteration 39, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2346.395
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:46.427718] Finished iteration 40, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2336.805
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:48.710387] Finished iteration 41, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2282.673
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:51.037116] Finished iteration 42, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2326.661
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:53.402449] Finished iteration 43, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2365.443
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:55.736612] Finished iteration 44, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2334.020
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:58.078952] Finished iteration 45, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2342.285
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:00.406681] Finished iteration 46, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2327.822
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:02.716731] Finished iteration 47, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2309.861
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:04.981573] Finished iteration 48, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2264.808
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:07.346288] Finished iteration 49, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2364.727
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:09.650092] Finished iteration 50, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2303.923
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:11.991000] Finished iteration 51, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2340.688
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:14.281555] Finished iteration 52, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2290.639
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:16.600299] Finished iteration 53, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2318.558
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:18.900155] Finished iteration 54, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2299.830
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:21.189532] Finished iteration 55, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2289.348
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:23.504964] Finished iteration 56, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2315.396
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:25.830014] Finished iteration 57, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2325.156
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:28.188408] Finished iteration 58, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2358.226
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:30.534452] Finished iteration 59, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2345.995
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:32.832108] Finished iteration 60, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2297.642
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:35.141830] Finished iteration 61, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2309.676
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:37.442470] Finished iteration 62, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2300.605
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:39.789909] Finished iteration 63, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2347.441
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:42.122350] Finished iteration 64, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2332.428
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:44.420743] Finished iteration 65, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2298.316
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:46.773113] Finished iteration 66, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2352.352
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:49.193458] Finished iteration 67, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2420.328
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:51.493706] Finished iteration 68, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2300.187
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:53.852129] Finished iteration 69, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2358.406
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:56.183538] Finished iteration 70, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2331.352
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:58.517336] Finished iteration 71, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2333.790
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:00.838354] Finished iteration 72, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2321.139
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:03.149382] Finished iteration 73, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2310.943
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:05.456313] Finished iteration 74, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2306.894
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:07.715902] Finished iteration 75, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2259.551
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:10.016742] Finished iteration 76, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2300.684
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:12.352720] Finished iteration 77, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2335.925
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:14.718242] Finished iteration 78, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2365.644
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:17.017616] Finished iteration 79, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2299.158
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:19.356561] Finished iteration 80, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2338.904
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:21.657093] Finished iteration 81, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2300.639
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:23.925252] Finished iteration 82, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2267.971
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:26.187752] Finished iteration 83, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2262.608
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:28.492948] Finished iteration 84, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2305.199
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:30.776649] Finished iteration 85, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2283.620
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:33.084616] Finished iteration 86, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2307.948
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:35.320017] Finished iteration 87, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2235.177
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:37.616513] Finished iteration 88, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2296.611
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:40.014932] Finished iteration 89, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2398.235
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:42.289133] Finished iteration 90, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2274.152
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:44.566216] Finished iteration 91, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2277.225
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:46.895636] Finished iteration 92, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2329.202
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:49.212159] Finished iteration 93, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2316.670
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:51.539944] Finished iteration 94, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2327.559
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:53.831616] Finished iteration 95, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2291.634
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:56.158867] Finished iteration 96, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2327.243
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:58.427263] Finished iteration 97, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2268.348
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:00.734164] Finished iteration 98, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2306.865
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:03.061009] Finished iteration 99, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2326.815
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:05.419514] Finished iteration 100, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2358.484
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:07.736550] Finished iteration 101, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2316.995
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:10.041743] Finished iteration 102, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2305.175
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:12.338847] Finished iteration 103, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2297.220
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:14.654536] Finished iteration 104, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2315.493
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:16.988827] Finished iteration 105, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2334.441
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:19.276679] Finished iteration 106, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2287.634
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:21.532300] Finished iteration 107, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2255.773
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:23.817209] Finished iteration 108, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2284.821
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:26.109147] Finished iteration 109, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2291.735
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:28.394863] Finished iteration 110, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2285.833
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:30.656916] Finished iteration 111, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2261.857
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:33.000461] Finished iteration 112, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2343.525
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:35.347471] Finished iteration 113, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2347.114
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:37.639728] Finished iteration 114, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2292.070
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:39.983917] Finished iteration 115, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2344.162
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:42.297727] Finished iteration 116, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2313.967
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:44.584948] Finished iteration 117, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2286.975
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:46.898026] Finished iteration 118, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2313.072
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:49.149705] Finished iteration 119, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2251.626
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:51.375893] Finished iteration 120, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2226.301
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:53.648965] Finished iteration 121, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2272.901
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:55.969060] Finished iteration 122, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2320.047
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:58.362601] Finished iteration 123, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2393.651
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:00.676795] Finished iteration 124, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2314.154
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:02.970051] Finished iteration 125, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2293.050
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:05.280952] Finished iteration 126, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2311.030
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:07.639922] Finished iteration 127, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2358.926
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:10.024536] Finished iteration 128, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2384.406
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:12.366545] Finished iteration 129, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2341.988
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:14.750841] Finished iteration 130, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2384.445
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:17.066263] Finished iteration 131, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2315.225
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:19.368021] Finished iteration 132, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2301.841
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:21.682854] Finished iteration 133, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2314.640
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:24.038174] Finished iteration 134, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2355.286
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:26.393915] Finished iteration 135, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2355.680
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:28.677467] Finished iteration 136, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2283.726
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:31.005667] Finished iteration 137, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2327.953
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:33.313605] Finished iteration 138, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2307.905
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:35.587249] Finished iteration 139, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2273.617
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:37.885252] Finished iteration 140, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2297.991
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:40.184954] Finished iteration 141, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2299.845
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:42.520982] Finished iteration 142, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2335.801
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:44.827837] Finished iteration 143, CKPT_AND_STOP: False, flag: tensor([1], dtype=torch.int32), speed: 2306.806
2022-11-24 13:58:44.832453 Begin to save checkpont to s3://spot-checkpoints/bert and exit
Opt ckpt time 4.655102491378784
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 7 signal handler called with signal 10
Process done with return code 0
Parent process ID: 16876 node: 172.31.22.229
24 cutpoints
Stages 1
13 20868437708.800007
7 13915698585.599995
10 17153729331.199993
8 14622140211.200005
9 15846820659.199995
Predicted microbatch size for 1: 8
comm size 0
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 1 5 0 1286522.0947265625 0
End of simulation:  Mini-batch time (usec) = 2905085
Min send: 10000000, max send 0
Min long send: 10000000, max long send 0
Min fwd: 10000000, max fwd 0; min bwd 10000000, max bwd 0
Min long fwd: 126283, max long fwd 129698; min long bwd 193190, max long bwd 199310
Time taken by simulation: 50 microseconds

Stages 2
13 10987980083.2
19 14996390399.999996
22 16963644723.199997
20 15631126630.400002
Predicted microbatch size for 2: 19
comm size 9961472
WARNING: no send time found, 2 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 2 4 0 645340.8203125 542254.6839368516
End of simulation:  Mini-batch time (usec) = 3338780
Min send: 10000000, max send 0
Min long send: 542586, max long send 555338
Min fwd: 107744, max fwd 113936; min bwd 155753, max bwd 158782
Min long fwd: 131842, max long fwd 138676; min long bwd 169332, max long bwd 173300
Time taken by simulation: 95 microseconds

Stages 3
13 7832942284.800001
19 10697074380.8
22 12097432473.599998
23 12575272243.2
24 13035207577.6
Predicted microbatch size for 3: 24
comm size 12582912
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 5 0 443515.80810546875 663682.2411979454
End of simulation:  Mini-batch time (usec) = 4988556
Min send: 10000000, max send 0
Min long send: 664014, max long send 679713
Min fwd: 72258, max fwd 88035; min bwd 119079, max bwd 130804
Min long fwd: 107414, max long fwd 112703; min long bwd 150032, max long bwd 153679
Time taken by simulation: 211 microseconds

Stages 4
13 6255423385.6
19 8547416371.2
22 9664326348.8
23 10045446451.2
24 10412856422.4
Predicted microbatch size for 4: 24
comm size 12582912
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 7 0 358221.00830078125 663682.2411979454
End of simulation:  Mini-batch time (usec) = 6464795
Min send: 10000000, max send 0
Min long send: 663870, max long send 683729
Min fwd: 53924, max fwd 67812; min bwd 83975, max bwd 97299
Min long fwd: 86081, max long fwd 91318; min long bwd 118237, max long bwd 121834
Time taken by simulation: 310 microseconds

Stages 6
13 4698582732.8
19 6397758361.599999
22 7231220224.0
23 7515620659.2
24 7790505267.2
Predicted microbatch size for 6: 24
comm size 12582912
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 11 0 240705.6121826172 663682.2411979454
End of simulation:  Mini-batch time (usec) = 9735715
Min send: 10000000, max send 0
Min long send: 663764, max long send 689782
Min fwd: 32942, max fwd 48168; min bwd 55337, max bwd 68897
Min long fwd: 65982, max long fwd 73316; min long bwd 85277, max long bwd 90311
Time taken by simulation: 770 microseconds

Stages 8
13 3930501529.6000004
19 5322929356.799999
22 6014667161.6
23 6250707763.2
24 6479329689.6
Predicted microbatch size for 8: 24
comm size 12582912
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 15 0 176039.7491455078 663682.2411979454
End of simulation:  Mini-batch time (usec) = 13724566
Min send: 10000000, max send 0
Min long send: 663736, max long send 690844
Min fwd: 22801, max fwd 38139; min bwd 36151, max bwd 55503
Min long fwd: 51106, max long fwd 59884; min long bwd 68124, max long bwd 75476
Time taken by simulation: 1458 microseconds

Stages 12
13 3141742080.0
19 4248100352.0
22 4798114099.200001
23 4985794867.2
24 5168154112.0
Predicted microbatch size for 12: 24
comm size 12582912
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 22 0 97192.52014160156 663682.2411979454
End of simulation:  Mini-batch time (usec) = 21189724
Min send: 10000000, max send 0
Min long send: 663682, max long send 690844
Min fwd: 10724, max fwd 28920; min bwd 23319, max bwd 41964
Min long fwd: 40826, max long fwd 50474; min long bwd 49192, max long bwd 58811
Time taken by simulation: 3406 microseconds

{1: 2.905085, 2: 3.33878, 3: 4.988556, 4: 6.464795, 6: 9.735715, 8: 13.724566, 12: 21.189724}
{1: 8, 2: 19, 3: 24, 4: 24, 6: 24, 8: 24, 12: 24}
best config is: 2 19
expected time is 3.33878
14 per stage
28 servers!
Config:
ranks: range(7, 8)
train batch size: 1024
partitions: 2
chunk_size: 19
data depth: 14
stage to rank map: 0,2,4,6,8,10,12,14,16,18,20,22,24,26;1,3,5,7,9,11,13,15,17,19,21,23,25,27;
World size is 28
/opt/conda/envs/varuna/bin/python -u /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --rank=7 --chunk_size=19 --local_rank=0 --stage_to_rank_map=0,2,4,6,8,10,12,14,16,18,20,22,24,26;1,3,5,7,9,11,13,15,17,19,21,23,25,27; --batch-size=73 --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna --resume_step 144
device: cuda:0 n_gpu: 1, distributed training: True, 16-bits training: True
dry run time 0.03084111213684082
SHARED WEIGHTS ARE
[(0, 1)]
this rank  7 is part of pipeline replica  3
4 chunks
Begin to load checkpint from s3://spot-checkpoints/bert/ckpt_144.pt
2022-11-24 13:59:22.777193 resume step from  144
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 7 signal handler called with signal 10
2022-11-24 14:00:23.036695 - Finished loading checkpoint, takes 60.121 secs
2022-11-24 14:00:31.377230 Begin to exit
Process done with return code 0
Parent process ID: 18166 node: 172.31.22.229
24 cutpoints
Stages 1
13 20868437708.800007
7 13915698585.599995
10 17153729331.199993
8 14622140211.200005
9 15846820659.199995
Predicted microbatch size for 1: 8
comm size 0
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 1 4 0 3150942.3828125 0
End of simulation:  Mini-batch time (usec) = 4450032
Min send: 10000000, max send 0
Min long send: 10000000, max long send 0
Min fwd: 10000000, max fwd 0; min bwd 10000000, max bwd 0
Min long fwd: 127414, max long fwd 129698; min long bwd 194806, max long bwd 199310
Time taken by simulation: 46 microseconds

Stages 2
13 10987980083.2
19 14996390399.999996
22 16963644723.199997
20 15631126630.400002
Predicted microbatch size for 2: 19
comm size 9961472
WARNING: no send time found, 2 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 2 4 0 673273.3154296875 542254.6839368516
End of simulation:  Mini-batch time (usec) = 3366713
Min send: 10000000, max send 0
Min long send: 542586, max long send 555338
Min fwd: 107744, max fwd 113936; min bwd 155753, max bwd 158782
Min long fwd: 131842, max long fwd 138676; min long bwd 169332, max long bwd 173300
Time taken by simulation: 102 microseconds

Stages 3
13 7832942284.800001
19 10697074380.8
22 12097432473.599998
23 12575272243.2
24 13035207577.6
Predicted microbatch size for 3: 24
comm size 12582912
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 5 0 448996.58203125 663682.2411979454
End of simulation:  Mini-batch time (usec) = 4994037
Min send: 10000000, max send 0
Min long send: 664014, max long send 679713
Min fwd: 72258, max fwd 88035; min bwd 119079, max bwd 130804
Min long fwd: 107414, max long fwd 112703; min long bwd 150032, max long bwd 153679
Time taken by simulation: 168 microseconds

Stages 4
13 6255423385.6
19 8547416371.2
22 9664326348.8
23 10045446451.2
24 10412856422.4
Predicted microbatch size for 4: 24
comm size 12582912
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 6 0 375752.13623046875 663682.2411979454
End of simulation:  Mini-batch time (usec) = 6314108
Min send: 10000000, max send 0
Min long send: 663764, max long send 688387
Min fwd: 53924, max fwd 66948; min bwd 83975, max bwd 98046
Min long fwd: 84759, max long fwd 91250; min long bwd 120659, max long bwd 125455
Time taken by simulation: 270 microseconds

Stages 6
13 4698582732.8
19 6397758361.599999
22 7231220224.0
23 7515620659.2
24 7790505267.2
Predicted microbatch size for 6: 24
comm size 12582912
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 9 0 241996.6583251953 663682.2411979454
End of simulation:  Mini-batch time (usec) = 9164548
Min send: 10000000, max send 0
Min long send: 663736, max long send 687371
Min fwd: 33746, max fwd 47347; min bwd 54554, max bwd 72477
Min long fwd: 65864, max long fwd 73316; min long bwd 84274, max long bwd 89413
Time taken by simulation: 668 microseconds

Stages 8
13 3930501529.6000004
19 5322929356.799999
22 6014667161.6
23 6250707763.2
24 6479329689.6
Predicted microbatch size for 8: 24
comm size 12582912
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 11 0 214379.08935546875 663682.2411979454
End of simulation:  Mini-batch time (usec) = 12421079
Min send: 10000000, max send 0
Min long send: 663682, max long send 689782
Min fwd: 22992, max fwd 37161; min bwd 37517, max bwd 55449
Min long fwd: 51419, max long fwd 57045; min long bwd 68935, max long bwd 77274
Time taken by simulation: 1032 microseconds

Stages 12
13 3141742080.0
19 4248100352.0
22 4798114099.200001
23 4985794867.2
24 5168154112.0
Predicted microbatch size for 12: 24
comm size 12582912
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 22 0 97192.52014160156 663682.2411979454
End of simulation:  Mini-batch time (usec) = 21189724
Min send: 10000000, max send 0
Min long send: 663682, max long send 690844
Min fwd: 10724, max fwd 28920; min bwd 23319, max bwd 41964
Min long fwd: 40826, max long fwd 50474; min long bwd 49192, max long bwd 58811
Time taken by simulation: 3398 microseconds

{1: 4.450032, 2: 3.366713, 3: 4.994037, 4: 6.314108, 6: 9.164548, 8: 12.421079, 12: 21.189724}
{1: 8, 2: 19, 3: 24, 4: 24, 6: 24, 8: 24, 12: 24}
best config is: 2 19
expected time is 3.366713
16 per stage
32 servers!
Config:
ranks: range(7, 8)
train batch size: 1024
partitions: 2
chunk_size: 19
data depth: 16
stage to rank map: 0,2,4,6,8,10,12,14,16,18,20,22,24,26,28,30;1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31;
World size is 32
/opt/conda/envs/varuna/bin/python -u /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --rank=7 --chunk_size=19 --local_rank=0 --stage_to_rank_map=0,2,4,6,8,10,12,14,16,18,20,22,24,26,28,30;1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31; --batch-size=64 --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna --resume_step 144
device: cuda:0 n_gpu: 1, distributed training: True, 16-bits training: True
dry run time 0.006669759750366211
SHARED WEIGHTS ARE
[(0, 1)]
this rank  7 is part of pipeline replica  3
4 chunks
Begin to load checkpint from s3://spot-checkpoints/bert/ckpt_144.pt
2022-11-24 14:00:52.879331 resume step from  144
2022-11-24 14:01:49.398932 - Finished loading checkpoint, takes 56.404 secs
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  524288.0
[2022-11-24 14:02:26.492105] Finished iteration 144, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5707.945
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  262144.0
[2022-11-24 14:02:29.718583] Finished iteration 145, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3226.332
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  131072.0
[2022-11-24 14:02:32.851299] Finished iteration 146, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3132.678
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  65536.0
[2022-11-24 14:02:35.993876] Finished iteration 147, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3142.296
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  32768.0
[2022-11-24 14:02:39.103831] Finished iteration 148, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3109.906
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  16384.0
[2022-11-24 14:02:41.202943] Finished iteration 149, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2099.145
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  8192.0
[2022-11-24 14:02:43.338570] Finished iteration 150, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2135.446
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  4096.0
[2022-11-24 14:02:45.391597] Finished iteration 151, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2053.001
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  2048.0
[2022-11-24 14:02:47.492917] Finished iteration 152, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2101.283
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1024.0
[2022-11-24 14:02:49.610612] Finished iteration 153, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2117.648
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  512.0
[2022-11-24 14:02:51.710444] Finished iteration 154, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2099.972
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  256.0
[2022-11-24 14:02:53.788504] Finished iteration 155, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2077.877
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  128.0
[2022-11-24 14:02:55.941159] Finished iteration 156, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2152.627
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  64.0
[2022-11-24 14:02:58.046407] Finished iteration 157, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2105.367
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  32.0
[2022-11-24 14:03:00.150590] Finished iteration 158, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2103.948
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  16.0
[2022-11-24 14:03:02.264882] Finished iteration 159, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2114.472
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  8.0
[2022-11-24 14:03:04.356853] Finished iteration 160, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2091.745
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  4.0
[2022-11-24 14:03:06.510038] Finished iteration 161, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2153.151
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  2.0
[2022-11-24 14:03:08.604192] Finished iteration 162, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2094.102
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:11.890960] Finished iteration 163, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3286.996
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:14.008581] Finished iteration 164, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2117.487
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:16.136726] Finished iteration 165, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2127.905
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:18.237359] Finished iteration 166, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2100.596
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:20.378848] Finished iteration 167, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2141.465
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:22.446360] Finished iteration 168, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2067.546
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:24.592413] Finished iteration 169, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2145.959
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:26.738788] Finished iteration 170, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2146.345
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:28.900477] Finished iteration 171, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2161.656
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:31.042861] Finished iteration 172, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2142.353
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:33.203880] Finished iteration 173, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2161.154
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:35.288490] Finished iteration 174, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2084.397
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:37.404058] Finished iteration 175, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2115.542
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:39.480608] Finished iteration 176, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2076.515
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:41.594619] Finished iteration 177, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2113.987
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:43.756804] Finished iteration 178, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2162.155
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:45.956687] Finished iteration 179, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2199.851
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:48.052011] Finished iteration 180, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2095.499
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:50.182150] Finished iteration 181, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2129.884
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:52.297145] Finished iteration 182, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2115.163
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:54.412925] Finished iteration 183, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2115.530
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:56.558593] Finished iteration 184, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2145.791
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:58.645265] Finished iteration 185, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2086.622
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:00.757390] Finished iteration 186, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2112.088
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:02.905833] Finished iteration 187, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2148.264
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:04.990548] Finished iteration 188, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2084.716
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:07.125693] Finished iteration 189, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2135.091
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:09.253268] Finished iteration 190, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2127.507
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:11.355975] Finished iteration 191, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2102.779
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:13.489012] Finished iteration 192, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2133.065
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:15.599798] Finished iteration 193, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2110.730
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:17.700151] Finished iteration 194, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2100.331
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:19.829515] Finished iteration 195, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2129.284
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:21.958343] Finished iteration 196, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2128.662
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:24.114960] Finished iteration 197, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2156.576
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:26.183435] Finished iteration 198, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2068.420
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:28.233041] Finished iteration 199, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2049.618
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:30.358659] Finished iteration 200, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2125.585
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:32.473780] Finished iteration 201, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2115.226
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:34.593588] Finished iteration 202, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2119.581
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:36.707503] Finished iteration 203, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2113.884
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:38.819780] Finished iteration 204, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2112.248
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:41.280131] Finished iteration 205, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2460.356
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:43.730514] Finished iteration 206, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2450.500
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:45.870870] Finished iteration 207, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2140.296
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:49.109118] Finished iteration 208, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3238.310
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:51.569906] Finished iteration 209, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2460.637
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:53.754896] Finished iteration 210, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2184.724
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:55.857626] Finished iteration 211, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2102.886
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:57.917282] Finished iteration 212, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2059.494
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:00.061030] Finished iteration 213, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2143.792
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:02.201134] Finished iteration 214, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2139.940
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:04.278305] Finished iteration 215, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2077.125
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:06.413152] Finished iteration 216, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2134.940
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:08.545244] Finished iteration 217, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2131.908
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:10.634562] Finished iteration 218, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2089.331
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:12.762774] Finished iteration 219, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2128.118
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:14.891517] Finished iteration 220, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2128.869
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:16.968745] Finished iteration 221, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2077.249
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:19.086227] Finished iteration 222, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2117.375
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:21.200339] Finished iteration 223, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2114.053
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:23.324068] Finished iteration 224, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2123.528
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:25.457304] Finished iteration 225, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2133.386
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:27.577369] Finished iteration 226, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2119.837
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:29.675411] Finished iteration 227, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2098.006
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:31.834104] Finished iteration 228, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2158.671
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:33.998851] Finished iteration 229, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2164.862
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:36.153483] Finished iteration 230, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2154.693
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:38.255422] Finished iteration 231, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2101.787
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:40.371266] Finished iteration 232, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2115.779
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:42.486236] Finished iteration 233, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2115.008
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:44.598643] Finished iteration 234, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2112.150
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:46.748542] Finished iteration 235, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2150.002
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:48.842613] Finished iteration 236, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2094.019
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:50.955211] Finished iteration 237, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2112.465
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:53.034410] Finished iteration 238, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2079.123
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:55.133899] Finished iteration 239, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2099.432
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:57.226365] Finished iteration 240, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2092.680
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:00.136007] Finished iteration 241, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2909.419
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:02.249428] Finished iteration 242, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2113.329
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:04.374711] Finished iteration 243, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2125.267
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:06.470656] Finished iteration 244, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2095.886
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:08.572160] Finished iteration 245, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2101.486
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:10.732258] Finished iteration 246, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2160.108
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:12.788119] Finished iteration 247, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2055.800
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:14.891771] Finished iteration 248, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2103.639
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:17.014025] Finished iteration 249, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2122.235
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:19.120196] Finished iteration 250, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2106.247
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:21.220873] Finished iteration 251, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2100.619
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:23.341358] Finished iteration 252, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2120.442
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:25.429981] Finished iteration 253, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2088.724
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:27.536687] Finished iteration 254, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2106.493
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:29.641373] Finished iteration 255, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2104.633
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:31.762455] Finished iteration 256, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2121.027
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:33.952154] Finished iteration 257, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2189.673
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:36.048840] Finished iteration 258, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2096.610
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:38.100959] Finished iteration 259, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2052.077
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:40.174671] Finished iteration 260, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2073.573
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:42.340369] Finished iteration 261, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2165.624
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:44.437394] Finished iteration 262, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2096.973
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:46.531291] Finished iteration 263, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2093.867
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:48.625620] Finished iteration 264, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2094.530
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:50.766894] Finished iteration 265, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2141.063
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:52.908633] Finished iteration 266, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2141.622
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:55.003024] Finished iteration 267, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2094.374
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:57.071401] Finished iteration 268, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2068.485
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:59.211410] Finished iteration 269, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2139.957
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:07:01.337295] Finished iteration 270, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2125.747
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:07:03.426399] Finished iteration 271, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2089.031
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:07:05.555150] Finished iteration 272, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2128.696
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:07:07.621426] Finished iteration 273, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2066.243
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:07:09.663083] Finished iteration 274, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2041.630
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:07:11.778201] Finished iteration 275, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2115.270
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:07:13.953643] Finished iteration 276, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2175.365
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:07:16.760419] Finished iteration 277, CKPT_AND_STOP: False, flag: tensor([2], dtype=torch.int32), speed: 2806.795
2022-11-24 14:07:16.770617 Begin to save checkpont to s3://spot-checkpoints/bert and exit
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 7 signal handler called with signal 10
Opt ckpt time 4.132307291030884
Process done with return code 0
Parent process ID: 19799 node: 172.31.22.229
24 cutpoints
Stages 1
13 20868437708.800007
7 13915698585.599995
10 17153729331.199993
8 14622140211.200005
9 15846820659.199995
Predicted microbatch size for 1: 8
comm size 0
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 1 5 0 1286522.0947265625 0
End of simulation:  Mini-batch time (usec) = 2905085
Min send: 10000000, max send 0
Min long send: 10000000, max long send 0
Min fwd: 10000000, max fwd 0; min bwd 10000000, max bwd 0
Min long fwd: 126283, max long fwd 129698; min long bwd 193190, max long bwd 199310
Time taken by simulation: 55 microseconds

Stages 2
13 10987980083.2
19 14996390399.999996
22 16963644723.199997
20 15631126630.400002
Predicted microbatch size for 2: 19
comm size 9961472
WARNING: no send time found, 2 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 2 4 0 638222.2290039062 542254.6839368516
End of simulation:  Mini-batch time (usec) = 3331662
Min send: 10000000, max send 0
Min long send: 542586, max long send 555338
Min fwd: 107744, max fwd 113936; min bwd 155753, max bwd 158782
Min long fwd: 131842, max long fwd 138676; min long bwd 169332, max long bwd 173300
Time taken by simulation: 97 microseconds

Stages 3
13 7832942284.800001
19 10697074380.8
22 12097432473.599998
23 12575272243.2
24 13035207577.6
Predicted microbatch size for 3: 24
comm size 12582912
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 5 0 448996.58203125 663682.2411979454
End of simulation:  Mini-batch time (usec) = 4994037
Min send: 10000000, max send 0
Min long send: 664014, max long send 679713
Min fwd: 72258, max fwd 88035; min bwd 119079, max bwd 130804
Min long fwd: 107414, max long fwd 112703; min long bwd 150032, max long bwd 153679
Time taken by simulation: 192 microseconds

Stages 4
13 6255423385.6
19 8547416371.2
22 9664326348.8
23 10045446451.2
24 10412856422.4
Predicted microbatch size for 4: 24
comm size 12582912
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 7 0 358221.00830078125 663682.2411979454
End of simulation:  Mini-batch time (usec) = 6464795
Min send: 10000000, max send 0
Min long send: 663870, max long send 683729
Min fwd: 53924, max fwd 67812; min bwd 83975, max bwd 97299
Min long fwd: 86081, max long fwd 91318; min long bwd 118237, max long bwd 121834
Time taken by simulation: 314 microseconds

Stages 6
13 4698582732.8
19 6397758361.599999
22 7231220224.0
23 7515620659.2
24 7790505267.2
Predicted microbatch size for 6: 24
comm size 12582912
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 9 0 241996.6583251953 663682.2411979454
End of simulation:  Mini-batch time (usec) = 9164548
Min send: 10000000, max send 0
Min long send: 663736, max long send 687371
Min fwd: 33746, max fwd 47347; min bwd 54554, max bwd 72477
Min long fwd: 65864, max long fwd 73316; min long bwd 84274, max long bwd 89413
Time taken by simulation: 626 microseconds

Stages 8
13 3930501529.6000004
19 5322929356.799999
22 6014667161.6
23 6250707763.2
24 6479329689.6
Predicted microbatch size for 8: 24
comm size 12582912
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 15 0 176039.7491455078 663682.2411979454
End of simulation:  Mini-batch time (usec) = 13724566
Min send: 10000000, max send 0
Min long send: 663736, max long send 690844
Min fwd: 22801, max fwd 38139; min bwd 36151, max bwd 55503
Min long fwd: 51106, max long fwd 59884; min long bwd 68124, max long bwd 75476
Time taken by simulation: 1546 microseconds

Stages 12
13 3141742080.0
19 4248100352.0
22 4798114099.200001
23 4985794867.2
24 5168154112.0
Predicted microbatch size for 12: 24
comm size 12582912
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 22 0 97192.52014160156 663682.2411979454
End of simulation:  Mini-batch time (usec) = 21189724
Min send: 10000000, max send 0
Min long send: 663682, max long send 690844
Min fwd: 10724, max fwd 28920; min bwd 23319, max bwd 41964
Min long fwd: 40826, max long fwd 50474; min long bwd 49192, max long bwd 58811
Time taken by simulation: 3351 microseconds

{1: 2.905085, 2: 3.331662, 3: 4.994037, 4: 6.464795, 6: 9.164548, 8: 13.724566, 12: 21.189724}
{1: 8, 2: 19, 3: 24, 4: 24, 6: 24, 8: 24, 12: 24}
best config is: 2 19
expected time is 3.331662
15 per stage
30 servers!
Config:
ranks: range(7, 8)
train batch size: 1024
partitions: 2
chunk_size: 19
data depth: 15
stage to rank map: 0,2,4,6,8,10,12,14,16,18,20,22,24,26,28;1,3,5,7,9,11,13,15,17,19,21,23,25,27,29;
World size is 30
/opt/conda/envs/varuna/bin/python -u /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --rank=7 --chunk_size=19 --local_rank=0 --stage_to_rank_map=0,2,4,6,8,10,12,14,16,18,20,22,24,26,28;1,3,5,7,9,11,13,15,17,19,21,23,25,27,29; --batch-size=68 --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna --resume_step 278
device: cuda:0 n_gpu: 1, distributed training: True, 16-bits training: True
dry run time 0.09262490272521973
SHARED WEIGHTS ARE
[(0, 1)]
this rank  7 is part of pipeline replica  3
4 chunks
Begin to load checkpint from s3://spot-checkpoints/bert/ckpt_278.pt
2022-11-24 14:08:27.285596 resume step from  278
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 7 signal handler called with signal 10
2022-11-24 14:09:31.562643 - Finished loading checkpoint, takes 64.188 secs
Process done with return code 1
Parent process ID: 21236 node: 172.31.22.229
24 cutpoints
Stages 1
13 20868437708.800007
7 13915698585.599995
10 17153729331.199993
8 14622140211.200005
9 15846820659.199995
Predicted microbatch size for 1: 8
comm size 0
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 1 5 0 1286522.0947265625 0
End of simulation:  Mini-batch time (usec) = 2905085
Min send: 10000000, max send 0
Min long send: 10000000, max long send 0
Min fwd: 10000000, max fwd 0; min bwd 10000000, max bwd 0
Min long fwd: 126283, max long fwd 129698; min long bwd 193190, max long bwd 199310
Time taken by simulation: 45 microseconds

Stages 2
13 10987980083.2
19 14996390399.999996
22 16963644723.199997
20 15631126630.400002
Predicted microbatch size for 2: 19
comm size 9961472
WARNING: no send time found, 2 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 2 4 0 638222.2290039062 542254.6839368516
End of simulation:  Mini-batch time (usec) = 3331662
Min send: 10000000, max send 0
Min long send: 542586, max long send 555338
Min fwd: 107744, max fwd 113936; min bwd 155753, max bwd 158782
Min long fwd: 131842, max long fwd 138676; min long bwd 169332, max long bwd 173300
Time taken by simulation: 148 microseconds

Stages 3
13 7832942284.800001
19 10697074380.8
22 12097432473.599998
23 12575272243.2
24 13035207577.6
Predicted microbatch size for 3: 24
comm size 12582912
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 5 0 448996.58203125 663682.2411979454
End of simulation:  Mini-batch time (usec) = 4994037
Min send: 10000000, max send 0
Min long send: 664014, max long send 679713
Min fwd: 72258, max fwd 88035; min bwd 119079, max bwd 130804
Min long fwd: 107414, max long fwd 112703; min long bwd 150032, max long bwd 153679
Time taken by simulation: 177 microseconds

Stages 4
13 6255423385.6
19 8547416371.2
22 9664326348.8
23 10045446451.2
24 10412856422.4
Predicted microbatch size for 4: 24
comm size 12582912
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 7 0 358221.00830078125 663682.2411979454
End of simulation:  Mini-batch time (usec) = 6464795
Min send: 10000000, max send 0
Min long send: 663870, max long send 683729
Min fwd: 53924, max fwd 67812; min bwd 83975, max bwd 97299
Min long fwd: 86081, max long fwd 91318; min long bwd 118237, max long bwd 121834
Time taken by simulation: 318 microseconds

Stages 6
13 4698582732.8
19 6397758361.599999
22 7231220224.0
23 7515620659.2
24 7790505267.2
Predicted microbatch size for 6: 24
comm size 12582912
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 9 0 241996.6583251953 663682.2411979454
End of simulation:  Mini-batch time (usec) = 9164548
Min send: 10000000, max send 0
Min long send: 663736, max long send 687371
Min fwd: 33746, max fwd 47347; min bwd 54554, max bwd 72477
Min long fwd: 65864, max long fwd 73316; min long bwd 84274, max long bwd 89413
Time taken by simulation: 622 microseconds

Stages 8
13 3930501529.6000004
19 5322929356.799999
22 6014667161.6
23 6250707763.2
24 6479329689.6
Predicted microbatch size for 8: 24
comm size 12582912
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 15 0 176039.7491455078 663682.2411979454
End of simulation:  Mini-batch time (usec) = 13724566
Min send: 10000000, max send 0
Min long send: 663736, max long send 690844
Min fwd: 22801, max fwd 38139; min bwd 36151, max bwd 55503
Min long fwd: 51106, max long fwd 59884; min long bwd 68124, max long bwd 75476
Time taken by simulation: 1459 microseconds

Stages 12
13 3141742080.0
19 4248100352.0
22 4798114099.200001
23 4985794867.2
24 5168154112.0
Predicted microbatch size for 12: 24
comm size 12582912
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 22 0 97192.52014160156 663682.2411979454
End of simulation:  Mini-batch time (usec) = 21189724
Min send: 10000000, max send 0
Min long send: 663682, max long send 690844
Min fwd: 10724, max fwd 28920; min bwd 23319, max bwd 41964
Min long fwd: 40826, max long fwd 50474; min long bwd 49192, max long bwd 58811
Time taken by simulation: 3505 microseconds

{1: 2.905085, 2: 3.331662, 3: 4.994037, 4: 6.464795, 6: 9.164548, 8: 13.724566, 12: 21.189724}
{1: 8, 2: 19, 3: 24, 4: 24, 6: 24, 8: 24, 12: 24}
best config is: 2 19
expected time is 3.331662
15 per stage
30 servers!
Config:
ranks: range(7, 8)
train batch size: 1024
partitions: 2
chunk_size: 19
data depth: 15
stage to rank map: 0,2,4,6,8,10,12,14,16,18,20,22,24,26,28;1,3,5,7,9,11,13,15,17,19,21,23,25,27,29;
World size is 30
/opt/conda/envs/varuna/bin/python -u /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --rank=7 --chunk_size=19 --local_rank=0 --stage_to_rank_map=0,2,4,6,8,10,12,14,16,18,20,22,24,26,28;1,3,5,7,9,11,13,15,17,19,21,23,25,27,29; --batch-size=68 --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna --resume_step 278
device: cuda:0 n_gpu: 1, distributed training: True, 16-bits training: True
dry run time 0.12261486053466797
SHARED WEIGHTS ARE
[(0, 1)]
this rank  7 is part of pipeline replica  3
4 chunks
Begin to load checkpint from s3://spot-checkpoints/bert/ckpt_278.pt
2022-11-24 14:10:38.003210 resume step from  278
2022-11-24 14:11:43.725202 - Finished loading checkpoint, takes 65.655 secs
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  524288.0
[2022-11-24 14:12:03.156626] Finished iteration 278, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4740.764
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  262144.0
[2022-11-24 14:12:06.362898] Finished iteration 279, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3206.050
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  131072.0
[2022-11-24 14:12:09.539958] Finished iteration 280, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3177.017
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  65536.0
[2022-11-24 14:12:12.679834] Finished iteration 281, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3139.830
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  32768.0
[2022-11-24 14:12:16.118295] Finished iteration 282, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3438.483
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  16384.0
[2022-11-24 14:12:18.257723] Finished iteration 283, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2139.275
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  8192.0
[2022-11-24 14:12:20.400758] Finished iteration 284, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2143.002
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  4096.0
[2022-11-24 14:12:22.524100] Finished iteration 285, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2123.479
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  2048.0
[2022-11-24 14:12:24.634622] Finished iteration 286, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2110.470
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1024.0
[2022-11-24 14:12:26.723947] Finished iteration 287, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2089.110
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  512.0
[2022-11-24 14:12:28.849568] Finished iteration 288, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2125.599
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  256.0
[2022-11-24 14:12:30.958303] Finished iteration 289, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2108.716
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  128.0
[2022-11-24 14:12:33.124157] Finished iteration 290, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2165.804
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  64.0
[2022-11-24 14:12:35.261356] Finished iteration 291, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2137.337
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  32.0
[2022-11-24 14:12:37.400146] Finished iteration 292, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2138.605
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  16.0
[2022-11-24 14:12:39.495002] Finished iteration 293, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2094.793
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  8.0
[2022-11-24 14:12:41.582850] Finished iteration 294, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2088.008
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  4.0
[2022-11-24 14:12:43.735086] Finished iteration 295, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2151.994
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  2.0
[2022-11-24 14:12:45.878444] Finished iteration 296, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2143.477
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:12:47.977739] Finished iteration 297, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2099.100
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:12:50.114593] Finished iteration 298, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2136.827
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:12:52.263309] Finished iteration 299, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2148.679
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:12:54.434760] Finished iteration 300, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2171.427
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:12:56.561602] Finished iteration 301, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2126.841
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:12:58.734207] Finished iteration 302, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2172.724
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:00.850962] Finished iteration 303, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2116.529
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:03.005119] Finished iteration 304, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2154.127
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:05.146250] Finished iteration 305, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2141.174
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:07.622518] Finished iteration 306, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2476.163
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:10.009424] Finished iteration 307, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2386.889
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:12.159951] Finished iteration 308, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2150.648
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:14.274411] Finished iteration 309, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2114.324
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:16.434357] Finished iteration 310, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2160.024
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:18.554559] Finished iteration 311, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2119.970
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:20.685559] Finished iteration 312, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2130.977
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:22.798365] Finished iteration 313, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2112.803
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:24.959147] Finished iteration 314, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2160.728
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:27.096524] Finished iteration 315, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2137.495
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:29.286708] Finished iteration 316, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2189.981
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:31.384953] Finished iteration 317, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2098.238
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:33.516745] Finished iteration 318, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2131.752
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:35.777384] Finished iteration 319, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2260.755
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:37.930902] Finished iteration 320, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2153.461
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:40.075709] Finished iteration 321, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2144.764
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:42.232080] Finished iteration 322, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2156.170
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:44.369074] Finished iteration 323, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2136.983
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:46.494355] Finished iteration 324, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2125.275
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:48.749241] Finished iteration 325, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2254.825
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:50.871875] Finished iteration 326, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2122.608
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:53.720510] Finished iteration 327, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2848.620
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:55.852741] Finished iteration 328, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2132.171
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:58.037527] Finished iteration 329, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2184.906
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:00.145487] Finished iteration 330, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2107.833
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:02.240652] Finished iteration 331, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2095.235
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:04.397001] Finished iteration 332, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2156.169
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:06.518142] Finished iteration 333, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2121.075
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:08.638981] Finished iteration 334, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2120.796
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:10.770075] Finished iteration 335, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2131.221
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:12.890754] Finished iteration 336, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2120.587
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:15.027617] Finished iteration 337, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2136.835
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:17.191546] Finished iteration 338, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2163.725
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:19.320605] Finished iteration 339, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2129.110
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:21.435387] Finished iteration 340, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2114.870
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:23.597986] Finished iteration 341, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2162.479
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:25.755192] Finished iteration 342, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2156.985
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:27.893210] Finished iteration 343, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2137.986
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:30.035860] Finished iteration 344, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2142.654
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:32.184501] Finished iteration 345, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2148.816
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:34.320879] Finished iteration 346, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2136.223
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:36.419234] Finished iteration 347, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2098.306
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:38.598899] Finished iteration 348, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2179.505
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:40.708133] Finished iteration 349, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2109.308
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:42.903432] Finished iteration 350, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2195.258
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:45.036070] Finished iteration 351, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2132.448
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:47.166227] Finished iteration 352, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2130.281
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:49.266468] Finished iteration 353, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2100.179
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:51.414268] Finished iteration 354, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2147.638
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:53.608390] Finished iteration 355, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2194.074
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:55.729727] Finished iteration 356, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2121.271
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:57.846147] Finished iteration 357, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2116.386
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:59.953947] Finished iteration 358, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2107.780
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:02.086623] Finished iteration 359, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2132.820
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:04.208093] Finished iteration 360, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2121.404
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:06.372959] Finished iteration 361, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2164.644
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:08.535453] Finished iteration 362, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2162.500
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:10.690521] Finished iteration 363, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2155.185
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:12.886533] Finished iteration 364, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2195.823
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:15.002340] Finished iteration 365, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2115.918
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:17.109044] Finished iteration 366, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2106.502
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:19.276253] Finished iteration 367, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2167.301
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:21.394975] Finished iteration 368, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2118.660
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:23.547408] Finished iteration 369, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2152.270
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:25.707321] Finished iteration 370, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2160.040
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:27.858071] Finished iteration 371, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2150.713
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:29.970128] Finished iteration 372, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2111.842
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:32.108377] Finished iteration 373, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2138.371
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:34.270847] Finished iteration 374, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2162.426
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:36.395274] Finished iteration 375, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2124.178
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:38.518178] Finished iteration 376, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2123.074
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:40.700036] Finished iteration 377, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2181.829
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:42.818260] Finished iteration 378, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2118.119
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:44.959290] Finished iteration 379, CKPT_AND_STOP: False, flag: tensor([1], dtype=torch.int32), speed: 2140.889
2022-11-24 14:15:44.964662 Begin to save checkpont to s3://spot-checkpoints/bert and exit
Opt ckpt time 3.6495110988616943
Signal handler called with signal 10


 STOPPING VARUNA !!



Process done with return code -10
Parent process ID: 22945 node: 172.31.22.229
24 cutpoints
Stages 1
13 20868437708.800007
7 13915698585.599995
10 17153729331.199993
8 14622140211.200005
9 15846820659.199995
Predicted microbatch size for 1: 8
comm size 0
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 1 5 0 1286522.0947265625 0
End of simulation:  Mini-batch time (usec) = 2905085
Min send: 10000000, max send 0
Min long send: 10000000, max long send 0
Min fwd: 10000000, max fwd 0; min bwd 10000000, max bwd 0
Min long fwd: 126283, max long fwd 129698; min long bwd 193190, max long bwd 199310
Time taken by simulation: 53 microseconds

Stages 2
13 10987980083.2
19 14996390399.999996
22 16963644723.199997
20 15631126630.400002
Predicted microbatch size for 2: 19
comm size 9961472
WARNING: no send time found, 2 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 2 4 0 638222.2290039062 542254.6839368516
End of simulation:  Mini-batch time (usec) = 3331662
Min send: 10000000, max send 0
Min long send: 542586, max long send 555338
Min fwd: 107744, max fwd 113936; min bwd 155753, max bwd 158782
Min long fwd: 131842, max long fwd 138676; min long bwd 169332, max long bwd 173300
Time taken by simulation: 98 microseconds

Stages 3
13 7832942284.800001
19 10697074380.8
22 12097432473.599998
23 12575272243.2
24 13035207577.6
Predicted microbatch size for 3: 24
comm size 12582912
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 5 0 448996.58203125 663682.2411979454
End of simulation:  Mini-batch time (usec) = 4994037
Min send: 10000000, max send 0
Min long send: 664014, max long send 679713
Min fwd: 72258, max fwd 88035; min bwd 119079, max bwd 130804
Min long fwd: 107414, max long fwd 112703; min long bwd 150032, max long bwd 153679
Time taken by simulation: 169 microseconds

Stages 4
13 6255423385.6
19 8547416371.2
22 9664326348.8
23 10045446451.2
24 10412856422.4
Predicted microbatch size for 4: 24
comm size 12582912
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 7 0 358221.00830078125 663682.2411979454
End of simulation:  Mini-batch time (usec) = 6464795
Min send: 10000000, max send 0
Min long send: 663870, max long send 683729
Min fwd: 53924, max fwd 67812; min bwd 83975, max bwd 97299
Min long fwd: 86081, max long fwd 91318; min long bwd 118237, max long bwd 121834
Time taken by simulation: 318 microseconds

Stages 6
13 4698582732.8
19 6397758361.599999
22 7231220224.0
23 7515620659.2
24 7790505267.2
Predicted microbatch size for 6: 24
comm size 12582912
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 9 0 241996.6583251953 663682.2411979454
End of simulation:  Mini-batch time (usec) = 9164548
Min send: 10000000, max send 0
Min long send: 663736, max long send 687371
Min fwd: 33746, max fwd 47347; min bwd 54554, max bwd 72477
Min long fwd: 65864, max long fwd 73316; min long bwd 84274, max long bwd 89413
Time taken by simulation: 616 microseconds

Stages 8
13 3930501529.6000004
19 5322929356.799999
22 6014667161.6
23 6250707763.2
24 6479329689.6
Predicted microbatch size for 8: 24
comm size 12582912
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 15 0 176039.7491455078 663682.2411979454
End of simulation:  Mini-batch time (usec) = 13724566
Min send: 10000000, max send 0
Min long send: 663736, max long send 690844
Min fwd: 22801, max fwd 38139; min bwd 36151, max bwd 55503
Min long fwd: 51106, max long fwd 59884; min long bwd 68124, max long bwd 75476
Time taken by simulation: 1461 microseconds

Stages 12
13 3141742080.0
19 4248100352.0
22 4798114099.200001
23 4985794867.2
24 5168154112.0
Predicted microbatch size for 12: 24
comm size 12582912
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 22 0 97192.52014160156 663682.2411979454
End of simulation:  Mini-batch time (usec) = 21189724
Min send: 10000000, max send 0
Min long send: 663682, max long send 690844
Min fwd: 10724, max fwd 28920; min bwd 23319, max bwd 41964
Min long fwd: 40826, max long fwd 50474; min long bwd 49192, max long bwd 58811
Time taken by simulation: 3388 microseconds

{1: 2.905085, 2: 3.331662, 3: 4.994037, 4: 6.464795, 6: 9.164548, 8: 13.724566, 12: 21.189724}
{1: 8, 2: 19, 3: 24, 4: 24, 6: 24, 8: 24, 12: 24}
best config is: 2 19
expected time is 3.331662
15 per stage
30 servers!
Config:
ranks: range(7, 8)
train batch size: 1024
partitions: 2
chunk_size: 19
data depth: 15
stage to rank map: 0,2,4,6,8,10,12,14,16,18,20,22,24,26,28;1,3,5,7,9,11,13,15,17,19,21,23,25,27,29;
World size is 30
/opt/conda/envs/varuna/bin/python -u /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --rank=7 --chunk_size=19 --local_rank=0 --stage_to_rank_map=0,2,4,6,8,10,12,14,16,18,20,22,24,26,28;1,3,5,7,9,11,13,15,17,19,21,23,25,27,29; --batch-size=68 --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna --resume_step 380
device: cuda:0 n_gpu: 1, distributed training: True, 16-bits training: True
dry run time 1.200702428817749
SHARED WEIGHTS ARE
[(0, 1)]
this rank  7 is part of pipeline replica  3
4 chunks
Begin to load checkpint from s3://spot-checkpoints/bert/ckpt_380.pt
2022-11-24 14:16:27.103403 resume step from  380
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 7 signal handler called with signal 10
2022-11-24 14:17:34.311894 - Finished loading checkpoint, takes 62.273 secs
2022-11-24 14:17:54.293169 Begin to exit
Process done with return code 0
Parent process ID: 24333 node: 172.31.22.229
24 cutpoints
Stages 1
13 20868437708.800007
7 13915698585.599995
10 17153729331.199993
8 14622140211.200005
9 15846820659.199995
Predicted microbatch size for 1: 8
comm size 0
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 1 4 0 3150942.3828125 0
End of simulation:  Mini-batch time (usec) = 4450032
Min send: 10000000, max send 0
Min long send: 10000000, max long send 0
Min fwd: 10000000, max fwd 0; min bwd 10000000, max bwd 0
Min long fwd: 127414, max long fwd 129698; min long bwd 194806, max long bwd 199310
Time taken by simulation: 47 microseconds

Stages 2
13 10987980083.2
19 14996390399.999996
22 16963644723.199997
20 15631126630.400002
Predicted microbatch size for 2: 19
comm size 9961472
WARNING: no send time found, 2 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 2 4 0 673273.3154296875 542254.6839368516
End of simulation:  Mini-batch time (usec) = 3366713
Min send: 10000000, max send 0
Min long send: 542586, max long send 555338
Min fwd: 107744, max fwd 113936; min bwd 155753, max bwd 158782
Min long fwd: 131842, max long fwd 138676; min long bwd 169332, max long bwd 173300
Time taken by simulation: 99 microseconds

Stages 3
13 7832942284.800001
19 10697074380.8
22 12097432473.599998
23 12575272243.2
24 13035207577.6
Predicted microbatch size for 3: 24
comm size 12582912
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 5 0 448996.58203125 663682.2411979454
End of simulation:  Mini-batch time (usec) = 4994037
Min send: 10000000, max send 0
Min long send: 664014, max long send 679713
Min fwd: 72258, max fwd 88035; min bwd 119079, max bwd 130804
Min long fwd: 107414, max long fwd 112703; min long bwd 150032, max long bwd 153679
Time taken by simulation: 167 microseconds

Stages 4
13 6255423385.6
19 8547416371.2
22 9664326348.8
23 10045446451.2
24 10412856422.4
Predicted microbatch size for 4: 24
comm size 12582912
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 6 0 375752.13623046875 663682.2411979454
End of simulation:  Mini-batch time (usec) = 6314108
Min send: 10000000, max send 0
Min long send: 663764, max long send 688387
Min fwd: 53924, max fwd 66948; min bwd 83975, max bwd 98046
Min long fwd: 84759, max long fwd 91250; min long bwd 120659, max long bwd 125455
Time taken by simulation: 269 microseconds

Stages 6
13 4698582732.8
19 6397758361.599999
22 7231220224.0
23 7515620659.2
24 7790505267.2
Predicted microbatch size for 6: 24
comm size 12582912
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 9 0 241996.6583251953 663682.2411979454
End of simulation:  Mini-batch time (usec) = 9164548
Min send: 10000000, max send 0
Min long send: 663736, max long send 687371
Min fwd: 33746, max fwd 47347; min bwd 54554, max bwd 72477
Min long fwd: 65864, max long fwd 73316; min long bwd 84274, max long bwd 89413
Time taken by simulation: 621 microseconds

Stages 8
13 3930501529.6000004
19 5322929356.799999
22 6014667161.6
23 6250707763.2
24 6479329689.6
Predicted microbatch size for 8: 24
comm size 12582912
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 11 0 214379.08935546875 663682.2411979454
End of simulation:  Mini-batch time (usec) = 12421079
Min send: 10000000, max send 0
Min long send: 663682, max long send 689782
Min fwd: 22992, max fwd 37161; min bwd 37517, max bwd 55449
Min long fwd: 51419, max long fwd 57045; min long bwd 68935, max long bwd 77274
Time taken by simulation: 1036 microseconds

Stages 12
13 3141742080.0
19 4248100352.0
22 4798114099.200001
23 4985794867.2
24 5168154112.0
Predicted microbatch size for 12: 24
comm size 12582912
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 22 0 97192.52014160156 663682.2411979454
End of simulation:  Mini-batch time (usec) = 21189724
Min send: 10000000, max send 0
Min long send: 663682, max long send 690844
Min fwd: 10724, max fwd 28920; min bwd 23319, max bwd 41964
Min long fwd: 40826, max long fwd 50474; min long bwd 49192, max long bwd 58811
Time taken by simulation: 3419 microseconds

{1: 4.450032, 2: 3.366713, 3: 4.994037, 4: 6.314108, 6: 9.164548, 8: 12.421079, 12: 21.189724}
{1: 8, 2: 19, 3: 24, 4: 24, 6: 24, 8: 24, 12: 24}
best config is: 2 19
expected time is 3.366713
16 per stage
32 servers!
Config:
ranks: range(7, 8)
train batch size: 1024
partitions: 2
chunk_size: 19
data depth: 16
stage to rank map: 0,2,4,6,8,10,12,14,16,18,20,22,24,26,28,30;1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31;
World size is 32
/opt/conda/envs/varuna/bin/python -u /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --rank=7 --chunk_size=19 --local_rank=0 --stage_to_rank_map=0,2,4,6,8,10,12,14,16,18,20,22,24,26,28,30;1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31; --batch-size=64 --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna --resume_step 380
device: cuda:0 n_gpu: 1, distributed training: True, 16-bits training: True
dry run time 0.02671360969543457
SHARED WEIGHTS ARE
[(0, 1)]
this rank  7 is part of pipeline replica  3
4 chunks
Begin to load checkpint from s3://spot-checkpoints/bert/ckpt_380.pt
2022-11-24 14:18:15.825780 resume step from  380
2022-11-24 14:19:23.887458 - Finished loading checkpoint, takes 63.085 secs
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  524288.0
[2022-11-24 14:19:34.550099] Finished iteration 380, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5716.522
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  262144.0
[2022-11-24 14:19:37.744497] Finished iteration 381, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3194.100
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  131072.0
[2022-11-24 14:19:40.912538] Finished iteration 382, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3168.004
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  65536.0
[2022-11-24 14:19:44.061618] Finished iteration 383, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3149.034
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  32768.0
[2022-11-24 14:19:47.215270] Finished iteration 384, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3153.624
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  16384.0
[2022-11-24 14:19:49.556575] Finished iteration 385, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2341.197
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  8192.0
[2022-11-24 14:19:51.666302] Finished iteration 386, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2109.901
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  4096.0
[2022-11-24 14:19:53.814831] Finished iteration 387, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2148.290
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  2048.0
[2022-11-24 14:19:55.883001] Finished iteration 388, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2068.119
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1024.0
[2022-11-24 14:19:57.962491] Finished iteration 389, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2079.479
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  512.0
[2022-11-24 14:20:00.062312] Finished iteration 390, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2099.792
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  256.0
[2022-11-24 14:20:02.204337] Finished iteration 391, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2142.004
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  128.0
[2022-11-24 14:20:05.148915] Finished iteration 392, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2944.521
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  64.0
[2022-11-24 14:20:07.258636] Finished iteration 393, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2109.690
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  32.0
[2022-11-24 14:20:09.352741] Finished iteration 394, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2094.223
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  16.0
[2022-11-24 14:20:12.388733] Finished iteration 395, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3035.799
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  8.0
[2022-11-24 14:20:14.479894] Finished iteration 396, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2091.152
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  4.0
[2022-11-24 14:20:16.551877] Finished iteration 397, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2071.965
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  2.0
[2022-11-24 14:20:18.636946] Finished iteration 398, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2085.032
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:20.687793] Finished iteration 399, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2050.950
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:22.762763] Finished iteration 400, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2074.755
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:24.878334] Finished iteration 401, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2115.738
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:26.991563] Finished iteration 402, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2113.134
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:29.635591] Finished iteration 403, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2643.996
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:31.803244] Finished iteration 404, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2167.458
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:33.880792] Finished iteration 405, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2077.534
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:36.000325] Finished iteration 406, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2119.619
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:38.096665] Finished iteration 407, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2096.308
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:40.231718] Finished iteration 408, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2134.981
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:42.297230] Finished iteration 409, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2065.369
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:44.371609] Finished iteration 410, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2074.445
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:46.486518] Finished iteration 411, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2114.711
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:48.571750] Finished iteration 412, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2085.330
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:50.667780] Finished iteration 413, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2095.872
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:52.760189] Finished iteration 414, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2092.398
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:54.903536] Finished iteration 415, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2143.309
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:56.954299] Finished iteration 416, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2050.756
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:59.111364] Finished iteration 417, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2157.002
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:01.193096] Finished iteration 418, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2081.707
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:03.271456] Finished iteration 419, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2078.347
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:05.379856] Finished iteration 420, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2108.350
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:07.452924] Finished iteration 421, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2073.038
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:09.590864] Finished iteration 422, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2137.914
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:11.681206] Finished iteration 423, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2090.311
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:13.806552] Finished iteration 424, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2125.469
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:15.917021] Finished iteration 425, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2110.289
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:18.016166] Finished iteration 426, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2099.232
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:20.077681] Finished iteration 427, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2061.345
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:22.181473] Finished iteration 428, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2103.735
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:24.231128] Finished iteration 429, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2049.625
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:26.330296] Finished iteration 430, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2099.321
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:28.395808] Finished iteration 431, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2065.435
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:30.483810] Finished iteration 432, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2087.951
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:32.560095] Finished iteration 433, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2076.132
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:34.701302] Finished iteration 434, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2141.294
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:36.860486] Finished iteration 435, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2159.171
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:39.032276] Finished iteration 436, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2171.558
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:41.157501] Finished iteration 437, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2125.200
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:43.345763] Finished iteration 438, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2188.215
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:45.444611] Finished iteration 439, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2098.816
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:47.581469] Finished iteration 440, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2136.823
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:49.678265] Finished iteration 441, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2096.802
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:51.808029] Finished iteration 442, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2129.864
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:53.890496] Finished iteration 443, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2082.267
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:56.016710] Finished iteration 444, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2126.317
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:58.112326] Finished iteration 445, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2095.444
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:00.206609] Finished iteration 446, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2094.397
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:02.254609] Finished iteration 447, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2047.944
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:04.361492] Finished iteration 448, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2106.680
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:06.473632] Finished iteration 449, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2112.308
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:08.547882] Finished iteration 450, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2074.006
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:10.655307] Finished iteration 451, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2107.549
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:12.836311] Finished iteration 452, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2180.799
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:14.934147] Finished iteration 453, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2097.984
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:17.060380] Finished iteration 454, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2126.160
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:19.118587] Finished iteration 455, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2058.028
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:21.195202] Finished iteration 456, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2076.728
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:24.181715] Finished iteration 457, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2986.318
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:26.274543] Finished iteration 458, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2092.949
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:28.311042] Finished iteration 459, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2036.434
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:30.385714] Finished iteration 460, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2074.652
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:32.484604] Finished iteration 461, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2098.803
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:34.588291] Finished iteration 462, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2103.497
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:36.653815] Finished iteration 463, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2065.511
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:38.785064] Finished iteration 464, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2131.200
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:40.823066] Finished iteration 465, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2037.990
7 Overflow !!
7 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:42.943053] Finished iteration 466, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2120.097
Parent process ID: 23906 node: 172.31.19.171
Killing process on gpu with nvidia-smi | grep 'python' | awk '{ print $5 }' | xargs -n1 kill -9
24 cutpoints
Stages 1
13 20868437708.800007
7 13915698585.599995
10 17153729331.199993
8 14622140211.200005
9 15846820659.199995
Predicted microbatch size for 1: 8
comm size 0
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 1 6 0 1334585.0830078125 0
End of simulation:  Mini-batch time (usec) = 3270291
Min send: 10000000, max send 0
Min long send: 10000000, max long send 0
Min fwd: 10000000, max fwd 0; min bwd 10000000, max bwd 0
Min long fwd: 126112, max long fwd 129698; min long bwd 191031, max long bwd 199310
Time taken by simulation: 46 microseconds

Stages 2
13 10987980083.2
19 14996390399.999996
22 16963644723.199997
20 15631126630.400002
Predicted microbatch size for 2: 19
comm size 9961472
WARNING: no send time found, 2 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 2 5 0 608509.5825195312 542254.6839368516
End of simulation:  Mini-batch time (usec) = 3607863
Min send: 10000000, max send 0
Min long send: 542586, max long send 558986
Min fwd: 106816, max fwd 113936; min bwd 154625, max bwd 157669
Min long fwd: 134083, max long fwd 138081; min long bwd 169664, max long bwd 173713
Time taken by simulation: 111 microseconds

Stages 3
13 7832942284.800001
19 10697074380.8
22 12097432473.599998
23 12575272243.2
24 13035207577.6
Predicted microbatch size for 3: 24
comm size 12582912
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 7 0 441679.38232421875 663682.2411979454
End of simulation:  Mini-batch time (usec) = 5526356
Min send: 10000000, max send 0
Min long send: 664014, max long send 688387
Min fwd: 70473, max fwd 86449; min bwd 116125, max bwd 131549
Min long fwd: 107949, max long fwd 111566; min long bwd 147972, max long bwd 154852
Time taken by simulation: 234 microseconds

Stages 4
13 6255423385.6
19 8547416371.2
22 9664326348.8
23 10045446451.2
24 10412856422.4
Predicted microbatch size for 4: 24
comm size 12582912
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 9 0 322485.90087890625 663682.2411979454
End of simulation:  Mini-batch time (usec) = 6859347
Min send: 10000000, max send 0
Min long send: 663764, max long send 686148
Min fwd: 51765, max fwd 67812; min bwd 84974, max bwd 98885
Min long fwd: 83336, max long fwd 90554; min long bwd 118409, max long bwd 124254
Time taken by simulation: 409 microseconds

Stages 6
13 4698582732.8
19 6397758361.599999
22 7231220224.0
23 7515620659.2
24 7790505267.2
Predicted microbatch size for 6: 24
comm size 12582912
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 15 0 205807.43408203125 663682.2411979454
End of simulation:  Mini-batch time (usec) = 11152793
Min send: 10000000, max send 0
Min long send: 663736, max long send 688387
Min fwd: 32603, max fwd 47172; min bwd 54003, max bwd 69793
Min long fwd: 66617, max long fwd 70492; min long bwd 81618, max long bwd 89601
Time taken by simulation: 1115 microseconds

Stages 8
13 3930501529.6000004
19 5322929356.799999
22 6014667161.6
23 6250707763.2
24 6479329689.6
Predicted microbatch size for 8: 24
comm size 12582912
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 22 0 120660.06469726562 663682.2411979454
End of simulation:  Mini-batch time (usec) = 15792286
Min send: 10000000, max send 0
Min long send: 663682, max long send 690844
Min fwd: 23237, max fwd 38139; min bwd 35712, max bwd 56890
Min long fwd: 51613, max long fwd 57677; min long bwd 69478, max long bwd 76496
Time taken by simulation: 2205 microseconds

Stages 12
13 3141742080.0
19 4248100352.0
22 4798114099.200001
23 4985794867.2
24 5168154112.0
Predicted microbatch size for 12: 24
comm size 12582912
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 43 0 0 663682.2411979454
End of simulation:  Mini-batch time (usec) = 28245316
Min send: 10000000, max send 0
Min long send: 663682, max long send 693511
Min fwd: 10606, max fwd 31119; min bwd 22396, max bwd 41317
Min long fwd: 40838, max long fwd 49874; min long bwd 47936, max long bwd 55473
Time taken by simulation: 6836 microseconds

{1: 3.270291, 2: 3.607863, 3: 5.526356, 4: 6.859347, 6: 11.152793, 8: 15.792286, 12: 28.245316}
{1: 8, 2: 19, 3: 24, 4: 24, 6: 24, 8: 24, 12: 24}
best config is: 2 19
expected time is 3.607863
11 per stage
22 servers!
Config:
ranks: range(7, 8)
train batch size: 1024
partitions: 2
chunk_size: 19
data depth: 11
stage to rank map: 0,2,4,6,8,10,12,14,16,18,20;1,3,5,7,9,11,13,15,17,19,21;
World size is 22
/opt/conda/envs/varuna/bin/python -u /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --rank=7 --chunk_size=19 --local_rank=0 --stage_to_rank_map=0,2,4,6,8,10,12,14,16,18,20;1,3,5,7,9,11,13,15,17,19,21; --batch-size=93 --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna --resume_step 380
device: cuda:0 n_gpu: 1, distributed training: True, 16-bits training: True
dry run time 0.11083006858825684
SHARED WEIGHTS ARE
[(0, 1)]
this rank  7 is part of pipeline replica  3
5 chunks
Begin to load checkpint from s3://spot-checkpoints/bert/ckpt_380.pt
2022-11-24 14:32:07.093500 resume step from  380
