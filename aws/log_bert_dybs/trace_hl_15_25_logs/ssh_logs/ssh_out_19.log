Parent process ID: 12055 node: 172.31.30.133
24 cutpoints
Stages 1
13 20868437708.800007
7 13915698585.599995
10 17153729331.199993
8 14622140211.200005
9 15846820659.199995
Predicted microbatch size for 1: 8
comm size 0
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 1 5 0 1286522.0947265625 0
End of simulation:  Mini-batch time (usec) = 2905085
Min send: 10000000, max send 0
Min long send: 10000000, max long send 0
Min fwd: 10000000, max fwd 0; min bwd 10000000, max bwd 0
Min long fwd: 126283, max long fwd 129698; min long bwd 193190, max long bwd 199310
Time taken by simulation: 46 microseconds

Stages 2
13 10987980083.2
19 14996390399.999996
22 16963644723.199997
20 15631126630.400002
Predicted microbatch size for 2: 19
comm size 9961472
WARNING: no send time found, 2 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 2 5 0 635506.6528320312 542254.6839368516
End of simulation:  Mini-batch time (usec) = 3634860
Min send: 10000000, max send 0
Min long send: 542586, max long send 558986
Min fwd: 106816, max fwd 113936; min bwd 154625, max bwd 157669
Min long fwd: 134083, max long fwd 138081; min long bwd 169664, max long bwd 173713
Time taken by simulation: 114 microseconds

Stages 3
13 7832942284.800001
19 10697074380.8
22 12097432473.599998
23 12575272243.2
24 13035207577.6
Predicted microbatch size for 3: 24
comm size 12582912
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 5 0 443515.80810546875 663682.2411979454
End of simulation:  Mini-batch time (usec) = 4988556
Min send: 10000000, max send 0
Min long send: 664014, max long send 679713
Min fwd: 72258, max fwd 88035; min bwd 119079, max bwd 130804
Min long fwd: 107414, max long fwd 112703; min long bwd 150032, max long bwd 153679
Time taken by simulation: 171 microseconds

Stages 4
13 6255423385.6
19 8547416371.2
22 9664326348.8
23 10045446451.2
24 10412856422.4
Predicted microbatch size for 4: 24
comm size 12582912
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 8 0 326449.15771484375 663682.2411979454
End of simulation:  Mini-batch time (usec) = 6677364
Min send: 10000000, max send 0
Min long send: 663870, max long send 686148
Min fwd: 51765, max fwd 66948; min bwd 85303, max bwd 98547
Min long fwd: 83336, max long fwd 91250; min long bwd 118529, max long bwd 127083
Time taken by simulation: 366 microseconds

Stages 6
13 4698582732.8
19 6397758361.599999
22 7231220224.0
23 7515620659.2
24 7790505267.2
Predicted microbatch size for 6: 24
comm size 12582912
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 11 0 240705.6121826172 663682.2411979454
End of simulation:  Mini-batch time (usec) = 9735715
Min send: 10000000, max send 0
Min long send: 663764, max long send 689782
Min fwd: 32942, max fwd 48168; min bwd 55337, max bwd 68897
Min long fwd: 65982, max long fwd 73316; min long bwd 85277, max long bwd 90311
Time taken by simulation: 765 microseconds

Stages 8
13 3930501529.6000004
19 5322929356.799999
22 6014667161.6
23 6250707763.2
24 6479329689.6
Predicted microbatch size for 8: 24
comm size 12582912
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 15 0 176039.7491455078 663682.2411979454
End of simulation:  Mini-batch time (usec) = 13724566
Min send: 10000000, max send 0
Min long send: 663736, max long send 690844
Min fwd: 22801, max fwd 38139; min bwd 36151, max bwd 55503
Min long fwd: 51106, max long fwd 59884; min long bwd 68124, max long bwd 75476
Time taken by simulation: 1460 microseconds

Stages 12
13 3141742080.0
19 4248100352.0
22 4798114099.200001
23 4985794867.2
24 5168154112.0
Predicted microbatch size for 12: 24
comm size 12582912
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 22 0 97192.52014160156 663682.2411979454
End of simulation:  Mini-batch time (usec) = 21189724
Min send: 10000000, max send 0
Min long send: 663682, max long send 690844
Min fwd: 10724, max fwd 28920; min bwd 23319, max bwd 41964
Min long fwd: 40826, max long fwd 50474; min long bwd 49192, max long bwd 58811
Time taken by simulation: 3392 microseconds

{1: 2.905085, 2: 3.63486, 3: 4.988556, 4: 6.677364, 6: 9.735715, 8: 13.724566, 12: 21.189724}
{1: 8, 2: 19, 3: 24, 4: 24, 6: 24, 8: 24, 12: 24}
best config is: 2 19
expected time is 3.63486
13 per stage
26 servers!
Config:
ranks: range(19, 20)
train batch size: 1024
partitions: 2
chunk_size: 19
data depth: 13
stage to rank map: 0,2,4,6,8,10,12,14,16,18,20,22,24;1,3,5,7,9,11,13,15,17,19,21,23,25;
World size is 26
/opt/conda/envs/varuna/bin/python -u /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --rank=19 --chunk_size=19 --local_rank=0 --stage_to_rank_map=0,2,4,6,8,10,12,14,16,18,20,22,24;1,3,5,7,9,11,13,15,17,19,21,23,25; --batch-size=78 --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna
device: cuda:0 n_gpu: 1, distributed training: True, 16-bits training: True
dry run time 0.16624164581298828
SHARED WEIGHTS ARE
[(0, 1)]
this rank  19 is part of pipeline replica  9
5 chunks
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  524288.0
[2022-11-24 13:53:10.905465] Finished iteration 0, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5379.847
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  262144.0
[2022-11-24 13:53:13.226781] Finished iteration 1, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2321.064
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  131072.0
[2022-11-24 13:53:16.602746] Finished iteration 2, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3375.953
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  65536.0
[2022-11-24 13:53:18.981848] Finished iteration 3, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2379.058
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  32768.0
[2022-11-24 13:53:22.305382] Finished iteration 4, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3323.539
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  16384.0
[2022-11-24 13:53:24.666005] Finished iteration 5, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2360.524
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  8192.0
[2022-11-24 13:53:26.925352] Finished iteration 6, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2259.302
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  4096.0
[2022-11-24 13:53:29.274673] Finished iteration 7, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2349.284
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  2048.0
[2022-11-24 13:53:31.594380] Finished iteration 8, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2319.727
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1024.0
[2022-11-24 13:53:33.927880] Finished iteration 9, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2333.443
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  512.0
[2022-11-24 13:53:36.246057] Finished iteration 10, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2318.121
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  256.0
[2022-11-24 13:53:38.522723] Finished iteration 11, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2276.652
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  128.0
[2022-11-24 13:53:40.862194] Finished iteration 12, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2339.427
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  64.0
[2022-11-24 13:53:43.161638] Finished iteration 13, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2299.384
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  32.0
[2022-11-24 13:53:45.444293] Finished iteration 14, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2282.624
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  16.0
[2022-11-24 13:53:47.776295] Finished iteration 15, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2331.985
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  8.0
[2022-11-24 13:53:50.044926] Finished iteration 16, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2268.581
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  4.0
[2022-11-24 13:53:52.349489] Finished iteration 17, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2304.537
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  2.0
[2022-11-24 13:53:54.690342] Finished iteration 18, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2340.858
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:53:56.995525] Finished iteration 19, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2305.114
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:53:59.272345] Finished iteration 20, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2276.793
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:01.598759] Finished iteration 21, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2326.390
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:03.911133] Finished iteration 22, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2312.338
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:06.193301] Finished iteration 23, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2282.128
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:08.481176] Finished iteration 24, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2287.848
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:10.772132] Finished iteration 25, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2290.918
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:13.098170] Finished iteration 26, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2326.015
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:15.415654] Finished iteration 27, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2317.446
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:17.757439] Finished iteration 28, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2341.763
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:20.935191] Finished iteration 29, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3177.715
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:23.192900] Finished iteration 30, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2257.675
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:25.535787] Finished iteration 31, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2342.856
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:27.807082] Finished iteration 32, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2271.274
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:30.120480] Finished iteration 33, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2313.365
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:32.458767] Finished iteration 34, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2338.255
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:34.754535] Finished iteration 35, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2295.737
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:37.086794] Finished iteration 36, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2332.231
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:39.415134] Finished iteration 37, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2328.330
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:41.742744] Finished iteration 38, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2327.561
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:44.089365] Finished iteration 39, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2346.586
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:46.426244] Finished iteration 40, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2336.888
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:48.709035] Finished iteration 41, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2282.735
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:51.035574] Finished iteration 42, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2326.507
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:53.401014] Finished iteration 43, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2365.436
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:55.735088] Finished iteration 44, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2334.016
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:58.077527] Finished iteration 45, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2342.553
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:00.405332] Finished iteration 46, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2327.624
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:02.715260] Finished iteration 47, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2309.886
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:04.980105] Finished iteration 48, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2264.808
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:07.344903] Finished iteration 49, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2364.770
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:09.648651] Finished iteration 50, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2303.715
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:11.989643] Finished iteration 51, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2340.966
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:14.280094] Finished iteration 52, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2290.452
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:16.598669] Finished iteration 53, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2318.504
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:18.898764] Finished iteration 54, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2300.064
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:21.188137] Finished iteration 55, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2289.344
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:23.503582] Finished iteration 56, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2315.408
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:25.828548] Finished iteration 57, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2324.936
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:28.187089] Finished iteration 58, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2358.508
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:30.533026] Finished iteration 59, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2345.909
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:32.830719] Finished iteration 60, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2297.692
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:35.140393] Finished iteration 61, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2309.638
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:37.441011] Finished iteration 62, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2300.547
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:39.788409] Finished iteration 63, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2347.379
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:42.120983] Finished iteration 64, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2332.534
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:44.419350] Finished iteration 65, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2298.340
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:46.771733] Finished iteration 66, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2352.361
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:49.192045] Finished iteration 67, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2420.298
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:51.491961] Finished iteration 68, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2299.879
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:53.850749] Finished iteration 69, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2358.773
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:56.182030] Finished iteration 70, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2331.216
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:58.515915] Finished iteration 71, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2333.859
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:00.836664] Finished iteration 72, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2320.726
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:03.147915] Finished iteration 73, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2311.217
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:05.454808] Finished iteration 74, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2306.886
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:07.714268] Finished iteration 75, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2259.465
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:10.015262] Finished iteration 76, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2300.898
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:12.351284] Finished iteration 77, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2335.990
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:14.716828] Finished iteration 78, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2365.515
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:17.016163] Finished iteration 79, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2299.304
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:19.355002] Finished iteration 80, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2338.807
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:21.655566] Finished iteration 81, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2300.529
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:23.923809] Finished iteration 82, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2268.212
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:26.186233] Finished iteration 83, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2262.439
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:28.491624] Finished iteration 84, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2305.320
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:30.775197] Finished iteration 85, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2283.536
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:33.083258] Finished iteration 86, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2308.046
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:35.318458] Finished iteration 87, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2235.171
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:37.614969] Finished iteration 88, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2296.460
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:40.013433] Finished iteration 89, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2398.432
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:42.287696] Finished iteration 90, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2274.235
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:44.564653] Finished iteration 91, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2276.937
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:46.894075] Finished iteration 92, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2329.402
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:49.210708] Finished iteration 93, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2316.598
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:51.538511] Finished iteration 94, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2327.765
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:53.830130] Finished iteration 95, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2291.595
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:56.157517] Finished iteration 96, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2327.364
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:58.425876] Finished iteration 97, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2268.320
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:00.732674] Finished iteration 98, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2306.764
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:03.059309] Finished iteration 99, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2326.595
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:05.417885] Finished iteration 100, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2358.549
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:07.735210] Finished iteration 101, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2317.284
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:10.040098] Finished iteration 102, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2304.865
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:12.337521] Finished iteration 103, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2297.396
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:14.652980] Finished iteration 104, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2315.432
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:16.987308] Finished iteration 105, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2334.311
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:19.275261] Finished iteration 106, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2287.933
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:21.530883] Finished iteration 107, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2255.584
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:23.815686] Finished iteration 108, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2284.754
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:26.107749] Finished iteration 109, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2292.048
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:28.393307] Finished iteration 110, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2285.515
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:30.655538] Finished iteration 111, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2262.202
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:32.999095] Finished iteration 112, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2343.533
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:35.346092] Finished iteration 113, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2346.977
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:37.638254] Finished iteration 114, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2292.182
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:39.982615] Finished iteration 115, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2344.269
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:42.296406] Finished iteration 116, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2313.761
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:44.583377] Finished iteration 117, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2286.939
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:46.896565] Finished iteration 118, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2313.156
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:49.148175] Finished iteration 119, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2251.562
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:51.374396] Finished iteration 120, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2226.230
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:53.647591] Finished iteration 121, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2273.132
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:55.967572] Finished iteration 122, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2319.967
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:58.361025] Finished iteration 123, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2393.400
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:00.675364] Finished iteration 124, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2314.307
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:02.968626] Finished iteration 125, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2293.229
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:05.279462] Finished iteration 126, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2310.812
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:07.638482] Finished iteration 127, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2358.989
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:10.023206] Finished iteration 128, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2384.684
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:12.365032] Finished iteration 129, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2341.800
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:14.749466] Finished iteration 130, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2384.395
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:17.064939] Finished iteration 131, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2315.448
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:19.366537] Finished iteration 132, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2301.559
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:21.681606] Finished iteration 133, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2315.043
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:24.036752] Finished iteration 134, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2355.117
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:26.392472] Finished iteration 135, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2355.691
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:28.676041] Finished iteration 136, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2283.539
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:31.004230] Finished iteration 137, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2328.153
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:33.312250] Finished iteration 138, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2308.019
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:35.585866] Finished iteration 139, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2273.592
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:37.883896] Finished iteration 140, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2297.973
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:40.183611] Finished iteration 141, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2299.689
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:42.519598] Finished iteration 142, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2335.953
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:44.826284] Finished iteration 143, CKPT_AND_STOP: False, flag: tensor([1], dtype=torch.int32), speed: 2306.695
2022-11-24 13:58:44.830812 Begin to save checkpont to s3://spot-checkpoints/bert and exit
Opt ckpt time 8.713711977005005
Process done with return code 0
Parent process ID: 12772 node: 172.31.30.133
24 cutpoints
Stages 1
13 20868437708.800007
7 13915698585.599995
10 17153729331.199993
8 14622140211.200005
9 15846820659.199995
Predicted microbatch size for 1: 8
comm size 0
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 1 5 0 1286522.0947265625 0
End of simulation:  Mini-batch time (usec) = 2905085
Min send: 10000000, max send 0
Min long send: 10000000, max long send 0
Min fwd: 10000000, max fwd 0; min bwd 10000000, max bwd 0
Min long fwd: 126283, max long fwd 129698; min long bwd 193190, max long bwd 199310
Time taken by simulation: 47 microseconds

Stages 2
13 10987980083.2
19 14996390399.999996
22 16963644723.199997
20 15631126630.400002
Predicted microbatch size for 2: 19
comm size 9961472
WARNING: no send time found, 2 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 2 4 0 645340.8203125 542254.6839368516
End of simulation:  Mini-batch time (usec) = 3338780
Min send: 10000000, max send 0
Min long send: 542586, max long send 555338
Min fwd: 107744, max fwd 113936; min bwd 155753, max bwd 158782
Min long fwd: 131842, max long fwd 138676; min long bwd 169332, max long bwd 173300
Time taken by simulation: 103 microseconds

Stages 3
13 7832942284.800001
19 10697074380.8
22 12097432473.599998
23 12575272243.2
24 13035207577.6
Predicted microbatch size for 3: 24
comm size 12582912
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 5 0 443515.80810546875 663682.2411979454
End of simulation:  Mini-batch time (usec) = 4988556
Min send: 10000000, max send 0
Min long send: 664014, max long send 679713
Min fwd: 72258, max fwd 88035; min bwd 119079, max bwd 130804
Min long fwd: 107414, max long fwd 112703; min long bwd 150032, max long bwd 153679
Time taken by simulation: 174 microseconds

Stages 4
13 6255423385.6
19 8547416371.2
22 9664326348.8
23 10045446451.2
24 10412856422.4
Predicted microbatch size for 4: 24
comm size 12582912
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 7 0 358221.00830078125 663682.2411979454
End of simulation:  Mini-batch time (usec) = 6464795
Min send: 10000000, max send 0
Min long send: 663870, max long send 683729
Min fwd: 53924, max fwd 67812; min bwd 83975, max bwd 97299
Min long fwd: 86081, max long fwd 91318; min long bwd 118237, max long bwd 121834
Time taken by simulation: 310 microseconds

Stages 6
13 4698582732.8
19 6397758361.599999
22 7231220224.0
23 7515620659.2
24 7790505267.2
Predicted microbatch size for 6: 24
comm size 12582912
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 11 0 240705.6121826172 663682.2411979454
End of simulation:  Mini-batch time (usec) = 9735715
Min send: 10000000, max send 0
Min long send: 663764, max long send 689782
Min fwd: 32942, max fwd 48168; min bwd 55337, max bwd 68897
Min long fwd: 65982, max long fwd 73316; min long bwd 85277, max long bwd 90311
Time taken by simulation: 763 microseconds

Stages 8
13 3930501529.6000004
19 5322929356.799999
22 6014667161.6
23 6250707763.2
24 6479329689.6
Predicted microbatch size for 8: 24
comm size 12582912
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 15 0 176039.7491455078 663682.2411979454
End of simulation:  Mini-batch time (usec) = 13724566
Min send: 10000000, max send 0
Min long send: 663736, max long send 690844
Min fwd: 22801, max fwd 38139; min bwd 36151, max bwd 55503
Min long fwd: 51106, max long fwd 59884; min long bwd 68124, max long bwd 75476
Time taken by simulation: 1487 microseconds

Stages 12
13 3141742080.0
19 4248100352.0
22 4798114099.200001
23 4985794867.2
24 5168154112.0
Predicted microbatch size for 12: 24
comm size 12582912
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 22 0 97192.52014160156 663682.2411979454
End of simulation:  Mini-batch time (usec) = 21189724
Min send: 10000000, max send 0
Min long send: 663682, max long send 690844
Min fwd: 10724, max fwd 28920; min bwd 23319, max bwd 41964
Min long fwd: 40826, max long fwd 50474; min long bwd 49192, max long bwd 58811
Time taken by simulation: 3413 microseconds

{1: 2.905085, 2: 3.33878, 3: 4.988556, 4: 6.464795, 6: 9.735715, 8: 13.724566, 12: 21.189724}
{1: 8, 2: 19, 3: 24, 4: 24, 6: 24, 8: 24, 12: 24}
best config is: 2 19
expected time is 3.33878
14 per stage
28 servers!
Config:
ranks: range(19, 20)
train batch size: 1024
partitions: 2
chunk_size: 19
data depth: 14
stage to rank map: 0,2,4,6,8,10,12,14,16,18,20,22,24,26;1,3,5,7,9,11,13,15,17,19,21,23,25,27;
World size is 28
/opt/conda/envs/varuna/bin/python -u /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --rank=19 --chunk_size=19 --local_rank=0 --stage_to_rank_map=0,2,4,6,8,10,12,14,16,18,20,22,24,26;1,3,5,7,9,11,13,15,17,19,21,23,25,27; --batch-size=73 --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna --resume_step 144
device: cuda:0 n_gpu: 1, distributed training: True, 16-bits training: True
dry run time 0.22278881072998047
SHARED WEIGHTS ARE
[(0, 1)]
this rank  19 is part of pipeline replica  9
4 chunks
Begin to load checkpint from s3://spot-checkpoints/bert/ckpt_144.pt
2022-11-24 13:59:22.749115 resume step from  144
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 19 signal handler called with signal 10
2022-11-24 14:00:17.383382 - Finished loading checkpoint, takes 54.469 secs
2022-11-24 14:00:31.375090 Begin to exit
Process done with return code 0
Parent process ID: 14075 node: 172.31.30.133
24 cutpoints
Stages 1
13 20868437708.800007
7 13915698585.599995
10 17153729331.199993
8 14622140211.200005
9 15846820659.199995
Predicted microbatch size for 1: 8
comm size 0
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 1 4 0 3150942.3828125 0
End of simulation:  Mini-batch time (usec) = 4450032
Min send: 10000000, max send 0
Min long send: 10000000, max long send 0
Min fwd: 10000000, max fwd 0; min bwd 10000000, max bwd 0
Min long fwd: 127414, max long fwd 129698; min long bwd 194806, max long bwd 199310
Time taken by simulation: 48 microseconds

Stages 2
13 10987980083.2
19 14996390399.999996
22 16963644723.199997
20 15631126630.400002
Predicted microbatch size for 2: 19
comm size 9961472
WARNING: no send time found, 2 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 2 4 0 673273.3154296875 542254.6839368516
End of simulation:  Mini-batch time (usec) = 3366713
Min send: 10000000, max send 0
Min long send: 542586, max long send 555338
Min fwd: 107744, max fwd 113936; min bwd 155753, max bwd 158782
Min long fwd: 131842, max long fwd 138676; min long bwd 169332, max long bwd 173300
Time taken by simulation: 95 microseconds

Stages 3
13 7832942284.800001
19 10697074380.8
22 12097432473.599998
23 12575272243.2
24 13035207577.6
Predicted microbatch size for 3: 24
comm size 12582912
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 5 0 448996.58203125 663682.2411979454
End of simulation:  Mini-batch time (usec) = 4994037
Min send: 10000000, max send 0
Min long send: 664014, max long send 679713
Min fwd: 72258, max fwd 88035; min bwd 119079, max bwd 130804
Min long fwd: 107414, max long fwd 112703; min long bwd 150032, max long bwd 153679
Time taken by simulation: 172 microseconds

Stages 4
13 6255423385.6
19 8547416371.2
22 9664326348.8
23 10045446451.2
24 10412856422.4
Predicted microbatch size for 4: 24
comm size 12582912
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 6 0 375752.13623046875 663682.2411979454
End of simulation:  Mini-batch time (usec) = 6314108
Min send: 10000000, max send 0
Min long send: 663764, max long send 688387
Min fwd: 53924, max fwd 66948; min bwd 83975, max bwd 98046
Min long fwd: 84759, max long fwd 91250; min long bwd 120659, max long bwd 125455
Time taken by simulation: 293 microseconds

Stages 6
13 4698582732.8
19 6397758361.599999
22 7231220224.0
23 7515620659.2
24 7790505267.2
Predicted microbatch size for 6: 24
comm size 12582912
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 9 0 241996.6583251953 663682.2411979454
End of simulation:  Mini-batch time (usec) = 9164548
Min send: 10000000, max send 0
Min long send: 663736, max long send 687371
Min fwd: 33746, max fwd 47347; min bwd 54554, max bwd 72477
Min long fwd: 65864, max long fwd 73316; min long bwd 84274, max long bwd 89413
Time taken by simulation: 617 microseconds

Stages 8
13 3930501529.6000004
19 5322929356.799999
22 6014667161.6
23 6250707763.2
24 6479329689.6
Predicted microbatch size for 8: 24
comm size 12582912
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 11 0 214379.08935546875 663682.2411979454
End of simulation:  Mini-batch time (usec) = 12421079
Min send: 10000000, max send 0
Min long send: 663682, max long send 689782
Min fwd: 22992, max fwd 37161; min bwd 37517, max bwd 55449
Min long fwd: 51419, max long fwd 57045; min long bwd 68935, max long bwd 77274
Time taken by simulation: 1037 microseconds

Stages 12
13 3141742080.0
19 4248100352.0
22 4798114099.200001
23 4985794867.2
24 5168154112.0
Predicted microbatch size for 12: 24
comm size 12582912
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 22 0 97192.52014160156 663682.2411979454
End of simulation:  Mini-batch time (usec) = 21189724
Min send: 10000000, max send 0
Min long send: 663682, max long send 690844
Min fwd: 10724, max fwd 28920; min bwd 23319, max bwd 41964
Min long fwd: 40826, max long fwd 50474; min long bwd 49192, max long bwd 58811
Time taken by simulation: 3416 microseconds

{1: 4.450032, 2: 3.366713, 3: 4.994037, 4: 6.314108, 6: 9.164548, 8: 12.421079, 12: 21.189724}
{1: 8, 2: 19, 3: 24, 4: 24, 6: 24, 8: 24, 12: 24}
best config is: 2 19
expected time is 3.366713
16 per stage
32 servers!
Config:
ranks: range(19, 20)
train batch size: 1024
partitions: 2
chunk_size: 19
data depth: 16
stage to rank map: 0,2,4,6,8,10,12,14,16,18,20,22,24,26,28,30;1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31;
World size is 32
/opt/conda/envs/varuna/bin/python -u /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --rank=19 --chunk_size=19 --local_rank=0 --stage_to_rank_map=0,2,4,6,8,10,12,14,16,18,20,22,24,26,28,30;1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31; --batch-size=64 --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna --resume_step 144
device: cuda:0 n_gpu: 1, distributed training: True, 16-bits training: True
dry run time 0.15943336486816406
SHARED WEIGHTS ARE
[(0, 1)]
this rank  19 is part of pipeline replica  9
4 chunks
Begin to load checkpint from s3://spot-checkpoints/bert/ckpt_144.pt
2022-11-24 14:00:52.814461 resume step from  144
2022-11-24 14:01:46.367560 - Finished loading checkpoint, takes 53.375 secs
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  524288.0
[2022-11-24 14:02:26.490584] Finished iteration 144, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5710.294
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  262144.0
[2022-11-24 14:02:29.717096] Finished iteration 145, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3226.294
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  131072.0
[2022-11-24 14:02:32.850006] Finished iteration 146, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3132.859
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  65536.0
[2022-11-24 14:02:35.992507] Finished iteration 147, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3142.457
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  32768.0
[2022-11-24 14:02:39.102377] Finished iteration 148, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3109.900
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  16384.0
[2022-11-24 14:02:41.201494] Finished iteration 149, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2098.971
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  8192.0
[2022-11-24 14:02:43.337003] Finished iteration 150, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2135.459
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  4096.0
[2022-11-24 14:02:45.390191] Finished iteration 151, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2053.205
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  2048.0
[2022-11-24 14:02:47.491501] Finished iteration 152, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2101.226
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1024.0
[2022-11-24 14:02:49.609192] Finished iteration 153, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2117.653
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  512.0
[2022-11-24 14:02:51.709092] Finished iteration 154, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2099.885
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  256.0
[2022-11-24 14:02:53.787049] Finished iteration 155, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2077.926
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  128.0
[2022-11-24 14:02:55.939685] Finished iteration 156, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2152.598
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  64.0
[2022-11-24 14:02:58.044765] Finished iteration 157, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2105.044
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  32.0
[2022-11-24 14:03:00.148972] Finished iteration 158, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2104.181
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  16.0
[2022-11-24 14:03:02.263336] Finished iteration 159, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2114.330
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  8.0
[2022-11-24 14:03:04.355465] Finished iteration 160, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2092.096
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  4.0
[2022-11-24 14:03:06.508685] Finished iteration 161, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2153.182
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  2.0
[2022-11-24 14:03:08.602712] Finished iteration 162, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2093.996
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:11.889087] Finished iteration 163, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3286.342
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:14.007102] Finished iteration 164, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2117.982
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:16.135184] Finished iteration 165, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2128.046
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:18.235807] Finished iteration 166, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2100.591
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:20.377509] Finished iteration 167, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2141.693
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:22.445046] Finished iteration 168, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2067.485
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:24.591025] Finished iteration 169, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2145.952
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:26.737371] Finished iteration 170, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2146.297
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:28.899136] Finished iteration 171, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2161.740
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:31.041576] Finished iteration 172, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2142.403
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:33.202346] Finished iteration 173, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2160.769
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:35.286940] Finished iteration 174, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2084.523
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:37.402611] Finished iteration 175, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2115.637
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:39.479177] Finished iteration 176, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2076.541
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:41.593132] Finished iteration 177, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2113.922
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:43.755378] Finished iteration 178, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2162.211
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:45.955349] Finished iteration 179, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2199.938
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:48.050593] Finished iteration 180, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2095.209
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:50.180799] Finished iteration 181, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2130.174
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:52.295620] Finished iteration 182, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2114.792
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:54.411425] Finished iteration 183, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2115.771
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:56.556859] Finished iteration 184, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2145.394
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:58.643890] Finished iteration 185, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2087.011
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:00.756031] Finished iteration 186, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2112.124
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:02.904340] Finished iteration 187, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2148.280
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:04.988995] Finished iteration 188, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2084.625
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:07.124037] Finished iteration 189, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2134.988
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:09.251735] Finished iteration 190, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2127.666
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:11.354149] Finished iteration 191, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2102.379
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:13.487633] Finished iteration 192, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2133.450
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:15.598259] Finished iteration 193, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2110.631
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:17.698739] Finished iteration 194, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2100.414
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:19.828083] Finished iteration 195, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2129.318
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:21.956760] Finished iteration 196, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2128.678
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:24.113515] Finished iteration 197, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2156.692
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:26.181962] Finished iteration 198, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2068.413
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:28.231690] Finished iteration 199, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2049.691
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:30.357282] Finished iteration 200, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2125.567
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:32.472302] Finished iteration 201, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2114.996
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:34.592058] Finished iteration 202, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2119.733
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:36.706182] Finished iteration 203, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2114.099
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:38.818379] Finished iteration 204, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2112.149
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:41.278682] Finished iteration 205, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2460.275
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:43.729048] Finished iteration 206, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2450.329
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:45.869375] Finished iteration 207, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2140.296
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:49.107394] Finished iteration 208, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3237.988
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:51.568283] Finished iteration 209, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2460.827
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:53.753370] Finished iteration 210, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2185.060
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:55.856107] Finished iteration 211, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2102.708
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:57.915768] Finished iteration 212, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2059.626
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:00.059668] Finished iteration 213, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2143.883
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:02.199542] Finished iteration 214, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2139.857
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:04.276822] Finished iteration 215, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2077.219
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:06.411602] Finished iteration 216, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2134.756
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:08.543803] Finished iteration 217, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2132.166
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:10.633099] Finished iteration 218, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2089.263
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:12.761343] Finished iteration 219, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2128.216
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:14.890063] Finished iteration 220, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2128.694
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:16.967290] Finished iteration 221, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2077.212
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:19.084526] Finished iteration 222, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2117.171
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:21.199001] Finished iteration 223, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2114.431
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:23.322629] Finished iteration 224, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2123.601
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:25.455995] Finished iteration 225, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2133.340
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:27.576019] Finished iteration 226, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2119.978
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:29.674021] Finished iteration 227, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2097.967
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:31.832669] Finished iteration 228, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2158.613
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:33.997374] Finished iteration 229, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2164.673
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:36.151825] Finished iteration 230, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2154.421
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:38.254048] Finished iteration 231, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2102.189
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:40.369903] Finished iteration 232, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2115.819
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:42.484798] Finished iteration 233, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2114.874
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:44.597144] Finished iteration 234, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2112.333
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:46.747159] Finished iteration 235, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2149.970
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:48.841240] Finished iteration 236, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2094.065
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:50.953648] Finished iteration 237, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2112.355
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:53.033026] Finished iteration 238, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2079.344
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:55.132233] Finished iteration 239, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2099.200
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:57.224804] Finished iteration 240, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2092.514
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:00.134489] Finished iteration 241, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2909.657
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:02.247725] Finished iteration 242, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2113.204
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:04.373275] Finished iteration 243, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2125.532
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:06.469245] Finished iteration 244, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2095.919
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:08.570771] Finished iteration 245, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2101.490
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:10.730797] Finished iteration 246, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2160.007
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:12.786823] Finished iteration 247, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2056.010
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:14.890369] Finished iteration 248, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2103.523
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:17.012642] Finished iteration 249, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2122.207
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:19.118890] Finished iteration 250, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2106.217
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:21.219002] Finished iteration 251, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2100.221
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:23.340095] Finished iteration 252, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2120.900
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:25.428468] Finished iteration 253, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2088.341
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:27.535343] Finished iteration 254, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2106.839
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:29.640005] Finished iteration 255, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2104.633
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:31.761023] Finished iteration 256, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2120.995
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:33.950778] Finished iteration 257, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2189.709
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:36.047440] Finished iteration 258, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2096.628
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:38.099539] Finished iteration 259, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2052.078
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:40.173200] Finished iteration 260, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2073.620
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:42.338881] Finished iteration 261, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2165.655
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:44.436090] Finished iteration 262, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2097.172
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:46.529951] Finished iteration 263, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2093.827
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:48.624193] Finished iteration 264, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2094.209
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:50.765402] Finished iteration 265, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2141.180
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:52.907227] Finished iteration 266, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2141.789
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:55.001678] Finished iteration 267, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2094.419
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:57.069978] Finished iteration 268, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2068.272
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:59.209702] Finished iteration 269, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2139.691
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:07:01.335859] Finished iteration 270, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2126.136
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:07:03.424981] Finished iteration 271, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2089.075
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:07:05.553782] Finished iteration 272, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2128.772
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:07:07.620062] Finished iteration 273, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2066.249
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:07:09.661675] Finished iteration 274, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2041.572
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:07:11.776711] Finished iteration 275, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2115.008
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:07:13.952278] Finished iteration 276, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2175.532
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:07:16.758676] Finished iteration 277, CKPT_AND_STOP: False, flag: tensor([2], dtype=torch.int32), speed: 2806.385
2022-11-24 14:07:16.763319 Begin to save checkpont to s3://spot-checkpoints/bert and exit
Opt ckpt time 3.7894961833953857
Process done with return code 0
Parent process ID: 15780 node: 172.31.30.133
24 cutpoints
Stages 1
13 20868437708.800007
7 13915698585.599995
10 17153729331.199993
8 14622140211.200005
9 15846820659.199995
Predicted microbatch size for 1: 8
comm size 0
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 1 5 0 1286522.0947265625 0
End of simulation:  Mini-batch time (usec) = 2905085
Min send: 10000000, max send 0
Min long send: 10000000, max long send 0
Min fwd: 10000000, max fwd 0; min bwd 10000000, max bwd 0
Min long fwd: 126283, max long fwd 129698; min long bwd 193190, max long bwd 199310
Time taken by simulation: 51 microseconds

Stages 2
13 10987980083.2
19 14996390399.999996
22 16963644723.199997
20 15631126630.400002
Predicted microbatch size for 2: 19
comm size 9961472
WARNING: no send time found, 2 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 2 4 0 638222.2290039062 542254.6839368516
End of simulation:  Mini-batch time (usec) = 3331662
Min send: 10000000, max send 0
Min long send: 542586, max long send 555338
Min fwd: 107744, max fwd 113936; min bwd 155753, max bwd 158782
Min long fwd: 131842, max long fwd 138676; min long bwd 169332, max long bwd 173300
Time taken by simulation: 95 microseconds

Stages 3
13 7832942284.800001
19 10697074380.8
22 12097432473.599998
23 12575272243.2
24 13035207577.6
Predicted microbatch size for 3: 24
comm size 12582912
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 5 0 448996.58203125 663682.2411979454
End of simulation:  Mini-batch time (usec) = 4994037
Min send: 10000000, max send 0
Min long send: 664014, max long send 679713
Min fwd: 72258, max fwd 88035; min bwd 119079, max bwd 130804
Min long fwd: 107414, max long fwd 112703; min long bwd 150032, max long bwd 153679
Time taken by simulation: 175 microseconds

Stages 4
13 6255423385.6
19 8547416371.2
22 9664326348.8
23 10045446451.2
24 10412856422.4
Predicted microbatch size for 4: 24
comm size 12582912
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 7 0 358221.00830078125 663682.2411979454
End of simulation:  Mini-batch time (usec) = 6464795
Min send: 10000000, max send 0
Min long send: 663870, max long send 683729
Min fwd: 53924, max fwd 67812; min bwd 83975, max bwd 97299
Min long fwd: 86081, max long fwd 91318; min long bwd 118237, max long bwd 121834
Time taken by simulation: 316 microseconds

Stages 6
13 4698582732.8
19 6397758361.599999
22 7231220224.0
23 7515620659.2
24 7790505267.2
Predicted microbatch size for 6: 24
comm size 12582912
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 9 0 241996.6583251953 663682.2411979454
End of simulation:  Mini-batch time (usec) = 9164548
Min send: 10000000, max send 0
Min long send: 663736, max long send 687371
Min fwd: 33746, max fwd 47347; min bwd 54554, max bwd 72477
Min long fwd: 65864, max long fwd 73316; min long bwd 84274, max long bwd 89413
Time taken by simulation: 627 microseconds

Stages 8
13 3930501529.6000004
19 5322929356.799999
22 6014667161.6
23 6250707763.2
24 6479329689.6
Predicted microbatch size for 8: 24
comm size 12582912
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 15 0 176039.7491455078 663682.2411979454
End of simulation:  Mini-batch time (usec) = 13724566
Min send: 10000000, max send 0
Min long send: 663736, max long send 690844
Min fwd: 22801, max fwd 38139; min bwd 36151, max bwd 55503
Min long fwd: 51106, max long fwd 59884; min long bwd 68124, max long bwd 75476
Time taken by simulation: 1460 microseconds

Stages 12
13 3141742080.0
19 4248100352.0
22 4798114099.200001
23 4985794867.2
24 5168154112.0
Predicted microbatch size for 12: 24
comm size 12582912
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 22 0 97192.52014160156 663682.2411979454
End of simulation:  Mini-batch time (usec) = 21189724
Min send: 10000000, max send 0
Min long send: 663682, max long send 690844
Min fwd: 10724, max fwd 28920; min bwd 23319, max bwd 41964
Min long fwd: 40826, max long fwd 50474; min long bwd 49192, max long bwd 58811
Time taken by simulation: 3465 microseconds

{1: 2.905085, 2: 3.331662, 3: 4.994037, 4: 6.464795, 6: 9.164548, 8: 13.724566, 12: 21.189724}
{1: 8, 2: 19, 3: 24, 4: 24, 6: 24, 8: 24, 12: 24}
best config is: 2 19
expected time is 3.331662
15 per stage
30 servers!
Config:
ranks: range(19, 20)
train batch size: 1024
partitions: 2
chunk_size: 19
data depth: 15
stage to rank map: 0,2,4,6,8,10,12,14,16,18,20,22,24,26,28;1,3,5,7,9,11,13,15,17,19,21,23,25,27,29;
World size is 30
/opt/conda/envs/varuna/bin/python -u /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --rank=19 --chunk_size=19 --local_rank=0 --stage_to_rank_map=0,2,4,6,8,10,12,14,16,18,20,22,24,26,28;1,3,5,7,9,11,13,15,17,19,21,23,25,27,29; --batch-size=68 --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna --resume_step 278
device: cuda:0 n_gpu: 1, distributed training: True, 16-bits training: True
dry run time 0.1300642490386963
SHARED WEIGHTS ARE
[(0, 1)]
this rank  19 is part of pipeline replica  9
4 chunks
Begin to load checkpint from s3://spot-checkpoints/bert/ckpt_278.pt
2022-11-24 14:08:27.239680 resume step from  278
2022-11-24 14:09:28.594481 - Finished loading checkpoint, takes 61.222 secs
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 19 signal handler called with signal 10
Process done with return code 1
Parent process ID: 16732 node: 172.31.23.137
24 cutpoints
Stages 1
13 20868437708.800007
7 13915698585.599995
10 17153729331.199993
8 14622140211.200005
9 15846820659.199995
Predicted microbatch size for 1: 8
comm size 0
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 1 5 0 1286522.0947265625 0
End of simulation:  Mini-batch time (usec) = 2905085
Min send: 10000000, max send 0
Min long send: 10000000, max long send 0
Min fwd: 10000000, max fwd 0; min bwd 10000000, max bwd 0
Min long fwd: 126283, max long fwd 129698; min long bwd 193190, max long bwd 199310
Time taken by simulation: 50 microseconds

Stages 2
13 10987980083.2
19 14996390399.999996
22 16963644723.199997
20 15631126630.400002
Predicted microbatch size for 2: 19
comm size 9961472
WARNING: no send time found, 2 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 2 4 0 638222.2290039062 542254.6839368516
End of simulation:  Mini-batch time (usec) = 3331662
Min send: 10000000, max send 0
Min long send: 542586, max long send 555338
Min fwd: 107744, max fwd 113936; min bwd 155753, max bwd 158782
Min long fwd: 131842, max long fwd 138676; min long bwd 169332, max long bwd 173300
Time taken by simulation: 103 microseconds

Stages 3
13 7832942284.800001
19 10697074380.8
22 12097432473.599998
23 12575272243.2
24 13035207577.6
Predicted microbatch size for 3: 24
comm size 12582912
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 5 0 448996.58203125 663682.2411979454
End of simulation:  Mini-batch time (usec) = 4994037
Min send: 10000000, max send 0
Min long send: 664014, max long send 679713
Min fwd: 72258, max fwd 88035; min bwd 119079, max bwd 130804
Min long fwd: 107414, max long fwd 112703; min long bwd 150032, max long bwd 153679
Time taken by simulation: 174 microseconds

Stages 4
13 6255423385.6
19 8547416371.2
22 9664326348.8
23 10045446451.2
24 10412856422.4
Predicted microbatch size for 4: 24
comm size 12582912
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 7 0 358221.00830078125 663682.2411979454
End of simulation:  Mini-batch time (usec) = 6464795
Min send: 10000000, max send 0
Min long send: 663870, max long send 683729
Min fwd: 53924, max fwd 67812; min bwd 83975, max bwd 97299
Min long fwd: 86081, max long fwd 91318; min long bwd 118237, max long bwd 121834
Time taken by simulation: 312 microseconds

Stages 6
13 4698582732.8
19 6397758361.599999
22 7231220224.0
23 7515620659.2
24 7790505267.2
Predicted microbatch size for 6: 24
comm size 12582912
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 9 0 241996.6583251953 663682.2411979454
End of simulation:  Mini-batch time (usec) = 9164548
Min send: 10000000, max send 0
Min long send: 663736, max long send 687371
Min fwd: 33746, max fwd 47347; min bwd 54554, max bwd 72477
Min long fwd: 65864, max long fwd 73316; min long bwd 84274, max long bwd 89413
Time taken by simulation: 624 microseconds

Stages 8
13 3930501529.6000004
19 5322929356.799999
22 6014667161.6
23 6250707763.2
24 6479329689.6
Predicted microbatch size for 8: 24
comm size 12582912
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 15 0 176039.7491455078 663682.2411979454
End of simulation:  Mini-batch time (usec) = 13724566
Min send: 10000000, max send 0
Min long send: 663736, max long send 690844
Min fwd: 22801, max fwd 38139; min bwd 36151, max bwd 55503
Min long fwd: 51106, max long fwd 59884; min long bwd 68124, max long bwd 75476
Time taken by simulation: 1463 microseconds

Stages 12
13 3141742080.0
19 4248100352.0
22 4798114099.200001
23 4985794867.2
24 5168154112.0
Predicted microbatch size for 12: 24
comm size 12582912
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 22 0 97192.52014160156 663682.2411979454
End of simulation:  Mini-batch time (usec) = 21189724
Min send: 10000000, max send 0
Min long send: 663682, max long send 690844
Min fwd: 10724, max fwd 28920; min bwd 23319, max bwd 41964
Min long fwd: 40826, max long fwd 50474; min long bwd 49192, max long bwd 58811
Time taken by simulation: 3410 microseconds

{1: 2.905085, 2: 3.331662, 3: 4.994037, 4: 6.464795, 6: 9.164548, 8: 13.724566, 12: 21.189724}
{1: 8, 2: 19, 3: 24, 4: 24, 6: 24, 8: 24, 12: 24}
best config is: 2 19
expected time is 3.331662
15 per stage
30 servers!
Config:
ranks: range(19, 20)
train batch size: 1024
partitions: 2
chunk_size: 19
data depth: 15
stage to rank map: 0,2,4,6,8,10,12,14,16,18,20,22,24,26,28;1,3,5,7,9,11,13,15,17,19,21,23,25,27,29;
World size is 30
/opt/conda/envs/varuna/bin/python -u /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --rank=19 --chunk_size=19 --local_rank=0 --stage_to_rank_map=0,2,4,6,8,10,12,14,16,18,20,22,24,26,28;1,3,5,7,9,11,13,15,17,19,21,23,25,27,29; --batch-size=68 --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna --resume_step 278
device: cuda:0 n_gpu: 1, distributed training: True, 16-bits training: True
dry run time 0.1660633087158203
SHARED WEIGHTS ARE
[(0, 1)]
this rank  19 is part of pipeline replica  9
4 chunks
Begin to load checkpint from s3://spot-checkpoints/bert/ckpt_278.pt
2022-11-24 14:10:37.942092 resume step from  278
2022-11-24 14:11:47.564408 - Finished loading checkpoint, takes 69.498 secs
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  524288.0
[2022-11-24 14:12:03.153841] Finished iteration 278, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4742.193
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  262144.0
[2022-11-24 14:12:06.359586] Finished iteration 279, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3205.314
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  131072.0
[2022-11-24 14:12:09.536935] Finished iteration 280, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3177.076
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  65536.0
[2022-11-24 14:12:12.677079] Finished iteration 281, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3140.166
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  32768.0
[2022-11-24 14:12:16.115557] Finished iteration 282, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3438.413
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  16384.0
[2022-11-24 14:12:18.254943] Finished iteration 283, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2139.301
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  8192.0
[2022-11-24 14:12:20.398008] Finished iteration 284, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2143.036
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  4096.0
[2022-11-24 14:12:22.521253] Finished iteration 285, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2123.404
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  2048.0
[2022-11-24 14:12:24.631816] Finished iteration 286, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2110.459
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1024.0
[2022-11-24 14:12:26.721121] Finished iteration 287, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2089.114
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  512.0
[2022-11-24 14:12:28.846831] Finished iteration 288, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2125.822
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  256.0
[2022-11-24 14:12:30.955531] Finished iteration 289, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2108.629
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  128.0
[2022-11-24 14:12:33.121416] Finished iteration 290, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2165.700
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  64.0
[2022-11-24 14:12:35.258553] Finished iteration 291, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2137.137
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  32.0
[2022-11-24 14:12:37.397401] Finished iteration 292, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2138.795
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  16.0
[2022-11-24 14:12:39.492086] Finished iteration 293, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2094.655
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  8.0
[2022-11-24 14:12:41.580090] Finished iteration 294, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2087.991
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  4.0
[2022-11-24 14:12:43.732523] Finished iteration 295, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2152.401
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  2.0
[2022-11-24 14:12:45.875606] Finished iteration 296, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2143.050
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:12:47.975042] Finished iteration 297, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2099.528
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:12:50.111812] Finished iteration 298, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2136.595
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:12:52.260435] Finished iteration 299, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2148.594
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:12:54.431978] Finished iteration 300, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2171.658
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:12:56.558735] Finished iteration 301, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2126.575
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:12:58.731491] Finished iteration 302, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2172.724
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:00.848272] Finished iteration 303, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2116.741
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:03.002163] Finished iteration 304, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2154.049
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:05.143488] Finished iteration 305, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2141.245
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:07.617612] Finished iteration 306, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2474.066
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:10.006516] Finished iteration 307, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2388.710
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:12.156999] Finished iteration 308, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2150.590
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:14.271639] Finished iteration 309, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2114.770
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:16.431625] Finished iteration 310, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2159.731
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:18.551781] Finished iteration 311, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2120.002
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:20.682685] Finished iteration 312, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2130.868
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:22.795594] Finished iteration 313, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2112.879
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:24.956341] Finished iteration 314, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2160.744
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:27.093871] Finished iteration 315, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2137.589
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:29.283894] Finished iteration 316, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2189.864
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:31.382008] Finished iteration 317, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2098.236
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:33.513926] Finished iteration 318, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2131.847
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:35.774535] Finished iteration 319, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2260.493
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:37.928035] Finished iteration 320, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2153.474
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:40.072884] Finished iteration 321, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2144.642
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:42.229200] Finished iteration 322, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2156.276
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:44.366282] Finished iteration 323, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2137.212
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:46.491508] Finished iteration 324, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2125.009
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:48.746401] Finished iteration 325, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2254.873
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:50.869175] Finished iteration 326, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2122.740
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:53.717701] Finished iteration 327, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2848.488
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:55.849909] Finished iteration 328, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2132.203
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:58.034510] Finished iteration 329, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2184.681
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:00.142734] Finished iteration 330, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2108.037
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:02.237851] Finished iteration 331, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2095.086
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:04.394166] Finished iteration 332, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2156.324
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:06.515367] Finished iteration 333, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2121.125
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:08.636318] Finished iteration 334, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2121.050
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:10.767424] Finished iteration 335, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2131.052
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:12.888004] Finished iteration 336, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2120.384
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:15.024751] Finished iteration 337, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2136.865
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:17.188776] Finished iteration 338, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2163.970
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:19.317532] Finished iteration 339, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2128.752
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:21.432521] Finished iteration 340, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2114.950
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:23.595146] Finished iteration 341, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2162.567
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:25.752322] Finished iteration 342, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2157.135
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:27.890196] Finished iteration 343, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2137.845
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:30.033115] Finished iteration 344, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2142.807
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:32.181590] Finished iteration 345, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2148.441
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:34.318144] Finished iteration 346, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2136.527
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:36.416509] Finished iteration 347, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2098.164
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:38.596180] Finished iteration 348, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2179.641
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:40.705331] Finished iteration 349, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2109.246
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:42.900652] Finished iteration 350, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2195.125
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:45.033272] Finished iteration 351, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2132.716
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:47.163431] Finished iteration 352, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2130.107
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:49.263481] Finished iteration 353, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2099.887
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:51.411561] Finished iteration 354, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2148.166
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:53.605638] Finished iteration 355, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2194.014
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:55.726950] Finished iteration 356, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2121.125
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:57.843394] Finished iteration 357, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2116.546
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:59.951054] Finished iteration 358, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2107.498
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:02.083788] Finished iteration 359, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2132.689
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:04.205373] Finished iteration 360, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2121.542
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:06.370228] Finished iteration 361, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2164.853
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:08.532350] Finished iteration 362, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2162.068
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:10.687677] Finished iteration 363, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2155.284
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:12.883848] Finished iteration 364, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2196.282
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:14.999394] Finished iteration 365, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2115.359
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:17.106248] Finished iteration 366, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2106.872
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:19.273502] Finished iteration 367, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2167.217
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:21.392222] Finished iteration 368, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2118.794
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:23.544673] Finished iteration 369, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2152.263
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:25.704453] Finished iteration 370, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2159.907
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:27.855337] Finished iteration 371, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2150.782
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:29.967168] Finished iteration 372, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2111.798
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:32.105558] Finished iteration 373, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2138.163
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:34.268042] Finished iteration 374, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2162.466
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:36.392459] Finished iteration 375, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2124.516
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:38.515436] Finished iteration 376, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2122.787
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:40.697336] Finished iteration 377, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2181.995
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:42.815414] Finished iteration 378, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2118.076
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:44.956453] Finished iteration 379, CKPT_AND_STOP: False, flag: tensor([1], dtype=torch.int32), speed: 2140.805
2022-11-24 14:15:44.961125 Begin to save checkpont to s3://spot-checkpoints/bert and exit
Opt ckpt time 3.364748954772949
Process done with return code 0
Parent process ID: 18440 node: 172.31.23.137
24 cutpoints
Stages 1
13 20868437708.800007
7 13915698585.599995
10 17153729331.199993
8 14622140211.200005
9 15846820659.199995
Predicted microbatch size for 1: 8
comm size 0
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 1 5 0 1286522.0947265625 0
End of simulation:  Mini-batch time (usec) = 2905085
Min send: 10000000, max send 0
Min long send: 10000000, max long send 0
Min fwd: 10000000, max fwd 0; min bwd 10000000, max bwd 0
Min long fwd: 126283, max long fwd 129698; min long bwd 193190, max long bwd 199310
Time taken by simulation: 56 microseconds

Stages 2
13 10987980083.2
19 14996390399.999996
22 16963644723.199997
20 15631126630.400002
Predicted microbatch size for 2: 19
comm size 9961472
WARNING: no send time found, 2 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 2 4 0 638222.2290039062 542254.6839368516
End of simulation:  Mini-batch time (usec) = 3331662
Min send: 10000000, max send 0
Min long send: 542586, max long send 555338
Min fwd: 107744, max fwd 113936; min bwd 155753, max bwd 158782
Min long fwd: 131842, max long fwd 138676; min long bwd 169332, max long bwd 173300
Time taken by simulation: 102 microseconds

Stages 3
13 7832942284.800001
19 10697074380.8
22 12097432473.599998
23 12575272243.2
24 13035207577.6
Predicted microbatch size for 3: 24
comm size 12582912
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 5 0 448996.58203125 663682.2411979454
End of simulation:  Mini-batch time (usec) = 4994037
Min send: 10000000, max send 0
Min long send: 664014, max long send 679713
Min fwd: 72258, max fwd 88035; min bwd 119079, max bwd 130804
Min long fwd: 107414, max long fwd 112703; min long bwd 150032, max long bwd 153679
Time taken by simulation: 173 microseconds

Stages 4
13 6255423385.6
19 8547416371.2
22 9664326348.8
23 10045446451.2
24 10412856422.4
Predicted microbatch size for 4: 24
comm size 12582912
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 7 0 358221.00830078125 663682.2411979454
End of simulation:  Mini-batch time (usec) = 6464795
Min send: 10000000, max send 0
Min long send: 663870, max long send 683729
Min fwd: 53924, max fwd 67812; min bwd 83975, max bwd 97299
Min long fwd: 86081, max long fwd 91318; min long bwd 118237, max long bwd 121834
Time taken by simulation: 319 microseconds

Stages 6
13 4698582732.8
19 6397758361.599999
22 7231220224.0
23 7515620659.2
24 7790505267.2
Predicted microbatch size for 6: 24
comm size 12582912
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 9 0 241996.6583251953 663682.2411979454
End of simulation:  Mini-batch time (usec) = 9164548
Min send: 10000000, max send 0
Min long send: 663736, max long send 687371
Min fwd: 33746, max fwd 47347; min bwd 54554, max bwd 72477
Min long fwd: 65864, max long fwd 73316; min long bwd 84274, max long bwd 89413
Time taken by simulation: 663 microseconds

Stages 8
13 3930501529.6000004
19 5322929356.799999
22 6014667161.6
23 6250707763.2
24 6479329689.6
Predicted microbatch size for 8: 24
comm size 12582912
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 15 0 176039.7491455078 663682.2411979454
End of simulation:  Mini-batch time (usec) = 13724566
Min send: 10000000, max send 0
Min long send: 663736, max long send 690844
Min fwd: 22801, max fwd 38139; min bwd 36151, max bwd 55503
Min long fwd: 51106, max long fwd 59884; min long bwd 68124, max long bwd 75476
Time taken by simulation: 1455 microseconds

Stages 12
13 3141742080.0
19 4248100352.0
22 4798114099.200001
23 4985794867.2
24 5168154112.0
Predicted microbatch size for 12: 24
comm size 12582912
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 22 0 97192.52014160156 663682.2411979454
End of simulation:  Mini-batch time (usec) = 21189724
Min send: 10000000, max send 0
Min long send: 663682, max long send 690844
Min fwd: 10724, max fwd 28920; min bwd 23319, max bwd 41964
Min long fwd: 40826, max long fwd 50474; min long bwd 49192, max long bwd 58811
Time taken by simulation: 3533 microseconds

{1: 2.905085, 2: 3.331662, 3: 4.994037, 4: 6.464795, 6: 9.164548, 8: 13.724566, 12: 21.189724}
{1: 8, 2: 19, 3: 24, 4: 24, 6: 24, 8: 24, 12: 24}
best config is: 2 19
expected time is 3.331662
15 per stage
30 servers!
Config:
ranks: range(19, 20)
train batch size: 1024
partitions: 2
chunk_size: 19
data depth: 15
stage to rank map: 0,2,4,6,8,10,12,14,16,18,20,22,24,26,28;1,3,5,7,9,11,13,15,17,19,21,23,25,27,29;
World size is 30
/opt/conda/envs/varuna/bin/python -u /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --rank=19 --chunk_size=19 --local_rank=0 --stage_to_rank_map=0,2,4,6,8,10,12,14,16,18,20,22,24,26,28;1,3,5,7,9,11,13,15,17,19,21,23,25,27,29; --batch-size=68 --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna --resume_step 380
device: cuda:0 n_gpu: 1, distributed training: True, 16-bits training: True
dry run time 1.2440993785858154
SHARED WEIGHTS ARE
[(0, 1)]
this rank  19 is part of pipeline replica  9
4 chunks
Begin to load checkpint from s3://spot-checkpoints/bert/ckpt_380.pt
2022-11-24 14:16:27.088005 resume step from  380
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 19 signal handler called with signal 10
2022-11-24 14:17:38.363055 - Finished loading checkpoint, takes 66.327 secs
2022-11-24 14:17:54.289844 Begin to exit
Process done with return code 0
Parent process ID: 19828 node: 172.31.23.137
24 cutpoints
Stages 1
13 20868437708.800007
7 13915698585.599995
10 17153729331.199993
8 14622140211.200005
9 15846820659.199995
Predicted microbatch size for 1: 8
comm size 0
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 1 4 0 3150942.3828125 0
End of simulation:  Mini-batch time (usec) = 4450032
Min send: 10000000, max send 0
Min long send: 10000000, max long send 0
Min fwd: 10000000, max fwd 0; min bwd 10000000, max bwd 0
Min long fwd: 127414, max long fwd 129698; min long bwd 194806, max long bwd 199310
Time taken by simulation: 47 microseconds

Stages 2
13 10987980083.2
19 14996390399.999996
22 16963644723.199997
20 15631126630.400002
Predicted microbatch size for 2: 19
comm size 9961472
WARNING: no send time found, 2 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 2 4 0 673273.3154296875 542254.6839368516
End of simulation:  Mini-batch time (usec) = 3366713
Min send: 10000000, max send 0
Min long send: 542586, max long send 555338
Min fwd: 107744, max fwd 113936; min bwd 155753, max bwd 158782
Min long fwd: 131842, max long fwd 138676; min long bwd 169332, max long bwd 173300
Time taken by simulation: 97 microseconds

Stages 3
13 7832942284.800001
19 10697074380.8
22 12097432473.599998
23 12575272243.2
24 13035207577.6
Predicted microbatch size for 3: 24
comm size 12582912
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 5 0 448996.58203125 663682.2411979454
End of simulation:  Mini-batch time (usec) = 4994037
Min send: 10000000, max send 0
Min long send: 664014, max long send 679713
Min fwd: 72258, max fwd 88035; min bwd 119079, max bwd 130804
Min long fwd: 107414, max long fwd 112703; min long bwd 150032, max long bwd 153679
Time taken by simulation: 172 microseconds

Stages 4
13 6255423385.6
19 8547416371.2
22 9664326348.8
23 10045446451.2
24 10412856422.4
Predicted microbatch size for 4: 24
comm size 12582912
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 6 0 375752.13623046875 663682.2411979454
End of simulation:  Mini-batch time (usec) = 6314108
Min send: 10000000, max send 0
Min long send: 663764, max long send 688387
Min fwd: 53924, max fwd 66948; min bwd 83975, max bwd 98046
Min long fwd: 84759, max long fwd 91250; min long bwd 120659, max long bwd 125455
Time taken by simulation: 277 microseconds

Stages 6
13 4698582732.8
19 6397758361.599999
22 7231220224.0
23 7515620659.2
24 7790505267.2
Predicted microbatch size for 6: 24
comm size 12582912
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 9 0 241996.6583251953 663682.2411979454
End of simulation:  Mini-batch time (usec) = 9164548
Min send: 10000000, max send 0
Min long send: 663736, max long send 687371
Min fwd: 33746, max fwd 47347; min bwd 54554, max bwd 72477
Min long fwd: 65864, max long fwd 73316; min long bwd 84274, max long bwd 89413
Time taken by simulation: 655 microseconds

Stages 8
13 3930501529.6000004
19 5322929356.799999
22 6014667161.6
23 6250707763.2
24 6479329689.6
Predicted microbatch size for 8: 24
comm size 12582912
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 11 0 214379.08935546875 663682.2411979454
End of simulation:  Mini-batch time (usec) = 12421079
Min send: 10000000, max send 0
Min long send: 663682, max long send 689782
Min fwd: 22992, max fwd 37161; min bwd 37517, max bwd 55449
Min long fwd: 51419, max long fwd 57045; min long bwd 68935, max long bwd 77274
Time taken by simulation: 1168 microseconds

Stages 12
13 3141742080.0
19 4248100352.0
22 4798114099.200001
23 4985794867.2
24 5168154112.0
Predicted microbatch size for 12: 24
comm size 12582912
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 22 0 97192.52014160156 663682.2411979454
End of simulation:  Mini-batch time (usec) = 21189724
Min send: 10000000, max send 0
Min long send: 663682, max long send 690844
Min fwd: 10724, max fwd 28920; min bwd 23319, max bwd 41964
Min long fwd: 40826, max long fwd 50474; min long bwd 49192, max long bwd 58811
Time taken by simulation: 3379 microseconds

{1: 4.450032, 2: 3.366713, 3: 4.994037, 4: 6.314108, 6: 9.164548, 8: 12.421079, 12: 21.189724}
{1: 8, 2: 19, 3: 24, 4: 24, 6: 24, 8: 24, 12: 24}
best config is: 2 19
expected time is 3.366713
16 per stage
32 servers!
Config:
ranks: range(19, 20)
train batch size: 1024
partitions: 2
chunk_size: 19
data depth: 16
stage to rank map: 0,2,4,6,8,10,12,14,16,18,20,22,24,26,28,30;1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31;
World size is 32
/opt/conda/envs/varuna/bin/python -u /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --rank=19 --chunk_size=19 --local_rank=0 --stage_to_rank_map=0,2,4,6,8,10,12,14,16,18,20,22,24,26,28,30;1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31; --batch-size=64 --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna --resume_step 380
device: cuda:0 n_gpu: 1, distributed training: True, 16-bits training: True
dry run time 0.08092975616455078
SHARED WEIGHTS ARE
[(0, 1)]
this rank  19 is part of pipeline replica  9
4 chunks
Begin to load checkpint from s3://spot-checkpoints/bert/ckpt_380.pt
2022-11-24 14:18:15.798000 resume step from  380
2022-11-24 14:19:26.947792 - Finished loading checkpoint, takes 66.148 secs
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  524288.0
[2022-11-24 14:19:34.547450] Finished iteration 380, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5718.891
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  262144.0
[2022-11-24 14:19:37.741860] Finished iteration 381, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3194.043
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  131072.0
[2022-11-24 14:19:40.909726] Finished iteration 382, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3168.025
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  65536.0
[2022-11-24 14:19:44.059010] Finished iteration 383, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3149.050
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  32768.0
[2022-11-24 14:19:47.212609] Finished iteration 384, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3153.736
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  16384.0
[2022-11-24 14:19:49.554027] Finished iteration 385, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2341.141
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  8192.0
[2022-11-24 14:19:51.663511] Finished iteration 386, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2109.453
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  4096.0
[2022-11-24 14:19:53.812212] Finished iteration 387, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2148.698
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  2048.0
[2022-11-24 14:19:55.880309] Finished iteration 388, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2068.060
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1024.0
[2022-11-24 14:19:57.959831] Finished iteration 389, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2079.604
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  512.0
[2022-11-24 14:20:00.059369] Finished iteration 390, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2099.513
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  256.0
[2022-11-24 14:20:02.201558] Finished iteration 391, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2142.000
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  128.0
[2022-11-24 14:20:05.146257] Finished iteration 392, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2944.881
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  64.0
[2022-11-24 14:20:07.255864] Finished iteration 393, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2109.312
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  32.0
[2022-11-24 14:20:09.350073] Finished iteration 394, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2094.217
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  16.0
[2022-11-24 14:20:12.385940] Finished iteration 395, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3035.787
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  8.0
[2022-11-24 14:20:14.477262] Finished iteration 396, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2091.290
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  4.0
[2022-11-24 14:20:16.549196] Finished iteration 397, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2072.114
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  2.0
[2022-11-24 14:20:18.634168] Finished iteration 398, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2084.753
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:20.685084] Finished iteration 399, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2050.987
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:22.760167] Finished iteration 400, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2074.893
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:24.875687] Finished iteration 401, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2115.666
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:26.988810] Finished iteration 402, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2112.918
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:29.632909] Finished iteration 403, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2644.051
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:31.800615] Finished iteration 404, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2167.677
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:33.878081] Finished iteration 405, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2077.441
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:35.997440] Finished iteration 406, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2119.431
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:38.094066] Finished iteration 407, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2096.613
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:40.229043] Finished iteration 408, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2134.772
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:42.294486] Finished iteration 409, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2065.436
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:44.368938] Finished iteration 410, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2074.413
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:46.483875] Finished iteration 411, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2114.919
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:48.569137] Finished iteration 412, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2085.321
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:50.665231] Finished iteration 413, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2096.062
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:52.757536] Finished iteration 414, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2092.234
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:54.900904] Finished iteration 415, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2143.334
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:56.951644] Finished iteration 416, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2050.679
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:59.108687] Finished iteration 417, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2157.049
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:01.190432] Finished iteration 418, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2081.684
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:03.268893] Finished iteration 419, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2078.404
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:05.377093] Finished iteration 420, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2108.155
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:07.450273] Finished iteration 421, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2073.137
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:09.588095] Finished iteration 422, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2137.747
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:11.678484] Finished iteration 423, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2090.203
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:13.803806] Finished iteration 424, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2125.428
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:15.914272] Finished iteration 425, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2110.305
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:18.013312] Finished iteration 426, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2098.988
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:20.075166] Finished iteration 427, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2061.816
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:22.178918] Finished iteration 428, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2103.752
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:24.228505] Finished iteration 429, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2049.560
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:26.327426] Finished iteration 430, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2099.022
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:28.393201] Finished iteration 431, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2065.572
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:30.481136] Finished iteration 432, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2087.897
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:32.557473] Finished iteration 433, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2076.460
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:34.698648] Finished iteration 434, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2141.001
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:36.857879] Finished iteration 435, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2159.193
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:39.029530] Finished iteration 436, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2171.605
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:41.154825] Finished iteration 437, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2125.275
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:43.343221] Finished iteration 438, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2188.346
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:45.441880] Finished iteration 439, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2098.649
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:47.578934] Finished iteration 440, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2137.010
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:49.675652] Finished iteration 441, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2096.863
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:51.805404] Finished iteration 442, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2129.536
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:53.887804] Finished iteration 443, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2082.480
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:56.014125] Finished iteration 444, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2126.327
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:58.109757] Finished iteration 445, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2095.562
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:00.203843] Finished iteration 446, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2093.916
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:02.251930] Finished iteration 447, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2048.209
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:04.358943] Finished iteration 448, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2106.799
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:06.471142] Finished iteration 449, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2112.159
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:08.545332] Finished iteration 450, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2074.150
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:10.652519] Finished iteration 451, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2107.162
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:12.833539] Finished iteration 452, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2181.132
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:14.931543] Finished iteration 453, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2097.806
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:17.057661] Finished iteration 454, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2126.096
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:19.115858] Finished iteration 455, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2058.280
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:21.192360] Finished iteration 456, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2076.347
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:24.179140] Finished iteration 457, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2986.878
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:26.271991] Finished iteration 458, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2092.799
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:28.308557] Finished iteration 459, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2036.510
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:30.383097] Finished iteration 460, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2074.502
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:32.482031] Finished iteration 461, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2098.752
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:34.585472] Finished iteration 462, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2103.418
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:36.651306] Finished iteration 463, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2065.936
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:38.782336] Finished iteration 464, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2130.841
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:40.820401] Finished iteration 465, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2038.057
19 Overflow !!
19 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:42.940426] Finished iteration 466, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2120.100
Parent process ID: 16114 node: 172.31.30.89
Killing process on gpu with nvidia-smi | grep 'python' | awk '{ print $5 }' | xargs -n1 kill -9
24 cutpoints
Stages 1
13 20868437708.800007
7 13915698585.599995
10 17153729331.199993
8 14622140211.200005
9 15846820659.199995
Predicted microbatch size for 1: 8
comm size 0
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 1 6 0 1334585.0830078125 0
End of simulation:  Mini-batch time (usec) = 3270291
Min send: 10000000, max send 0
Min long send: 10000000, max long send 0
Min fwd: 10000000, max fwd 0; min bwd 10000000, max bwd 0
Min long fwd: 126112, max long fwd 129698; min long bwd 191031, max long bwd 199310
Time taken by simulation: 51 microseconds

Stages 2
13 10987980083.2
19 14996390399.999996
22 16963644723.199997
20 15631126630.400002
Predicted microbatch size for 2: 19
comm size 9961472
WARNING: no send time found, 2 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 2 5 0 608509.5825195312 542254.6839368516
End of simulation:  Mini-batch time (usec) = 3607863
Min send: 10000000, max send 0
Min long send: 542586, max long send 558986
Min fwd: 106816, max fwd 113936; min bwd 154625, max bwd 157669
Min long fwd: 134083, max long fwd 138081; min long bwd 169664, max long bwd 173713
Time taken by simulation: 112 microseconds

Stages 3
13 7832942284.800001
19 10697074380.8
22 12097432473.599998
23 12575272243.2
24 13035207577.6
Predicted microbatch size for 3: 24
comm size 12582912
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 7 0 441679.38232421875 663682.2411979454
End of simulation:  Mini-batch time (usec) = 5526356
Min send: 10000000, max send 0
Min long send: 664014, max long send 688387
Min fwd: 70473, max fwd 86449; min bwd 116125, max bwd 131549
Min long fwd: 107949, max long fwd 111566; min long bwd 147972, max long bwd 154852
Time taken by simulation: 231 microseconds

Stages 4
13 6255423385.6
19 8547416371.2
22 9664326348.8
23 10045446451.2
24 10412856422.4
Predicted microbatch size for 4: 24
comm size 12582912
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 9 0 322485.90087890625 663682.2411979454
End of simulation:  Mini-batch time (usec) = 6859347
Min send: 10000000, max send 0
Min long send: 663764, max long send 686148
Min fwd: 51765, max fwd 67812; min bwd 84974, max bwd 98885
Min long fwd: 83336, max long fwd 90554; min long bwd 118409, max long bwd 124254
Time taken by simulation: 408 microseconds

Stages 6
13 4698582732.8
19 6397758361.599999
22 7231220224.0
23 7515620659.2
24 7790505267.2
Predicted microbatch size for 6: 24
comm size 12582912
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 15 0 205807.43408203125 663682.2411979454
End of simulation:  Mini-batch time (usec) = 11152793
Min send: 10000000, max send 0
Min long send: 663736, max long send 688387
Min fwd: 32603, max fwd 47172; min bwd 54003, max bwd 69793
Min long fwd: 66617, max long fwd 70492; min long bwd 81618, max long bwd 89601
Time taken by simulation: 1064 microseconds

Stages 8
13 3930501529.6000004
19 5322929356.799999
22 6014667161.6
23 6250707763.2
24 6479329689.6
Predicted microbatch size for 8: 24
comm size 12582912
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 22 0 120660.06469726562 663682.2411979454
End of simulation:  Mini-batch time (usec) = 15792286
Min send: 10000000, max send 0
Min long send: 663682, max long send 690844
Min fwd: 23237, max fwd 38139; min bwd 35712, max bwd 56890
Min long fwd: 51613, max long fwd 57677; min long bwd 69478, max long bwd 76496
Time taken by simulation: 2260 microseconds

Stages 12
13 3141742080.0
19 4248100352.0
22 4798114099.200001
23 4985794867.2
24 5168154112.0
Predicted microbatch size for 12: 24
comm size 12582912
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 43 0 0 663682.2411979454
End of simulation:  Mini-batch time (usec) = 28245316
Min send: 10000000, max send 0
Min long send: 663682, max long send 693511
Min fwd: 10606, max fwd 31119; min bwd 22396, max bwd 41317
Min long fwd: 40838, max long fwd 49874; min long bwd 47936, max long bwd 55473
Time taken by simulation: 6885 microseconds

{1: 3.270291, 2: 3.607863, 3: 5.526356, 4: 6.859347, 6: 11.152793, 8: 15.792286, 12: 28.245316}
{1: 8, 2: 19, 3: 24, 4: 24, 6: 24, 8: 24, 12: 24}
best config is: 2 19
expected time is 3.607863
11 per stage
22 servers!
Config:
ranks: range(19, 20)
train batch size: 1024
partitions: 2
chunk_size: 19
data depth: 11
stage to rank map: 0,2,4,6,8,10,12,14,16,18,20;1,3,5,7,9,11,13,15,17,19,21;
World size is 22
/opt/conda/envs/varuna/bin/python -u /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --rank=19 --chunk_size=19 --local_rank=0 --stage_to_rank_map=0,2,4,6,8,10,12,14,16,18,20;1,3,5,7,9,11,13,15,17,19,21; --batch-size=93 --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna --resume_step 380
device: cuda:0 n_gpu: 1, distributed training: True, 16-bits training: True
dry run time 0.15129828453063965
SHARED WEIGHTS ARE
[(0, 1)]
this rank  19 is part of pipeline replica  9
5 chunks
Begin to load checkpint from s3://spot-checkpoints/bert/ckpt_380.pt
2022-11-24 14:32:07.078292 resume step from  380
