Traceback (most recent call last):
  File "/home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py", line 846, in <module>
    args, final_loss, train_time_raw, global_step = main()
  File "/home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py", line 644, in main
    dist.all_reduce(flag)
  File "/opt/conda/envs/varuna/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 1321, in all_reduce
    work.wait()
RuntimeError: [/opt/conda/conda-bld/pytorch_1646755888534/work/third_party/gloo/gloo/transport/tcp/pair.cc:598] Connection closed by peer [172.31.27.216]:60087
Traceback (most recent call last):
  File "/home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py", line 846, in <module>
    args, final_loss, train_time_raw, global_step = main()
  File "/home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py", line 727, in main
    loss, overflow, grad_norm = model.step(batch)
  File "/home/ubuntu/varuna/varuna/varuna.py", line 296, in step
    overflow, grad_norm = self.sync_across_workers(clip_grad_max_norm)
  File "/home/ubuntu/varuna/varuna/varuna.py", line 603, in sync_across_workers
    overflow_buf, global_grad_norm, reduced_loss = self.all_reduce_pipeline_meta(master_grads,
  File "/home/ubuntu/varuna/varuna/varuna.py", line 643, in all_reduce_pipeline_meta
    torch.distributed.all_reduce(allred_tensor, group=self.pipeline_group)
  File "/opt/conda/envs/varuna/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 1321, in all_reduce
    work.wait()
RuntimeError: [/opt/conda/conda-bld/pytorch_1646755888534/work/third_party/gloo/gloo/transport/tcp/pair.cc:598] Connection closed by peer [172.31.27.216]:46785
