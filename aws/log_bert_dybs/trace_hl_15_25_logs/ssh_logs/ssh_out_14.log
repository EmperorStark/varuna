Parent process ID: 16045 node: 172.31.21.109
24 cutpoints
Stages 1
13 20868437708.800007
7 13915698585.599995
10 17153729331.199993
8 14622140211.200005
9 15846820659.199995
Predicted microbatch size for 1: 8
comm size 0
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 1 5 0 1286522.0947265625 0
End of simulation:  Mini-batch time (usec) = 2905085
Min send: 10000000, max send 0
Min long send: 10000000, max long send 0
Min fwd: 10000000, max fwd 0; min bwd 10000000, max bwd 0
Min long fwd: 126283, max long fwd 129698; min long bwd 193190, max long bwd 199310
Time taken by simulation: 48 microseconds

Stages 2
13 10987980083.2
19 14996390399.999996
22 16963644723.199997
20 15631126630.400002
Predicted microbatch size for 2: 19
comm size 9961472
WARNING: no send time found, 2 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 2 5 0 635506.6528320312 542254.6839368516
End of simulation:  Mini-batch time (usec) = 3634860
Min send: 10000000, max send 0
Min long send: 542586, max long send 558986
Min fwd: 106816, max fwd 113936; min bwd 154625, max bwd 157669
Min long fwd: 134083, max long fwd 138081; min long bwd 169664, max long bwd 173713
Time taken by simulation: 115 microseconds

Stages 3
13 7832942284.800001
19 10697074380.8
22 12097432473.599998
23 12575272243.2
24 13035207577.6
Predicted microbatch size for 3: 24
comm size 12582912
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 5 0 443515.80810546875 663682.2411979454
End of simulation:  Mini-batch time (usec) = 4988556
Min send: 10000000, max send 0
Min long send: 664014, max long send 679713
Min fwd: 72258, max fwd 88035; min bwd 119079, max bwd 130804
Min long fwd: 107414, max long fwd 112703; min long bwd 150032, max long bwd 153679
Time taken by simulation: 167 microseconds

Stages 4
13 6255423385.6
19 8547416371.2
22 9664326348.8
23 10045446451.2
24 10412856422.4
Predicted microbatch size for 4: 24
comm size 12582912
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 8 0 326449.15771484375 663682.2411979454
End of simulation:  Mini-batch time (usec) = 6677364
Min send: 10000000, max send 0
Min long send: 663870, max long send 686148
Min fwd: 51765, max fwd 66948; min bwd 85303, max bwd 98547
Min long fwd: 83336, max long fwd 91250; min long bwd 118529, max long bwd 127083
Time taken by simulation: 403 microseconds

Stages 6
13 4698582732.8
19 6397758361.599999
22 7231220224.0
23 7515620659.2
24 7790505267.2
Predicted microbatch size for 6: 24
comm size 12582912
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 11 0 240705.6121826172 663682.2411979454
End of simulation:  Mini-batch time (usec) = 9735715
Min send: 10000000, max send 0
Min long send: 663764, max long send 689782
Min fwd: 32942, max fwd 48168; min bwd 55337, max bwd 68897
Min long fwd: 65982, max long fwd 73316; min long bwd 85277, max long bwd 90311
Time taken by simulation: 769 microseconds

Stages 8
13 3930501529.6000004
19 5322929356.799999
22 6014667161.6
23 6250707763.2
24 6479329689.6
Predicted microbatch size for 8: 24
comm size 12582912
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 15 0 176039.7491455078 663682.2411979454
End of simulation:  Mini-batch time (usec) = 13724566
Min send: 10000000, max send 0
Min long send: 663736, max long send 690844
Min fwd: 22801, max fwd 38139; min bwd 36151, max bwd 55503
Min long fwd: 51106, max long fwd 59884; min long bwd 68124, max long bwd 75476
Time taken by simulation: 1502 microseconds

Stages 12
13 3141742080.0
19 4248100352.0
22 4798114099.200001
23 4985794867.2
24 5168154112.0
Predicted microbatch size for 12: 24
comm size 12582912
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 22 0 97192.52014160156 663682.2411979454
End of simulation:  Mini-batch time (usec) = 21189724
Min send: 10000000, max send 0
Min long send: 663682, max long send 690844
Min fwd: 10724, max fwd 28920; min bwd 23319, max bwd 41964
Min long fwd: 40826, max long fwd 50474; min long bwd 49192, max long bwd 58811
Time taken by simulation: 3690 microseconds

{1: 2.905085, 2: 3.63486, 3: 4.988556, 4: 6.677364, 6: 9.735715, 8: 13.724566, 12: 21.189724}
{1: 8, 2: 19, 3: 24, 4: 24, 6: 24, 8: 24, 12: 24}
best config is: 2 19
expected time is 3.63486
13 per stage
26 servers!
Config:
ranks: range(14, 15)
train batch size: 1024
partitions: 2
chunk_size: 19
data depth: 13
stage to rank map: 0,2,4,6,8,10,12,14,16,18,20,22,24;1,3,5,7,9,11,13,15,17,19,21,23,25;
World size is 26
/opt/conda/envs/varuna/bin/python -u /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --rank=14 --chunk_size=19 --local_rank=0 --stage_to_rank_map=0,2,4,6,8,10,12,14,16,18,20,22,24;1,3,5,7,9,11,13,15,17,19,21,23,25; --batch-size=78 --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna
device: cuda:0 n_gpu: 1, distributed training: True, 16-bits training: True
dry run time 0.1269242763519287
SHARED WEIGHTS ARE
[(0, 1)]
this rank  14 is part of pipeline replica  7
5 chunks
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  524288.0
[2022-11-24 13:53:10.908215] Finished iteration 0, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5378.865
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  262144.0
[2022-11-24 13:53:13.229579] Finished iteration 1, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2321.038
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  131072.0
[2022-11-24 13:53:16.605666] Finished iteration 2, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3376.168
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  65536.0
[2022-11-24 13:53:18.984625] Finished iteration 3, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2378.830
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  32768.0
[2022-11-24 13:53:22.308232] Finished iteration 4, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3323.651
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  16384.0
[2022-11-24 13:53:24.668799] Finished iteration 5, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2360.450
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  8192.0
[2022-11-24 13:53:26.928104] Finished iteration 6, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2259.282
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  4096.0
[2022-11-24 13:53:29.277457] Finished iteration 7, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2349.308
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  2048.0
[2022-11-24 13:53:31.597156] Finished iteration 8, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2319.798
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1024.0
[2022-11-24 13:53:33.930685] Finished iteration 9, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2333.373
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  512.0
[2022-11-24 13:53:36.248801] Finished iteration 10, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2318.037
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  256.0
[2022-11-24 13:53:38.525480] Finished iteration 11, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2276.661
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  128.0
[2022-11-24 13:53:40.864917] Finished iteration 12, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2339.548
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  64.0
[2022-11-24 13:53:43.164342] Finished iteration 13, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2299.395
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  32.0
[2022-11-24 13:53:45.447172] Finished iteration 14, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2282.825
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  16.0
[2022-11-24 13:53:47.779082] Finished iteration 15, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2331.811
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  8.0
[2022-11-24 13:53:50.047745] Finished iteration 16, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2268.495
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  4.0
[2022-11-24 13:53:52.352248] Finished iteration 17, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2304.420
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  2.0
[2022-11-24 13:53:54.693152] Finished iteration 18, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2341.061
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:53:56.998244] Finished iteration 19, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2304.999
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:53:59.275154] Finished iteration 20, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2276.721
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:01.601473] Finished iteration 21, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2326.306
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:03.913869] Finished iteration 22, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2312.369
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:06.196019] Finished iteration 23, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2282.095
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:08.483917] Finished iteration 24, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2287.922
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:10.774855] Finished iteration 25, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2290.849
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:13.100940] Finished iteration 26, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2326.175
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:15.418394] Finished iteration 27, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2317.512
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:17.760259] Finished iteration 28, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2341.574
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:20.938054] Finished iteration 29, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3177.961
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:23.195648] Finished iteration 30, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2257.462
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:25.538509] Finished iteration 31, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2342.671
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:27.809754] Finished iteration 32, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2271.260
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:30.123173] Finished iteration 33, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2313.496
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:32.461447] Finished iteration 34, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2338.223
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:34.757267] Finished iteration 35, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2295.626
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:37.089794] Finished iteration 36, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2332.720
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:39.417960] Finished iteration 37, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2327.943
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:41.745589] Finished iteration 38, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2327.743
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:44.092175] Finished iteration 39, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2346.373
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:46.429016] Finished iteration 40, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2336.807
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:48.711772] Finished iteration 41, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2282.836
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:51.038389] Finished iteration 42, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2326.576
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:53.403802] Finished iteration 43, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2365.236
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:55.737946] Finished iteration 44, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2334.337
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:58.080233] Finished iteration 45, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2342.126
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:00.408095] Finished iteration 46, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2327.683
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:02.718048] Finished iteration 47, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2310.079
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:04.982833] Finished iteration 48, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2264.585
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:07.347637] Finished iteration 49, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2364.811
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:09.651386] Finished iteration 50, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2303.697
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:11.992382] Finished iteration 51, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2340.989
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:14.282833] Finished iteration 52, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2290.421
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:16.601590] Finished iteration 53, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2318.929
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:18.901514] Finished iteration 54, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2299.619
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:21.190862] Finished iteration 55, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2289.315
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:23.506303] Finished iteration 56, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2315.407
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:25.831318] Finished iteration 57, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2325.024
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:28.189731] Finished iteration 58, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2358.378
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:30.535736] Finished iteration 59, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2345.949
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:32.833441] Finished iteration 60, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2297.678
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:35.143138] Finished iteration 61, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2309.700
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:37.443784] Finished iteration 62, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2300.766
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:39.791186] Finished iteration 63, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2347.224
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:42.123717] Finished iteration 64, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2332.489
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:44.422056] Finished iteration 65, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2298.293
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:46.774439] Finished iteration 66, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2352.486
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:49.194858] Finished iteration 67, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2420.349
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:51.494982] Finished iteration 68, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2299.926
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:53.853484] Finished iteration 69, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2358.511
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:56.184789] Finished iteration 70, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2331.231
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:58.518679] Finished iteration 71, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2333.866
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:00.839638] Finished iteration 72, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2321.063
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:03.150655] Finished iteration 73, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2310.824
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:05.457565] Finished iteration 74, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2306.927
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:07.717062] Finished iteration 75, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2259.475
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:10.018039] Finished iteration 76, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2300.896
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:12.354000] Finished iteration 77, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2335.959
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:14.719577] Finished iteration 78, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2365.540
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:17.018891] Finished iteration 79, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2299.253
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:19.357817] Finished iteration 80, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2339.055
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:21.658413] Finished iteration 81, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2300.623
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:23.926564] Finished iteration 82, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2267.885
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:26.189023] Finished iteration 83, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2262.407
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:28.494311] Finished iteration 84, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2305.264
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:30.777989] Finished iteration 85, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2283.643
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:33.086032] Finished iteration 86, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2308.162
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:35.321356] Finished iteration 87, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2235.293
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:37.617853] Finished iteration 88, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2296.467
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:40.016323] Finished iteration 89, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2398.491
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:42.290395] Finished iteration 90, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2273.776
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:44.567503] Finished iteration 91, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2277.071
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:46.896995] Finished iteration 92, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2329.532
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:49.213448] Finished iteration 93, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2316.492
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:51.541251] Finished iteration 94, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2327.614
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:53.832913] Finished iteration 95, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2291.641
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:56.160292] Finished iteration 96, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2327.401
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:58.428588] Finished iteration 97, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2268.208
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:00.735470] Finished iteration 98, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2306.906
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:03.062343] Finished iteration 99, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2327.050
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:05.420654] Finished iteration 100, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2357.967
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:07.737957] Finished iteration 101, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2317.266
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:10.043027] Finished iteration 102, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2305.193
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:12.340198] Finished iteration 103, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2296.988
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:14.655840] Finished iteration 104, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2315.637
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:16.990078] Finished iteration 105, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2334.324
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:19.277995] Finished iteration 106, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2287.738
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:21.533572] Finished iteration 107, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2255.678
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:23.818541] Finished iteration 108, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2284.808
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:26.110441] Finished iteration 109, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2291.814
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:28.396099] Finished iteration 110, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2285.635
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:30.658311] Finished iteration 111, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2262.183
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:33.001790] Finished iteration 112, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2343.625
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:35.348845] Finished iteration 113, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2346.891
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:37.641043] Finished iteration 114, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2292.171
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:39.985300] Finished iteration 115, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2344.173
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:42.299104] Finished iteration 116, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2313.767
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:44.586242] Finished iteration 117, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2287.234
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:46.899264] Finished iteration 118, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2312.858
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:49.150946] Finished iteration 119, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2251.858
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:51.377261] Finished iteration 120, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2226.060
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:53.650260] Finished iteration 121, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2272.982
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:55.970276] Finished iteration 122, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2320.025
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:58.363913] Finished iteration 123, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2393.693
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:00.678062] Finished iteration 124, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2314.119
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:02.971375] Finished iteration 125, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2293.082
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:05.282204] Finished iteration 126, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2310.809
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:07.641255] Finished iteration 127, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2359.010
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:10.025911] Finished iteration 128, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2384.669
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:12.367828] Finished iteration 129, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2341.853
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:14.752156] Finished iteration 130, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2384.281
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:17.067620] Finished iteration 131, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2315.438
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:19.369356] Finished iteration 132, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2301.710
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:21.684245] Finished iteration 133, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2314.863
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:24.039472] Finished iteration 134, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2355.203
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:26.395176] Finished iteration 135, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2355.674
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:28.678726] Finished iteration 136, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2283.531
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:31.006979] Finished iteration 137, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2328.205
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:33.314929] Finished iteration 138, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2307.926
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:35.588546] Finished iteration 139, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2273.626
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:37.886624] Finished iteration 140, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2298.219
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:40.186302] Finished iteration 141, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2299.408
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:42.522317] Finished iteration 142, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2336.013
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:44.829002] Finished iteration 143, CKPT_AND_STOP: False, flag: tensor([1], dtype=torch.int32), speed: 2306.634
2022-11-24 13:58:44.833404 Begin to save checkpont to s3://spot-checkpoints/bert and exit
Opt ckpt time 4.419458389282227
Process done with return code 0
Parent process ID: 16749 node: 172.31.21.109
24 cutpoints
Stages 1
13 20868437708.800007
7 13915698585.599995
10 17153729331.199993
8 14622140211.200005
9 15846820659.199995
Predicted microbatch size for 1: 8
comm size 0
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 1 5 0 1286522.0947265625 0
End of simulation:  Mini-batch time (usec) = 2905085
Min send: 10000000, max send 0
Min long send: 10000000, max long send 0
Min fwd: 10000000, max fwd 0; min bwd 10000000, max bwd 0
Min long fwd: 126283, max long fwd 129698; min long bwd 193190, max long bwd 199310
Time taken by simulation: 43 microseconds

Stages 2
13 10987980083.2
19 14996390399.999996
22 16963644723.199997
20 15631126630.400002
Predicted microbatch size for 2: 19
comm size 9961472
WARNING: no send time found, 2 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 2 4 0 645340.8203125 542254.6839368516
End of simulation:  Mini-batch time (usec) = 3338780
Min send: 10000000, max send 0
Min long send: 542586, max long send 555338
Min fwd: 107744, max fwd 113936; min bwd 155753, max bwd 158782
Min long fwd: 131842, max long fwd 138676; min long bwd 169332, max long bwd 173300
Time taken by simulation: 101 microseconds

Stages 3
13 7832942284.800001
19 10697074380.8
22 12097432473.599998
23 12575272243.2
24 13035207577.6
Predicted microbatch size for 3: 24
comm size 12582912
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 5 0 443515.80810546875 663682.2411979454
End of simulation:  Mini-batch time (usec) = 4988556
Min send: 10000000, max send 0
Min long send: 664014, max long send 679713
Min fwd: 72258, max fwd 88035; min bwd 119079, max bwd 130804
Min long fwd: 107414, max long fwd 112703; min long bwd 150032, max long bwd 153679
Time taken by simulation: 167 microseconds

Stages 4
13 6255423385.6
19 8547416371.2
22 9664326348.8
23 10045446451.2
24 10412856422.4
Predicted microbatch size for 4: 24
comm size 12582912
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 7 0 358221.00830078125 663682.2411979454
End of simulation:  Mini-batch time (usec) = 6464795
Min send: 10000000, max send 0
Min long send: 663870, max long send 683729
Min fwd: 53924, max fwd 67812; min bwd 83975, max bwd 97299
Min long fwd: 86081, max long fwd 91318; min long bwd 118237, max long bwd 121834
Time taken by simulation: 309 microseconds

Stages 6
13 4698582732.8
19 6397758361.599999
22 7231220224.0
23 7515620659.2
24 7790505267.2
Predicted microbatch size for 6: 24
comm size 12582912
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 11 0 240705.6121826172 663682.2411979454
End of simulation:  Mini-batch time (usec) = 9735715
Min send: 10000000, max send 0
Min long send: 663764, max long send 689782
Min fwd: 32942, max fwd 48168; min bwd 55337, max bwd 68897
Min long fwd: 65982, max long fwd 73316; min long bwd 85277, max long bwd 90311
Time taken by simulation: 807 microseconds

Stages 8
13 3930501529.6000004
19 5322929356.799999
22 6014667161.6
23 6250707763.2
24 6479329689.6
Predicted microbatch size for 8: 24
comm size 12582912
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 15 0 176039.7491455078 663682.2411979454
End of simulation:  Mini-batch time (usec) = 13724566
Min send: 10000000, max send 0
Min long send: 663736, max long send 690844
Min fwd: 22801, max fwd 38139; min bwd 36151, max bwd 55503
Min long fwd: 51106, max long fwd 59884; min long bwd 68124, max long bwd 75476
Time taken by simulation: 1461 microseconds

Stages 12
13 3141742080.0
19 4248100352.0
22 4798114099.200001
23 4985794867.2
24 5168154112.0
Predicted microbatch size for 12: 24
comm size 12582912
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 22 0 97192.52014160156 663682.2411979454
End of simulation:  Mini-batch time (usec) = 21189724
Min send: 10000000, max send 0
Min long send: 663682, max long send 690844
Min fwd: 10724, max fwd 28920; min bwd 23319, max bwd 41964
Min long fwd: 40826, max long fwd 50474; min long bwd 49192, max long bwd 58811
Time taken by simulation: 3374 microseconds

{1: 2.905085, 2: 3.33878, 3: 4.988556, 4: 6.464795, 6: 9.735715, 8: 13.724566, 12: 21.189724}
{1: 8, 2: 19, 3: 24, 4: 24, 6: 24, 8: 24, 12: 24}
best config is: 2 19
expected time is 3.33878
14 per stage
28 servers!
Config:
ranks: range(14, 15)
train batch size: 1024
partitions: 2
chunk_size: 19
data depth: 14
stage to rank map: 0,2,4,6,8,10,12,14,16,18,20,22,24,26;1,3,5,7,9,11,13,15,17,19,21,23,25,27;
World size is 28
/opt/conda/envs/varuna/bin/python -u /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --rank=14 --chunk_size=19 --local_rank=0 --stage_to_rank_map=0,2,4,6,8,10,12,14,16,18,20,22,24,26;1,3,5,7,9,11,13,15,17,19,21,23,25,27; --batch-size=73 --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna --resume_step 144
device: cuda:0 n_gpu: 1, distributed training: True, 16-bits training: True
dry run time 0.1558835506439209
SHARED WEIGHTS ARE
[(0, 1)]
this rank  14 is part of pipeline replica  7
4 chunks
Begin to load checkpint from s3://spot-checkpoints/bert/ckpt_144.pt
2022-11-24 13:59:22.783645 resume step from  144
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 14 signal handler called with signal 10
2022-11-24 14:00:25.410258 - Finished loading checkpoint, takes 62.493 secs
2022-11-24 14:00:31.378241 Begin to exit
Process done with return code 0
Parent process ID: 18032 node: 172.31.21.109
24 cutpoints
Stages 1
13 20868437708.800007
7 13915698585.599995
10 17153729331.199993
8 14622140211.200005
9 15846820659.199995
Predicted microbatch size for 1: 8
comm size 0
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 1 4 0 3150942.3828125 0
End of simulation:  Mini-batch time (usec) = 4450032
Min send: 10000000, max send 0
Min long send: 10000000, max long send 0
Min fwd: 10000000, max fwd 0; min bwd 10000000, max bwd 0
Min long fwd: 127414, max long fwd 129698; min long bwd 194806, max long bwd 199310
Time taken by simulation: 43 microseconds

Stages 2
13 10987980083.2
19 14996390399.999996
22 16963644723.199997
20 15631126630.400002
Predicted microbatch size for 2: 19
comm size 9961472
WARNING: no send time found, 2 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 2 4 0 673273.3154296875 542254.6839368516
End of simulation:  Mini-batch time (usec) = 3366713
Min send: 10000000, max send 0
Min long send: 542586, max long send 555338
Min fwd: 107744, max fwd 113936; min bwd 155753, max bwd 158782
Min long fwd: 131842, max long fwd 138676; min long bwd 169332, max long bwd 173300
Time taken by simulation: 95 microseconds

Stages 3
13 7832942284.800001
19 10697074380.8
22 12097432473.599998
23 12575272243.2
24 13035207577.6
Predicted microbatch size for 3: 24
comm size 12582912
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 5 0 448996.58203125 663682.2411979454
End of simulation:  Mini-batch time (usec) = 4994037
Min send: 10000000, max send 0
Min long send: 664014, max long send 679713
Min fwd: 72258, max fwd 88035; min bwd 119079, max bwd 130804
Min long fwd: 107414, max long fwd 112703; min long bwd 150032, max long bwd 153679
Time taken by simulation: 172 microseconds

Stages 4
13 6255423385.6
19 8547416371.2
22 9664326348.8
23 10045446451.2
24 10412856422.4
Predicted microbatch size for 4: 24
comm size 12582912
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 6 0 375752.13623046875 663682.2411979454
End of simulation:  Mini-batch time (usec) = 6314108
Min send: 10000000, max send 0
Min long send: 663764, max long send 688387
Min fwd: 53924, max fwd 66948; min bwd 83975, max bwd 98046
Min long fwd: 84759, max long fwd 91250; min long bwd 120659, max long bwd 125455
Time taken by simulation: 273 microseconds

Stages 6
13 4698582732.8
19 6397758361.599999
22 7231220224.0
23 7515620659.2
24 7790505267.2
Predicted microbatch size for 6: 24
comm size 12582912
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 9 0 241996.6583251953 663682.2411979454
End of simulation:  Mini-batch time (usec) = 9164548
Min send: 10000000, max send 0
Min long send: 663736, max long send 687371
Min fwd: 33746, max fwd 47347; min bwd 54554, max bwd 72477
Min long fwd: 65864, max long fwd 73316; min long bwd 84274, max long bwd 89413
Time taken by simulation: 618 microseconds

Stages 8
13 3930501529.6000004
19 5322929356.799999
22 6014667161.6
23 6250707763.2
24 6479329689.6
Predicted microbatch size for 8: 24
comm size 12582912
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 11 0 214379.08935546875 663682.2411979454
End of simulation:  Mini-batch time (usec) = 12421079
Min send: 10000000, max send 0
Min long send: 663682, max long send 689782
Min fwd: 22992, max fwd 37161; min bwd 37517, max bwd 55449
Min long fwd: 51419, max long fwd 57045; min long bwd 68935, max long bwd 77274
Time taken by simulation: 1112 microseconds

Stages 12
13 3141742080.0
19 4248100352.0
22 4798114099.200001
23 4985794867.2
24 5168154112.0
Predicted microbatch size for 12: 24
comm size 12582912
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 22 0 97192.52014160156 663682.2411979454
End of simulation:  Mini-batch time (usec) = 21189724
Min send: 10000000, max send 0
Min long send: 663682, max long send 690844
Min fwd: 10724, max fwd 28920; min bwd 23319, max bwd 41964
Min long fwd: 40826, max long fwd 50474; min long bwd 49192, max long bwd 58811
Time taken by simulation: 3406 microseconds

{1: 4.450032, 2: 3.366713, 3: 4.994037, 4: 6.314108, 6: 9.164548, 8: 12.421079, 12: 21.189724}
{1: 8, 2: 19, 3: 24, 4: 24, 6: 24, 8: 24, 12: 24}
best config is: 2 19
expected time is 3.366713
16 per stage
32 servers!
Config:
ranks: range(14, 15)
train batch size: 1024
partitions: 2
chunk_size: 19
data depth: 16
stage to rank map: 0,2,4,6,8,10,12,14,16,18,20,22,24,26,28,30;1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31;
World size is 32
/opt/conda/envs/varuna/bin/python -u /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --rank=14 --chunk_size=19 --local_rank=0 --stage_to_rank_map=0,2,4,6,8,10,12,14,16,18,20,22,24,26,28,30;1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31; --batch-size=64 --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna --resume_step 144
device: cuda:0 n_gpu: 1, distributed training: True, 16-bits training: True
dry run time 0.14754319190979004
SHARED WEIGHTS ARE
[(0, 1)]
this rank  14 is part of pipeline replica  7
4 chunks
Begin to load checkpint from s3://spot-checkpoints/bert/ckpt_144.pt
2022-11-24 14:00:52.850148 resume step from  144
2022-11-24 14:01:50.736556 - Finished loading checkpoint, takes 57.740 secs
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  524288.0
[2022-11-24 14:02:26.493398] Finished iteration 144, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5710.160
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  262144.0
[2022-11-24 14:02:29.719801] Finished iteration 145, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3226.180
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  131072.0
[2022-11-24 14:02:32.852611] Finished iteration 146, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3132.768
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  65536.0
[2022-11-24 14:02:35.995125] Finished iteration 147, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3142.483
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  32768.0
[2022-11-24 14:02:39.105051] Finished iteration 148, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3110.076
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  16384.0
[2022-11-24 14:02:41.204173] Finished iteration 149, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2098.840
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  8192.0
[2022-11-24 14:02:43.339705] Finished iteration 150, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2135.594
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  4096.0
[2022-11-24 14:02:45.392848] Finished iteration 151, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2052.979
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  2048.0
[2022-11-24 14:02:47.494172] Finished iteration 152, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2101.300
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1024.0
[2022-11-24 14:02:49.611849] Finished iteration 153, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2117.798
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  512.0
[2022-11-24 14:02:51.711771] Finished iteration 154, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2099.881
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  256.0
[2022-11-24 14:02:53.789769] Finished iteration 155, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2077.825
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  128.0
[2022-11-24 14:02:55.942427] Finished iteration 156, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2152.612
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  64.0
[2022-11-24 14:02:58.047467] Finished iteration 157, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2105.051
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  32.0
[2022-11-24 14:03:00.151864] Finished iteration 158, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2104.355
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  16.0
[2022-11-24 14:03:02.265963] Finished iteration 159, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2114.082
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  8.0
[2022-11-24 14:03:04.358161] Finished iteration 160, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2092.386
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  4.0
[2022-11-24 14:03:06.511424] Finished iteration 161, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2152.930
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  2.0
[2022-11-24 14:03:08.605469] Finished iteration 162, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2094.036
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:11.892114] Finished iteration 163, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3286.647
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:14.009844] Finished iteration 164, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2117.687
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:16.137958] Finished iteration 165, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2128.052
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:18.238597] Finished iteration 166, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2100.610
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:20.380187] Finished iteration 167, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2141.692
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:22.447709] Finished iteration 168, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2067.501
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:24.593743] Finished iteration 169, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2146.013
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:26.740078] Finished iteration 170, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2146.229
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:28.901798] Finished iteration 171, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2161.735
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:31.044178] Finished iteration 172, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2142.151
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:33.205139] Finished iteration 173, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2160.925
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:35.289703] Finished iteration 174, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2084.541
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:37.405299] Finished iteration 175, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2115.538
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:39.481912] Finished iteration 176, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2076.773
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:41.595774] Finished iteration 177, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2113.630
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:43.758088] Finished iteration 178, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2162.457
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:45.958025] Finished iteration 179, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2199.909
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:48.053264] Finished iteration 180, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2095.009
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:50.183473] Finished iteration 181, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2130.159
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:52.298341] Finished iteration 182, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2114.896
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:54.414144] Finished iteration 183, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2115.842
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:56.559812] Finished iteration 184, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2145.715
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:58.646588] Finished iteration 185, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2086.651
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:00.758763] Finished iteration 186, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2112.102
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:02.907115] Finished iteration 187, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2148.156
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:04.991727] Finished iteration 188, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2084.588
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:07.126799] Finished iteration 189, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2135.202
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:09.254570] Finished iteration 190, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2127.557
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:11.357152] Finished iteration 191, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2102.560
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:13.490291] Finished iteration 192, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2133.142
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:15.600858] Finished iteration 193, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2110.517
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:17.701405] Finished iteration 194, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2100.523
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:19.830757] Finished iteration 195, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2129.332
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:21.959473] Finished iteration 196, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2128.844
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:24.116247] Finished iteration 197, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2156.723
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:26.184632] Finished iteration 198, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2068.191
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:28.234392] Finished iteration 199, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2049.702
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:30.359951] Finished iteration 200, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2125.531
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:32.474981] Finished iteration 201, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2114.998
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:34.594755] Finished iteration 202, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2119.745
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:36.708879] Finished iteration 203, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2114.116
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:38.821024] Finished iteration 204, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2112.083
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:41.281421] Finished iteration 205, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2460.422
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:43.731723] Finished iteration 206, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2450.245
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:45.872081] Finished iteration 207, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2140.462
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:49.110263] Finished iteration 208, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3238.229
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:51.571077] Finished iteration 209, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2460.642
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:53.756155] Finished iteration 210, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2184.907
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:55.858863] Finished iteration 211, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2102.651
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:57.918584] Finished iteration 212, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2059.690
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:00.062430] Finished iteration 213, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2143.814
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:02.202367] Finished iteration 214, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2139.935
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:04.279544] Finished iteration 215, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2077.146
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:06.414361] Finished iteration 216, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2134.930
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:08.546465] Finished iteration 217, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2131.912
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:10.635811] Finished iteration 218, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2089.304
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:12.764036] Finished iteration 219, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2128.335
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:14.892766] Finished iteration 220, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2128.680
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:16.969957] Finished iteration 221, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2077.019
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:19.087424] Finished iteration 222, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2117.453
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:21.201626] Finished iteration 223, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2114.221
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:23.325334] Finished iteration 224, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2123.773
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:25.458601] Finished iteration 225, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2133.035
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:27.578672] Finished iteration 226, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2120.210
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:29.676732] Finished iteration 227, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2098.075
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:31.835396] Finished iteration 228, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2158.376
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:34.000109] Finished iteration 229, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2164.817
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:36.154582] Finished iteration 230, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2154.435
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:38.256699] Finished iteration 231, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2102.086
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:40.372582] Finished iteration 232, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2115.841
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:42.487532] Finished iteration 233, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2114.753
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:44.599970] Finished iteration 234, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2112.408
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:46.749874] Finished iteration 235, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2149.913
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:48.843886] Finished iteration 236, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2093.959
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:50.956352] Finished iteration 237, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2112.427
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:53.035677] Finished iteration 238, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2079.304
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:55.135082] Finished iteration 239, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2099.384
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:57.227689] Finished iteration 240, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2092.794
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:00.137338] Finished iteration 241, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2909.510
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:02.250460] Finished iteration 242, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2113.061
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:04.375956] Finished iteration 243, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2125.312
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:06.471994] Finished iteration 244, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2096.177
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:08.573453] Finished iteration 245, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2101.378
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:10.733483] Finished iteration 246, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2160.048
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:12.789459] Finished iteration 247, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2055.873
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:14.893053] Finished iteration 248, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2103.412
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:17.015381] Finished iteration 249, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2122.362
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:19.121502] Finished iteration 250, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2105.993
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:21.221790] Finished iteration 251, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2100.291
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:23.342716] Finished iteration 252, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2121.017
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:25.431119] Finished iteration 253, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2088.345
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:27.538035] Finished iteration 254, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2106.794
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:29.642657] Finished iteration 255, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2104.722
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:31.763805] Finished iteration 256, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2121.036
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:33.953430] Finished iteration 257, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2189.501
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:36.050087] Finished iteration 258, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2096.573
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:38.102265] Finished iteration 259, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2052.278
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:40.175851] Finished iteration 260, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2073.576
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:42.341560] Finished iteration 261, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2165.701
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:44.438812] Finished iteration 262, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2097.138
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:46.532612] Finished iteration 263, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2093.755
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:48.626859] Finished iteration 264, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2094.213
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:50.768085] Finished iteration 265, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2141.042
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:52.909911] Finished iteration 266, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2141.827
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:55.004247] Finished iteration 267, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2094.279
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:57.072646] Finished iteration 268, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2068.387
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:59.212571] Finished iteration 269, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2139.875
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:07:01.338613] Finished iteration 270, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2126.162
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:07:03.427707] Finished iteration 271, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2088.916
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:07:05.556497] Finished iteration 272, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2128.794
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:07:07.622602] Finished iteration 273, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2066.019
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:07:09.664349] Finished iteration 274, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2041.722
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:07:11.779448] Finished iteration 275, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2115.130
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:07:13.954896] Finished iteration 276, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2175.351
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:07:16.761294] Finished iteration 277, CKPT_AND_STOP: False, flag: tensor([2], dtype=torch.int32), speed: 2806.389
2022-11-24 14:07:16.765870 Begin to save checkpont to s3://spot-checkpoints/bert and exit
Opt ckpt time 4.617331504821777
Process done with return code 0
Parent process ID: 19659 node: 172.31.21.109
24 cutpoints
Stages 1
13 20868437708.800007
7 13915698585.599995
10 17153729331.199993
8 14622140211.200005
9 15846820659.199995
Predicted microbatch size for 1: 8
comm size 0
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 1 5 0 1286522.0947265625 0
End of simulation:  Mini-batch time (usec) = 2905085
Min send: 10000000, max send 0
Min long send: 10000000, max long send 0
Min fwd: 10000000, max fwd 0; min bwd 10000000, max bwd 0
Min long fwd: 126283, max long fwd 129698; min long bwd 193190, max long bwd 199310
Time taken by simulation: 48 microseconds

Stages 2
13 10987980083.2
19 14996390399.999996
22 16963644723.199997
20 15631126630.400002
Predicted microbatch size for 2: 19
comm size 9961472
WARNING: no send time found, 2 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 2 4 0 638222.2290039062 542254.6839368516
End of simulation:  Mini-batch time (usec) = 3331662
Min send: 10000000, max send 0
Min long send: 542586, max long send 555338
Min fwd: 107744, max fwd 113936; min bwd 155753, max bwd 158782
Min long fwd: 131842, max long fwd 138676; min long bwd 169332, max long bwd 173300
Time taken by simulation: 93 microseconds

Stages 3
13 7832942284.800001
19 10697074380.8
22 12097432473.599998
23 12575272243.2
24 13035207577.6
Predicted microbatch size for 3: 24
comm size 12582912
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 5 0 448996.58203125 663682.2411979454
End of simulation:  Mini-batch time (usec) = 4994037
Min send: 10000000, max send 0
Min long send: 664014, max long send 679713
Min fwd: 72258, max fwd 88035; min bwd 119079, max bwd 130804
Min long fwd: 107414, max long fwd 112703; min long bwd 150032, max long bwd 153679
Time taken by simulation: 168 microseconds

Stages 4
13 6255423385.6
19 8547416371.2
22 9664326348.8
23 10045446451.2
24 10412856422.4
Predicted microbatch size for 4: 24
comm size 12582912
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 7 0 358221.00830078125 663682.2411979454
End of simulation:  Mini-batch time (usec) = 6464795
Min send: 10000000, max send 0
Min long send: 663870, max long send 683729
Min fwd: 53924, max fwd 67812; min bwd 83975, max bwd 97299
Min long fwd: 86081, max long fwd 91318; min long bwd 118237, max long bwd 121834
Time taken by simulation: 327 microseconds

Stages 6
13 4698582732.8
19 6397758361.599999
22 7231220224.0
23 7515620659.2
24 7790505267.2
Predicted microbatch size for 6: 24
comm size 12582912
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 9 0 241996.6583251953 663682.2411979454
End of simulation:  Mini-batch time (usec) = 9164548
Min send: 10000000, max send 0
Min long send: 663736, max long send 687371
Min fwd: 33746, max fwd 47347; min bwd 54554, max bwd 72477
Min long fwd: 65864, max long fwd 73316; min long bwd 84274, max long bwd 89413
Time taken by simulation: 622 microseconds

Stages 8
13 3930501529.6000004
19 5322929356.799999
22 6014667161.6
23 6250707763.2
24 6479329689.6
Predicted microbatch size for 8: 24
comm size 12582912
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 15 0 176039.7491455078 663682.2411979454
End of simulation:  Mini-batch time (usec) = 13724566
Min send: 10000000, max send 0
Min long send: 663736, max long send 690844
Min fwd: 22801, max fwd 38139; min bwd 36151, max bwd 55503
Min long fwd: 51106, max long fwd 59884; min long bwd 68124, max long bwd 75476
Time taken by simulation: 1461 microseconds

Stages 12
13 3141742080.0
19 4248100352.0
22 4798114099.200001
23 4985794867.2
24 5168154112.0
Predicted microbatch size for 12: 24
comm size 12582912
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 22 0 97192.52014160156 663682.2411979454
End of simulation:  Mini-batch time (usec) = 21189724
Min send: 10000000, max send 0
Min long send: 663682, max long send 690844
Min fwd: 10724, max fwd 28920; min bwd 23319, max bwd 41964
Min long fwd: 40826, max long fwd 50474; min long bwd 49192, max long bwd 58811
Time taken by simulation: 3391 microseconds

{1: 2.905085, 2: 3.331662, 3: 4.994037, 4: 6.464795, 6: 9.164548, 8: 13.724566, 12: 21.189724}
{1: 8, 2: 19, 3: 24, 4: 24, 6: 24, 8: 24, 12: 24}
best config is: 2 19
expected time is 3.331662
15 per stage
30 servers!
Config:
ranks: range(14, 15)
train batch size: 1024
partitions: 2
chunk_size: 19
data depth: 15
stage to rank map: 0,2,4,6,8,10,12,14,16,18,20,22,24,26,28;1,3,5,7,9,11,13,15,17,19,21,23,25,27,29;
World size is 30
/opt/conda/envs/varuna/bin/python -u /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --rank=14 --chunk_size=19 --local_rank=0 --stage_to_rank_map=0,2,4,6,8,10,12,14,16,18,20,22,24,26,28;1,3,5,7,9,11,13,15,17,19,21,23,25,27,29; --batch-size=68 --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna --resume_step 278
device: cuda:0 n_gpu: 1, distributed training: True, 16-bits training: True
dry run time 0.11745190620422363
SHARED WEIGHTS ARE
[(0, 1)]
this rank  14 is part of pipeline replica  7
4 chunks
Begin to load checkpint from s3://spot-checkpoints/bert/ckpt_278.pt
2022-11-24 14:08:27.294808 resume step from  278
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 14 signal handler called with signal 10
2022-11-24 14:09:31.370847 - Finished loading checkpoint, takes 63.995 secs
Process done with return code 1
Parent process ID: 20903 node: 172.31.19.112
24 cutpoints
Stages 1
13 20868437708.800007
7 13915698585.599995
10 17153729331.199993
8 14622140211.200005
9 15846820659.199995
Predicted microbatch size for 1: 8
comm size 0
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 1 5 0 1286522.0947265625 0
End of simulation:  Mini-batch time (usec) = 2905085
Min send: 10000000, max send 0
Min long send: 10000000, max long send 0
Min fwd: 10000000, max fwd 0; min bwd 10000000, max bwd 0
Min long fwd: 126283, max long fwd 129698; min long bwd 193190, max long bwd 199310
Time taken by simulation: 43 microseconds

Stages 2
13 10987980083.2
19 14996390399.999996
22 16963644723.199997
20 15631126630.400002
Predicted microbatch size for 2: 19
comm size 9961472
WARNING: no send time found, 2 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 2 4 0 638222.2290039062 542254.6839368516
End of simulation:  Mini-batch time (usec) = 3331662
Min send: 10000000, max send 0
Min long send: 542586, max long send 555338
Min fwd: 107744, max fwd 113936; min bwd 155753, max bwd 158782
Min long fwd: 131842, max long fwd 138676; min long bwd 169332, max long bwd 173300
Time taken by simulation: 97 microseconds

Stages 3
13 7832942284.800001
19 10697074380.8
22 12097432473.599998
23 12575272243.2
24 13035207577.6
Predicted microbatch size for 3: 24
comm size 12582912
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 5 0 448996.58203125 663682.2411979454
End of simulation:  Mini-batch time (usec) = 4994037
Min send: 10000000, max send 0
Min long send: 664014, max long send 679713
Min fwd: 72258, max fwd 88035; min bwd 119079, max bwd 130804
Min long fwd: 107414, max long fwd 112703; min long bwd 150032, max long bwd 153679
Time taken by simulation: 166 microseconds

Stages 4
13 6255423385.6
19 8547416371.2
22 9664326348.8
23 10045446451.2
24 10412856422.4
Predicted microbatch size for 4: 24
comm size 12582912
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 7 0 358221.00830078125 663682.2411979454
End of simulation:  Mini-batch time (usec) = 6464795
Min send: 10000000, max send 0
Min long send: 663870, max long send 683729
Min fwd: 53924, max fwd 67812; min bwd 83975, max bwd 97299
Min long fwd: 86081, max long fwd 91318; min long bwd 118237, max long bwd 121834
Time taken by simulation: 315 microseconds

Stages 6
13 4698582732.8
19 6397758361.599999
22 7231220224.0
23 7515620659.2
24 7790505267.2
Predicted microbatch size for 6: 24
comm size 12582912
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 9 0 241996.6583251953 663682.2411979454
End of simulation:  Mini-batch time (usec) = 9164548
Min send: 10000000, max send 0
Min long send: 663736, max long send 687371
Min fwd: 33746, max fwd 47347; min bwd 54554, max bwd 72477
Min long fwd: 65864, max long fwd 73316; min long bwd 84274, max long bwd 89413
Time taken by simulation: 629 microseconds

Stages 8
13 3930501529.6000004
19 5322929356.799999
22 6014667161.6
23 6250707763.2
24 6479329689.6
Predicted microbatch size for 8: 24
comm size 12582912
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 15 0 176039.7491455078 663682.2411979454
End of simulation:  Mini-batch time (usec) = 13724566
Min send: 10000000, max send 0
Min long send: 663736, max long send 690844
Min fwd: 22801, max fwd 38139; min bwd 36151, max bwd 55503
Min long fwd: 51106, max long fwd 59884; min long bwd 68124, max long bwd 75476
Time taken by simulation: 1587 microseconds

Stages 12
13 3141742080.0
19 4248100352.0
22 4798114099.200001
23 4985794867.2
24 5168154112.0
Predicted microbatch size for 12: 24
comm size 12582912
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 22 0 97192.52014160156 663682.2411979454
End of simulation:  Mini-batch time (usec) = 21189724
Min send: 10000000, max send 0
Min long send: 663682, max long send 690844
Min fwd: 10724, max fwd 28920; min bwd 23319, max bwd 41964
Min long fwd: 40826, max long fwd 50474; min long bwd 49192, max long bwd 58811
Time taken by simulation: 3437 microseconds

{1: 2.905085, 2: 3.331662, 3: 4.994037, 4: 6.464795, 6: 9.164548, 8: 13.724566, 12: 21.189724}
{1: 8, 2: 19, 3: 24, 4: 24, 6: 24, 8: 24, 12: 24}
best config is: 2 19
expected time is 3.331662
15 per stage
30 servers!
Config:
ranks: range(14, 15)
train batch size: 1024
partitions: 2
chunk_size: 19
data depth: 15
stage to rank map: 0,2,4,6,8,10,12,14,16,18,20,22,24,26,28;1,3,5,7,9,11,13,15,17,19,21,23,25,27,29;
World size is 30
/opt/conda/envs/varuna/bin/python -u /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --rank=14 --chunk_size=19 --local_rank=0 --stage_to_rank_map=0,2,4,6,8,10,12,14,16,18,20,22,24,26,28;1,3,5,7,9,11,13,15,17,19,21,23,25,27,29; --batch-size=68 --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna --resume_step 278
device: cuda:0 n_gpu: 1, distributed training: True, 16-bits training: True
dry run time 0.19027185440063477
SHARED WEIGHTS ARE
[(0, 1)]
this rank  14 is part of pipeline replica  7
4 chunks
Begin to load checkpint from s3://spot-checkpoints/bert/ckpt_278.pt
2022-11-24 14:10:38.001299 resume step from  278
2022-11-24 14:11:58.369899 - Finished loading checkpoint, takes 80.302 secs
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  524288.0
[2022-11-24 14:12:03.154617] Finished iteration 278, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4741.692
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  262144.0
[2022-11-24 14:12:06.360938] Finished iteration 279, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3206.200
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  131072.0
[2022-11-24 14:12:09.538035] Finished iteration 280, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3177.033
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  65536.0
[2022-11-24 14:12:12.677942] Finished iteration 281, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3139.868
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  32768.0
[2022-11-24 14:12:16.116361] Finished iteration 282, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3438.367
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  16384.0
[2022-11-24 14:12:18.255770] Finished iteration 283, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2139.435
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  8192.0
[2022-11-24 14:12:20.398809] Finished iteration 284, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2143.023
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  4096.0
[2022-11-24 14:12:22.522105] Finished iteration 285, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2123.242
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  2048.0
[2022-11-24 14:12:24.632621] Finished iteration 286, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2110.295
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1024.0
[2022-11-24 14:12:26.721978] Finished iteration 287, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2089.332
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  512.0
[2022-11-24 14:12:28.847738] Finished iteration 288, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2125.870
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  256.0
[2022-11-24 14:12:30.956386] Finished iteration 289, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2108.504
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  128.0
[2022-11-24 14:12:33.122262] Finished iteration 290, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2165.968
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  64.0
[2022-11-24 14:12:35.259398] Finished iteration 291, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2136.938
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  32.0
[2022-11-24 14:12:37.398139] Finished iteration 292, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2138.734
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  16.0
[2022-11-24 14:12:39.492877] Finished iteration 293, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2094.796
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  8.0
[2022-11-24 14:12:41.580911] Finished iteration 294, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2087.965
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  4.0
[2022-11-24 14:12:43.733337] Finished iteration 295, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2152.461
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  2.0
[2022-11-24 14:12:45.876461] Finished iteration 296, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2142.855
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:12:47.975848] Finished iteration 297, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2099.349
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:12:50.112833] Finished iteration 298, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2137.176
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:12:52.261363] Finished iteration 299, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2148.369
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:12:54.432938] Finished iteration 300, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2171.631
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:12:56.559635] Finished iteration 301, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2126.441
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:12:58.732325] Finished iteration 302, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2172.634
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:00.849144] Finished iteration 303, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2116.821
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:03.003009] Finished iteration 304, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2153.800
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:05.144300] Finished iteration 305, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2141.377
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:07.618598] Finished iteration 306, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2474.156
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:10.007389] Finished iteration 307, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2388.866
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:12.157848] Finished iteration 308, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2150.294
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:14.272539] Finished iteration 309, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2114.823
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:16.432448] Finished iteration 310, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2159.696
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:18.552674] Finished iteration 311, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2120.322
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:20.683526] Finished iteration 312, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2130.661
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:22.796398] Finished iteration 313, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2112.830
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:24.957158] Finished iteration 314, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2160.863
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:27.094659] Finished iteration 315, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2137.468
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:29.284723] Finished iteration 316, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2189.882
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:31.382877] Finished iteration 317, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2098.108
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:33.514801] Finished iteration 318, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2131.911
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:35.775423] Finished iteration 319, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2260.595
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:37.928863] Finished iteration 320, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2153.538
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:40.073754] Finished iteration 321, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2144.705
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:42.230046] Finished iteration 322, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2156.267
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:44.367110] Finished iteration 323, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2137.183
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:46.492383] Finished iteration 324, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2125.071
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:48.747269] Finished iteration 325, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2254.854
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:50.870104] Finished iteration 326, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2122.884
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:53.718584] Finished iteration 327, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2848.372
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:55.850837] Finished iteration 328, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2132.355
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:58.035385] Finished iteration 329, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2184.361
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:00.143612] Finished iteration 330, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2108.265
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:02.238746] Finished iteration 331, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2095.045
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:04.395228] Finished iteration 332, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2156.483
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:06.516291] Finished iteration 333, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2121.079
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:08.637112] Finished iteration 334, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2120.784
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:10.768209] Finished iteration 335, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2131.037
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:12.888906] Finished iteration 336, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2120.536
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:15.025640] Finished iteration 337, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2136.697
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:17.189609] Finished iteration 338, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2163.958
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:19.318570] Finished iteration 339, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2129.084
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:21.433433] Finished iteration 340, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2114.703
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:23.596045] Finished iteration 341, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2162.631
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:25.753261] Finished iteration 342, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2157.111
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:27.891406] Finished iteration 343, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2138.282
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:30.033950] Finished iteration 344, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2142.397
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:32.182527] Finished iteration 345, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2148.374
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:34.318965] Finished iteration 346, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2136.400
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:36.417378] Finished iteration 347, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2098.397
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:38.597008] Finished iteration 348, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2179.597
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:40.706234] Finished iteration 349, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2109.346
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:42.901529] Finished iteration 350, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2195.114
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:45.034184] Finished iteration 351, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2132.613
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:47.164370] Finished iteration 352, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2130.195
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:49.264498] Finished iteration 353, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2100.088
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:51.412418] Finished iteration 354, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2147.981
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:53.606475] Finished iteration 355, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2193.964
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:55.727751] Finished iteration 356, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2121.104
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:57.844215] Finished iteration 357, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2116.462
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:59.952010] Finished iteration 358, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2107.745
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:02.084650] Finished iteration 359, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2132.633
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:04.206159] Finished iteration 360, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2121.510
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:06.371182] Finished iteration 361, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2165.161
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:08.533322] Finished iteration 362, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2161.844
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:10.688703] Finished iteration 363, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2155.509
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:12.884744] Finished iteration 364, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2195.857
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:15.000440] Finished iteration 365, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2115.656
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:17.107106] Finished iteration 366, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2106.631
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:19.274424] Finished iteration 367, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2167.355
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:21.393107] Finished iteration 368, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2118.804
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:23.545543] Finished iteration 369, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2152.153
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:25.705356] Finished iteration 370, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2159.905
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:27.856239] Finished iteration 371, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2150.708
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:29.968122] Finished iteration 372, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2111.989
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:32.106519] Finished iteration 373, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2138.212
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:34.268939] Finished iteration 374, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2162.407
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:36.393435] Finished iteration 375, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2124.539
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:38.516275] Finished iteration 376, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2122.734
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:40.698233] Finished iteration 377, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2181.915
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:42.816284] Finished iteration 378, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2117.975
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:44.957332] Finished iteration 379, CKPT_AND_STOP: False, flag: tensor([1], dtype=torch.int32), speed: 2141.024
2022-11-24 14:15:44.961893 Begin to save checkpont to s3://spot-checkpoints/bert and exit
Opt ckpt time 4.335228443145752
Process done with return code 0
Parent process ID: 22709 node: 172.31.19.112
24 cutpoints
Stages 1
13 20868437708.800007
7 13915698585.599995
10 17153729331.199993
8 14622140211.200005
9 15846820659.199995
Predicted microbatch size for 1: 8
comm size 0
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 1 5 0 1286522.0947265625 0
End of simulation:  Mini-batch time (usec) = 2905085
Min send: 10000000, max send 0
Min long send: 10000000, max long send 0
Min fwd: 10000000, max fwd 0; min bwd 10000000, max bwd 0
Min long fwd: 126283, max long fwd 129698; min long bwd 193190, max long bwd 199310
Time taken by simulation: 44 microseconds

Stages 2
13 10987980083.2
19 14996390399.999996
22 16963644723.199997
20 15631126630.400002
Predicted microbatch size for 2: 19
comm size 9961472
WARNING: no send time found, 2 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 2 4 0 638222.2290039062 542254.6839368516
End of simulation:  Mini-batch time (usec) = 3331662
Min send: 10000000, max send 0
Min long send: 542586, max long send 555338
Min fwd: 107744, max fwd 113936; min bwd 155753, max bwd 158782
Min long fwd: 131842, max long fwd 138676; min long bwd 169332, max long bwd 173300
Time taken by simulation: 101 microseconds

Stages 3
13 7832942284.800001
19 10697074380.8
22 12097432473.599998
23 12575272243.2
24 13035207577.6
Predicted microbatch size for 3: 24
comm size 12582912
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 5 0 448996.58203125 663682.2411979454
End of simulation:  Mini-batch time (usec) = 4994037
Min send: 10000000, max send 0
Min long send: 664014, max long send 679713
Min fwd: 72258, max fwd 88035; min bwd 119079, max bwd 130804
Min long fwd: 107414, max long fwd 112703; min long bwd 150032, max long bwd 153679
Time taken by simulation: 177 microseconds

Stages 4
13 6255423385.6
19 8547416371.2
22 9664326348.8
23 10045446451.2
24 10412856422.4
Predicted microbatch size for 4: 24
comm size 12582912
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 7 0 358221.00830078125 663682.2411979454
End of simulation:  Mini-batch time (usec) = 6464795
Min send: 10000000, max send 0
Min long send: 663870, max long send 683729
Min fwd: 53924, max fwd 67812; min bwd 83975, max bwd 97299
Min long fwd: 86081, max long fwd 91318; min long bwd 118237, max long bwd 121834
Time taken by simulation: 322 microseconds

Stages 6
13 4698582732.8
19 6397758361.599999
22 7231220224.0
23 7515620659.2
24 7790505267.2
Predicted microbatch size for 6: 24
comm size 12582912
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 9 0 241996.6583251953 663682.2411979454
End of simulation:  Mini-batch time (usec) = 9164548
Min send: 10000000, max send 0
Min long send: 663736, max long send 687371
Min fwd: 33746, max fwd 47347; min bwd 54554, max bwd 72477
Min long fwd: 65864, max long fwd 73316; min long bwd 84274, max long bwd 89413
Time taken by simulation: 661 microseconds

Stages 8
13 3930501529.6000004
19 5322929356.799999
22 6014667161.6
23 6250707763.2
24 6479329689.6
Predicted microbatch size for 8: 24
comm size 12582912
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 15 0 176039.7491455078 663682.2411979454
End of simulation:  Mini-batch time (usec) = 13724566
Min send: 10000000, max send 0
Min long send: 663736, max long send 690844
Min fwd: 22801, max fwd 38139; min bwd 36151, max bwd 55503
Min long fwd: 51106, max long fwd 59884; min long bwd 68124, max long bwd 75476
Time taken by simulation: 1552 microseconds

Stages 12
13 3141742080.0
19 4248100352.0
22 4798114099.200001
23 4985794867.2
24 5168154112.0
Predicted microbatch size for 12: 24
comm size 12582912
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 22 0 97192.52014160156 663682.2411979454
End of simulation:  Mini-batch time (usec) = 21189724
Min send: 10000000, max send 0
Min long send: 663682, max long send 690844
Min fwd: 10724, max fwd 28920; min bwd 23319, max bwd 41964
Min long fwd: 40826, max long fwd 50474; min long bwd 49192, max long bwd 58811
Time taken by simulation: 3421 microseconds

{1: 2.905085, 2: 3.331662, 3: 4.994037, 4: 6.464795, 6: 9.164548, 8: 13.724566, 12: 21.189724}
{1: 8, 2: 19, 3: 24, 4: 24, 6: 24, 8: 24, 12: 24}
best config is: 2 19
expected time is 3.331662
15 per stage
30 servers!
Config:
ranks: range(14, 15)
train batch size: 1024
partitions: 2
chunk_size: 19
data depth: 15
stage to rank map: 0,2,4,6,8,10,12,14,16,18,20,22,24,26,28;1,3,5,7,9,11,13,15,17,19,21,23,25,27,29;
World size is 30
/opt/conda/envs/varuna/bin/python -u /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --rank=14 --chunk_size=19 --local_rank=0 --stage_to_rank_map=0,2,4,6,8,10,12,14,16,18,20,22,24,26,28;1,3,5,7,9,11,13,15,17,19,21,23,25,27,29; --batch-size=68 --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna --resume_step 380
device: cuda:0 n_gpu: 1, distributed training: True, 16-bits training: True
dry run time 1.254512071609497
SHARED WEIGHTS ARE
[(0, 1)]
this rank  14 is part of pipeline replica  7
4 chunks
Begin to load checkpint from s3://spot-checkpoints/bert/ckpt_380.pt
2022-11-24 14:16:27.044769 resume step from  380
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 14 signal handler called with signal 10
2022-11-24 14:17:54.279520 - Finished loading checkpoint, takes 82.243 secs
2022-11-24 14:17:54.291090 Begin to exit
Process done with return code 0
Parent process ID: 24092 node: 172.31.19.112
24 cutpoints
Stages 1
13 20868437708.800007
7 13915698585.599995
10 17153729331.199993
8 14622140211.200005
9 15846820659.199995
Predicted microbatch size for 1: 8
comm size 0
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 1 4 0 3150942.3828125 0
End of simulation:  Mini-batch time (usec) = 4450032
Min send: 10000000, max send 0
Min long send: 10000000, max long send 0
Min fwd: 10000000, max fwd 0; min bwd 10000000, max bwd 0
Min long fwd: 127414, max long fwd 129698; min long bwd 194806, max long bwd 199310
Time taken by simulation: 41 microseconds

Stages 2
13 10987980083.2
19 14996390399.999996
22 16963644723.199997
20 15631126630.400002
Predicted microbatch size for 2: 19
comm size 9961472
WARNING: no send time found, 2 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 2 4 0 673273.3154296875 542254.6839368516
End of simulation:  Mini-batch time (usec) = 3366713
Min send: 10000000, max send 0
Min long send: 542586, max long send 555338
Min fwd: 107744, max fwd 113936; min bwd 155753, max bwd 158782
Min long fwd: 131842, max long fwd 138676; min long bwd 169332, max long bwd 173300
Time taken by simulation: 98 microseconds

Stages 3
13 7832942284.800001
19 10697074380.8
22 12097432473.599998
23 12575272243.2
24 13035207577.6
Predicted microbatch size for 3: 24
comm size 12582912
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 5 0 448996.58203125 663682.2411979454
End of simulation:  Mini-batch time (usec) = 4994037
Min send: 10000000, max send 0
Min long send: 664014, max long send 679713
Min fwd: 72258, max fwd 88035; min bwd 119079, max bwd 130804
Min long fwd: 107414, max long fwd 112703; min long bwd 150032, max long bwd 153679
Time taken by simulation: 168 microseconds

Stages 4
13 6255423385.6
19 8547416371.2
22 9664326348.8
23 10045446451.2
24 10412856422.4
Predicted microbatch size for 4: 24
comm size 12582912
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 6 0 375752.13623046875 663682.2411979454
End of simulation:  Mini-batch time (usec) = 6314108
Min send: 10000000, max send 0
Min long send: 663764, max long send 688387
Min fwd: 53924, max fwd 66948; min bwd 83975, max bwd 98046
Min long fwd: 84759, max long fwd 91250; min long bwd 120659, max long bwd 125455
Time taken by simulation: 347 microseconds

Stages 6
13 4698582732.8
19 6397758361.599999
22 7231220224.0
23 7515620659.2
24 7790505267.2
Predicted microbatch size for 6: 24
comm size 12582912
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 9 0 241996.6583251953 663682.2411979454
End of simulation:  Mini-batch time (usec) = 9164548
Min send: 10000000, max send 0
Min long send: 663736, max long send 687371
Min fwd: 33746, max fwd 47347; min bwd 54554, max bwd 72477
Min long fwd: 65864, max long fwd 73316; min long bwd 84274, max long bwd 89413
Time taken by simulation: 621 microseconds

Stages 8
13 3930501529.6000004
19 5322929356.799999
22 6014667161.6
23 6250707763.2
24 6479329689.6
Predicted microbatch size for 8: 24
comm size 12582912
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 11 0 214379.08935546875 663682.2411979454
End of simulation:  Mini-batch time (usec) = 12421079
Min send: 10000000, max send 0
Min long send: 663682, max long send 689782
Min fwd: 22992, max fwd 37161; min bwd 37517, max bwd 55449
Min long fwd: 51419, max long fwd 57045; min long bwd 68935, max long bwd 77274
Time taken by simulation: 1148 microseconds

Stages 12
13 3141742080.0
19 4248100352.0
22 4798114099.200001
23 4985794867.2
24 5168154112.0
Predicted microbatch size for 12: 24
comm size 12582912
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 22 0 97192.52014160156 663682.2411979454
End of simulation:  Mini-batch time (usec) = 21189724
Min send: 10000000, max send 0
Min long send: 663682, max long send 690844
Min fwd: 10724, max fwd 28920; min bwd 23319, max bwd 41964
Min long fwd: 40826, max long fwd 50474; min long bwd 49192, max long bwd 58811
Time taken by simulation: 3384 microseconds

{1: 4.450032, 2: 3.366713, 3: 4.994037, 4: 6.314108, 6: 9.164548, 8: 12.421079, 12: 21.189724}
{1: 8, 2: 19, 3: 24, 4: 24, 6: 24, 8: 24, 12: 24}
best config is: 2 19
expected time is 3.366713
16 per stage
32 servers!
Config:
ranks: range(14, 15)
train batch size: 1024
partitions: 2
chunk_size: 19
data depth: 16
stage to rank map: 0,2,4,6,8,10,12,14,16,18,20,22,24,26,28,30;1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31;
World size is 32
/opt/conda/envs/varuna/bin/python -u /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --rank=14 --chunk_size=19 --local_rank=0 --stage_to_rank_map=0,2,4,6,8,10,12,14,16,18,20,22,24,26,28,30;1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31; --batch-size=64 --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna --resume_step 380
device: cuda:0 n_gpu: 1, distributed training: True, 16-bits training: True
dry run time 0.13124871253967285
SHARED WEIGHTS ARE
[(0, 1)]
this rank  14 is part of pipeline replica  7
4 chunks
Begin to load checkpint from s3://spot-checkpoints/bert/ckpt_380.pt
2022-11-24 14:18:15.776922 resume step from  380
2022-11-24 14:19:22.477418 - Finished loading checkpoint, takes 61.676 secs
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  524288.0
[2022-11-24 14:19:34.548322] Finished iteration 380, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5718.368
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  262144.0
[2022-11-24 14:19:37.742765] Finished iteration 381, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3194.244
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  131072.0
[2022-11-24 14:19:40.910652] Finished iteration 382, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3167.884
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  65536.0
[2022-11-24 14:19:44.059924] Finished iteration 383, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3149.382
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  32768.0
[2022-11-24 14:19:47.213525] Finished iteration 384, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3153.354
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  16384.0
[2022-11-24 14:19:49.554873] Finished iteration 385, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2341.278
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  8192.0
[2022-11-24 14:19:51.664427] Finished iteration 386, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2109.627
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  4096.0
[2022-11-24 14:19:53.813071] Finished iteration 387, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2148.464
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  2048.0
[2022-11-24 14:19:55.881222] Finished iteration 388, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2068.120
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1024.0
[2022-11-24 14:19:57.960710] Finished iteration 389, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2079.624
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  512.0
[2022-11-24 14:20:00.060299] Finished iteration 390, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2099.544
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  256.0
[2022-11-24 14:20:02.202564] Finished iteration 391, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2142.059
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  128.0
[2022-11-24 14:20:05.147122] Finished iteration 392, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2944.534
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  64.0
[2022-11-24 14:20:07.256812] Finished iteration 393, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2109.697
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  32.0
[2022-11-24 14:20:09.350952] Finished iteration 394, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2094.041
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  16.0
[2022-11-24 14:20:12.386807] Finished iteration 395, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3035.889
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  8.0
[2022-11-24 14:20:14.478160] Finished iteration 396, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2091.436
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  4.0
[2022-11-24 14:20:16.550142] Finished iteration 397, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2071.940
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  2.0
[2022-11-24 14:20:18.635157] Finished iteration 398, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2084.921
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:20.685999] Finished iteration 399, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2050.721
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:22.761045] Finished iteration 400, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2074.968
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:24.876525] Finished iteration 401, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2115.452
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:26.989771] Finished iteration 402, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2113.283
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:29.633779] Finished iteration 403, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2643.906
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:31.801480] Finished iteration 404, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2167.654
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:33.879015] Finished iteration 405, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2077.635
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:35.998455] Finished iteration 406, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2119.299
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:38.094929] Finished iteration 407, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2096.417
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:40.229957] Finished iteration 408, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2135.007
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:42.295390] Finished iteration 409, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2065.474
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:44.369826] Finished iteration 410, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2074.451
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:46.484792] Finished iteration 411, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2114.911
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:48.570025] Finished iteration 412, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2085.220
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:50.666015] Finished iteration 413, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2095.763
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:52.758452] Finished iteration 414, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2092.528
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:54.901786] Finished iteration 415, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2143.362
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:56.952524] Finished iteration 416, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2050.513
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:59.109584] Finished iteration 417, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2157.017
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:01.191297] Finished iteration 418, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2081.687
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:03.269734] Finished iteration 419, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2078.538
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:05.377996] Finished iteration 420, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2108.074
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:07.451209] Finished iteration 421, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2073.353
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:09.588942] Finished iteration 422, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2137.514
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:11.679379] Finished iteration 423, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2090.400
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:13.804757] Finished iteration 424, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2125.414
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:15.915230] Finished iteration 425, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2110.377
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:18.014155] Finished iteration 426, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2098.916
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:20.076043] Finished iteration 427, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2061.827
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:22.179816] Finished iteration 428, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2103.792
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:24.229344] Finished iteration 429, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2049.448
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:26.328545] Finished iteration 430, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2099.224
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:28.394090] Finished iteration 431, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2065.459
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:30.482055] Finished iteration 432, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2088.077
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:32.558371] Finished iteration 433, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2076.098
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:34.699573] Finished iteration 434, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2141.320
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:36.858735] Finished iteration 435, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2158.972
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:39.030597] Finished iteration 436, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2171.901
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:41.155718] Finished iteration 437, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2125.026
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:43.344146] Finished iteration 438, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2188.545
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:45.442808] Finished iteration 439, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2098.493
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:47.579830] Finished iteration 440, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2136.968
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:49.676548] Finished iteration 441, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2096.698
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:51.806268] Finished iteration 442, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2129.721
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:53.888723] Finished iteration 443, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2082.371
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:56.015056] Finished iteration 444, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2126.552
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:58.110586] Finished iteration 445, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2095.220
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:00.204890] Finished iteration 446, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2094.494
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:02.252800] Finished iteration 447, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2047.792
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:04.359809] Finished iteration 448, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2106.803
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:06.471994] Finished iteration 449, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2112.285
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:08.546287] Finished iteration 450, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2074.303
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:10.653417] Finished iteration 451, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2106.899
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:12.834476] Finished iteration 452, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2181.030
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:14.932387] Finished iteration 453, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2098.008
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:17.058605] Finished iteration 454, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2126.209
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:19.116795] Finished iteration 455, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2058.100
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:21.193225] Finished iteration 456, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2076.255
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:24.179974] Finished iteration 457, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2986.849
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:26.272821] Finished iteration 458, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2092.809
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:28.309426] Finished iteration 459, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2036.654
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:30.383984] Finished iteration 460, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2074.457
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:32.482969] Finished iteration 461, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2098.981
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:34.586551] Finished iteration 462, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2103.554
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:36.652252] Finished iteration 463, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2065.581
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:38.783255] Finished iteration 464, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2130.707
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:40.821303] Finished iteration 465, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2038.154
14 Overflow !!
14 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:42.941286] Finished iteration 466, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2119.819
14 Overflow !!
Process done with return code 1
Parent process ID: 21758 node: 172.31.26.140
Killing process on gpu with nvidia-smi | grep 'python' | awk '{ print $5 }' | xargs -n1 kill -9
24 cutpoints
Stages 1
13 20868437708.800007
7 13915698585.599995
10 17153729331.199993
8 14622140211.200005
9 15846820659.199995
Predicted microbatch size for 1: 8
comm size 0
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 1 6 0 1334585.0830078125 0
End of simulation:  Mini-batch time (usec) = 3270291
Min send: 10000000, max send 0
Min long send: 10000000, max long send 0
Min fwd: 10000000, max fwd 0; min bwd 10000000, max bwd 0
Min long fwd: 126112, max long fwd 129698; min long bwd 191031, max long bwd 199310
Time taken by simulation: 55 microseconds

Stages 2
13 10987980083.2
19 14996390399.999996
22 16963644723.199997
20 15631126630.400002
Predicted microbatch size for 2: 19
comm size 9961472
WARNING: no send time found, 2 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 2 5 0 608509.5825195312 542254.6839368516
End of simulation:  Mini-batch time (usec) = 3607863
Min send: 10000000, max send 0
Min long send: 542586, max long send 558986
Min fwd: 106816, max fwd 113936; min bwd 154625, max bwd 157669
Min long fwd: 134083, max long fwd 138081; min long bwd 169664, max long bwd 173713
Time taken by simulation: 114 microseconds

Stages 3
13 7832942284.800001
19 10697074380.8
22 12097432473.599998
23 12575272243.2
24 13035207577.6
Predicted microbatch size for 3: 24
comm size 12582912
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 7 0 441679.38232421875 663682.2411979454
End of simulation:  Mini-batch time (usec) = 5526356
Min send: 10000000, max send 0
Min long send: 664014, max long send 688387
Min fwd: 70473, max fwd 86449; min bwd 116125, max bwd 131549
Min long fwd: 107949, max long fwd 111566; min long bwd 147972, max long bwd 154852
Time taken by simulation: 234 microseconds

Stages 4
13 6255423385.6
19 8547416371.2
22 9664326348.8
23 10045446451.2
24 10412856422.4
Predicted microbatch size for 4: 24
comm size 12582912
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 9 0 322485.90087890625 663682.2411979454
End of simulation:  Mini-batch time (usec) = 6859347
Min send: 10000000, max send 0
Min long send: 663764, max long send 686148
Min fwd: 51765, max fwd 67812; min bwd 84974, max bwd 98885
Min long fwd: 83336, max long fwd 90554; min long bwd 118409, max long bwd 124254
Time taken by simulation: 433 microseconds

Stages 6
13 4698582732.8
19 6397758361.599999
22 7231220224.0
23 7515620659.2
24 7790505267.2
Predicted microbatch size for 6: 24
comm size 12582912
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 15 0 205807.43408203125 663682.2411979454
End of simulation:  Mini-batch time (usec) = 11152793
Min send: 10000000, max send 0
Min long send: 663736, max long send 688387
Min fwd: 32603, max fwd 47172; min bwd 54003, max bwd 69793
Min long fwd: 66617, max long fwd 70492; min long bwd 81618, max long bwd 89601
Time taken by simulation: 1067 microseconds

Stages 8
13 3930501529.6000004
19 5322929356.799999
22 6014667161.6
23 6250707763.2
24 6479329689.6
Predicted microbatch size for 8: 24
comm size 12582912
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 22 0 120660.06469726562 663682.2411979454
End of simulation:  Mini-batch time (usec) = 15792286
Min send: 10000000, max send 0
Min long send: 663682, max long send 690844
Min fwd: 23237, max fwd 38139; min bwd 35712, max bwd 56890
Min long fwd: 51613, max long fwd 57677; min long bwd 69478, max long bwd 76496
Time taken by simulation: 2173 microseconds

Stages 12
13 3141742080.0
19 4248100352.0
22 4798114099.200001
23 4985794867.2
24 5168154112.0
Predicted microbatch size for 12: 24
comm size 12582912
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 43 0 0 663682.2411979454
End of simulation:  Mini-batch time (usec) = 28245316
Min send: 10000000, max send 0
Min long send: 663682, max long send 693511
Min fwd: 10606, max fwd 31119; min bwd 22396, max bwd 41317
Min long fwd: 40838, max long fwd 49874; min long bwd 47936, max long bwd 55473
Time taken by simulation: 6932 microseconds

{1: 3.270291, 2: 3.607863, 3: 5.526356, 4: 6.859347, 6: 11.152793, 8: 15.792286, 12: 28.245316}
{1: 8, 2: 19, 3: 24, 4: 24, 6: 24, 8: 24, 12: 24}
best config is: 2 19
expected time is 3.607863
11 per stage
22 servers!
Config:
ranks: range(14, 15)
train batch size: 1024
partitions: 2
chunk_size: 19
data depth: 11
stage to rank map: 0,2,4,6,8,10,12,14,16,18,20;1,3,5,7,9,11,13,15,17,19,21;
World size is 22
/opt/conda/envs/varuna/bin/python -u /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --rank=14 --chunk_size=19 --local_rank=0 --stage_to_rank_map=0,2,4,6,8,10,12,14,16,18,20;1,3,5,7,9,11,13,15,17,19,21; --batch-size=93 --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna --resume_step 380
device: cuda:0 n_gpu: 1, distributed training: True, 16-bits training: True
dry run time 0.050171852111816406
SHARED WEIGHTS ARE
[(0, 1)]
this rank  14 is part of pipeline replica  7
5 chunks
Begin to load checkpint from s3://spot-checkpoints/bert/ckpt_380.pt
2022-11-24 14:32:07.134661 resume step from  380
