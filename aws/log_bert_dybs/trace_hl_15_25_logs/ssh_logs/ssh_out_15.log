Parent process ID: 15846 node: 172.31.19.112
24 cutpoints
Stages 1
13 20868437708.800007
7 13915698585.599995
10 17153729331.199993
8 14622140211.200005
9 15846820659.199995
Predicted microbatch size for 1: 8
comm size 0
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 1 5 0 1286522.0947265625 0
End of simulation:  Mini-batch time (usec) = 2905085
Min send: 10000000, max send 0
Min long send: 10000000, max long send 0
Min fwd: 10000000, max fwd 0; min bwd 10000000, max bwd 0
Min long fwd: 126283, max long fwd 129698; min long bwd 193190, max long bwd 199310
Time taken by simulation: 45 microseconds

Stages 2
13 10987980083.2
19 14996390399.999996
22 16963644723.199997
20 15631126630.400002
Predicted microbatch size for 2: 19
comm size 9961472
WARNING: no send time found, 2 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 2 5 0 635506.6528320312 542254.6839368516
End of simulation:  Mini-batch time (usec) = 3634860
Min send: 10000000, max send 0
Min long send: 542586, max long send 558986
Min fwd: 106816, max fwd 113936; min bwd 154625, max bwd 157669
Min long fwd: 134083, max long fwd 138081; min long bwd 169664, max long bwd 173713
Time taken by simulation: 118 microseconds

Stages 3
13 7832942284.800001
19 10697074380.8
22 12097432473.599998
23 12575272243.2
24 13035207577.6
Predicted microbatch size for 3: 24
comm size 12582912
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 5 0 443515.80810546875 663682.2411979454
End of simulation:  Mini-batch time (usec) = 4988556
Min send: 10000000, max send 0
Min long send: 664014, max long send 679713
Min fwd: 72258, max fwd 88035; min bwd 119079, max bwd 130804
Min long fwd: 107414, max long fwd 112703; min long bwd 150032, max long bwd 153679
Time taken by simulation: 179 microseconds

Stages 4
13 6255423385.6
19 8547416371.2
22 9664326348.8
23 10045446451.2
24 10412856422.4
Predicted microbatch size for 4: 24
comm size 12582912
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 8 0 326449.15771484375 663682.2411979454
End of simulation:  Mini-batch time (usec) = 6677364
Min send: 10000000, max send 0
Min long send: 663870, max long send 686148
Min fwd: 51765, max fwd 66948; min bwd 85303, max bwd 98547
Min long fwd: 83336, max long fwd 91250; min long bwd 118529, max long bwd 127083
Time taken by simulation: 368 microseconds

Stages 6
13 4698582732.8
19 6397758361.599999
22 7231220224.0
23 7515620659.2
24 7790505267.2
Predicted microbatch size for 6: 24
comm size 12582912
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 11 0 240705.6121826172 663682.2411979454
End of simulation:  Mini-batch time (usec) = 9735715
Min send: 10000000, max send 0
Min long send: 663764, max long send 689782
Min fwd: 32942, max fwd 48168; min bwd 55337, max bwd 68897
Min long fwd: 65982, max long fwd 73316; min long bwd 85277, max long bwd 90311
Time taken by simulation: 890 microseconds

Stages 8
13 3930501529.6000004
19 5322929356.799999
22 6014667161.6
23 6250707763.2
24 6479329689.6
Predicted microbatch size for 8: 24
comm size 12582912
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 15 0 176039.7491455078 663682.2411979454
End of simulation:  Mini-batch time (usec) = 13724566
Min send: 10000000, max send 0
Min long send: 663736, max long send 690844
Min fwd: 22801, max fwd 38139; min bwd 36151, max bwd 55503
Min long fwd: 51106, max long fwd 59884; min long bwd 68124, max long bwd 75476
Time taken by simulation: 1537 microseconds

Stages 12
13 3141742080.0
19 4248100352.0
22 4798114099.200001
23 4985794867.2
24 5168154112.0
Predicted microbatch size for 12: 24
comm size 12582912
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 22 0 97192.52014160156 663682.2411979454
End of simulation:  Mini-batch time (usec) = 21189724
Min send: 10000000, max send 0
Min long send: 663682, max long send 690844
Min fwd: 10724, max fwd 28920; min bwd 23319, max bwd 41964
Min long fwd: 40826, max long fwd 50474; min long bwd 49192, max long bwd 58811
Time taken by simulation: 3404 microseconds

{1: 2.905085, 2: 3.63486, 3: 4.988556, 4: 6.677364, 6: 9.735715, 8: 13.724566, 12: 21.189724}
{1: 8, 2: 19, 3: 24, 4: 24, 6: 24, 8: 24, 12: 24}
best config is: 2 19
expected time is 3.63486
13 per stage
26 servers!
Config:
ranks: range(15, 16)
train batch size: 1024
partitions: 2
chunk_size: 19
data depth: 13
stage to rank map: 0,2,4,6,8,10,12,14,16,18,20,22,24;1,3,5,7,9,11,13,15,17,19,21,23,25;
World size is 26
/opt/conda/envs/varuna/bin/python -u /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --rank=15 --chunk_size=19 --local_rank=0 --stage_to_rank_map=0,2,4,6,8,10,12,14,16,18,20,22,24;1,3,5,7,9,11,13,15,17,19,21,23,25; --batch-size=78 --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna
device: cuda:0 n_gpu: 1, distributed training: True, 16-bits training: True
dry run time 0.13799285888671875
SHARED WEIGHTS ARE
[(0, 1)]
this rank  15 is part of pipeline replica  7
5 chunks
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  524288.0
[2022-11-24 13:53:10.904634] Finished iteration 0, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5379.731
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  262144.0
[2022-11-24 13:53:13.226025] Finished iteration 1, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2321.272
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  131072.0
[2022-11-24 13:53:16.602157] Finished iteration 2, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3375.991
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  65536.0
[2022-11-24 13:53:18.981133] Finished iteration 3, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2378.808
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  32768.0
[2022-11-24 13:53:22.304709] Finished iteration 4, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3323.780
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  16384.0
[2022-11-24 13:53:24.665207] Finished iteration 5, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2360.244
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  8192.0
[2022-11-24 13:53:26.924558] Finished iteration 6, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2259.303
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  4096.0
[2022-11-24 13:53:29.273915] Finished iteration 7, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2349.296
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  2048.0
[2022-11-24 13:53:31.593570] Finished iteration 8, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2319.628
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1024.0
[2022-11-24 13:53:33.927106] Finished iteration 9, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2333.654
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  512.0
[2022-11-24 13:53:36.245293] Finished iteration 10, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2318.131
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  256.0
[2022-11-24 13:53:38.521938] Finished iteration 11, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2276.670
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  128.0
[2022-11-24 13:53:40.861386] Finished iteration 12, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2339.185
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  64.0
[2022-11-24 13:53:43.160794] Finished iteration 13, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2299.513
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  32.0
[2022-11-24 13:53:45.443560] Finished iteration 14, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2282.585
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  16.0
[2022-11-24 13:53:47.775513] Finished iteration 15, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2332.096
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  8.0
[2022-11-24 13:53:50.044163] Finished iteration 16, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2268.462
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  4.0
[2022-11-24 13:53:52.348694] Finished iteration 17, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2304.472
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  2.0
[2022-11-24 13:53:54.689603] Finished iteration 18, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2340.930
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:53:56.994723] Finished iteration 19, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2305.203
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:53:59.271612] Finished iteration 20, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2276.707
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:01.597944] Finished iteration 21, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2326.254
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:03.910371] Finished iteration 22, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2312.401
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:06.192502] Finished iteration 23, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2282.248
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:08.480394] Finished iteration 24, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2287.868
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:10.771337] Finished iteration 25, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2290.736
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:13.097424] Finished iteration 26, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2326.040
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:15.414817] Finished iteration 27, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2317.374
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:17.756718] Finished iteration 28, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2341.872
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:20.934419] Finished iteration 29, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3177.798
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:23.192165] Finished iteration 30, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2257.788
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:25.535006] Finished iteration 31, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2342.581
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:27.806225] Finished iteration 32, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2271.211
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:30.119687] Finished iteration 33, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2313.523
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:32.457956] Finished iteration 34, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2338.108
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:34.753771] Finished iteration 35, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2295.779
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:37.086223] Finished iteration 36, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2332.487
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:39.414458] Finished iteration 37, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2328.378
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:41.742064] Finished iteration 38, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2327.326
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:44.088658] Finished iteration 39, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2346.593
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:46.425448] Finished iteration 40, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2336.695
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:48.708249] Finished iteration 41, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2282.892
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:51.034874] Finished iteration 42, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2326.598
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:53.400229] Finished iteration 43, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2365.143
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:55.734358] Finished iteration 44, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2334.164
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:54:58.076718] Finished iteration 45, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2342.261
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:00.404522] Finished iteration 46, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2327.782
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:02.714501] Finished iteration 47, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2309.943
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:04.979326] Finished iteration 48, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2264.777
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:07.344123] Finished iteration 49, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2364.943
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:09.647881] Finished iteration 50, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2303.557
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:11.988845] Finished iteration 51, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2340.924
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:14.279294] Finished iteration 52, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2290.425
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:16.597931] Finished iteration 53, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2318.669
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:18.897991] Finished iteration 54, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2299.960
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:21.187349] Finished iteration 55, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2289.360
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:23.502811] Finished iteration 56, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2315.533
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:25.827811] Finished iteration 57, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2324.994
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:28.186231] Finished iteration 58, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2358.267
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:30.532208] Finished iteration 59, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2345.905
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:32.829911] Finished iteration 60, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2297.766
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:35.139618] Finished iteration 61, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2309.530
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:37.440211] Finished iteration 62, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2300.567
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:39.787650] Finished iteration 63, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2347.410
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:42.120178] Finished iteration 64, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2332.630
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:44.418525] Finished iteration 65, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2298.183
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:46.770920] Finished iteration 66, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2352.396
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:49.191287] Finished iteration 67, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2420.333
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:51.491498] Finished iteration 68, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2300.303
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:53.849990] Finished iteration 69, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2358.437
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:56.181257] Finished iteration 70, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2331.089
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:55:58.515168] Finished iteration 71, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2333.892
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:00.836150] Finished iteration 72, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2321.151
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:03.147155] Finished iteration 73, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2310.744
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:05.454049] Finished iteration 74, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2306.815
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:07.713535] Finished iteration 75, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2259.438
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:10.014545] Finished iteration 76, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2301.058
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:12.350477] Finished iteration 77, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2335.849
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:14.716039] Finished iteration 78, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2365.524
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:17.015354] Finished iteration 79, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2299.273
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:19.354278] Finished iteration 80, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2338.955
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:21.654860] Finished iteration 81, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2300.524
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:23.923084] Finished iteration 82, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2268.284
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:26.185540] Finished iteration 83, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2262.337
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:28.490826] Finished iteration 84, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2305.192
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:30.774474] Finished iteration 85, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2283.752
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:33.082432] Finished iteration 86, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2307.785
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:35.317804] Finished iteration 87, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2235.465
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:37.614346] Finished iteration 88, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2296.382
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:40.012779] Finished iteration 89, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2398.480
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:42.286917] Finished iteration 90, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2274.027
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:44.563978] Finished iteration 91, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2277.163
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:46.893384] Finished iteration 92, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2329.350
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:49.210002] Finished iteration 93, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2316.635
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:51.537741] Finished iteration 94, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2327.644
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:53.829390] Finished iteration 95, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2291.569
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:56.156722] Finished iteration 96, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2327.290
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:56:58.425075] Finished iteration 97, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2268.180
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:00.731865] Finished iteration 98, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2306.754
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:03.058528] Finished iteration 99, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2326.691
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:05.417134] Finished iteration 100, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2358.522
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:07.734428] Finished iteration 101, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2317.260
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:10.039548] Finished iteration 102, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2305.155
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:12.336698] Finished iteration 103, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2297.079
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:14.652356] Finished iteration 104, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2315.731
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:16.986571] Finished iteration 105, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2334.103
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:19.274498] Finished iteration 106, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2287.963
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:21.530069] Finished iteration 107, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2255.373
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:23.815000] Finished iteration 108, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2284.960
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:26.106933] Finished iteration 109, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2291.885
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:28.392573] Finished iteration 110, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2285.576
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:30.654787] Finished iteration 111, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2262.169
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:32.998305] Finished iteration 112, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2343.671
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:35.345339] Finished iteration 113, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2346.967
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:37.637496] Finished iteration 114, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2291.979
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:39.981771] Finished iteration 115, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2344.218
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:42.295629] Finished iteration 116, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2313.842
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:44.582680] Finished iteration 117, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2287.006
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:46.895768] Finished iteration 118, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2313.067
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:49.147354] Finished iteration 119, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2251.547
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:51.373785] Finished iteration 120, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2226.476
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:53.646747] Finished iteration 121, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2272.854
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:55.966770] Finished iteration 122, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2320.016
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:57:58.360418] Finished iteration 123, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2393.622
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:00.674557] Finished iteration 124, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2314.072
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:02.967885] Finished iteration 125, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2293.469
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:05.278695] Finished iteration 126, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2310.730
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:07.637708] Finished iteration 127, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2358.838
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:10.022431] Finished iteration 128, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2384.733
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:12.364332] Finished iteration 129, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2341.849
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:14.748704] Finished iteration 130, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2384.449
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:17.064143] Finished iteration 131, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2315.393
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:19.365912] Finished iteration 132, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2301.773
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:21.680776] Finished iteration 133, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2314.612
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:24.035993] Finished iteration 134, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2355.344
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:26.391682] Finished iteration 135, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2355.490
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:28.675274] Finished iteration 136, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2283.577
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:31.003514] Finished iteration 137, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2328.175
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:33.311480] Finished iteration 138, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2307.939
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:35.585070] Finished iteration 139, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2273.556
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:37.883105] Finished iteration 140, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2298.133
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:40.182834] Finished iteration 141, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2299.561
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:42.518870] Finished iteration 142, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2336.002
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 13:58:44.825520] Finished iteration 143, CKPT_AND_STOP: False, flag: tensor([1], dtype=torch.int32), speed: 2306.775
2022-11-24 13:58:44.834689 Begin to save checkpont to s3://spot-checkpoints/bert and exit
Opt ckpt time 4.713567733764648
Process done with return code 0
Parent process ID: 16551 node: 172.31.19.112
24 cutpoints
Stages 1
13 20868437708.800007
7 13915698585.599995
10 17153729331.199993
8 14622140211.200005
9 15846820659.199995
Predicted microbatch size for 1: 8
comm size 0
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 1 5 0 1286522.0947265625 0
End of simulation:  Mini-batch time (usec) = 2905085
Min send: 10000000, max send 0
Min long send: 10000000, max long send 0
Min fwd: 10000000, max fwd 0; min bwd 10000000, max bwd 0
Min long fwd: 126283, max long fwd 129698; min long bwd 193190, max long bwd 199310
Time taken by simulation: 47 microseconds

Stages 2
13 10987980083.2
19 14996390399.999996
22 16963644723.199997
20 15631126630.400002
Predicted microbatch size for 2: 19
comm size 9961472
WARNING: no send time found, 2 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 2 4 0 645340.8203125 542254.6839368516
End of simulation:  Mini-batch time (usec) = 3338780
Min send: 10000000, max send 0
Min long send: 542586, max long send 555338
Min fwd: 107744, max fwd 113936; min bwd 155753, max bwd 158782
Min long fwd: 131842, max long fwd 138676; min long bwd 169332, max long bwd 173300
Time taken by simulation: 104 microseconds

Stages 3
13 7832942284.800001
19 10697074380.8
22 12097432473.599998
23 12575272243.2
24 13035207577.6
Predicted microbatch size for 3: 24
comm size 12582912
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 5 0 443515.80810546875 663682.2411979454
End of simulation:  Mini-batch time (usec) = 4988556
Min send: 10000000, max send 0
Min long send: 664014, max long send 679713
Min fwd: 72258, max fwd 88035; min bwd 119079, max bwd 130804
Min long fwd: 107414, max long fwd 112703; min long bwd 150032, max long bwd 153679
Time taken by simulation: 169 microseconds

Stages 4
13 6255423385.6
19 8547416371.2
22 9664326348.8
23 10045446451.2
24 10412856422.4
Predicted microbatch size for 4: 24
comm size 12582912
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 7 0 358221.00830078125 663682.2411979454
End of simulation:  Mini-batch time (usec) = 6464795
Min send: 10000000, max send 0
Min long send: 663870, max long send 683729
Min fwd: 53924, max fwd 67812; min bwd 83975, max bwd 97299
Min long fwd: 86081, max long fwd 91318; min long bwd 118237, max long bwd 121834
Time taken by simulation: 348 microseconds

Stages 6
13 4698582732.8
19 6397758361.599999
22 7231220224.0
23 7515620659.2
24 7790505267.2
Predicted microbatch size for 6: 24
comm size 12582912
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 11 0 240705.6121826172 663682.2411979454
End of simulation:  Mini-batch time (usec) = 9735715
Min send: 10000000, max send 0
Min long send: 663764, max long send 689782
Min fwd: 32942, max fwd 48168; min bwd 55337, max bwd 68897
Min long fwd: 65982, max long fwd 73316; min long bwd 85277, max long bwd 90311
Time taken by simulation: 804 microseconds

Stages 8
13 3930501529.6000004
19 5322929356.799999
22 6014667161.6
23 6250707763.2
24 6479329689.6
Predicted microbatch size for 8: 24
comm size 12582912
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 15 0 176039.7491455078 663682.2411979454
End of simulation:  Mini-batch time (usec) = 13724566
Min send: 10000000, max send 0
Min long send: 663736, max long send 690844
Min fwd: 22801, max fwd 38139; min bwd 36151, max bwd 55503
Min long fwd: 51106, max long fwd 59884; min long bwd 68124, max long bwd 75476
Time taken by simulation: 1503 microseconds

Stages 12
13 3141742080.0
19 4248100352.0
22 4798114099.200001
23 4985794867.2
24 5168154112.0
Predicted microbatch size for 12: 24
comm size 12582912
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 22 0 97192.52014160156 663682.2411979454
End of simulation:  Mini-batch time (usec) = 21189724
Min send: 10000000, max send 0
Min long send: 663682, max long send 690844
Min fwd: 10724, max fwd 28920; min bwd 23319, max bwd 41964
Min long fwd: 40826, max long fwd 50474; min long bwd 49192, max long bwd 58811
Time taken by simulation: 3395 microseconds

{1: 2.905085, 2: 3.33878, 3: 4.988556, 4: 6.464795, 6: 9.735715, 8: 13.724566, 12: 21.189724}
{1: 8, 2: 19, 3: 24, 4: 24, 6: 24, 8: 24, 12: 24}
best config is: 2 19
expected time is 3.33878
14 per stage
28 servers!
Config:
ranks: range(15, 16)
train batch size: 1024
partitions: 2
chunk_size: 19
data depth: 14
stage to rank map: 0,2,4,6,8,10,12,14,16,18,20,22,24,26;1,3,5,7,9,11,13,15,17,19,21,23,25,27;
World size is 28
/opt/conda/envs/varuna/bin/python -u /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --rank=15 --chunk_size=19 --local_rank=0 --stage_to_rank_map=0,2,4,6,8,10,12,14,16,18,20,22,24,26;1,3,5,7,9,11,13,15,17,19,21,23,25,27; --batch-size=73 --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna --resume_step 144
device: cuda:0 n_gpu: 1, distributed training: True, 16-bits training: True
dry run time 0.1580061912536621
SHARED WEIGHTS ARE
[(0, 1)]
this rank  15 is part of pipeline replica  7
4 chunks
Begin to load checkpint from s3://spot-checkpoints/bert/ckpt_144.pt
2022-11-24 13:59:22.860217 resume step from  144
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 15 signal handler called with signal 10
2022-11-24 14:00:24.847698 - Finished loading checkpoint, takes 61.934 secs
2022-11-24 14:00:31.374714 Begin to exit
Process done with return code 0
Parent process ID: 17840 node: 172.31.19.112
24 cutpoints
Stages 1
13 20868437708.800007
7 13915698585.599995
10 17153729331.199993
8 14622140211.200005
9 15846820659.199995
Predicted microbatch size for 1: 8
comm size 0
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 1 4 0 3150942.3828125 0
End of simulation:  Mini-batch time (usec) = 4450032
Min send: 10000000, max send 0
Min long send: 10000000, max long send 0
Min fwd: 10000000, max fwd 0; min bwd 10000000, max bwd 0
Min long fwd: 127414, max long fwd 129698; min long bwd 194806, max long bwd 199310
Time taken by simulation: 39 microseconds

Stages 2
13 10987980083.2
19 14996390399.999996
22 16963644723.199997
20 15631126630.400002
Predicted microbatch size for 2: 19
comm size 9961472
WARNING: no send time found, 2 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 2 4 0 673273.3154296875 542254.6839368516
End of simulation:  Mini-batch time (usec) = 3366713
Min send: 10000000, max send 0
Min long send: 542586, max long send 555338
Min fwd: 107744, max fwd 113936; min bwd 155753, max bwd 158782
Min long fwd: 131842, max long fwd 138676; min long bwd 169332, max long bwd 173300
Time taken by simulation: 95 microseconds

Stages 3
13 7832942284.800001
19 10697074380.8
22 12097432473.599998
23 12575272243.2
24 13035207577.6
Predicted microbatch size for 3: 24
comm size 12582912
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 5 0 448996.58203125 663682.2411979454
End of simulation:  Mini-batch time (usec) = 4994037
Min send: 10000000, max send 0
Min long send: 664014, max long send 679713
Min fwd: 72258, max fwd 88035; min bwd 119079, max bwd 130804
Min long fwd: 107414, max long fwd 112703; min long bwd 150032, max long bwd 153679
Time taken by simulation: 167 microseconds

Stages 4
13 6255423385.6
19 8547416371.2
22 9664326348.8
23 10045446451.2
24 10412856422.4
Predicted microbatch size for 4: 24
comm size 12582912
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 6 0 375752.13623046875 663682.2411979454
End of simulation:  Mini-batch time (usec) = 6314108
Min send: 10000000, max send 0
Min long send: 663764, max long send 688387
Min fwd: 53924, max fwd 66948; min bwd 83975, max bwd 98046
Min long fwd: 84759, max long fwd 91250; min long bwd 120659, max long bwd 125455
Time taken by simulation: 279 microseconds

Stages 6
13 4698582732.8
19 6397758361.599999
22 7231220224.0
23 7515620659.2
24 7790505267.2
Predicted microbatch size for 6: 24
comm size 12582912
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 9 0 241996.6583251953 663682.2411979454
End of simulation:  Mini-batch time (usec) = 9164548
Min send: 10000000, max send 0
Min long send: 663736, max long send 687371
Min fwd: 33746, max fwd 47347; min bwd 54554, max bwd 72477
Min long fwd: 65864, max long fwd 73316; min long bwd 84274, max long bwd 89413
Time taken by simulation: 634 microseconds

Stages 8
13 3930501529.6000004
19 5322929356.799999
22 6014667161.6
23 6250707763.2
24 6479329689.6
Predicted microbatch size for 8: 24
comm size 12582912
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 11 0 214379.08935546875 663682.2411979454
End of simulation:  Mini-batch time (usec) = 12421079
Min send: 10000000, max send 0
Min long send: 663682, max long send 689782
Min fwd: 22992, max fwd 37161; min bwd 37517, max bwd 55449
Min long fwd: 51419, max long fwd 57045; min long bwd 68935, max long bwd 77274
Time taken by simulation: 1047 microseconds

Stages 12
13 3141742080.0
19 4248100352.0
22 4798114099.200001
23 4985794867.2
24 5168154112.0
Predicted microbatch size for 12: 24
comm size 12582912
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 22 0 97192.52014160156 663682.2411979454
End of simulation:  Mini-batch time (usec) = 21189724
Min send: 10000000, max send 0
Min long send: 663682, max long send 690844
Min fwd: 10724, max fwd 28920; min bwd 23319, max bwd 41964
Min long fwd: 40826, max long fwd 50474; min long bwd 49192, max long bwd 58811
Time taken by simulation: 3396 microseconds

{1: 4.450032, 2: 3.366713, 3: 4.994037, 4: 6.314108, 6: 9.164548, 8: 12.421079, 12: 21.189724}
{1: 8, 2: 19, 3: 24, 4: 24, 6: 24, 8: 24, 12: 24}
best config is: 2 19
expected time is 3.366713
16 per stage
32 servers!
Config:
ranks: range(15, 16)
train batch size: 1024
partitions: 2
chunk_size: 19
data depth: 16
stage to rank map: 0,2,4,6,8,10,12,14,16,18,20,22,24,26,28,30;1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31;
World size is 32
/opt/conda/envs/varuna/bin/python -u /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --rank=15 --chunk_size=19 --local_rank=0 --stage_to_rank_map=0,2,4,6,8,10,12,14,16,18,20,22,24,26,28,30;1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31; --batch-size=64 --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna --resume_step 144
device: cuda:0 n_gpu: 1, distributed training: True, 16-bits training: True
dry run time 0.1161797046661377
SHARED WEIGHTS ARE
[(0, 1)]
this rank  15 is part of pipeline replica  7
4 chunks
Begin to load checkpint from s3://spot-checkpoints/bert/ckpt_144.pt
2022-11-24 14:00:52.840046 resume step from  144
2022-11-24 14:02:20.736846 - Finished loading checkpoint, takes 87.744 secs
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  524288.0
[2022-11-24 14:02:26.489910] Finished iteration 144, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5695.900
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  262144.0
[2022-11-24 14:02:29.716374] Finished iteration 145, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3226.406
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  131072.0
[2022-11-24 14:02:32.849248] Finished iteration 146, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3132.653
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  65536.0
[2022-11-24 14:02:35.991743] Finished iteration 147, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3142.611
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  32768.0
[2022-11-24 14:02:39.101592] Finished iteration 148, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3109.784
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  16384.0
[2022-11-24 14:02:41.200751] Finished iteration 149, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2098.858
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  8192.0
[2022-11-24 14:02:43.336260] Finished iteration 150, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2135.648
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  4096.0
[2022-11-24 14:02:45.389425] Finished iteration 151, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2052.947
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  2048.0
[2022-11-24 14:02:47.490791] Finished iteration 152, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2101.479
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1024.0
[2022-11-24 14:02:49.608425] Finished iteration 153, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2117.573
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  512.0
[2022-11-24 14:02:51.708393] Finished iteration 154, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2099.971
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  256.0
[2022-11-24 14:02:53.786393] Finished iteration 155, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2077.902
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  128.0
[2022-11-24 14:02:55.939003] Finished iteration 156, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2152.608
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  64.0
[2022-11-24 14:02:58.043969] Finished iteration 157, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2104.787
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  32.0
[2022-11-24 14:03:00.148386] Finished iteration 158, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2104.352
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  16.0
[2022-11-24 14:03:02.262518] Finished iteration 159, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2114.121
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  8.0
[2022-11-24 14:03:04.354701] Finished iteration 160, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2092.145
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  4.0
[2022-11-24 14:03:06.507974] Finished iteration 161, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2153.255
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  2.0
[2022-11-24 14:03:08.602079] Finished iteration 162, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2094.315
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:11.888623] Finished iteration 163, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3286.229
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:14.006408] Finished iteration 164, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2117.788
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:16.134512] Finished iteration 165, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2128.068
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:18.235149] Finished iteration 166, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2100.552
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:20.376697] Finished iteration 167, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2141.544
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:22.444277] Finished iteration 168, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2067.564
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:24.590253] Finished iteration 169, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2145.946
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:26.736626] Finished iteration 170, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2146.424
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:28.898363] Finished iteration 171, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2161.695
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:31.040785] Finished iteration 172, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2142.499
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:33.201716] Finished iteration 173, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2160.764
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:35.286305] Finished iteration 174, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2084.539
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:37.401848] Finished iteration 175, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2115.346
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:39.478465] Finished iteration 176, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2076.727
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:41.592320] Finished iteration 177, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2113.673
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:43.754604] Finished iteration 178, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2162.383
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:45.954541] Finished iteration 179, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2199.754
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:48.049908] Finished iteration 180, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2095.513
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:50.180034] Finished iteration 181, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2130.069
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:52.294895] Finished iteration 182, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2114.769
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:54.410712] Finished iteration 183, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2115.776
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:56.556288] Finished iteration 184, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2145.407
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:03:58.643117] Finished iteration 185, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2086.756
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:00.755264] Finished iteration 186, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2112.351
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:02.903676] Finished iteration 187, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2148.157
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:04.988329] Finished iteration 188, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2084.716
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:07.123352] Finished iteration 189, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2134.977
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:09.251111] Finished iteration 190, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2127.605
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:11.353731] Finished iteration 191, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2102.591
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:13.486851] Finished iteration 192, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2133.098
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:15.597466] Finished iteration 193, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2110.677
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:17.697993] Finished iteration 194, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2100.345
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:19.827382] Finished iteration 195, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2129.522
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:21.956075] Finished iteration 196, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2128.498
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:24.112840] Finished iteration 197, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2156.739
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:26.181257] Finished iteration 198, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2068.376
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:28.230977] Finished iteration 199, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2049.819
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:30.356535] Finished iteration 200, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2125.369
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:32.471573] Finished iteration 201, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2115.014
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:34.591325] Finished iteration 202, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2119.750
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:36.705434] Finished iteration 203, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2114.183
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:38.817590] Finished iteration 204, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2111.963
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:41.278022] Finished iteration 205, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2460.526
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:43.728304] Finished iteration 206, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2450.115
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:45.868670] Finished iteration 207, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2140.359
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:49.106748] Finished iteration 208, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3238.104
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:51.567660] Finished iteration 209, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2460.941
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:53.752610] Finished iteration 210, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2184.902
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:55.855429] Finished iteration 211, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2102.753
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:04:57.915046] Finished iteration 212, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2059.480
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:00.059010] Finished iteration 213, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2143.916
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:02.198982] Finished iteration 214, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2140.188
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:04.276122] Finished iteration 215, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2076.816
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:06.410907] Finished iteration 216, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2134.770
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:08.543019] Finished iteration 217, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2132.068
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:10.632373] Finished iteration 218, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2089.324
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:12.760641] Finished iteration 219, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2128.374
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:14.889367] Finished iteration 220, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2128.673
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:16.966508] Finished iteration 221, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2077.120
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:19.083978] Finished iteration 222, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2117.349
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:21.198232] Finished iteration 223, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2114.295
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:23.321904] Finished iteration 224, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2123.760
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:25.455190] Finished iteration 225, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2132.979
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:27.575279] Finished iteration 226, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2120.136
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:29.673312] Finished iteration 227, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2097.985
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:31.831955] Finished iteration 228, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2158.463
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:33.996694] Finished iteration 229, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2164.855
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:36.151180] Finished iteration 230, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2154.451
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:38.253299] Finished iteration 231, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2102.044
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:40.369134] Finished iteration 232, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2115.788
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:42.484066] Finished iteration 233, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2114.755
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:44.596534] Finished iteration 234, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2112.583
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:46.746442] Finished iteration 235, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2149.709
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:48.840504] Finished iteration 236, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2094.038
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:50.952986] Finished iteration 237, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2112.648
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:53.032329] Finished iteration 238, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2079.333
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:55.131682] Finished iteration 239, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2099.232
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:05:57.224224] Finished iteration 240, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2092.299
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:00.133892] Finished iteration 241, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2909.631
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:02.247061] Finished iteration 242, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2113.198
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:04.372570] Finished iteration 243, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2125.539
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:06.468527] Finished iteration 244, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2095.775
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:08.569986] Finished iteration 245, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2101.452
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:10.730040] Finished iteration 246, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2160.178
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:12.786036] Finished iteration 247, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2055.815
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:14.889654] Finished iteration 248, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2103.575
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:17.011846] Finished iteration 249, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2122.269
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:19.118073] Finished iteration 250, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2106.029
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:21.218292] Finished iteration 251, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2100.341
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:23.339340] Finished iteration 252, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2120.858
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:25.427738] Finished iteration 253, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2088.364
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:27.534575] Finished iteration 254, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2106.962
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:29.639229] Finished iteration 255, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2104.587
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:31.760366] Finished iteration 256, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2120.996
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:33.949958] Finished iteration 257, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2189.739
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:36.046684] Finished iteration 258, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2096.477
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:38.098883] Finished iteration 259, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2052.378
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:40.172452] Finished iteration 260, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2073.269
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:42.338126] Finished iteration 261, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2165.685
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:44.435306] Finished iteration 262, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2097.113
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:46.529184] Finished iteration 263, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2093.990
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:48.623434] Finished iteration 264, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2094.198
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:50.764702] Finished iteration 265, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2141.227
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:52.906473] Finished iteration 266, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2141.740
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:55.000872] Finished iteration 267, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2094.197
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:57.069242] Finished iteration 268, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2068.489
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:06:59.209176] Finished iteration 269, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2139.864
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:07:01.335260] Finished iteration 270, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2126.065
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:07:03.424306] Finished iteration 271, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2088.840
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:07:05.553066] Finished iteration 272, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2128.725
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:07:07.619287] Finished iteration 273, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2066.355
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:07:09.660945] Finished iteration 274, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2041.449
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:07:11.775946] Finished iteration 275, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2115.120
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:07:13.951515] Finished iteration 276, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2175.511
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:07:16.757912] Finished iteration 277, CKPT_AND_STOP: False, flag: tensor([2], dtype=torch.int32), speed: 2806.279
2022-11-24 14:07:16.762972 Begin to save checkpont to s3://spot-checkpoints/bert and exit
Opt ckpt time 3.95981502532959
Process done with return code 0
Parent process ID: 19472 node: 172.31.19.112
24 cutpoints
Stages 1
13 20868437708.800007
7 13915698585.599995
10 17153729331.199993
8 14622140211.200005
9 15846820659.199995
Predicted microbatch size for 1: 8
comm size 0
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 1 5 0 1286522.0947265625 0
End of simulation:  Mini-batch time (usec) = 2905085
Min send: 10000000, max send 0
Min long send: 10000000, max long send 0
Min fwd: 10000000, max fwd 0; min bwd 10000000, max bwd 0
Min long fwd: 126283, max long fwd 129698; min long bwd 193190, max long bwd 199310
Time taken by simulation: 46 microseconds

Stages 2
13 10987980083.2
19 14996390399.999996
22 16963644723.199997
20 15631126630.400002
Predicted microbatch size for 2: 19
comm size 9961472
WARNING: no send time found, 2 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 2 4 0 638222.2290039062 542254.6839368516
End of simulation:  Mini-batch time (usec) = 3331662
Min send: 10000000, max send 0
Min long send: 542586, max long send 555338
Min fwd: 107744, max fwd 113936; min bwd 155753, max bwd 158782
Min long fwd: 131842, max long fwd 138676; min long bwd 169332, max long bwd 173300
Time taken by simulation: 96 microseconds

Stages 3
13 7832942284.800001
19 10697074380.8
22 12097432473.599998
23 12575272243.2
24 13035207577.6
Predicted microbatch size for 3: 24
comm size 12582912
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 5 0 448996.58203125 663682.2411979454
End of simulation:  Mini-batch time (usec) = 4994037
Min send: 10000000, max send 0
Min long send: 664014, max long send 679713
Min fwd: 72258, max fwd 88035; min bwd 119079, max bwd 130804
Min long fwd: 107414, max long fwd 112703; min long bwd 150032, max long bwd 153679
Time taken by simulation: 168 microseconds

Stages 4
13 6255423385.6
19 8547416371.2
22 9664326348.8
23 10045446451.2
24 10412856422.4
Predicted microbatch size for 4: 24
comm size 12582912
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 7 0 358221.00830078125 663682.2411979454
End of simulation:  Mini-batch time (usec) = 6464795
Min send: 10000000, max send 0
Min long send: 663870, max long send 683729
Min fwd: 53924, max fwd 67812; min bwd 83975, max bwd 97299
Min long fwd: 86081, max long fwd 91318; min long bwd 118237, max long bwd 121834
Time taken by simulation: 314 microseconds

Stages 6
13 4698582732.8
19 6397758361.599999
22 7231220224.0
23 7515620659.2
24 7790505267.2
Predicted microbatch size for 6: 24
comm size 12582912
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 9 0 241996.6583251953 663682.2411979454
End of simulation:  Mini-batch time (usec) = 9164548
Min send: 10000000, max send 0
Min long send: 663736, max long send 687371
Min fwd: 33746, max fwd 47347; min bwd 54554, max bwd 72477
Min long fwd: 65864, max long fwd 73316; min long bwd 84274, max long bwd 89413
Time taken by simulation: 719 microseconds

Stages 8
13 3930501529.6000004
19 5322929356.799999
22 6014667161.6
23 6250707763.2
24 6479329689.6
Predicted microbatch size for 8: 24
comm size 12582912
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 15 0 176039.7491455078 663682.2411979454
End of simulation:  Mini-batch time (usec) = 13724566
Min send: 10000000, max send 0
Min long send: 663736, max long send 690844
Min fwd: 22801, max fwd 38139; min bwd 36151, max bwd 55503
Min long fwd: 51106, max long fwd 59884; min long bwd 68124, max long bwd 75476
Time taken by simulation: 1455 microseconds

Stages 12
13 3141742080.0
19 4248100352.0
22 4798114099.200001
23 4985794867.2
24 5168154112.0
Predicted microbatch size for 12: 24
comm size 12582912
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 22 0 97192.52014160156 663682.2411979454
End of simulation:  Mini-batch time (usec) = 21189724
Min send: 10000000, max send 0
Min long send: 663682, max long send 690844
Min fwd: 10724, max fwd 28920; min bwd 23319, max bwd 41964
Min long fwd: 40826, max long fwd 50474; min long bwd 49192, max long bwd 58811
Time taken by simulation: 3390 microseconds

{1: 2.905085, 2: 3.331662, 3: 4.994037, 4: 6.464795, 6: 9.164548, 8: 13.724566, 12: 21.189724}
{1: 8, 2: 19, 3: 24, 4: 24, 6: 24, 8: 24, 12: 24}
best config is: 2 19
expected time is 3.331662
15 per stage
30 servers!
Config:
ranks: range(15, 16)
train batch size: 1024
partitions: 2
chunk_size: 19
data depth: 15
stage to rank map: 0,2,4,6,8,10,12,14,16,18,20,22,24,26,28;1,3,5,7,9,11,13,15,17,19,21,23,25,27,29;
World size is 30
/opt/conda/envs/varuna/bin/python -u /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --rank=15 --chunk_size=19 --local_rank=0 --stage_to_rank_map=0,2,4,6,8,10,12,14,16,18,20,22,24,26,28;1,3,5,7,9,11,13,15,17,19,21,23,25,27,29; --batch-size=68 --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna --resume_step 278
device: cuda:0 n_gpu: 1, distributed training: True, 16-bits training: True
dry run time 0.11307644844055176
SHARED WEIGHTS ARE
[(0, 1)]
this rank  15 is part of pipeline replica  7
4 chunks
Begin to load checkpint from s3://spot-checkpoints/bert/ckpt_278.pt
2022-11-24 14:08:27.266020 resume step from  278
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 15 signal handler called with signal 10
2022-11-24 14:09:31.427935 - Finished loading checkpoint, takes 64.056 secs
Process done with return code 1
Parent process ID: 20891 node: 172.31.21.254
24 cutpoints
Stages 1
13 20868437708.800007
7 13915698585.599995
10 17153729331.199993
8 14622140211.200005
9 15846820659.199995
Predicted microbatch size for 1: 8
comm size 0
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 1 5 0 1286522.0947265625 0
End of simulation:  Mini-batch time (usec) = 2905085
Min send: 10000000, max send 0
Min long send: 10000000, max long send 0
Min fwd: 10000000, max fwd 0; min bwd 10000000, max bwd 0
Min long fwd: 126283, max long fwd 129698; min long bwd 193190, max long bwd 199310
Time taken by simulation: 46 microseconds

Stages 2
13 10987980083.2
19 14996390399.999996
22 16963644723.199997
20 15631126630.400002
Predicted microbatch size for 2: 19
comm size 9961472
WARNING: no send time found, 2 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 2 4 0 638222.2290039062 542254.6839368516
End of simulation:  Mini-batch time (usec) = 3331662
Min send: 10000000, max send 0
Min long send: 542586, max long send 555338
Min fwd: 107744, max fwd 113936; min bwd 155753, max bwd 158782
Min long fwd: 131842, max long fwd 138676; min long bwd 169332, max long bwd 173300
Time taken by simulation: 93 microseconds

Stages 3
13 7832942284.800001
19 10697074380.8
22 12097432473.599998
23 12575272243.2
24 13035207577.6
Predicted microbatch size for 3: 24
comm size 12582912
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 5 0 448996.58203125 663682.2411979454
End of simulation:  Mini-batch time (usec) = 4994037
Min send: 10000000, max send 0
Min long send: 664014, max long send 679713
Min fwd: 72258, max fwd 88035; min bwd 119079, max bwd 130804
Min long fwd: 107414, max long fwd 112703; min long bwd 150032, max long bwd 153679
Time taken by simulation: 174 microseconds

Stages 4
13 6255423385.6
19 8547416371.2
22 9664326348.8
23 10045446451.2
24 10412856422.4
Predicted microbatch size for 4: 24
comm size 12582912
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 7 0 358221.00830078125 663682.2411979454
End of simulation:  Mini-batch time (usec) = 6464795
Min send: 10000000, max send 0
Min long send: 663870, max long send 683729
Min fwd: 53924, max fwd 67812; min bwd 83975, max bwd 97299
Min long fwd: 86081, max long fwd 91318; min long bwd 118237, max long bwd 121834
Time taken by simulation: 314 microseconds

Stages 6
13 4698582732.8
19 6397758361.599999
22 7231220224.0
23 7515620659.2
24 7790505267.2
Predicted microbatch size for 6: 24
comm size 12582912
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 9 0 241996.6583251953 663682.2411979454
End of simulation:  Mini-batch time (usec) = 9164548
Min send: 10000000, max send 0
Min long send: 663736, max long send 687371
Min fwd: 33746, max fwd 47347; min bwd 54554, max bwd 72477
Min long fwd: 65864, max long fwd 73316; min long bwd 84274, max long bwd 89413
Time taken by simulation: 619 microseconds

Stages 8
13 3930501529.6000004
19 5322929356.799999
22 6014667161.6
23 6250707763.2
24 6479329689.6
Predicted microbatch size for 8: 24
comm size 12582912
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 15 0 176039.7491455078 663682.2411979454
End of simulation:  Mini-batch time (usec) = 13724566
Min send: 10000000, max send 0
Min long send: 663736, max long send 690844
Min fwd: 22801, max fwd 38139; min bwd 36151, max bwd 55503
Min long fwd: 51106, max long fwd 59884; min long bwd 68124, max long bwd 75476
Time taken by simulation: 1466 microseconds

Stages 12
13 3141742080.0
19 4248100352.0
22 4798114099.200001
23 4985794867.2
24 5168154112.0
Predicted microbatch size for 12: 24
comm size 12582912
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 22 0 97192.52014160156 663682.2411979454
End of simulation:  Mini-batch time (usec) = 21189724
Min send: 10000000, max send 0
Min long send: 663682, max long send 690844
Min fwd: 10724, max fwd 28920; min bwd 23319, max bwd 41964
Min long fwd: 40826, max long fwd 50474; min long bwd 49192, max long bwd 58811
Time taken by simulation: 3412 microseconds

{1: 2.905085, 2: 3.331662, 3: 4.994037, 4: 6.464795, 6: 9.164548, 8: 13.724566, 12: 21.189724}
{1: 8, 2: 19, 3: 24, 4: 24, 6: 24, 8: 24, 12: 24}
best config is: 2 19
expected time is 3.331662
15 per stage
30 servers!
Config:
ranks: range(15, 16)
train batch size: 1024
partitions: 2
chunk_size: 19
data depth: 15
stage to rank map: 0,2,4,6,8,10,12,14,16,18,20,22,24,26,28;1,3,5,7,9,11,13,15,17,19,21,23,25,27,29;
World size is 30
/opt/conda/envs/varuna/bin/python -u /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --rank=15 --chunk_size=19 --local_rank=0 --stage_to_rank_map=0,2,4,6,8,10,12,14,16,18,20,22,24,26,28;1,3,5,7,9,11,13,15,17,19,21,23,25,27,29; --batch-size=68 --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna --resume_step 278
device: cuda:0 n_gpu: 1, distributed training: True, 16-bits training: True
dry run time 0.1458287239074707
SHARED WEIGHTS ARE
[(0, 1)]
this rank  15 is part of pipeline replica  7
4 chunks
Begin to load checkpint from s3://spot-checkpoints/bert/ckpt_278.pt
2022-11-24 14:10:37.947598 resume step from  278
2022-11-24 14:11:41.518177 - Finished loading checkpoint, takes 63.447 secs
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  524288.0
[2022-11-24 14:12:03.158328] Finished iteration 278, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4741.843
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  262144.0
[2022-11-24 14:12:06.364537] Finished iteration 279, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3205.726
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  131072.0
[2022-11-24 14:12:09.541663] Finished iteration 280, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3177.286
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  65536.0
[2022-11-24 14:12:12.681588] Finished iteration 281, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3139.701
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  32768.0
[2022-11-24 14:12:16.120050] Finished iteration 282, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3438.461
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  16384.0
[2022-11-24 14:12:18.259459] Finished iteration 283, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2139.293
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  8192.0
[2022-11-24 14:12:20.402499] Finished iteration 284, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2143.130
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  4096.0
[2022-11-24 14:12:22.525789] Finished iteration 285, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2123.103
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  2048.0
[2022-11-24 14:12:24.636321] Finished iteration 286, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2110.496
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1024.0
[2022-11-24 14:12:26.725672] Finished iteration 287, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2089.465
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  512.0
[2022-11-24 14:12:28.851417] Finished iteration 288, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2125.559
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  256.0
[2022-11-24 14:12:30.960089] Finished iteration 289, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2108.636
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  128.0
[2022-11-24 14:12:33.125920] Finished iteration 290, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2165.800
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  64.0
[2022-11-24 14:12:35.263092] Finished iteration 291, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2137.171
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  32.0
[2022-11-24 14:12:37.401844] Finished iteration 292, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2138.828
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  16.0
[2022-11-24 14:12:39.496554] Finished iteration 293, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2094.529
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  8.0
[2022-11-24 14:12:41.584661] Finished iteration 294, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2088.216
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  4.0
[2022-11-24 14:12:43.737041] Finished iteration 295, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2152.327
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  2.0
[2022-11-24 14:12:45.880151] Finished iteration 296, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2142.945
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:12:47.979570] Finished iteration 297, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2099.389
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:12:50.116410] Finished iteration 298, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2136.938
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:12:52.265029] Finished iteration 299, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2148.562
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:12:54.436523] Finished iteration 300, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2171.313
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:12:56.563312] Finished iteration 301, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2126.885
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:12:58.735997] Finished iteration 302, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2172.644
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:00.852763] Finished iteration 303, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2116.612
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:03.006660] Finished iteration 304, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2153.867
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:05.148015] Finished iteration 305, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2141.437
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:07.622206] Finished iteration 306, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2474.038
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:10.011062] Finished iteration 307, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2388.942
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:12.161545] Finished iteration 308, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2150.421
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:14.276186] Finished iteration 309, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2114.455
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:16.436102] Finished iteration 310, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2159.908
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:18.556328] Finished iteration 311, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2120.315
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:20.687155] Finished iteration 312, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2130.658
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:22.800074] Finished iteration 313, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2112.874
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:24.960836] Finished iteration 314, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2160.755
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:27.098331] Finished iteration 315, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2137.485
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:29.288407] Finished iteration 316, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2190.022
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:31.386582] Finished iteration 317, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2098.126
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:33.518466] Finished iteration 318, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2131.865
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:35.779101] Finished iteration 319, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2260.722
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:37.932558] Finished iteration 320, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2153.462
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:40.077390] Finished iteration 321, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2144.732
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:42.233752] Finished iteration 322, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2156.318
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:44.370841] Finished iteration 323, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2137.055
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:46.496072] Finished iteration 324, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2125.168
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:48.750963] Finished iteration 325, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2254.853
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:50.873736] Finished iteration 326, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2122.590
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:53.722278] Finished iteration 327, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2848.552
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:55.854524] Finished iteration 328, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2132.307
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:13:58.039096] Finished iteration 329, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2184.546
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:00.147229] Finished iteration 330, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2107.965
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:02.242399] Finished iteration 331, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2095.119
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:04.398815] Finished iteration 332, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2156.386
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:06.519919] Finished iteration 333, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2121.065
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:08.640811] Finished iteration 334, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2121.004
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:10.771897] Finished iteration 335, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2130.919
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:12.892550] Finished iteration 336, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2120.728
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:15.029288] Finished iteration 337, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2136.705
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:17.193282] Finished iteration 338, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2163.955
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:19.322211] Finished iteration 339, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2128.908
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:21.437071] Finished iteration 340, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2114.650
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:23.599687] Finished iteration 341, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2162.589
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:25.756850] Finished iteration 342, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2157.146
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:27.895000] Finished iteration 343, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2138.104
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:30.037578] Finished iteration 344, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2142.569
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:32.186142] Finished iteration 345, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2148.546
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:34.322652] Finished iteration 346, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2136.587
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:36.421027] Finished iteration 347, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2098.323
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:38.600670] Finished iteration 348, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2179.599
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:40.709854] Finished iteration 349, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2109.156
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:42.905182] Finished iteration 350, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2195.152
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:45.037827] Finished iteration 351, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2132.592
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:47.167951] Finished iteration 352, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2130.225
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:49.268069] Finished iteration 353, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2099.937
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:51.416087] Finished iteration 354, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2148.006
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:53.610127] Finished iteration 355, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2194.028
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:55.731431] Finished iteration 356, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2121.392
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:57.847932] Finished iteration 357, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2116.427
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:14:59.955670] Finished iteration 358, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2107.692
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:02.088267] Finished iteration 359, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2132.563
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:04.209857] Finished iteration 360, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2121.395
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:06.374785] Finished iteration 361, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2165.039
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:08.536973] Finished iteration 362, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2162.006
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:10.692316] Finished iteration 363, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2155.329
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:12.888389] Finished iteration 364, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2196.223
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:15.004101] Finished iteration 365, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2115.470
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:17.110794] Finished iteration 366, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2106.787
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:19.278066] Finished iteration 367, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2167.262
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:21.396703] Finished iteration 368, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2118.572
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:23.549202] Finished iteration 369, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2152.443
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:25.709011] Finished iteration 370, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2159.631
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:27.859857] Finished iteration 371, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2150.828
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:29.971715] Finished iteration 372, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2111.817
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:32.110131] Finished iteration 373, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2138.425
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:34.272595] Finished iteration 374, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2162.397
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:36.396970] Finished iteration 375, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2124.481
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:38.519930] Finished iteration 376, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2122.802
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:40.701877] Finished iteration 377, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2182.062
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:42.819942] Finished iteration 378, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2117.974
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:15:44.961001] Finished iteration 379, CKPT_AND_STOP: False, flag: tensor([1], dtype=torch.int32), speed: 2140.891
2022-11-24 14:15:44.965453 Begin to save checkpont to s3://spot-checkpoints/bert and exit
Opt ckpt time 4.226115465164185
Process done with return code 0
Parent process ID: 22599 node: 172.31.21.254
24 cutpoints
Stages 1
13 20868437708.800007
7 13915698585.599995
10 17153729331.199993
8 14622140211.200005
9 15846820659.199995
Predicted microbatch size for 1: 8
comm size 0
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 1 5 0 1286522.0947265625 0
End of simulation:  Mini-batch time (usec) = 2905085
Min send: 10000000, max send 0
Min long send: 10000000, max long send 0
Min fwd: 10000000, max fwd 0; min bwd 10000000, max bwd 0
Min long fwd: 126283, max long fwd 129698; min long bwd 193190, max long bwd 199310
Time taken by simulation: 46 microseconds

Stages 2
13 10987980083.2
19 14996390399.999996
22 16963644723.199997
20 15631126630.400002
Predicted microbatch size for 2: 19
comm size 9961472
WARNING: no send time found, 2 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 2 4 0 638222.2290039062 542254.6839368516
End of simulation:  Mini-batch time (usec) = 3331662
Min send: 10000000, max send 0
Min long send: 542586, max long send 555338
Min fwd: 107744, max fwd 113936; min bwd 155753, max bwd 158782
Min long fwd: 131842, max long fwd 138676; min long bwd 169332, max long bwd 173300
Time taken by simulation: 99 microseconds

Stages 3
13 7832942284.800001
19 10697074380.8
22 12097432473.599998
23 12575272243.2
24 13035207577.6
Predicted microbatch size for 3: 24
comm size 12582912
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 5 0 448996.58203125 663682.2411979454
End of simulation:  Mini-batch time (usec) = 4994037
Min send: 10000000, max send 0
Min long send: 664014, max long send 679713
Min fwd: 72258, max fwd 88035; min bwd 119079, max bwd 130804
Min long fwd: 107414, max long fwd 112703; min long bwd 150032, max long bwd 153679
Time taken by simulation: 172 microseconds

Stages 4
13 6255423385.6
19 8547416371.2
22 9664326348.8
23 10045446451.2
24 10412856422.4
Predicted microbatch size for 4: 24
comm size 12582912
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 7 0 358221.00830078125 663682.2411979454
End of simulation:  Mini-batch time (usec) = 6464795
Min send: 10000000, max send 0
Min long send: 663870, max long send 683729
Min fwd: 53924, max fwd 67812; min bwd 83975, max bwd 97299
Min long fwd: 86081, max long fwd 91318; min long bwd 118237, max long bwd 121834
Time taken by simulation: 310 microseconds

Stages 6
13 4698582732.8
19 6397758361.599999
22 7231220224.0
23 7515620659.2
24 7790505267.2
Predicted microbatch size for 6: 24
comm size 12582912
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 9 0 241996.6583251953 663682.2411979454
End of simulation:  Mini-batch time (usec) = 9164548
Min send: 10000000, max send 0
Min long send: 663736, max long send 687371
Min fwd: 33746, max fwd 47347; min bwd 54554, max bwd 72477
Min long fwd: 65864, max long fwd 73316; min long bwd 84274, max long bwd 89413
Time taken by simulation: 663 microseconds

Stages 8
13 3930501529.6000004
19 5322929356.799999
22 6014667161.6
23 6250707763.2
24 6479329689.6
Predicted microbatch size for 8: 24
comm size 12582912
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 15 0 176039.7491455078 663682.2411979454
End of simulation:  Mini-batch time (usec) = 13724566
Min send: 10000000, max send 0
Min long send: 663736, max long send 690844
Min fwd: 22801, max fwd 38139; min bwd 36151, max bwd 55503
Min long fwd: 51106, max long fwd 59884; min long bwd 68124, max long bwd 75476
Time taken by simulation: 1480 microseconds

Stages 12
13 3141742080.0
19 4248100352.0
22 4798114099.200001
23 4985794867.2
24 5168154112.0
Predicted microbatch size for 12: 24
comm size 12582912
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 22 0 97192.52014160156 663682.2411979454
End of simulation:  Mini-batch time (usec) = 21189724
Min send: 10000000, max send 0
Min long send: 663682, max long send 690844
Min fwd: 10724, max fwd 28920; min bwd 23319, max bwd 41964
Min long fwd: 40826, max long fwd 50474; min long bwd 49192, max long bwd 58811
Time taken by simulation: 3394 microseconds

{1: 2.905085, 2: 3.331662, 3: 4.994037, 4: 6.464795, 6: 9.164548, 8: 13.724566, 12: 21.189724}
{1: 8, 2: 19, 3: 24, 4: 24, 6: 24, 8: 24, 12: 24}
best config is: 2 19
expected time is 3.331662
15 per stage
30 servers!
Config:
ranks: range(15, 16)
train batch size: 1024
partitions: 2
chunk_size: 19
data depth: 15
stage to rank map: 0,2,4,6,8,10,12,14,16,18,20,22,24,26,28;1,3,5,7,9,11,13,15,17,19,21,23,25,27,29;
World size is 30
/opt/conda/envs/varuna/bin/python -u /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --rank=15 --chunk_size=19 --local_rank=0 --stage_to_rank_map=0,2,4,6,8,10,12,14,16,18,20,22,24,26,28;1,3,5,7,9,11,13,15,17,19,21,23,25,27,29; --batch-size=68 --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna --resume_step 380
device: cuda:0 n_gpu: 1, distributed training: True, 16-bits training: True
dry run time 1.2771594524383545
SHARED WEIGHTS ARE
[(0, 1)]
this rank  15 is part of pipeline replica  7
4 chunks
Begin to load checkpint from s3://spot-checkpoints/bert/ckpt_380.pt
2022-11-24 14:16:27.120506 resume step from  380
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 15 signal handler called with signal 10
2022-11-24 14:17:31.567141 - Finished loading checkpoint, takes 59.527 secs
2022-11-24 14:17:54.294694 Begin to exit
Process done with return code 0
Parent process ID: 23985 node: 172.31.21.254
24 cutpoints
Stages 1
13 20868437708.800007
7 13915698585.599995
10 17153729331.199993
8 14622140211.200005
9 15846820659.199995
Predicted microbatch size for 1: 8
comm size 0
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 1 4 0 3150942.3828125 0
End of simulation:  Mini-batch time (usec) = 4450032
Min send: 10000000, max send 0
Min long send: 10000000, max long send 0
Min fwd: 10000000, max fwd 0; min bwd 10000000, max bwd 0
Min long fwd: 127414, max long fwd 129698; min long bwd 194806, max long bwd 199310
Time taken by simulation: 45 microseconds

Stages 2
13 10987980083.2
19 14996390399.999996
22 16963644723.199997
20 15631126630.400002
Predicted microbatch size for 2: 19
comm size 9961472
WARNING: no send time found, 2 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 2 4 0 673273.3154296875 542254.6839368516
End of simulation:  Mini-batch time (usec) = 3366713
Min send: 10000000, max send 0
Min long send: 542586, max long send 555338
Min fwd: 107744, max fwd 113936; min bwd 155753, max bwd 158782
Min long fwd: 131842, max long fwd 138676; min long bwd 169332, max long bwd 173300
Time taken by simulation: 98 microseconds

Stages 3
13 7832942284.800001
19 10697074380.8
22 12097432473.599998
23 12575272243.2
24 13035207577.6
Predicted microbatch size for 3: 24
comm size 12582912
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 5 0 448996.58203125 663682.2411979454
End of simulation:  Mini-batch time (usec) = 4994037
Min send: 10000000, max send 0
Min long send: 664014, max long send 679713
Min fwd: 72258, max fwd 88035; min bwd 119079, max bwd 130804
Min long fwd: 107414, max long fwd 112703; min long bwd 150032, max long bwd 153679
Time taken by simulation: 191 microseconds

Stages 4
13 6255423385.6
19 8547416371.2
22 9664326348.8
23 10045446451.2
24 10412856422.4
Predicted microbatch size for 4: 24
comm size 12582912
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 6 0 375752.13623046875 663682.2411979454
End of simulation:  Mini-batch time (usec) = 6314108
Min send: 10000000, max send 0
Min long send: 663764, max long send 688387
Min fwd: 53924, max fwd 66948; min bwd 83975, max bwd 98046
Min long fwd: 84759, max long fwd 91250; min long bwd 120659, max long bwd 125455
Time taken by simulation: 274 microseconds

Stages 6
13 4698582732.8
19 6397758361.599999
22 7231220224.0
23 7515620659.2
24 7790505267.2
Predicted microbatch size for 6: 24
comm size 12582912
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 9 0 241996.6583251953 663682.2411979454
End of simulation:  Mini-batch time (usec) = 9164548
Min send: 10000000, max send 0
Min long send: 663736, max long send 687371
Min fwd: 33746, max fwd 47347; min bwd 54554, max bwd 72477
Min long fwd: 65864, max long fwd 73316; min long bwd 84274, max long bwd 89413
Time taken by simulation: 622 microseconds

Stages 8
13 3930501529.6000004
19 5322929356.799999
22 6014667161.6
23 6250707763.2
24 6479329689.6
Predicted microbatch size for 8: 24
comm size 12582912
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 11 0 214379.08935546875 663682.2411979454
End of simulation:  Mini-batch time (usec) = 12421079
Min send: 10000000, max send 0
Min long send: 663682, max long send 689782
Min fwd: 22992, max fwd 37161; min bwd 37517, max bwd 55449
Min long fwd: 51419, max long fwd 57045; min long bwd 68935, max long bwd 77274
Time taken by simulation: 1035 microseconds

Stages 12
13 3141742080.0
19 4248100352.0
22 4798114099.200001
23 4985794867.2
24 5168154112.0
Predicted microbatch size for 12: 24
comm size 12582912
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 22 0 97192.52014160156 663682.2411979454
End of simulation:  Mini-batch time (usec) = 21189724
Min send: 10000000, max send 0
Min long send: 663682, max long send 690844
Min fwd: 10724, max fwd 28920; min bwd 23319, max bwd 41964
Min long fwd: 40826, max long fwd 50474; min long bwd 49192, max long bwd 58811
Time taken by simulation: 3351 microseconds

{1: 4.450032, 2: 3.366713, 3: 4.994037, 4: 6.314108, 6: 9.164548, 8: 12.421079, 12: 21.189724}
{1: 8, 2: 19, 3: 24, 4: 24, 6: 24, 8: 24, 12: 24}
best config is: 2 19
expected time is 3.366713
16 per stage
32 servers!
Config:
ranks: range(15, 16)
train batch size: 1024
partitions: 2
chunk_size: 19
data depth: 16
stage to rank map: 0,2,4,6,8,10,12,14,16,18,20,22,24,26,28,30;1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31;
World size is 32
/opt/conda/envs/varuna/bin/python -u /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --rank=15 --chunk_size=19 --local_rank=0 --stage_to_rank_map=0,2,4,6,8,10,12,14,16,18,20,22,24,26,28,30;1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31; --batch-size=64 --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna --resume_step 380
device: cuda:0 n_gpu: 1, distributed training: True, 16-bits training: True
dry run time 0.14880895614624023
SHARED WEIGHTS ARE
[(0, 1)]
this rank  15 is part of pipeline replica  7
4 chunks
Begin to load checkpint from s3://spot-checkpoints/bert/ckpt_380.pt
2022-11-24 14:18:15.851286 resume step from  380
2022-11-24 14:19:22.120781 - Finished loading checkpoint, takes 61.316 secs
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  524288.0
[2022-11-24 14:19:34.551923] Finished iteration 380, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5718.536
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  262144.0
[2022-11-24 14:19:37.746349] Finished iteration 381, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3194.220
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  131072.0
[2022-11-24 14:19:40.914211] Finished iteration 382, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3167.823
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  65536.0
[2022-11-24 14:19:44.063499] Finished iteration 383, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3149.282
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  32768.0
[2022-11-24 14:19:47.217118] Finished iteration 384, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3153.674
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  16384.0
[2022-11-24 14:19:49.558508] Finished iteration 385, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2341.304
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  8192.0
[2022-11-24 14:19:51.668040] Finished iteration 386, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2109.481
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  4096.0
[2022-11-24 14:19:53.816657] Finished iteration 387, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2148.426
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  2048.0
[2022-11-24 14:19:55.884781] Finished iteration 388, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2068.093
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1024.0
[2022-11-24 14:19:57.964306] Finished iteration 389, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2079.496
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  512.0
[2022-11-24 14:20:00.063876] Finished iteration 390, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2099.540
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  256.0
[2022-11-24 14:20:02.206136] Finished iteration 391, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2142.254
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  128.0
[2022-11-24 14:20:05.150687] Finished iteration 392, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2944.494
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  64.0
[2022-11-24 14:20:07.260324] Finished iteration 393, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2109.746
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  32.0
[2022-11-24 14:20:09.354608] Finished iteration 394, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2094.138
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  16.0
[2022-11-24 14:20:12.390431] Finished iteration 395, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3035.748
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  8.0
[2022-11-24 14:20:14.481772] Finished iteration 396, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2091.317
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  4.0
[2022-11-24 14:20:16.553700] Finished iteration 397, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2071.922
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  2.0
[2022-11-24 14:20:18.638762] Finished iteration 398, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2085.009
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:20.689574] Finished iteration 399, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2050.796
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:22.764653] Finished iteration 400, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2075.151
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:24.880131] Finished iteration 401, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2115.303
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:26.993304] Finished iteration 402, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2113.275
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:29.637375] Finished iteration 403, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2644.054
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:31.805111] Finished iteration 404, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2167.523
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:33.882608] Finished iteration 405, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2077.469
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:36.002074] Finished iteration 406, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2119.436
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:38.098517] Finished iteration 407, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2096.389
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:40.233559] Finished iteration 408, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2135.003
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:42.298972] Finished iteration 409, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2065.513
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:44.373378] Finished iteration 410, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2074.353
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:46.488366] Finished iteration 411, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2114.820
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:48.573573] Finished iteration 412, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2085.298
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:50.669599] Finished iteration 413, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2095.857
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:52.761992] Finished iteration 414, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2092.357
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:54.905289] Finished iteration 415, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2143.393
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:56.956091] Finished iteration 416, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2050.624
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:20:59.113165] Finished iteration 417, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2157.051
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:01.194881] Finished iteration 418, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2081.705
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:03.273312] Finished iteration 419, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2078.525
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:05.381591] Finished iteration 420, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2108.209
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:07.454760] Finished iteration 421, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2073.119
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:09.592547] Finished iteration 422, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2137.750
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:11.682953] Finished iteration 423, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2090.348
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:13.808212] Finished iteration 424, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2125.236
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:15.918760] Finished iteration 425, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2110.352
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:18.017739] Finished iteration 426, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2099.064
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:20.079578] Finished iteration 427, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2061.692
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:22.183371] Finished iteration 428, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2103.862
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:24.232896] Finished iteration 429, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2049.342
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:26.331806] Finished iteration 430, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2098.880
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:28.397627] Finished iteration 431, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2065.823
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:30.485599] Finished iteration 432, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2087.910
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:32.561931] Finished iteration 433, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2076.302
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:34.703143] Finished iteration 434, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2141.190
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:36.862344] Finished iteration 435, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2159.168
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:39.034039] Finished iteration 436, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2171.658
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:41.159313] Finished iteration 437, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2125.380
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:43.347712] Finished iteration 438, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2188.218
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:45.446372] Finished iteration 439, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2098.621
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:47.583384] Finished iteration 440, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2137.117
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:49.680120] Finished iteration 441, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2096.554
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:51.809819] Finished iteration 442, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2129.673
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:53.892272] Finished iteration 443, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2082.548
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:56.018583] Finished iteration 444, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2126.153
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:21:58.114170] Finished iteration 445, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2095.710
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:00.208370] Finished iteration 446, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2094.012
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:02.256343] Finished iteration 447, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2047.928
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:04.363389] Finished iteration 448, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2106.997
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:06.475594] Finished iteration 449, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2112.316
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:08.549820] Finished iteration 450, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2074.033
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:10.656976] Finished iteration 451, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2107.252
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:12.838053] Finished iteration 452, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2181.065
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:14.935972] Finished iteration 453, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2097.715
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:17.062170] Finished iteration 454, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2126.329
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:19.120324] Finished iteration 455, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2058.067
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:21.196809] Finished iteration 456, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2076.448
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:24.183532] Finished iteration 457, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2986.706
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:26.276385] Finished iteration 458, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2092.633
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:28.312941] Finished iteration 459, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2036.524
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:30.387520] Finished iteration 460, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2074.562
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:32.486482] Finished iteration 461, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2098.922
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:34.589947] Finished iteration 462, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2103.579
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:36.655732] Finished iteration 463, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2065.575
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:38.786827] Finished iteration 464, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2131.203
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:40.824856] Finished iteration 465, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2038.007
15 Overflow !!
15 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
[2022-11-24 14:22:42.944857] Finished iteration 466, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2119.910
Parent process ID: 18383 node: 172.31.28.16
24 cutpoints
Stages 1
13 20868437708.800007
7 13915698585.599995
10 17153729331.199993
8 14622140211.200005
9 15846820659.199995
Predicted microbatch size for 1: 8
comm size 0
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 1 6 0 1334585.0830078125 0
End of simulation:  Mini-batch time (usec) = 3270291
Min send: 10000000, max send 0
Min long send: 10000000, max long send 0
Min fwd: 10000000, max fwd 0; min bwd 10000000, max bwd 0
Min long fwd: 126112, max long fwd 129698; min long bwd 191031, max long bwd 199310
Time taken by simulation: 55 microseconds

Stages 2
13 10987980083.2
19 14996390399.999996
22 16963644723.199997
20 15631126630.400002
Predicted microbatch size for 2: 19
comm size 9961472
WARNING: no send time found, 2 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 2 5 0 608509.5825195312 542254.6839368516
End of simulation:  Mini-batch time (usec) = 3607863
Min send: 10000000, max send 0
Min long send: 542586, max long send 558986
Min fwd: 106816, max fwd 113936; min bwd 154625, max bwd 157669
Min long fwd: 134083, max long fwd 138081; min long bwd 169664, max long bwd 173713
Time taken by simulation: 114 microseconds

Stages 3
13 7832942284.800001
19 10697074380.8
22 12097432473.599998
23 12575272243.2
24 13035207577.6
Predicted microbatch size for 3: 24
comm size 12582912
WARNING: no send time found, 3 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 3 7 0 441679.38232421875 663682.2411979454
End of simulation:  Mini-batch time (usec) = 5526356
Min send: 10000000, max send 0
Min long send: 664014, max long send 688387
Min fwd: 70473, max fwd 86449; min bwd 116125, max bwd 131549
Min long fwd: 107949, max long fwd 111566; min long bwd 147972, max long bwd 154852
Time taken by simulation: 235 microseconds

Stages 4
13 6255423385.6
19 8547416371.2
22 9664326348.8
23 10045446451.2
24 10412856422.4
Predicted microbatch size for 4: 24
comm size 12582912
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 9 0 322485.90087890625 663682.2411979454
End of simulation:  Mini-batch time (usec) = 6859347
Min send: 10000000, max send 0
Min long send: 663764, max long send 686148
Min fwd: 51765, max fwd 67812; min bwd 84974, max bwd 98885
Min long fwd: 83336, max long fwd 90554; min long bwd 118409, max long bwd 124254
Time taken by simulation: 406 microseconds

Stages 6
13 4698582732.8
19 6397758361.599999
22 7231220224.0
23 7515620659.2
24 7790505267.2
Predicted microbatch size for 6: 24
comm size 12582912
WARNING: no send time found, 6 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 6 15 0 205807.43408203125 663682.2411979454
End of simulation:  Mini-batch time (usec) = 11152793
Min send: 10000000, max send 0
Min long send: 663736, max long send 688387
Min fwd: 32603, max fwd 47172; min bwd 54003, max bwd 69793
Min long fwd: 66617, max long fwd 70492; min long bwd 81618, max long bwd 89601
Time taken by simulation: 1160 microseconds

Stages 8
13 3930501529.6000004
19 5322929356.799999
22 6014667161.6
23 6250707763.2
24 6479329689.6
Predicted microbatch size for 8: 24
comm size 12582912
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 22 0 120660.06469726562 663682.2411979454
End of simulation:  Mini-batch time (usec) = 15792286
Min send: 10000000, max send 0
Min long send: 663682, max long send 690844
Min fwd: 23237, max fwd 38139; min bwd 35712, max bwd 56890
Min long fwd: 51613, max long fwd 57677; min long bwd 69478, max long bwd 76496
Time taken by simulation: 2175 microseconds

Stages 12
13 3141742080.0
19 4248100352.0
22 4798114099.200001
23 4985794867.2
24 5168154112.0
Predicted microbatch size for 12: 24
comm size 12582912
WARNING: no send time found, 12 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 12 43 0 0 663682.2411979454
End of simulation:  Mini-batch time (usec) = 28245316
Min send: 10000000, max send 0
Min long send: 663682, max long send 693511
Min fwd: 10606, max fwd 31119; min bwd 22396, max bwd 41317
Min long fwd: 40838, max long fwd 49874; min long bwd 47936, max long bwd 55473
Time taken by simulation: 6864 microseconds

{1: 3.270291, 2: 3.607863, 3: 5.526356, 4: 6.859347, 6: 11.152793, 8: 15.792286, 12: 28.245316}
{1: 8, 2: 19, 3: 24, 4: 24, 6: 24, 8: 24, 12: 24}
best config is: 2 19
expected time is 3.607863
11 per stage
22 servers!
Config:
ranks: range(15, 16)
train batch size: 1024
partitions: 2
chunk_size: 19
data depth: 11
stage to rank map: 0,2,4,6,8,10,12,14,16,18,20;1,3,5,7,9,11,13,15,17,19,21;
World size is 22
/opt/conda/envs/varuna/bin/python -u /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --rank=15 --chunk_size=19 --local_rank=0 --stage_to_rank_map=0,2,4,6,8,10,12,14,16,18,20;1,3,5,7,9,11,13,15,17,19,21; --batch-size=93 --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna --resume_step 380
device: cuda:0 n_gpu: 1, distributed training: True, 16-bits training: True
dry run time 0.15409350395202637
SHARED WEIGHTS ARE
[(0, 1)]
this rank  15 is part of pipeline replica  7
5 chunks
Begin to load checkpint from s3://spot-checkpoints/bert/ckpt_380.pt
2022-11-24 14:32:07.132152 resume step from  380
