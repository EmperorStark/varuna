[2022-11-23 14:39:16.505831] Begin to replay trace trace_lh_80_90.txt
[2022-11-23 14:39:16.505888] >>> [0.000] next_event: add at 0
[2022-11-23 14:39:16.505912] >>> [0.000]      node to be add: ['172.31.28.108', '172.31.20.223', '172.31.18.152', '172.31.27.216', '172.31.24.208', '172.31.30.99', '172.31.16.100', '172.31.22.229', '172.31.22.165', '172.31.31.40', '172.31.19.171', '172.31.17.44', '172.31.28.236', '172.31.21.45', '172.31.21.109', '172.31.19.112', '172.31.21.254', '172.31.24.191']
[2022-11-23 14:39:16.507119] >>> [0.001] nnodes: 18, message: 
[2022-11-23 14:39:16.507189]                remain nodes: ['172.31.28.108', '172.31.20.223', '172.31.18.152', '172.31.27.216', '172.31.24.208', '172.31.30.99', '172.31.16.100', '172.31.22.229', '172.31.22.165', '172.31.31.40', '172.31.19.171', '172.31.17.44', '172.31.28.236', '172.31.21.45', '172.31.21.109', '172.31.19.112', '172.31.21.254', '172.31.24.191']
[2022-11-23 14:39:16.507209] >>> [0.001] next_event: no-op at 60000
Container nvidia build = 
Warning! /hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ directory missing. Training cannot start
/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/
/home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json
Logs written to /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/bert_lamb_pretraining.pyt_bert_pretraining_phase1_fp16_gbs1024.log
+ '[' -z /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/bert_lamb_pretraining.pyt_bert_pretraining_phase1_fp16_gbs1024.log ']'
+ tee /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/bert_lamb_pretraining.pyt_bert_pretraining_phase1_fp16_gbs1024.log
+ /opt/conda/envs/varuna/bin/python -m varuna.run_varuna --profile_folder s3://spot-checkpoints/bert-profile --batch_size 1024 --chunk_size 8 --gpus_per_node 1 --nstages 8 --machine_list /home/ubuntu/varuna/aws/hosts/available_machines.out /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna
reachable machines: ['172.31.28.108', '172.31.20.223', '172.31.18.152', '172.31.27.216', '172.31.24.208', '172.31.30.99', '172.31.16.100', '172.31.22.229', '172.31.22.165', '172.31.31.40', '172.31.19.171', '172.31.17.44', '172.31.28.236', '172.31.21.45', '172.31.21.109', '172.31.19.112', '172.31.21.254', '172.31.24.191']
/opt/conda/envs/varuna/bin/python -m varuna.morph_server /home/ubuntu/varuna/aws/hosts/available_machines.out /home/ubuntu/varuna/aws/hosts/varuna_current_machines 4200  > varuna_morph.out 2>varuna_morph.err &
/opt/conda/envs/varuna/bin/python -m varuna.catch_all /home/ubuntu/varuna/aws/hosts/varuna_current_machines 5000  > varuna_catch.out 2>varuna_catch.err &
ssh ubuntu@172.31.28.108 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 0 --nservers 18 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --nstages 8 /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.20.223 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 1 --nservers 18 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --nstages 8 /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.18.152 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 2 --nservers 18 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --nstages 8 /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.27.216 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 3 --nservers 18 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --nstages 8 /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.24.208 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 4 --nservers 18 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --nstages 8 /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.30.99 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 5 --nservers 18 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --nstages 8 /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.16.100 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 6 --nservers 18 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --nstages 8 /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.22.229 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 7 --nservers 18 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --nstages 8 /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.22.165 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 8 --nservers 18 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --nstages 8 /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.31.40 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 9 --nservers 18 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --nstages 8 /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.19.171 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 10 --nservers 18 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --nstages 8 /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.17.44 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 11 --nservers 18 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --nstages 8 /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.28.236 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 12 --nservers 18 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --nstages 8 /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.21.45 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 13 --nservers 18 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --nstages 8 /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.21.109 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 14 --nservers 18 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --nstages 8 /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.19.112 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 15 --nservers 18 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --nstages 8 /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.21.254 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 16 --nservers 18 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --nstages 8 /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
ssh ubuntu@172.31.24.191 echo "/opt/conda/envs/varuna/bin/python  -u -m varuna.launcher --ngpus_per_server 1   --node_rank 17 --nservers 18 --master_addr 172.31.28.108 --batch_size 1024 --chunk_size 8 --code_dir /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT --nstages 8 /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna" > launch_varuna.sh;  VARUNA_MANAGER_IP=172.31.28.108 VARUNA_MORPH_PORT=4200 VARUNA_HEARTBEAT_PORT=5000 PYTHONPATH=/home/ubuntu/varuna:$PYTHONPATH  bash launch_varuna.sh
+ set +x
finished pretraining
[2022-11-23 14:40:16.563634] >>> [60.058] nnodes: 18, no morph
[2022-11-23 14:40:16.563710] >>> [60.058] next_event: no-op at 120000
[2022-11-23 14:41:16.563622] >>> [120.058] nnodes: 18, no morph
[2022-11-23 14:41:16.563716] >>> [120.058] next_event: no-op at 180000
[2022-11-23 14:42:16.563617] >>> [180.058] nnodes: 18, no morph
[2022-11-23 14:42:16.563705] >>> [180.058] next_event: add at 240000
[2022-11-23 14:43:16.563627] >>> [240.058]      node to be add: ['172.31.16.5', '172.31.30.133']
[2022-11-23 14:43:16.564334] >>> [240.059] nnodes: 20, message: morph
[2022-11-23 14:43:16.564380]                remain nodes: ['172.31.28.108', '172.31.20.223', '172.31.18.152', '172.31.27.216', '172.31.24.208', '172.31.30.99', '172.31.16.100', '172.31.22.229', '172.31.22.165', '172.31.31.40', '172.31.19.171', '172.31.17.44', '172.31.28.236', '172.31.21.45', '172.31.21.109', '172.31.19.112', '172.31.21.254', '172.31.24.191', '172.31.16.5', '172.31.30.133']
[2022-11-23 14:43:16.564403] >>> [240.059] next_event: no-op at 300000
[2022-11-23 14:44:16.565869] >>> [300.060] nnodes: 20, no morph
[2022-11-23 14:44:16.565943] >>> [300.060] next_event: add at 360000
[2022-11-23 14:45:16.563680] >>> [360.058]      node to be add: ['172.31.23.137']
[2022-11-23 14:45:16.564498] >>> [360.059] nnodes: 21, message: morph
[2022-11-23 14:45:16.564555]                remain nodes: ['172.31.28.108', '172.31.20.223', '172.31.18.152', '172.31.27.216', '172.31.24.208', '172.31.30.99', '172.31.16.100', '172.31.22.229', '172.31.22.165', '172.31.31.40', '172.31.19.171', '172.31.17.44', '172.31.28.236', '172.31.21.45', '172.31.21.109', '172.31.19.112', '172.31.21.254', '172.31.24.191', '172.31.16.5', '172.31.30.133', '172.31.23.137']
[2022-11-23 14:45:16.564594] >>> [360.059] next_event: add at 420000
[2022-11-23 14:46:16.505952] >>> [420.000]      node to be add: ['172.31.21.137']
[2022-11-23 14:46:16.506466] >>> [420.001] nnodes: 22, message: morph
[2022-11-23 14:46:16.506528]                remain nodes: ['172.31.28.108', '172.31.20.223', '172.31.18.152', '172.31.27.216', '172.31.24.208', '172.31.30.99', '172.31.16.100', '172.31.22.229', '172.31.22.165', '172.31.31.40', '172.31.19.171', '172.31.17.44', '172.31.28.236', '172.31.21.45', '172.31.21.109', '172.31.19.112', '172.31.21.254', '172.31.24.191', '172.31.16.5', '172.31.30.133', '172.31.23.137', '172.31.21.137']
[2022-11-23 14:46:16.506546] >>> [420.001] next_event: no-op at 480000
[2022-11-23 14:47:16.565926] >>> [480.060] nnodes: 22, no morph
[2022-11-23 14:47:16.565997] >>> [480.060] next_event: no-op at 540000
[2022-11-23 14:48:16.563613] >>> [540.058] nnodes: 22, no morph
[2022-11-23 14:48:16.563679] >>> [540.058] next_event: add at 600000
[2022-11-23 14:49:16.565886] >>> [600.060]      node to be add: ['172.31.26.140']
[2022-11-23 14:49:16.566483] >>> [600.061] nnodes: 23, message: morph
[2022-11-23 14:49:16.566521]                remain nodes: ['172.31.28.108', '172.31.20.223', '172.31.18.152', '172.31.27.216', '172.31.24.208', '172.31.30.99', '172.31.16.100', '172.31.22.229', '172.31.22.165', '172.31.31.40', '172.31.19.171', '172.31.17.44', '172.31.28.236', '172.31.21.45', '172.31.21.109', '172.31.19.112', '172.31.21.254', '172.31.24.191', '172.31.16.5', '172.31.30.133', '172.31.23.137', '172.31.21.137', '172.31.26.140']
[2022-11-23 14:49:16.566548] >>> [600.061] next_event: add at 660000
[2022-11-23 14:50:16.566241] >>> [660.060]      node to be add: ['172.31.28.143']
[2022-11-23 14:50:16.566976] >>> [660.061] nnodes: 24, message: morph
[2022-11-23 14:50:16.567033]                remain nodes: ['172.31.28.108', '172.31.20.223', '172.31.18.152', '172.31.27.216', '172.31.24.208', '172.31.30.99', '172.31.16.100', '172.31.22.229', '172.31.22.165', '172.31.31.40', '172.31.19.171', '172.31.17.44', '172.31.28.236', '172.31.21.45', '172.31.21.109', '172.31.19.112', '172.31.21.254', '172.31.24.191', '172.31.16.5', '172.31.30.133', '172.31.23.137', '172.31.21.137', '172.31.26.140', '172.31.28.143']
[2022-11-23 14:50:16.567062] >>> [660.061] next_event: no-op at 720000
[2022-11-23 14:51:16.563625] >>> [720.058] nnodes: 24, no morph
[2022-11-23 14:51:16.563733] >>> [720.058] next_event: no-op at 780000
[2022-11-23 14:52:16.565874] >>> [780.060] nnodes: 24, no morph
[2022-11-23 14:52:16.566220] >>> [780.060] next_event: no-op at 840000
[2022-11-23 14:53:16.513023] >>> [840.007] nnodes: 24, no morph
[2022-11-23 14:53:16.513098] >>> [840.007] next_event: remove at 900000
[2022-11-23 14:53:46.535627] >>> [870.030]      node to be remove: ['172.31.31.40', '172.31.16.100', '172.31.19.171', '172.31.24.208']
[2022-11-23 14:53:46.536252] >>> [870.030] nnodes: 20, message: preempt 870.0301733016968
[2022-11-23 14:53:46.536296]                remain nodes: ['172.31.28.108', '172.31.20.223', '172.31.18.152', '172.31.27.216', '172.31.30.99', '172.31.22.229', '172.31.22.165', '172.31.17.44', '172.31.28.236', '172.31.21.45', '172.31.21.109', '172.31.19.112', '172.31.21.254', '172.31.24.191', '172.31.16.5', '172.31.30.133', '172.31.23.137', '172.31.21.137', '172.31.26.140', '172.31.28.143']
[2022-11-23 14:53:46.536343] >>> [870.030] next_event: no-op at 960000
[2022-11-23 14:55:16.595991] >>> [960.090] nnodes: 20, no morph
[2022-11-23 14:55:16.596115] >>> [960.090] next_event: remove at 1020000
[2022-11-23 14:55:46.533515] >>> [990.028]      node to be remove: ['172.31.19.112', '172.31.24.191', '172.31.16.5', '172.31.30.133']
[2022-11-23 14:55:46.534013] >>> [990.028] nnodes: 16, message: preempt 990.0280117988586
[2022-11-23 14:55:46.534048]                remain nodes: ['172.31.28.108', '172.31.20.223', '172.31.18.152', '172.31.27.216', '172.31.30.99', '172.31.22.229', '172.31.22.165', '172.31.17.44', '172.31.28.236', '172.31.21.45', '172.31.21.109', '172.31.21.254', '172.31.23.137', '172.31.21.137', '172.31.26.140', '172.31.28.143']
[2022-11-23 14:55:46.534062] >>> [990.028] next_event: no-op at 1080000
[2022-11-23 14:57:16.595600] >>> [1080.090] nnodes: 16, no morph
[2022-11-23 14:57:16.595666] >>> [1080.090] next_event: remove at 1140000
[2022-11-23 14:57:46.535637] >>> [1110.030]      node to be remove: ['172.31.22.229', '172.31.21.137']
[2022-11-23 14:57:46.536318] >>> [1110.030] nnodes: 14, message: preempt 1110.0302486419678
[2022-11-23 14:57:46.536364]                remain nodes: ['172.31.28.108', '172.31.20.223', '172.31.18.152', '172.31.27.216', '172.31.30.99', '172.31.22.165', '172.31.17.44', '172.31.28.236', '172.31.21.45', '172.31.21.109', '172.31.21.254', '172.31.23.137', '172.31.26.140', '172.31.28.143']
[2022-11-23 14:57:46.536382] >>> [1110.031] next_event: no-op at 1200000
[2022-11-23 14:59:16.595601] >>> [1200.090] nnodes: 14, no morph
[2022-11-23 14:59:16.595663] >>> [1200.090] next_event: remove at 1260000
[2022-11-23 14:59:46.535835] >>> [1230.030]      node to be remove: ['172.31.30.99', '172.31.17.44']
[2022-11-23 14:59:46.536510] >>> [1230.031] nnodes: 12, message: preempt 1230.030431509018
[2022-11-23 14:59:46.536572]                remain nodes: ['172.31.28.108', '172.31.20.223', '172.31.18.152', '172.31.27.216', '172.31.22.165', '172.31.28.236', '172.31.21.45', '172.31.21.109', '172.31.21.254', '172.31.23.137', '172.31.26.140', '172.31.28.143']
[2022-11-23 14:59:46.536589] >>> [1230.031] next_event: no-op at 1320000
[2022-11-23 15:01:16.595595] >>> [1320.090] nnodes: 12, no morph
[2022-11-23 15:01:16.595658] >>> [1320.090] next_event: remove at 1380000
[2022-11-23 15:01:46.535830] >>> [1350.030]      node to be remove: ['172.31.26.140']
[2022-11-23 15:01:46.536299] >>> [1350.030] nnodes: 11, message: preempt 1350.0303101539612
[2022-11-23 15:01:46.536339]                remain nodes: ['172.31.28.108', '172.31.20.223', '172.31.18.152', '172.31.27.216', '172.31.22.165', '172.31.28.236', '172.31.21.45', '172.31.21.109', '172.31.21.254', '172.31.23.137', '172.31.28.143']
[2022-11-23 15:01:46.536353] >>> [1350.031] next_event: no-op at 1440000
[2022-11-23 15:03:16.595604] >>> [1440.090] nnodes: 11, no morph
[2022-11-23 15:03:16.595661] >>> [1440.090] next_event: no-op at 1500000
[2022-11-23 15:04:16.565836] >>> [1500.060] nnodes: 11, no morph
[2022-11-23 15:04:16.565901] >>> [1500.060] next_event: add at 1560000
[2022-11-23 15:05:16.550610] >>> [1560.045]      node to be add: ['172.31.31.40']
[2022-11-23 15:05:16.551180] >>> [1560.045] nnodes: 12, message: morph
[2022-11-23 15:05:16.551218]                remain nodes: ['172.31.28.108', '172.31.20.223', '172.31.18.152', '172.31.27.216', '172.31.22.165', '172.31.28.236', '172.31.21.45', '172.31.21.109', '172.31.21.254', '172.31.23.137', '172.31.28.143', '172.31.31.40']
[2022-11-23 15:05:16.551234] >>> [1560.045] next_event: add at 1620000
[2022-11-23 15:06:16.563622] >>> [1620.058]      node to be add: ['172.31.16.100']
[2022-11-23 15:06:16.564150] >>> [1620.058] nnodes: 13, message: morph
[2022-11-23 15:06:16.564197]                remain nodes: ['172.31.28.108', '172.31.20.223', '172.31.18.152', '172.31.27.216', '172.31.22.165', '172.31.28.236', '172.31.21.45', '172.31.21.109', '172.31.21.254', '172.31.23.137', '172.31.28.143', '172.31.31.40', '172.31.16.100']
[2022-11-23 15:06:16.564219] >>> [1620.058] next_event: no-op at 1680000
[2022-11-23 15:07:16.565870] >>> [1680.060] nnodes: 13, no morph
[2022-11-23 15:07:16.565934] >>> [1680.060] next_event: remove at 1740000
[2022-11-23 15:07:46.535865] >>> [1710.030]      node to be remove: ['172.31.18.152']
[2022-11-23 15:07:46.536381] >>> [1710.031] nnodes: 12, message: preempt 1710.030333995819
[2022-11-23 15:07:46.536420]                remain nodes: ['172.31.28.108', '172.31.20.223', '172.31.27.216', '172.31.22.165', '172.31.28.236', '172.31.21.45', '172.31.21.109', '172.31.21.254', '172.31.23.137', '172.31.28.143', '172.31.31.40', '172.31.16.100']
[2022-11-23 15:07:46.536449] >>> [1710.031] next_event: add at 1800000
[2022-11-23 15:09:16.595919] >>> [1800.090]      node to be add: ['172.31.19.171']
[2022-11-23 15:09:16.596480] >>> [1800.091] nnodes: 13, message: morph
[2022-11-23 15:09:16.596518]                remain nodes: ['172.31.28.108', '172.31.20.223', '172.31.27.216', '172.31.22.165', '172.31.28.236', '172.31.21.45', '172.31.21.109', '172.31.21.254', '172.31.23.137', '172.31.28.143', '172.31.31.40', '172.31.16.100', '172.31.19.171']
[2022-11-23 15:09:16.596535] >>> [1800.091] next_event: no-op at 1860000
[2022-11-23 15:10:16.563609] >>> [1860.058] nnodes: 13, no morph
[2022-11-23 15:10:16.563690] >>> [1860.058] next_event: no-op at 1920000
[2022-11-23 15:11:16.563606] >>> [1920.058] nnodes: 13, no morph
[2022-11-23 15:11:16.563682] >>> [1920.058] next_event: no-op at 1980000
[2022-11-23 15:12:16.563604] >>> [1980.058] nnodes: 13, no morph
[2022-11-23 15:12:16.563666] >>> [1980.058] next_event: add at 2040000
[2022-11-23 15:13:16.542179] >>> [2040.036]      node to be add: ['172.31.24.208']
[2022-11-23 15:13:16.542852] >>> [2040.037] nnodes: 14, message: morph
[2022-11-23 15:13:16.542900]                remain nodes: ['172.31.28.108', '172.31.20.223', '172.31.27.216', '172.31.22.165', '172.31.28.236', '172.31.21.45', '172.31.21.109', '172.31.21.254', '172.31.23.137', '172.31.28.143', '172.31.31.40', '172.31.16.100', '172.31.19.171', '172.31.24.208']
[2022-11-23 15:13:16.542933] >>> [2040.037] next_event: no-op at 2100000
[2022-11-23 15:14:16.512171] >>> [2100.006] nnodes: 14, no morph
[2022-11-23 15:14:16.512226] >>> [2100.006] next_event: add at 2160000
[2022-11-23 15:15:16.563654] >>> [2160.058]      node to be add: ['172.31.19.112', '172.31.24.191', '172.31.16.5', '172.31.30.133']
[2022-11-23 15:15:16.564426] >>> [2160.059] nnodes: 18, message: morph
[2022-11-23 15:15:16.564518]                remain nodes: ['172.31.28.108', '172.31.20.223', '172.31.27.216', '172.31.22.165', '172.31.28.236', '172.31.21.45', '172.31.21.109', '172.31.21.254', '172.31.23.137', '172.31.28.143', '172.31.31.40', '172.31.16.100', '172.31.19.171', '172.31.24.208', '172.31.19.112', '172.31.24.191', '172.31.16.5', '172.31.30.133']
[2022-11-23 15:15:16.564542] >>> [2160.059] next_event: no-op at 2220000
[2022-11-23 15:16:16.565866] >>> [2220.060] nnodes: 18, no morph
[2022-11-23 15:16:16.565928] >>> [2220.060] next_event: no-op at 2280000
[2022-11-23 15:17:16.563603] >>> [2280.058] nnodes: 18, no morph
[2022-11-23 15:17:16.563666] >>> [2280.058] next_event: add at 2340000
[2022-11-23 15:18:16.563607] >>> [2340.058]      node to be add: ['172.31.22.229']
[2022-11-23 15:18:16.564141] >>> [2340.058] nnodes: 19, message: morph
[2022-11-23 15:18:16.564188]                remain nodes: ['172.31.28.108', '172.31.20.223', '172.31.27.216', '172.31.22.165', '172.31.28.236', '172.31.21.45', '172.31.21.109', '172.31.21.254', '172.31.23.137', '172.31.28.143', '172.31.31.40', '172.31.16.100', '172.31.19.171', '172.31.24.208', '172.31.19.112', '172.31.24.191', '172.31.16.5', '172.31.30.133', '172.31.22.229']
[2022-11-23 15:18:16.564215] >>> [2340.058] next_event: no-op at 2400000
[2022-11-23 15:19:16.563623] >>> [2400.058] nnodes: 19, no morph
[2022-11-23 15:19:16.563702] >>> [2400.058] next_event: no-op at 2460000
[2022-11-23 15:20:16.563611] >>> [2460.058] nnodes: 19, no morph
[2022-11-23 15:20:16.563684] >>> [2460.058] next_event: remove at 2520000
[2022-11-23 15:20:46.535876] >>> [2490.030]      node to be remove: ['172.31.16.5', '172.31.28.143', '172.31.27.216']
[2022-11-23 15:20:46.536465] >>> [2490.031] nnodes: 16, message: preempt 2490.0304079055786
[2022-11-23 15:20:46.536513]                remain nodes: ['172.31.28.108', '172.31.20.223', '172.31.22.165', '172.31.28.236', '172.31.21.45', '172.31.21.109', '172.31.21.254', '172.31.23.137', '172.31.31.40', '172.31.16.100', '172.31.19.171', '172.31.24.208', '172.31.19.112', '172.31.24.191', '172.31.30.133', '172.31.22.229']
[2022-11-23 15:20:46.536528] >>> [2490.031] next_event: no-op at 2580000
[2022-11-23 15:22:16.595697] >>> [2580.090] nnodes: 16, no morph
[2022-11-23 15:22:16.595895] >>> [2580.090] next_event: remove at 2640000
[2022-11-23 15:22:46.535661] >>> [2610.030]      node to be remove: ['172.31.21.45']
[2022-11-23 15:22:46.536678] >>> [2610.031] nnodes: 15, message: preempt 2610.0304963588715
[2022-11-23 15:22:46.536974]                remain nodes: ['172.31.28.108', '172.31.20.223', '172.31.22.165', '172.31.28.236', '172.31.21.109', '172.31.21.254', '172.31.23.137', '172.31.31.40', '172.31.16.100', '172.31.19.171', '172.31.24.208', '172.31.19.112', '172.31.24.191', '172.31.30.133', '172.31.22.229']
[2022-11-23 15:22:46.537014] >>> [2610.031] next_event: no-op at 2700000
[2022-11-23 15:24:16.595599] >>> [2700.090] nnodes: 15, no morph
[2022-11-23 15:24:16.595649] >>> [2700.090] next_event: no-op at 2760000
[2022-11-23 15:25:16.565826] >>> [2760.060] nnodes: 15, no morph
[2022-11-23 15:25:16.565896] >>> [2760.060] next_event: add at 2820000
[2022-11-23 15:26:16.565851] >>> [2820.060]      node to be add: ['172.31.21.137', '172.31.30.99']
[2022-11-23 15:26:16.566406] >>> [2820.061] nnodes: 17, message: morph
[2022-11-23 15:26:16.566464]                remain nodes: ['172.31.28.108', '172.31.20.223', '172.31.22.165', '172.31.28.236', '172.31.21.109', '172.31.21.254', '172.31.23.137', '172.31.31.40', '172.31.16.100', '172.31.19.171', '172.31.24.208', '172.31.19.112', '172.31.24.191', '172.31.30.133', '172.31.22.229', '172.31.21.137', '172.31.30.99']
[2022-11-23 15:26:16.566472] >>> [2820.061] next_event: no-op at 2880000
[2022-11-23 15:27:16.563602] >>> [2880.058] nnodes: 17, no morph
[2022-11-23 15:27:16.563658] >>> [2880.058] next_event: no-op at 2940000
[2022-11-23 15:28:16.563600] >>> [2940.058] nnodes: 17, no morph
[2022-11-23 15:29:16.566266] >>> [3000.060] nnodes: 17, message: preempt 3000.060220479965
[2022-11-23 15:29:16.566331]           Finally kill all
