Parent process ID: 80676 node: 172.31.28.108
Killing process on gpu with nvidia-smi | grep 'python' | awk '{ print $5 }' | xargs -n1 kill -9
2 per stage
16 servers!
Config:
ranks: range(0, 1)
train batch size: 1024
partitions: 8
chunk_size: 8
data depth: 2
stage to rank map: 0,8;1,9;2,10;3,11;4,12;5,13;6,14;7,15;
World size is 16
/opt/conda/envs/varuna/bin/python -u /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --rank=0 --chunk_size=8 --local_rank=0 --stage_to_rank_map=0,8;1,9;2,10;3,11;4,12;5,13;6,14;7,15; --batch-size=512 --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna
device: cuda:0 n_gpu: 1, distributed training: True, 16-bits training: True
DLL 2022-11-23 14:39:26.640226 - PARAMETER Config : ["Namespace(input_dir='/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/', config_file='bert_config.json', bert_model='bert-large-uncased', output_dir='s3://spot-checkpoints/bert', init_checkpoint=None, max_seq_length=128, max_predictions_per_seq=20, train_batch_size=512, learning_rate=0.006, num_train_epochs=3.0, max_steps=7038.0, warmup_proportion=0.2843, local_rank=0, seed=12439, gradient_accumulation_steps=1, fp16=True, amp=False, loss_scale=0.0, log_freq=1.0, checkpoint_activations=False, resume_from_checkpoint=False, resume_step=-1, num_steps_per_checkpoint=200, skip_checkpoint=False, phase2=False, allreduce_post_accumulation=False, allreduce_post_accumulation_fp16=False, phase1_end_step=7038, init_loss_scale=1048576, do_train=True, json_summary='/home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json', use_env=False, disable_progress_bar=False, steps_this_run=7038.0, varuna=True, stage_to_rank_map='0,8;1,9;2,10;3,11;4,12;5,13;6,14;7,15;', chunk_size=8, batch_size=512, rank=0, profiling=False, n_gpu=1)"] 
dry run time 0.10425257682800293
SHARED WEIGHTS ARE
[(0, 7)]
this rank  0 is part of pipeline replica  0
64 chunks
Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.

Defaults for this optimization level are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
DLL 2022-11-23 14:39:36.078522 - PARAMETER SEED : 12439 
DLL 2022-11-23 14:39:36.078683 - PARAMETER train_start : True 
DLL 2022-11-23 14:39:36.078746 - PARAMETER batch_size_per_gpu : 512 
DLL 2022-11-23 14:39:36.078784 - PARAMETER learning_rate : 0.006 
Finished iteration 0, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 10672.977
DLL 2022-11-23 14:39:46.796026 - Training Epoch: 0 Training Iteration: 1  average_loss : 11.2335205078125  step_loss : 11.2335205078125  learning_rate : 2.9986455118223097e-06 
Finished iteration 1, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5486.352
DLL 2022-11-23 14:39:52.279900 - Training Epoch: 0 Training Iteration: 2  average_loss : 11.232177734375  step_loss : 11.232177734375  learning_rate : 5.9972910236446195e-06 
Finished iteration 2, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5495.661
DLL 2022-11-23 14:39:57.775778 - Training Epoch: 0 Training Iteration: 3  average_loss : 11.24267578125  step_loss : 11.24267578125  learning_rate : 8.995936535466931e-06 
Finished iteration 3, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5625.425
DLL 2022-11-23 14:40:03.401198 - Training Epoch: 0 Training Iteration: 4  average_loss : 11.2244873046875  step_loss : 11.2244873046875  learning_rate : 1.1994582047289239e-05 
Finished iteration 4, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5427.033
DLL 2022-11-23 14:40:08.828100 - Training Epoch: 0 Training Iteration: 5  average_loss : 11.219970703125  step_loss : 11.219970703125  learning_rate : 1.499322755911155e-05 
Finished iteration 5, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4378.959
DLL 2022-11-23 14:40:13.207058 - Training Epoch: 0 Training Iteration: 6  average_loss : 11.2279052734375  step_loss : 11.2279052734375  learning_rate : 1.7991873070933862e-05 
Finished iteration 6, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4498.451
DLL 2022-11-23 14:40:17.705416 - Training Epoch: 0 Training Iteration: 7  average_loss : 11.229736328125  step_loss : 11.229736328125  learning_rate : 2.099051858275617e-05 
Finished iteration 7, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4508.202
DLL 2022-11-23 14:40:22.213733 - Training Epoch: 0 Training Iteration: 8  average_loss : 11.2354736328125  step_loss : 11.2354736328125  learning_rate : 2.3989164094578478e-05 
Finished iteration 8, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4371.279
DLL 2022-11-23 14:40:26.585257 - Training Epoch: 0 Training Iteration: 9  average_loss : 11.2239990234375  step_loss : 11.2239990234375  learning_rate : 2.698780960640079e-05 
Finished iteration 9, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4524.985
DLL 2022-11-23 14:40:31.110389 - Training Epoch: 0 Training Iteration: 10  average_loss : 11.2156982421875  step_loss : 11.2156982421875  learning_rate : 2.99864551182231e-05 
Finished iteration 10, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4216.220
DLL 2022-11-23 14:40:35.326582 - Training Epoch: 0 Training Iteration: 11  average_loss : 11.2110595703125  step_loss : 11.2110595703125  learning_rate : 3.298510063004541e-05 
Finished iteration 11, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4438.557
DLL 2022-11-23 14:40:39.770718 - Training Epoch: 0 Training Iteration: 12  average_loss : 11.1990966796875  step_loss : 11.1990966796875  learning_rate : 3.5983746141867724e-05 
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  524288.0
Finished iteration 12, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4258.899
DLL 2022-11-23 14:40:44.029486 - Training Epoch: 0 Training Iteration: 13  average_loss : 11.20361328125  step_loss : 11.20361328125  learning_rate : 3.898239165369003e-05 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  262144.0
Finished iteration 13, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4248.122
DLL 2022-11-23 14:40:48.272103 - Training Epoch: 0 Training Iteration: 14  average_loss : nan  step_loss : nan  learning_rate : 4.198103716551234e-05 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  131072.0
Finished iteration 14, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4452.742
DLL 2022-11-23 14:40:52.724810 - Training Epoch: 0 Training Iteration: 15  average_loss : nan  step_loss : nan  learning_rate : 4.497968267733465e-05 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  65536.0
Finished iteration 15, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4482.697
DLL 2022-11-23 14:40:57.208081 - Training Epoch: 0 Training Iteration: 16  average_loss : nan  step_loss : nan  learning_rate : 4.7978328189156956e-05 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  32768.0
Finished iteration 16, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4324.593
DLL 2022-11-23 14:41:01.537653 - Training Epoch: 0 Training Iteration: 17  average_loss : nan  step_loss : nan  learning_rate : 5.097697370097927e-05 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  16384.0
Finished iteration 17, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4292.547
DLL 2022-11-23 14:41:05.825076 - Training Epoch: 0 Training Iteration: 18  average_loss : nan  step_loss : nan  learning_rate : 5.397561921280158e-05 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  8192.0
Finished iteration 18, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4559.585
DLL 2022-11-23 14:41:10.390197 - Training Epoch: 0 Training Iteration: 19  average_loss : nan  step_loss : nan  learning_rate : 5.697426472462389e-05 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  4096.0
Finished iteration 19, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5294.821
DLL 2022-11-23 14:41:15.679419 - Training Epoch: 0 Training Iteration: 20  average_loss : nan  step_loss : nan  learning_rate : 5.99729102364462e-05 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  2048.0
Finished iteration 20, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4367.141
DLL 2022-11-23 14:41:20.046428 - Training Epoch: 0 Training Iteration: 21  average_loss : nan  step_loss : nan  learning_rate : 6.297155574826851e-05 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1024.0
Finished iteration 21, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4214.353
DLL 2022-11-23 14:41:24.260947 - Training Epoch: 0 Training Iteration: 22  average_loss : nan  step_loss : nan  learning_rate : 6.597020126009082e-05 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  512.0
Finished iteration 22, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4415.772
DLL 2022-11-23 14:41:28.684108 - Training Epoch: 0 Training Iteration: 23  average_loss : nan  step_loss : nan  learning_rate : 6.896884677191313e-05 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  256.0
Finished iteration 23, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4277.219
DLL 2022-11-23 14:41:32.953800 - Training Epoch: 0 Training Iteration: 24  average_loss : nan  step_loss : nan  learning_rate : 7.196749228373545e-05 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  128.0
Finished iteration 24, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4388.884
DLL 2022-11-23 14:41:37.342769 - Training Epoch: 0 Training Iteration: 25  average_loss : nan  step_loss : nan  learning_rate : 7.496613779555775e-05 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  64.0
Finished iteration 25, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4455.909
DLL 2022-11-23 14:41:41.798717 - Training Epoch: 0 Training Iteration: 26  average_loss : nan  step_loss : nan  learning_rate : 7.796478330738006e-05 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  32.0
Finished iteration 26, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4322.502
DLL 2022-11-23 14:41:46.121225 - Training Epoch: 0 Training Iteration: 27  average_loss : nan  step_loss : nan  learning_rate : 8.096342881920237e-05 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  16.0
Finished iteration 27, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4410.887
DLL 2022-11-23 14:41:50.532416 - Training Epoch: 0 Training Iteration: 28  average_loss : nan  step_loss : nan  learning_rate : 8.396207433102469e-05 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  8.0
Finished iteration 28, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4561.596
DLL 2022-11-23 14:41:55.099839 - Training Epoch: 0 Training Iteration: 29  average_loss : nan  step_loss : nan  learning_rate : 8.696071984284699e-05 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  4.0
Finished iteration 29, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4366.070
DLL 2022-11-23 14:41:59.460096 - Training Epoch: 0 Training Iteration: 30  average_loss : nan  step_loss : nan  learning_rate : 8.99593653546693e-05 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  2.0
Finished iteration 30, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4358.609
DLL 2022-11-23 14:42:03.824001 - Training Epoch: 0 Training Iteration: 31  average_loss : nan  step_loss : nan  learning_rate : 9.29580108664916e-05 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 31, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4638.512
DLL 2022-11-23 14:42:08.463103 - Training Epoch: 0 Training Iteration: 32  average_loss : nan  step_loss : nan  learning_rate : 9.595665637831391e-05 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 32, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4257.848
DLL 2022-11-23 14:42:12.714974 - Training Epoch: 0 Training Iteration: 33  average_loss : nan  step_loss : nan  learning_rate : 9.895530189013622e-05 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 33, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4369.574
DLL 2022-11-23 14:42:17.084842 - Training Epoch: 0 Training Iteration: 34  average_loss : nan  step_loss : nan  learning_rate : 0.00010195394740195854 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 34, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4832.196
DLL 2022-11-23 14:42:21.916861 - Training Epoch: 0 Training Iteration: 35  average_loss : nan  step_loss : nan  learning_rate : 0.00010495259291378085 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 35, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4511.120
DLL 2022-11-23 14:42:26.427998 - Training Epoch: 0 Training Iteration: 36  average_loss : nan  step_loss : nan  learning_rate : 0.00010795123842560316 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 36, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4521.224
DLL 2022-11-23 14:42:30.949501 - Training Epoch: 0 Training Iteration: 37  average_loss : nan  step_loss : nan  learning_rate : 0.00011094988393742548 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 37, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4467.366
DLL 2022-11-23 14:42:35.422224 - Training Epoch: 0 Training Iteration: 38  average_loss : nan  step_loss : nan  learning_rate : 0.00011394852944924778 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 38, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4349.062
DLL 2022-11-23 14:42:39.766156 - Training Epoch: 0 Training Iteration: 39  average_loss : nan  step_loss : nan  learning_rate : 0.00011694717496107008 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 39, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4297.889
DLL 2022-11-23 14:42:44.063769 - Training Epoch: 0 Training Iteration: 40  average_loss : nan  step_loss : nan  learning_rate : 0.0001199458204728924 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 40, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4337.167
DLL 2022-11-23 14:42:48.406424 - Training Epoch: 0 Training Iteration: 41  average_loss : nan  step_loss : nan  learning_rate : 0.0001229444659847147 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 41, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4422.321
DLL 2022-11-23 14:42:52.828722 - Training Epoch: 0 Training Iteration: 42  average_loss : nan  step_loss : nan  learning_rate : 0.00012594311149653702 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 42, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4362.401
DLL 2022-11-23 14:42:57.191344 - Training Epoch: 0 Training Iteration: 43  average_loss : nan  step_loss : nan  learning_rate : 0.00012894175700835933 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 43, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4478.814
DLL 2022-11-23 14:43:01.668273 - Training Epoch: 0 Training Iteration: 44  average_loss : nan  step_loss : nan  learning_rate : 0.00013194040252018164 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 44, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4374.796
DLL 2022-11-23 14:43:06.039379 - Training Epoch: 0 Training Iteration: 45  average_loss : nan  step_loss : nan  learning_rate : 0.00013493904803200396 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 45, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4662.562
DLL 2022-11-23 14:43:10.701855 - Training Epoch: 0 Training Iteration: 46  average_loss : nan  step_loss : nan  learning_rate : 0.00013793769354382627 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 46, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4395.869
DLL 2022-11-23 14:43:15.097958 - Training Epoch: 0 Training Iteration: 47  average_loss : nan  step_loss : nan  learning_rate : 0.00014093633905564855 
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 0 signal handler called with signal 10
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 47, CKPT_AND_STOP: True, flag: tensor([3], dtype=torch.int32), speed: 4263.749
DLL 2022-11-23 14:43:19.368583 - Training Epoch: 0 Training Iteration: 48  average_loss : nan  step_loss : nan  learning_rate : 0.0001439349845674709 
2022-11-23 14:43:19.368715 Begin to save checkpont to s3://spot-checkpoints/bert and exit
DLL 2022-11-23 14:43:19.368736 - PARAMETER checkpoint_step : 48 
Opt ckpt time 7.690438270568848
Process done with return code 0
Parent process ID: 81871 node: 172.31.28.108
2 per stage
16 servers!
Config:
ranks: range(0, 1)
train batch size: 1024
partitions: 8
chunk_size: 8
data depth: 2
stage to rank map: 0,8;1,9;2,10;3,11;4,12;5,13;6,14;7,15;
World size is 16
/opt/conda/envs/varuna/bin/python -u /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --rank=0 --chunk_size=8 --local_rank=0 --stage_to_rank_map=0,8;1,9;2,10;3,11;4,12;5,13;6,14;7,15; --batch-size=512 --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna --resume_step 48
device: cuda:0 n_gpu: 1, distributed training: True, 16-bits training: True
DLL 2022-11-23 14:43:37.200862 - PARAMETER Config : ["Namespace(input_dir='/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/', config_file='bert_config.json', bert_model='bert-large-uncased', output_dir='s3://spot-checkpoints/bert', init_checkpoint=None, max_seq_length=128, max_predictions_per_seq=20, train_batch_size=512, learning_rate=0.006, num_train_epochs=3.0, max_steps=7038.0, warmup_proportion=0.2843, local_rank=0, seed=12439, gradient_accumulation_steps=1, fp16=True, amp=False, loss_scale=0.0, log_freq=1.0, checkpoint_activations=False, resume_from_checkpoint=True, resume_step=48, num_steps_per_checkpoint=200, skip_checkpoint=False, phase2=False, allreduce_post_accumulation=False, allreduce_post_accumulation_fp16=False, phase1_end_step=7038, init_loss_scale=1048576, do_train=True, json_summary='/home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json', use_env=False, disable_progress_bar=False, steps_this_run=7038.0, varuna=True, stage_to_rank_map='0,8;1,9;2,10;3,11;4,12;5,13;6,14;7,15;', chunk_size=8, batch_size=512, rank=0, profiling=False, n_gpu=1)"] 
dry run time 0.548802375793457
SHARED WEIGHTS ARE
[(0, 7)]
this rank  0 is part of pipeline replica  0
64 chunks
Begin to load checkpint from s3://spot-checkpoints/bert/ckpt_48.pt
2022-11-23 14:43:47.793290 resume step from  48
Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.

Defaults for this optimization level are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
2022-11-23 14:43:57.713083 - Finished loading checkpoint, takes 9907.334 secs
DLL 2022-11-23 14:43:57.714115 - PARAMETER SEED : 12439 
DLL 2022-11-23 14:43:57.714235 - PARAMETER train_start : True 
DLL 2022-11-23 14:43:57.714286 - PARAMETER batch_size_per_gpu : 512 
DLL 2022-11-23 14:43:57.714322 - PARAMETER learning_rate : 0.006 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  524288.0
Finished iteration 48, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 12947.999
DLL 2022-11-23 14:44:10.705874 - Training Epoch: 0 Training Iteration: 49  average_loss : nan  step_loss : nan  learning_rate : 0.00014693363007929318 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  262144.0
Finished iteration 49, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5290.268
DLL 2022-11-23 14:44:15.987813 - Training Epoch: 0 Training Iteration: 50  average_loss : nan  step_loss : nan  learning_rate : 0.0001499322755911155 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  131072.0
Finished iteration 50, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5416.805
DLL 2022-11-23 14:44:21.412421 - Training Epoch: 0 Training Iteration: 51  average_loss : nan  step_loss : nan  learning_rate : 0.0001529309211029378 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  65536.0
Finished iteration 51, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5335.093
DLL 2022-11-23 14:44:26.745213 - Training Epoch: 0 Training Iteration: 52  average_loss : nan  step_loss : nan  learning_rate : 0.00015592956661476012 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  32768.0
Finished iteration 52, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5550.919
DLL 2022-11-23 14:44:32.290872 - Training Epoch: 0 Training Iteration: 53  average_loss : nan  step_loss : nan  learning_rate : 0.0001589282121265824 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  16384.0
Finished iteration 53, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4425.716
DLL 2022-11-23 14:44:36.716490 - Training Epoch: 0 Training Iteration: 54  average_loss : nan  step_loss : nan  learning_rate : 0.00016192685763840475 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  8192.0
Finished iteration 54, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5012.141
DLL 2022-11-23 14:44:41.728621 - Training Epoch: 0 Training Iteration: 55  average_loss : nan  step_loss : nan  learning_rate : 0.00016492550315022706 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  4096.0
Finished iteration 55, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4371.326
DLL 2022-11-23 14:44:46.099922 - Training Epoch: 0 Training Iteration: 56  average_loss : nan  step_loss : nan  learning_rate : 0.00016792414866204937 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  2048.0
Finished iteration 56, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4263.076
DLL 2022-11-23 14:44:50.363043 - Training Epoch: 0 Training Iteration: 57  average_loss : nan  step_loss : nan  learning_rate : 0.00017092279417387166 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1024.0
Finished iteration 57, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4197.507
DLL 2022-11-23 14:44:54.560483 - Training Epoch: 0 Training Iteration: 58  average_loss : nan  step_loss : nan  learning_rate : 0.00017392143968569397 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  512.0
Finished iteration 58, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4202.512
DLL 2022-11-23 14:44:58.763192 - Training Epoch: 0 Training Iteration: 59  average_loss : nan  step_loss : nan  learning_rate : 0.0001769200851975163 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  256.0
Finished iteration 59, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4489.727
DLL 2022-11-23 14:45:03.252942 - Training Epoch: 0 Training Iteration: 60  average_loss : nan  step_loss : nan  learning_rate : 0.0001799187307093386 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  128.0
Finished iteration 60, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4358.322
DLL 2022-11-23 14:45:07.611301 - Training Epoch: 0 Training Iteration: 61  average_loss : nan  step_loss : nan  learning_rate : 0.00018291737622116094 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  64.0
Finished iteration 61, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4389.174
DLL 2022-11-23 14:45:12.005722 - Training Epoch: 0 Training Iteration: 62  average_loss : nan  step_loss : nan  learning_rate : 0.0001859160217329832 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  32.0
Finished iteration 62, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4735.235
DLL 2022-11-23 14:45:16.735452 - Training Epoch: 0 Training Iteration: 63  average_loss : nan  step_loss : nan  learning_rate : 0.00018891466724480554 
Signal handler called with signal 10
Rank

 STOPPING VARUNA !!


 0 signal handler called with signal
 10
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  16.0
Finished iteration 63, CKPT_AND_STOP: True, flag: tensor([5], dtype=torch.int32), speed: 4347.308
DLL 2022-11-23 14:45:21.083445 - Training Epoch: 0 Training Iteration: 64  average_loss : nan  step_loss : nan  learning_rate : 0.00019191331275662782 
2022-11-23 14:45:21.083632 Begin to save checkpont to s3://spot-checkpoints/bert and exit
DLL 2022-11-23 14:45:21.083655 - PARAMETER checkpoint_step : 64 
Opt ckpt time 7.146775722503662
Process done with return code 0
Parent process ID: 82849 node: 172.31.28.108
2 per stage
16 servers!
Config:
ranks: range(0, 1)
train batch size: 1024
partitions: 8
chunk_size: 8
data depth: 2
stage to rank map: 0,8;1,9;2,10;3,11;4,12;5,13;6,14;7,15;
World size is 16
/opt/conda/envs/varuna/bin/python -u /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --rank=0 --chunk_size=8 --local_rank=0 --stage_to_rank_map=0,8;1,9;2,10;3,11;4,12;5,13;6,14;7,15; --batch-size=512 --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna --resume_step 64
device: cuda:0 n_gpu: 1, distributed training: True, 16-bits training: True
DLL 2022-11-23 14:45:39.088981 - PARAMETER Config : ["Namespace(input_dir='/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/', config_file='bert_config.json', bert_model='bert-large-uncased', output_dir='s3://spot-checkpoints/bert', init_checkpoint=None, max_seq_length=128, max_predictions_per_seq=20, train_batch_size=512, learning_rate=0.006, num_train_epochs=3.0, max_steps=7038.0, warmup_proportion=0.2843, local_rank=0, seed=12439, gradient_accumulation_steps=1, fp16=True, amp=False, loss_scale=0.0, log_freq=1.0, checkpoint_activations=False, resume_from_checkpoint=True, resume_step=64, num_steps_per_checkpoint=200, skip_checkpoint=False, phase2=False, allreduce_post_accumulation=False, allreduce_post_accumulation_fp16=False, phase1_end_step=7038, init_loss_scale=1048576, do_train=True, json_summary='/home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json', use_env=False, disable_progress_bar=False, steps_this_run=7038.0, varuna=True, stage_to_rank_map='0,8;1,9;2,10;3,11;4,12;5,13;6,14;7,15;', chunk_size=8, batch_size=512, rank=0, profiling=False, n_gpu=1)"] 
dry run time 0.07456135749816895
SHARED WEIGHTS ARE
[(0, 7)]
this rank  0 is part of pipeline replica  0
64 chunks
Begin to load checkpint from s3://spot-checkpoints/bert/ckpt_64.pt
2022-11-23 14:45:49.300175 resume step from  64
Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.

Defaults for this optimization level are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
2022-11-23 14:45:59.188416 - Finished loading checkpoint, takes 9876.319 secs
DLL 2022-11-23 14:45:59.189501 - PARAMETER SEED : 12439 
DLL 2022-11-23 14:45:59.189626 - PARAMETER train_start : True 
DLL 2022-11-23 14:45:59.189688 - PARAMETER batch_size_per_gpu : 512 
DLL 2022-11-23 14:45:59.189745 - PARAMETER learning_rate : 0.006 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  524288.0
Finished iteration 64, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 17599.561
DLL 2022-11-23 14:46:16.824917 - Training Epoch: 0 Training Iteration: 65  average_loss : nan  step_loss : nan  learning_rate : 0.00019491195826845016 
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 0 signal handler called with signal 10
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  262144.0
Finished iteration 65, CKPT_AND_STOP: True, flag: tensor([5], dtype=torch.int32), speed: 5802.120
DLL 2022-11-23 14:46:22.626761 - Training Epoch: 0 Training Iteration: 66  average_loss : nan  step_loss : nan  learning_rate : 0.00019791060378027245 
2022-11-23 14:46:22.626893 Begin to save checkpont to s3://spot-checkpoints/bert and exit
DLL 2022-11-23 14:46:22.626912 - PARAMETER checkpoint_step : 66 
Opt ckpt time 7.478556871414185
Process done with return code 0
Parent process ID: 83674 node: 172.31.28.108
2 per stage
16 servers!
Config:
ranks: range(0, 1)
train batch size: 1024
partitions: 8
chunk_size: 8
data depth: 2
stage to rank map: 0,8;1,9;2,10;3,11;4,12;5,13;6,14;7,15;
World size is 16
/opt/conda/envs/varuna/bin/python -u /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --rank=0 --chunk_size=8 --local_rank=0 --stage_to_rank_map=0,8;1,9;2,10;3,11;4,12;5,13;6,14;7,15; --batch-size=512 --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna --resume_step 66
device: cuda:0 n_gpu: 1, distributed training: True, 16-bits training: True
DLL 2022-11-23 14:46:40.507120 - PARAMETER Config : ["Namespace(input_dir='/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/', config_file='bert_config.json', bert_model='bert-large-uncased', output_dir='s3://spot-checkpoints/bert', init_checkpoint=None, max_seq_length=128, max_predictions_per_seq=20, train_batch_size=512, learning_rate=0.006, num_train_epochs=3.0, max_steps=7038.0, warmup_proportion=0.2843, local_rank=0, seed=12439, gradient_accumulation_steps=1, fp16=True, amp=False, loss_scale=0.0, log_freq=1.0, checkpoint_activations=False, resume_from_checkpoint=True, resume_step=66, num_steps_per_checkpoint=200, skip_checkpoint=False, phase2=False, allreduce_post_accumulation=False, allreduce_post_accumulation_fp16=False, phase1_end_step=7038, init_loss_scale=1048576, do_train=True, json_summary='/home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json', use_env=False, disable_progress_bar=False, steps_this_run=7038.0, varuna=True, stage_to_rank_map='0,8;1,9;2,10;3,11;4,12;5,13;6,14;7,15;', chunk_size=8, batch_size=512, rank=0, profiling=False, n_gpu=1)"] 
dry run time 0.10991168022155762
SHARED WEIGHTS ARE
[(0, 7)]
this rank  0 is part of pipeline replica  0
64 chunks
Begin to load checkpint from s3://spot-checkpoints/bert/ckpt_66.pt
2022-11-23 14:46:50.683196 resume step from  66
Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.

Defaults for this optimization level are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
2022-11-23 14:47:00.502815 - Finished loading checkpoint, takes 9807.285 secs
DLL 2022-11-23 14:47:00.503867 - PARAMETER SEED : 12439 
DLL 2022-11-23 14:47:00.503996 - PARAMETER train_start : True 
DLL 2022-11-23 14:47:00.504048 - PARAMETER batch_size_per_gpu : 512 
DLL 2022-11-23 14:47:00.504087 - PARAMETER learning_rate : 0.006 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  524288.0
Finished iteration 66, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 18356.592
DLL 2022-11-23 14:47:18.896214 - Training Epoch: 0 Training Iteration: 67  average_loss : nan  step_loss : nan  learning_rate : 0.00020090924929209476 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  262144.0
Finished iteration 67, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5467.295
DLL 2022-11-23 14:47:24.363585 - Training Epoch: 0 Training Iteration: 68  average_loss : nan  step_loss : nan  learning_rate : 0.00020390789480391708 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  131072.0
Finished iteration 68, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5708.973
DLL 2022-11-23 14:47:30.079984 - Training Epoch: 0 Training Iteration: 69  average_loss : nan  step_loss : nan  learning_rate : 0.0002069065403157394 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  65536.0
Finished iteration 69, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5755.333
DLL 2022-11-23 14:47:35.827396 - Training Epoch: 0 Training Iteration: 70  average_loss : nan  step_loss : nan  learning_rate : 0.0002099051858275617 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  32768.0
Finished iteration 70, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5468.096
DLL 2022-11-23 14:47:41.295804 - Training Epoch: 0 Training Iteration: 71  average_loss : nan  step_loss : nan  learning_rate : 0.00021290383133938402 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  16384.0
Finished iteration 71, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4322.493
DLL 2022-11-23 14:47:45.618480 - Training Epoch: 0 Training Iteration: 72  average_loss : nan  step_loss : nan  learning_rate : 0.00021590247685120633 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  8192.0
Finished iteration 72, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4308.534
DLL 2022-11-23 14:47:49.926624 - Training Epoch: 0 Training Iteration: 73  average_loss : nan  step_loss : nan  learning_rate : 0.00021890112236302861 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  4096.0
Finished iteration 73, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4279.718
DLL 2022-11-23 14:47:54.206806 - Training Epoch: 0 Training Iteration: 74  average_loss : nan  step_loss : nan  learning_rate : 0.00022189976787485096 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  2048.0
Finished iteration 74, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4458.833
DLL 2022-11-23 14:47:58.665461 - Training Epoch: 0 Training Iteration: 75  average_loss : nan  step_loss : nan  learning_rate : 0.00022489841338667327 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1024.0
Finished iteration 75, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4304.446
DLL 2022-11-23 14:48:02.970128 - Training Epoch: 0 Training Iteration: 76  average_loss : nan  step_loss : nan  learning_rate : 0.00022789705889849555 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  512.0
Finished iteration 76, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4330.569
DLL 2022-11-23 14:48:07.300613 - Training Epoch: 0 Training Iteration: 77  average_loss : nan  step_loss : nan  learning_rate : 0.00023089570441031787 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  256.0
Finished iteration 77, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4257.423
DLL 2022-11-23 14:48:11.557809 - Training Epoch: 0 Training Iteration: 78  average_loss : nan  step_loss : nan  learning_rate : 0.00023389434992214015 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  128.0
Finished iteration 78, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4307.572
DLL 2022-11-23 14:48:15.873575 - Training Epoch: 0 Training Iteration: 79  average_loss : nan  step_loss : nan  learning_rate : 0.00023689299543396247 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  64.0
Finished iteration 79, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4239.774
DLL 2022-11-23 14:48:20.105419 - Training Epoch: 0 Training Iteration: 80  average_loss : nan  step_loss : nan  learning_rate : 0.0002398916409457848 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  32.0
Finished iteration 80, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4337.207
DLL 2022-11-23 14:48:24.447953 - Training Epoch: 0 Training Iteration: 81  average_loss : nan  step_loss : nan  learning_rate : 0.00024289028645760712 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  16.0
Finished iteration 81, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4384.904
DLL 2022-11-23 14:48:28.827249 - Training Epoch: 0 Training Iteration: 82  average_loss : nan  step_loss : nan  learning_rate : 0.0002458889319694294 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  8.0
Finished iteration 82, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4352.490
DLL 2022-11-23 14:48:33.179904 - Training Epoch: 0 Training Iteration: 83  average_loss : nan  step_loss : nan  learning_rate : 0.0002488875774812517 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  4.0
Finished iteration 83, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4165.217
DLL 2022-11-23 14:48:37.345209 - Training Epoch: 0 Training Iteration: 84  average_loss : nan  step_loss : nan  learning_rate : 0.00025188622299307403 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  2.0
Finished iteration 84, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4387.404
DLL 2022-11-23 14:48:41.732628 - Training Epoch: 0 Training Iteration: 85  average_loss : nan  step_loss : nan  learning_rate : 0.00025488486850489635 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 85, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4289.296
DLL 2022-11-23 14:48:46.021856 - Training Epoch: 0 Training Iteration: 86  average_loss : nan  step_loss : nan  learning_rate : 0.00025788351401671866 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 86, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4403.818
DLL 2022-11-23 14:48:50.431577 - Training Epoch: 0 Training Iteration: 87  average_loss : nan  step_loss : nan  learning_rate : 0.00026088215952854097 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 87, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4337.478
DLL 2022-11-23 14:48:54.763132 - Training Epoch: 0 Training Iteration: 88  average_loss : nan  step_loss : nan  learning_rate : 0.0002638808050403633 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 88, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4501.200
DLL 2022-11-23 14:48:59.270260 - Training Epoch: 0 Training Iteration: 89  average_loss : nan  step_loss : nan  learning_rate : 0.0002668794505521856 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 89, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4357.294
DLL 2022-11-23 14:49:03.622159 - Training Epoch: 0 Training Iteration: 90  average_loss : nan  step_loss : nan  learning_rate : 0.0002698780960640079 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 90, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4361.837
DLL 2022-11-23 14:49:07.983706 - Training Epoch: 0 Training Iteration: 91  average_loss : nan  step_loss : nan  learning_rate : 0.00027287674157583017 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 91, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4574.569
DLL 2022-11-23 14:49:12.558632 - Training Epoch: 0 Training Iteration: 92  average_loss : nan  step_loss : nan  learning_rate : 0.00027587538708765254 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 92, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4419.190
DLL 2022-11-23 14:49:16.977751 - Training Epoch: 0 Training Iteration: 93  average_loss : nan  step_loss : nan  learning_rate : 0.00027887403259947485 
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 0 signal handler called with signal 10
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 93, CKPT_AND_STOP: True, flag: tensor([4], dtype=torch.int32), speed: 4340.456
DLL 2022-11-23 14:49:21.318222 - Training Epoch: 0 Training Iteration: 94  average_loss : nan  step_loss : nan  learning_rate : 0.0002818726781112971 
2022-11-23 14:49:21.318365 Begin to save checkpont to s3://spot-checkpoints/bert and exit
DLL 2022-11-23 14:49:21.318378 - PARAMETER checkpoint_step : 94 
Opt ckpt time 7.300593852996826
Process done with return code 0
Parent process ID: 84753 node: 172.31.28.108
2 per stage
16 servers!
Config:
ranks: range(0, 1)
train batch size: 1024
partitions: 8
chunk_size: 8
data depth: 2
stage to rank map: 0,8;1,9;2,10;3,11;4,12;5,13;6,14;7,15;
World size is 16
/opt/conda/envs/varuna/bin/python -u /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --rank=0 --chunk_size=8 --local_rank=0 --stage_to_rank_map=0,8;1,9;2,10;3,11;4,12;5,13;6,14;7,15; --batch-size=512 --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna --resume_step 94
device: cuda:0 n_gpu: 1, distributed training: True, 16-bits training: True
DLL 2022-11-23 14:49:40.970638 - PARAMETER Config : ["Namespace(input_dir='/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/', config_file='bert_config.json', bert_model='bert-large-uncased', output_dir='s3://spot-checkpoints/bert', init_checkpoint=None, max_seq_length=128, max_predictions_per_seq=20, train_batch_size=512, learning_rate=0.006, num_train_epochs=3.0, max_steps=7038.0, warmup_proportion=0.2843, local_rank=0, seed=12439, gradient_accumulation_steps=1, fp16=True, amp=False, loss_scale=0.0, log_freq=1.0, checkpoint_activations=False, resume_from_checkpoint=True, resume_step=94, num_steps_per_checkpoint=200, skip_checkpoint=False, phase2=False, allreduce_post_accumulation=False, allreduce_post_accumulation_fp16=False, phase1_end_step=7038, init_loss_scale=1048576, do_train=True, json_summary='/home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json', use_env=False, disable_progress_bar=False, steps_this_run=7038.0, varuna=True, stage_to_rank_map='0,8;1,9;2,10;3,11;4,12;5,13;6,14;7,15;', chunk_size=8, batch_size=512, rank=0, profiling=False, n_gpu=1)"] 
dry run time 0.06248354911804199
SHARED WEIGHTS ARE
[(0, 7)]
this rank  0 is part of pipeline replica  0
64 chunks
Begin to load checkpint from s3://spot-checkpoints/bert/ckpt_94.pt
2022-11-23 14:49:56.020334 resume step from  94
Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.

Defaults for this optimization level are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
2022-11-23 14:50:06.201604 - Finished loading checkpoint, takes 10169.516 secs
DLL 2022-11-23 14:50:06.202455 - PARAMETER SEED : 12439 
DLL 2022-11-23 14:50:06.202574 - PARAMETER train_start : True 
DLL 2022-11-23 14:50:06.202624 - PARAMETER batch_size_per_gpu : 512 
DLL 2022-11-23 14:50:06.202665 - PARAMETER learning_rate : 0.006 
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 0 signal handler called with signal 10
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  524288.0
Finished iteration 94, CKPT_AND_STOP: True, flag: tensor([2], dtype=torch.int32), speed: 12853.771
DLL 2022-11-23 14:50:19.092488 - Training Epoch: 0 Training Iteration: 95  average_loss : nan  step_loss : nan  learning_rate : 0.0002848713236231194 
2022-11-23 14:50:19.092750 Begin to save checkpont to s3://spot-checkpoints/bert and exit
DLL 2022-11-23 14:50:19.092770 - PARAMETER checkpoint_step : 95 
Opt ckpt time 8.44450306892395
Process done with return code 0
Parent process ID: 85507 node: 172.31.28.108
3 per stage
24 servers!
Config:
ranks: range(0, 1)
train batch size: 1024
partitions: 8
chunk_size: 8
data depth: 3
stage to rank map: 0,8,16;1,9,17;2,10,18;3,11,19;4,12,20;5,13,21;6,14,22;7,15,23;
World size is 24
/opt/conda/envs/varuna/bin/python -u /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --rank=0 --chunk_size=8 --local_rank=0 --stage_to_rank_map=0,8,16;1,9,17;2,10,18;3,11,19;4,12,20;5,13,21;6,14,22;7,15,23; --batch-size=341 --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna --resume_step 95
device: cuda:0 n_gpu: 1, distributed training: True, 16-bits training: True
DLL 2022-11-23 14:50:40.642773 - PARAMETER Config : ["Namespace(input_dir='/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/', config_file='bert_config.json', bert_model='bert-large-uncased', output_dir='s3://spot-checkpoints/bert', init_checkpoint=None, max_seq_length=128, max_predictions_per_seq=20, train_batch_size=341, learning_rate=0.006, num_train_epochs=3.0, max_steps=7038.0, warmup_proportion=0.2843, local_rank=0, seed=12439, gradient_accumulation_steps=1, fp16=True, amp=False, loss_scale=0.0, log_freq=1.0, checkpoint_activations=False, resume_from_checkpoint=True, resume_step=95, num_steps_per_checkpoint=200, skip_checkpoint=False, phase2=False, allreduce_post_accumulation=False, allreduce_post_accumulation_fp16=False, phase1_end_step=7038, init_loss_scale=1048576, do_train=True, json_summary='/home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json', use_env=False, disable_progress_bar=False, steps_this_run=7038.0, varuna=True, stage_to_rank_map='0,8,16;1,9,17;2,10,18;3,11,19;4,12,20;5,13,21;6,14,22;7,15,23;', chunk_size=8, batch_size=341, rank=0, profiling=False, n_gpu=1)"] 
dry run time 0.17598414421081543
SHARED WEIGHTS ARE
[(0, 7)]
this rank  0 is part of pipeline replica  0
43 chunks
Begin to load checkpint from s3://spot-checkpoints/bert/ckpt_95.pt
2022-11-23 14:50:50.896194 resume step from  95
Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.

Defaults for this optimization level are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
2022-11-23 14:51:00.571106 - Finished loading checkpoint, takes 9662.348 secs
DLL 2022-11-23 14:51:00.572175 - PARAMETER SEED : 12439 
DLL 2022-11-23 14:51:00.572310 - PARAMETER train_start : True 
DLL 2022-11-23 14:51:00.572365 - PARAMETER batch_size_per_gpu : 341 
DLL 2022-11-23 14:51:00.572441 - PARAMETER learning_rate : 0.006 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  524288.0
Finished iteration 95, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 14109.926
DLL 2022-11-23 14:51:14.717983 - Training Epoch: 0 Training Iteration: 96  average_loss : nan  step_loss : nan  learning_rate : 0.0002878699691349418 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  262144.0
Finished iteration 96, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4192.699
DLL 2022-11-23 14:51:18.910460 - Training Epoch: 0 Training Iteration: 97  average_loss : nan  step_loss : nan  learning_rate : 0.00029086861464676405 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  131072.0
Finished iteration 97, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4192.101
DLL 2022-11-23 14:51:23.102512 - Training Epoch: 0 Training Iteration: 98  average_loss : nan  step_loss : nan  learning_rate : 0.00029386726015858636 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  65536.0
Finished iteration 98, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4249.204
DLL 2022-11-23 14:51:27.352015 - Training Epoch: 0 Training Iteration: 99  average_loss : nan  step_loss : nan  learning_rate : 0.0002968659056704087 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  32768.0
Finished iteration 99, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4179.682
DLL 2022-11-23 14:51:31.531845 - Training Epoch: 0 Training Iteration: 100  average_loss : nan  step_loss : nan  learning_rate : 0.000299864551182231 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  16384.0
Finished iteration 100, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3264.668
DLL 2022-11-23 14:51:34.796150 - Training Epoch: 0 Training Iteration: 101  average_loss : nan  step_loss : nan  learning_rate : 0.0003028631966940533 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  8192.0
Finished iteration 101, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3237.898
DLL 2022-11-23 14:51:38.034346 - Training Epoch: 0 Training Iteration: 102  average_loss : nan  step_loss : nan  learning_rate : 0.0003058618422058756 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  4096.0
Finished iteration 102, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3427.940
DLL 2022-11-23 14:51:41.461985 - Training Epoch: 0 Training Iteration: 103  average_loss : nan  step_loss : nan  learning_rate : 0.000308860487717698 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  2048.0
Finished iteration 103, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3263.879
DLL 2022-11-23 14:51:44.726138 - Training Epoch: 0 Training Iteration: 104  average_loss : nan  step_loss : nan  learning_rate : 0.00031185913322952024 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1024.0
Finished iteration 104, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3127.718
DLL 2022-11-23 14:51:47.853708 - Training Epoch: 0 Training Iteration: 105  average_loss : nan  step_loss : nan  learning_rate : 0.0003148577787413425 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  512.0
Finished iteration 105, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3099.124
DLL 2022-11-23 14:51:50.952926 - Training Epoch: 0 Training Iteration: 106  average_loss : nan  step_loss : nan  learning_rate : 0.0003178564242531648 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  256.0
Finished iteration 106, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3204.925
DLL 2022-11-23 14:51:54.157725 - Training Epoch: 0 Training Iteration: 107  average_loss : nan  step_loss : nan  learning_rate : 0.0003208550697649872 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  128.0
Finished iteration 107, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3133.975
DLL 2022-11-23 14:51:57.291726 - Training Epoch: 0 Training Iteration: 108  average_loss : nan  step_loss : nan  learning_rate : 0.0003238537152768095 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  64.0
Finished iteration 108, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3167.366
DLL 2022-11-23 14:52:00.459659 - Training Epoch: 0 Training Iteration: 109  average_loss : nan  step_loss : nan  learning_rate : 0.0003268523607886318 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  32.0
Finished iteration 109, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3379.966
DLL 2022-11-23 14:52:03.839484 - Training Epoch: 0 Training Iteration: 110  average_loss : nan  step_loss : nan  learning_rate : 0.0003298510063004541 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  16.0
Finished iteration 110, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3088.605
DLL 2022-11-23 14:52:06.928035 - Training Epoch: 0 Training Iteration: 111  average_loss : nan  step_loss : nan  learning_rate : 0.00033284965181227643 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  8.0
Finished iteration 111, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3181.239
DLL 2022-11-23 14:52:10.109264 - Training Epoch: 0 Training Iteration: 112  average_loss : nan  step_loss : nan  learning_rate : 0.00033584829732409875 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  4.0
Finished iteration 112, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3336.326
DLL 2022-11-23 14:52:13.445619 - Training Epoch: 0 Training Iteration: 113  average_loss : nan  step_loss : nan  learning_rate : 0.000338846942835921 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  2.0
Finished iteration 113, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3153.747
DLL 2022-11-23 14:52:16.599093 - Training Epoch: 0 Training Iteration: 114  average_loss : nan  step_loss : nan  learning_rate : 0.0003418455883477433 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 114, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3212.405
DLL 2022-11-23 14:52:19.811683 - Training Epoch: 0 Training Iteration: 115  average_loss : nan  step_loss : nan  learning_rate : 0.0003448442338595657 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 115, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3153.079
DLL 2022-11-23 14:52:22.965026 - Training Epoch: 0 Training Iteration: 116  average_loss : nan  step_loss : nan  learning_rate : 0.00034784287937138794 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 116, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3224.701
DLL 2022-11-23 14:52:26.189691 - Training Epoch: 0 Training Iteration: 117  average_loss : nan  step_loss : nan  learning_rate : 0.00035084152488321026 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 117, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3179.445
DLL 2022-11-23 14:52:29.369063 - Training Epoch: 0 Training Iteration: 118  average_loss : nan  step_loss : nan  learning_rate : 0.0003538401703950326 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 118, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3122.876
DLL 2022-11-23 14:52:32.491906 - Training Epoch: 0 Training Iteration: 119  average_loss : nan  step_loss : nan  learning_rate : 0.0003568388159068549 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 119, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3121.995
DLL 2022-11-23 14:52:35.613803 - Training Epoch: 0 Training Iteration: 120  average_loss : nan  step_loss : nan  learning_rate : 0.0003598374614186772 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 120, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3175.167
DLL 2022-11-23 14:52:38.789260 - Training Epoch: 0 Training Iteration: 121  average_loss : nan  step_loss : nan  learning_rate : 0.00036283610693049946 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 121, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3163.125
DLL 2022-11-23 14:52:41.952456 - Training Epoch: 0 Training Iteration: 122  average_loss : nan  step_loss : nan  learning_rate : 0.0003658347524423219 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 122, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3088.756
DLL 2022-11-23 14:52:45.041030 - Training Epoch: 0 Training Iteration: 123  average_loss : nan  step_loss : nan  learning_rate : 0.00036883339795414414 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 123, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3170.634
DLL 2022-11-23 14:52:48.211607 - Training Epoch: 0 Training Iteration: 124  average_loss : nan  step_loss : nan  learning_rate : 0.0003718320434659664 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 124, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3176.065
DLL 2022-11-23 14:52:51.387810 - Training Epoch: 0 Training Iteration: 125  average_loss : nan  step_loss : nan  learning_rate : 0.00037483068897778876 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 125, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4008.217
DLL 2022-11-23 14:52:55.396128 - Training Epoch: 0 Training Iteration: 126  average_loss : nan  step_loss : nan  learning_rate : 0.0003778293344896111 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 126, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3129.889
DLL 2022-11-23 14:52:58.526134 - Training Epoch: 0 Training Iteration: 127  average_loss : nan  step_loss : nan  learning_rate : 0.0003808279800014334 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 127, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3395.429
DLL 2022-11-23 14:53:01.921479 - Training Epoch: 0 Training Iteration: 128  average_loss : nan  step_loss : nan  learning_rate : 0.00038382662551325565 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 128, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3254.329
DLL 2022-11-23 14:53:05.175845 - Training Epoch: 0 Training Iteration: 129  average_loss : nan  step_loss : nan  learning_rate : 0.00038682527102507796 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 129, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3288.834
DLL 2022-11-23 14:53:08.464672 - Training Epoch: 0 Training Iteration: 130  average_loss : nan  step_loss : nan  learning_rate : 0.00038982391653690033 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 130, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3093.163
DLL 2022-11-23 14:53:11.557972 - Training Epoch: 0 Training Iteration: 131  average_loss : nan  step_loss : nan  learning_rate : 0.0003928225620487226 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 131, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3171.479
DLL 2022-11-23 14:53:14.729401 - Training Epoch: 0 Training Iteration: 132  average_loss : nan  step_loss : nan  learning_rate : 0.0003958212075605449 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 132, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3171.422
DLL 2022-11-23 14:53:17.900790 - Training Epoch: 0 Training Iteration: 133  average_loss : nan  step_loss : nan  learning_rate : 0.00039881985307236727 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 133, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3284.989
DLL 2022-11-23 14:53:21.192124 - Training Epoch: 0 Training Iteration: 134  average_loss : nan  step_loss : nan  learning_rate : 0.0004018184985841895 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 134, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3315.435
DLL 2022-11-23 14:53:24.501515 - Training Epoch: 0 Training Iteration: 135  average_loss : nan  step_loss : nan  learning_rate : 0.00040481714409601184 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 135, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3368.636
DLL 2022-11-23 14:53:27.869980 - Training Epoch: 0 Training Iteration: 136  average_loss : nan  step_loss : nan  learning_rate : 0.00040781578960783415 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 136, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3157.827
DLL 2022-11-23 14:53:31.027860 - Training Epoch: 0 Training Iteration: 137  average_loss : nan  step_loss : nan  learning_rate : 0.0004108144351196565 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 137, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3173.913
DLL 2022-11-23 14:53:34.201608 - Training Epoch: 0 Training Iteration: 138  average_loss : nan  step_loss : nan  learning_rate : 0.0004138130806314788 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 138, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3230.317
DLL 2022-11-23 14:53:37.432051 - Training Epoch: 0 Training Iteration: 139  average_loss : nan  step_loss : nan  learning_rate : 0.00041681172614330104 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 139, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3947.949
DLL 2022-11-23 14:53:41.380180 - Training Epoch: 0 Training Iteration: 140  average_loss : nan  step_loss : nan  learning_rate : 0.0004198103716551234 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 140, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 3200.956
DLL 2022-11-23 14:53:44.581072 - Training Epoch: 0 Training Iteration: 141  average_loss : nan  step_loss : nan  learning_rate : 0.0004228090171669457 
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 0 signal handler called with signal 10
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 141, CKPT_AND_STOP: True, flag: tensor([1], dtype=torch.int32), speed: 3198.138
DLL 2022-11-23 14:53:47.780605 - Training Epoch: 0 Training Iteration: 142  average_loss : nan  step_loss : nan  learning_rate : 0.00042580766267876803 
2022-11-23 14:53:47.780785 Begin to save checkpont to s3://spot-checkpoints/bert and exit
DLL 2022-11-23 14:53:47.780815 - PARAMETER checkpoint_step : 142 
Opt ckpt time 6.261391639709473
Process done with return code 0
Parent process ID: 86970 node: 172.31.28.108
2 per stage
16 servers!
Config:
ranks: range(0, 1)
train batch size: 1024
partitions: 8
chunk_size: 8
data depth: 2
stage to rank map: 0,8;1,9;2,10;3,11;4,12;5,13;6,14;7,15;
World size is 16
/opt/conda/envs/varuna/bin/python -u /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --rank=0 --chunk_size=8 --local_rank=0 --stage_to_rank_map=0,8;1,9;2,10;3,11;4,12;5,13;6,14;7,15; --batch-size=512 --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna --resume_step 142
device: cuda:0 n_gpu: 1, distributed training: True, 16-bits training: True
DLL 2022-11-23 14:54:11.897031 - PARAMETER Config : ["Namespace(input_dir='/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/', config_file='bert_config.json', bert_model='bert-large-uncased', output_dir='s3://spot-checkpoints/bert', init_checkpoint=None, max_seq_length=128, max_predictions_per_seq=20, train_batch_size=512, learning_rate=0.006, num_train_epochs=3.0, max_steps=7038.0, warmup_proportion=0.2843, local_rank=0, seed=12439, gradient_accumulation_steps=1, fp16=True, amp=False, loss_scale=0.0, log_freq=1.0, checkpoint_activations=False, resume_from_checkpoint=True, resume_step=142, num_steps_per_checkpoint=200, skip_checkpoint=False, phase2=False, allreduce_post_accumulation=False, allreduce_post_accumulation_fp16=False, phase1_end_step=7038, init_loss_scale=1048576, do_train=True, json_summary='/home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json', use_env=False, disable_progress_bar=False, steps_this_run=7038.0, varuna=True, stage_to_rank_map='0,8;1,9;2,10;3,11;4,12;5,13;6,14;7,15;', chunk_size=8, batch_size=512, rank=0, profiling=False, n_gpu=1)"] 
dry run time 0.07030105590820312
SHARED WEIGHTS ARE
[(0, 7)]
this rank  0 is part of pipeline replica  0
64 chunks
Begin to load checkpint from s3://spot-checkpoints/bert/ckpt_142.pt
2022-11-23 14:54:26.791301 resume step from  142
Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.

Defaults for this optimization level are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
2022-11-23 14:54:37.776162 - Finished loading checkpoint, takes 10973.090 secs
DLL 2022-11-23 14:54:37.777012 - PARAMETER SEED : 12439 
DLL 2022-11-23 14:54:37.777138 - PARAMETER train_start : True 
DLL 2022-11-23 14:54:37.777231 - PARAMETER batch_size_per_gpu : 512 
DLL 2022-11-23 14:54:37.777299 - PARAMETER learning_rate : 0.006 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  524288.0
Finished iteration 142, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 12854.388
DLL 2022-11-23 14:54:50.667942 - Training Epoch: 0 Training Iteration: 143  average_loss : nan  step_loss : nan  learning_rate : 0.0004288063081905903 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  262144.0
Finished iteration 143, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5308.316
DLL 2022-11-23 14:54:55.975446 - Training Epoch: 0 Training Iteration: 144  average_loss : nan  step_loss : nan  learning_rate : 0.00043180495370241266 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  131072.0
Finished iteration 144, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5365.034
DLL 2022-11-23 14:55:01.346374 - Training Epoch: 0 Training Iteration: 145  average_loss : nan  step_loss : nan  learning_rate : 0.00043480359921423497 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  65536.0
Finished iteration 145, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5468.237
DLL 2022-11-23 14:55:06.808926 - Training Epoch: 0 Training Iteration: 146  average_loss : nan  step_loss : nan  learning_rate : 0.00043780224472605723 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  32768.0
Finished iteration 146, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5312.142
DLL 2022-11-23 14:55:12.121098 - Training Epoch: 0 Training Iteration: 147  average_loss : nan  step_loss : nan  learning_rate : 0.0004408008902378796 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  16384.0
Finished iteration 147, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4520.117
DLL 2022-11-23 14:55:16.641309 - Training Epoch: 0 Training Iteration: 148  average_loss : nan  step_loss : nan  learning_rate : 0.0004437995357497019 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  8192.0
Finished iteration 148, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4417.215
DLL 2022-11-23 14:55:21.058380 - Training Epoch: 0 Training Iteration: 149  average_loss : nan  step_loss : nan  learning_rate : 0.0004467981812615243 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  4096.0
Finished iteration 149, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4489.998
DLL 2022-11-23 14:55:25.548561 - Training Epoch: 0 Training Iteration: 150  average_loss : nan  step_loss : nan  learning_rate : 0.00044979682677334654 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  2048.0
Finished iteration 150, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4447.432
DLL 2022-11-23 14:55:29.995891 - Training Epoch: 0 Training Iteration: 151  average_loss : nan  step_loss : nan  learning_rate : 0.0004527954722851688 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1024.0
Finished iteration 151, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4419.837
DLL 2022-11-23 14:55:34.415815 - Training Epoch: 0 Training Iteration: 152  average_loss : nan  step_loss : nan  learning_rate : 0.0004557941177969911 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  512.0
Finished iteration 152, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4532.102
DLL 2022-11-23 14:55:38.956025 - Training Epoch: 0 Training Iteration: 153  average_loss : nan  step_loss : nan  learning_rate : 0.00045879276330881337 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  256.0
Finished iteration 153, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4301.200
DLL 2022-11-23 14:55:43.249076 - Training Epoch: 0 Training Iteration: 154  average_loss : nan  step_loss : nan  learning_rate : 0.00046179140882063573 
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 0 signal handler called with signal 10
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  128.0
Finished iteration 154, CKPT_AND_STOP: True, flag: tensor([1], dtype=torch.int32), speed: 4217.132
DLL 2022-11-23 14:55:47.466502 - Training Epoch: 0 Training Iteration: 155  average_loss : nan  step_loss : nan  learning_rate : 0.00046479005433245805 
2022-11-23 14:55:47.466660 Begin to save checkpont to s3://spot-checkpoints/bert and exit
DLL 2022-11-23 14:55:47.466689 - PARAMETER checkpoint_step : 155 
Opt ckpt time 6.794181823730469
Process done with return code 0
Parent process ID: 88108 node: 172.31.28.108
2 per stage
16 servers!
Config:
ranks: range(0, 1)
train batch size: 1024
partitions: 8
chunk_size: 8
data depth: 2
stage to rank map: 0,8;1,9;2,10;3,11;4,12;5,13;6,14;7,15;
World size is 16
/opt/conda/envs/varuna/bin/python -u /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --rank=0 --chunk_size=8 --local_rank=0 --stage_to_rank_map=0,8;1,9;2,10;3,11;4,12;5,13;6,14;7,15; --batch-size=512 --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna --resume_step 155
device: cuda:0 n_gpu: 1, distributed training: True, 16-bits training: True
DLL 2022-11-23 14:56:08.264015 - PARAMETER Config : ["Namespace(input_dir='/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/', config_file='bert_config.json', bert_model='bert-large-uncased', output_dir='s3://spot-checkpoints/bert', init_checkpoint=None, max_seq_length=128, max_predictions_per_seq=20, train_batch_size=512, learning_rate=0.006, num_train_epochs=3.0, max_steps=7038.0, warmup_proportion=0.2843, local_rank=0, seed=12439, gradient_accumulation_steps=1, fp16=True, amp=False, loss_scale=0.0, log_freq=1.0, checkpoint_activations=False, resume_from_checkpoint=True, resume_step=155, num_steps_per_checkpoint=200, skip_checkpoint=False, phase2=False, allreduce_post_accumulation=False, allreduce_post_accumulation_fp16=False, phase1_end_step=7038, init_loss_scale=1048576, do_train=True, json_summary='/home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json', use_env=False, disable_progress_bar=False, steps_this_run=7038.0, varuna=True, stage_to_rank_map='0,8;1,9;2,10;3,11;4,12;5,13;6,14;7,15;', chunk_size=8, batch_size=512, rank=0, profiling=False, n_gpu=1)"] 
dry run time 0.07518434524536133
SHARED WEIGHTS ARE
[(0, 7)]
this rank  0 is part of pipeline replica  0
64 chunks
Begin to load checkpint from s3://spot-checkpoints/bert/ckpt_155.pt
2022-11-23 14:56:18.394048 resume step from  155
Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.

Defaults for this optimization level are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
2022-11-23 14:56:28.333510 - Finished loading checkpoint, takes 9927.497 secs
DLL 2022-11-23 14:56:28.334829 - PARAMETER SEED : 12439 
DLL 2022-11-23 14:56:28.334960 - PARAMETER train_start : True 
DLL 2022-11-23 14:56:28.335067 - PARAMETER batch_size_per_gpu : 512 
DLL 2022-11-23 14:56:28.335151 - PARAMETER learning_rate : 0.006 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  524288.0
Finished iteration 155, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 13481.906
DLL 2022-11-23 14:56:41.853497 - Training Epoch: 0 Training Iteration: 156  average_loss : nan  step_loss : nan  learning_rate : 0.0004677886998442803 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  262144.0
Finished iteration 156, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6396.171
DLL 2022-11-23 14:56:48.249055 - Training Epoch: 0 Training Iteration: 157  average_loss : nan  step_loss : nan  learning_rate : 0.0004707873453561027 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  131072.0
Finished iteration 157, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5540.532
DLL 2022-11-23 14:56:53.789726 - Training Epoch: 0 Training Iteration: 158  average_loss : nan  step_loss : nan  learning_rate : 0.00047378599086792493 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  65536.0
Finished iteration 158, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5613.066
DLL 2022-11-23 14:56:59.402576 - Training Epoch: 0 Training Iteration: 159  average_loss : nan  step_loss : nan  learning_rate : 0.0004767846363797473 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  32768.0
Finished iteration 159, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5541.423
DLL 2022-11-23 14:57:04.944056 - Training Epoch: 0 Training Iteration: 160  average_loss : nan  step_loss : nan  learning_rate : 0.0004797832818915696 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  16384.0
Finished iteration 160, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4417.699
DLL 2022-11-23 14:57:09.367657 - Training Epoch: 0 Training Iteration: 161  average_loss : nan  step_loss : nan  learning_rate : 0.00048278192740339187 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  8192.0
Finished iteration 161, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4159.753
DLL 2022-11-23 14:57:13.521447 - Training Epoch: 0 Training Iteration: 162  average_loss : nan  step_loss : nan  learning_rate : 0.00048578057291521424 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  4096.0
Finished iteration 162, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4444.449
DLL 2022-11-23 14:57:17.966104 - Training Epoch: 0 Training Iteration: 163  average_loss : nan  step_loss : nan  learning_rate : 0.0004887792184270365 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  2048.0
Finished iteration 163, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4356.352
DLL 2022-11-23 14:57:22.322423 - Training Epoch: 0 Training Iteration: 164  average_loss : nan  step_loss : nan  learning_rate : 0.0004917778639388588 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1024.0
Finished iteration 164, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4492.236
DLL 2022-11-23 14:57:26.814606 - Training Epoch: 0 Training Iteration: 165  average_loss : nan  step_loss : nan  learning_rate : 0.0004947765094506812 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  512.0
Finished iteration 165, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4434.844
DLL 2022-11-23 14:57:31.249700 - Training Epoch: 0 Training Iteration: 166  average_loss : nan  step_loss : nan  learning_rate : 0.0004977751549625034 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  256.0
Finished iteration 166, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4467.929
DLL 2022-11-23 14:57:35.717818 - Training Epoch: 0 Training Iteration: 167  average_loss : nan  step_loss : nan  learning_rate : 0.0005007738004743258 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  128.0
Finished iteration 167, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5416.436
DLL 2022-11-23 14:57:41.139959 - Training Epoch: 0 Training Iteration: 168  average_loss : nan  step_loss : nan  learning_rate : 0.0005037724459861481 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  64.0
Finished iteration 168, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4521.141
DLL 2022-11-23 14:57:45.655388 - Training Epoch: 0 Training Iteration: 169  average_loss : nan  step_loss : nan  learning_rate : 0.0005067710914979704 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  32.0
Finished iteration 169, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4489.111
DLL 2022-11-23 14:57:50.144538 - Training Epoch: 0 Training Iteration: 170  average_loss : nan  step_loss : nan  learning_rate : 0.0005097697370097927 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  16.0
Finished iteration 170, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4176.006
DLL 2022-11-23 14:57:54.320579 - Training Epoch: 0 Training Iteration: 171  average_loss : nan  step_loss : nan  learning_rate : 0.0005127683825216149 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  8.0
Finished iteration 171, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4528.703
DLL 2022-11-23 14:57:58.854425 - Training Epoch: 0 Training Iteration: 172  average_loss : nan  step_loss : nan  learning_rate : 0.0005157670280334373 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  4.0
Finished iteration 172, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4408.184
DLL 2022-11-23 14:58:03.260603 - Training Epoch: 0 Training Iteration: 173  average_loss : nan  step_loss : nan  learning_rate : 0.0005187656735452596 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  2.0
Finished iteration 173, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4426.556
DLL 2022-11-23 14:58:07.689732 - Training Epoch: 0 Training Iteration: 174  average_loss : nan  step_loss : nan  learning_rate : 0.0005217643190570819 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 174, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4473.112
DLL 2022-11-23 14:58:12.157154 - Training Epoch: 0 Training Iteration: 175  average_loss : nan  step_loss : nan  learning_rate : 0.0005247629645689043 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 175, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4418.907
DLL 2022-11-23 14:58:16.581760 - Training Epoch: 0 Training Iteration: 176  average_loss : nan  step_loss : nan  learning_rate : 0.0005277616100807266 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 176, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4482.469
DLL 2022-11-23 14:58:21.063849 - Training Epoch: 0 Training Iteration: 177  average_loss : nan  step_loss : nan  learning_rate : 0.0005307602555925489 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 177, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4498.113
DLL 2022-11-23 14:58:25.564901 - Training Epoch: 0 Training Iteration: 178  average_loss : nan  step_loss : nan  learning_rate : 0.0005337589011043712 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 178, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4490.361
DLL 2022-11-23 14:58:30.047124 - Training Epoch: 0 Training Iteration: 179  average_loss : nan  step_loss : nan  learning_rate : 0.0005367575466161935 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 179, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4577.436
DLL 2022-11-23 14:58:34.624462 - Training Epoch: 0 Training Iteration: 180  average_loss : nan  step_loss : nan  learning_rate : 0.0005397561921280158 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 180, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4436.505
DLL 2022-11-23 14:58:39.066760 - Training Epoch: 0 Training Iteration: 181  average_loss : nan  step_loss : nan  learning_rate : 0.0005427548376398381 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 181, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4788.119
DLL 2022-11-23 14:58:43.849195 - Training Epoch: 0 Training Iteration: 182  average_loss : nan  step_loss : nan  learning_rate : 0.0005457534831516603 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 182, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4440.947
DLL 2022-11-23 14:58:48.291118 - Training Epoch: 0 Training Iteration: 183  average_loss : nan  step_loss : nan  learning_rate : 0.0005487521286634827 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 183, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4354.345
DLL 2022-11-23 14:58:52.644464 - Training Epoch: 0 Training Iteration: 184  average_loss : nan  step_loss : nan  learning_rate : 0.0005517507741753051 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 184, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4745.883
DLL 2022-11-23 14:58:57.396131 - Training Epoch: 0 Training Iteration: 185  average_loss : nan  step_loss : nan  learning_rate : 0.0005547494196871273 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 185, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4556.734
DLL 2022-11-23 14:59:01.947095 - Training Epoch: 0 Training Iteration: 186  average_loss : nan  step_loss : nan  learning_rate : 0.0005577480651989497 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 186, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4326.682
DLL 2022-11-23 14:59:06.278990 - Training Epoch: 0 Training Iteration: 187  average_loss : nan  step_loss : nan  learning_rate : 0.000560746710710772 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 187, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4426.518
DLL 2022-11-23 14:59:10.708580 - Training Epoch: 0 Training Iteration: 188  average_loss : nan  step_loss : nan  learning_rate : 0.0005637453562225942 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 188, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4442.665
DLL 2022-11-23 14:59:15.143306 - Training Epoch: 0 Training Iteration: 189  average_loss : nan  step_loss : nan  learning_rate : 0.0005667440017344166 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 189, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4740.018
DLL 2022-11-23 14:59:19.883697 - Training Epoch: 0 Training Iteration: 190  average_loss : nan  step_loss : nan  learning_rate : 0.0005697426472462388 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 190, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4304.195
DLL 2022-11-23 14:59:24.187972 - Training Epoch: 0 Training Iteration: 191  average_loss : nan  step_loss : nan  learning_rate : 0.0005727412927580613 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 191, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4178.766
DLL 2022-11-23 14:59:28.366122 - Training Epoch: 0 Training Iteration: 192  average_loss : nan  step_loss : nan  learning_rate : 0.0005757399382698836 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 192, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4235.725
DLL 2022-11-23 14:59:32.607920 - Training Epoch: 0 Training Iteration: 193  average_loss : nan  step_loss : nan  learning_rate : 0.0005787385837817058 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 193, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4292.579
DLL 2022-11-23 14:59:36.894565 - Training Epoch: 0 Training Iteration: 194  average_loss : nan  step_loss : nan  learning_rate : 0.0005817372292935281 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 194, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4401.229
DLL 2022-11-23 14:59:41.296012 - Training Epoch: 0 Training Iteration: 195  average_loss : nan  step_loss : nan  learning_rate : 0.0005847358748053504 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 195, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4260.273
DLL 2022-11-23 14:59:45.556145 - Training Epoch: 0 Training Iteration: 196  average_loss : nan  step_loss : nan  learning_rate : 0.0005877345203171727 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 196, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4641.337
DLL 2022-11-23 14:59:50.197315 - Training Epoch: 0 Training Iteration: 197  average_loss : nan  step_loss : nan  learning_rate : 0.000590733165828995 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 197, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4344.192
DLL 2022-11-23 14:59:54.541666 - Training Epoch: 0 Training Iteration: 198  average_loss : nan  step_loss : nan  learning_rate : 0.0005937318113408173 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 198, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4251.379
DLL 2022-11-23 14:59:58.793412 - Training Epoch: 0 Training Iteration: 199  average_loss : nan  step_loss : nan  learning_rate : 0.0005967304568526397 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 199, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4325.804
DLL 2022-11-23 15:00:03.119167 - Training Epoch: 0 Training Iteration: 200  average_loss : nan  step_loss : nan  learning_rate : 0.000599729102364462 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 200, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4227.389
DLL 2022-11-23 15:00:07.346634 - Training Epoch: 0 Training Iteration: 201  average_loss : nan  step_loss : nan  learning_rate : 0.0006027277478762843 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 201, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4225.986
DLL 2022-11-23 15:00:11.580081 - Training Epoch: 0 Training Iteration: 202  average_loss : nan  step_loss : nan  learning_rate : 0.0006057263933881066 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 202, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4279.467
DLL 2022-11-23 15:00:15.852108 - Training Epoch: 0 Training Iteration: 203  average_loss : nan  step_loss : nan  learning_rate : 0.0006087250388999289 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 203, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4453.549
DLL 2022-11-23 15:00:20.305523 - Training Epoch: 0 Training Iteration: 204  average_loss : nan  step_loss : nan  learning_rate : 0.0006117236844117512 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 204, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4417.521
DLL 2022-11-23 15:00:24.723015 - Training Epoch: 0 Training Iteration: 205  average_loss : nan  step_loss : nan  learning_rate : 0.0006147223299235735 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 205, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4747.252
DLL 2022-11-23 15:00:29.470329 - Training Epoch: 0 Training Iteration: 206  average_loss : nan  step_loss : nan  learning_rate : 0.000617720975435396 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 206, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5259.696
DLL 2022-11-23 15:00:34.730007 - Training Epoch: 0 Training Iteration: 207  average_loss : nan  step_loss : nan  learning_rate : 0.0006207196209472182 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 207, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4377.279
DLL 2022-11-23 15:00:39.113577 - Training Epoch: 0 Training Iteration: 208  average_loss : nan  step_loss : nan  learning_rate : 0.0006237182664590405 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 208, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4294.023
DLL 2022-11-23 15:00:43.401458 - Training Epoch: 0 Training Iteration: 209  average_loss : nan  step_loss : nan  learning_rate : 0.0006267169119708628 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 209, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4287.467
DLL 2022-11-23 15:00:47.688925 - Training Epoch: 0 Training Iteration: 210  average_loss : nan  step_loss : nan  learning_rate : 0.000629715557482685 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 210, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4209.620
DLL 2022-11-23 15:00:51.905180 - Training Epoch: 0 Training Iteration: 211  average_loss : nan  step_loss : nan  learning_rate : 0.0006327142029945074 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 211, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4606.469
DLL 2022-11-23 15:00:56.505357 - Training Epoch: 0 Training Iteration: 212  average_loss : nan  step_loss : nan  learning_rate : 0.0006357128485063296 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 212, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4401.884
DLL 2022-11-23 15:01:00.913694 - Training Epoch: 0 Training Iteration: 213  average_loss : nan  step_loss : nan  learning_rate : 0.000638711494018152 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 213, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4524.327
DLL 2022-11-23 15:01:05.437864 - Training Epoch: 0 Training Iteration: 214  average_loss : nan  step_loss : nan  learning_rate : 0.0006417101395299744 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 214, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5035.929
DLL 2022-11-23 15:01:10.467648 - Training Epoch: 0 Training Iteration: 215  average_loss : nan  step_loss : nan  learning_rate : 0.0006447087850417966 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 215, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4543.771
DLL 2022-11-23 15:01:15.011113 - Training Epoch: 0 Training Iteration: 216  average_loss : nan  step_loss : nan  learning_rate : 0.000647707430553619 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 216, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4708.468
DLL 2022-11-23 15:01:19.723495 - Training Epoch: 0 Training Iteration: 217  average_loss : nan  step_loss : nan  learning_rate : 0.0006507060760654413 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 217, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4251.164
DLL 2022-11-23 15:01:23.970854 - Training Epoch: 0 Training Iteration: 218  average_loss : nan  step_loss : nan  learning_rate : 0.0006537047215772636 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 218, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4239.970
DLL 2022-11-23 15:01:28.210863 - Training Epoch: 0 Training Iteration: 219  average_loss : nan  step_loss : nan  learning_rate : 0.0006567033670890859 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 219, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4424.234
DLL 2022-11-23 15:01:32.635180 - Training Epoch: 0 Training Iteration: 220  average_loss : nan  step_loss : nan  learning_rate : 0.0006597020126009082 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 220, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4582.711
DLL 2022-11-23 15:01:37.226191 - Training Epoch: 0 Training Iteration: 221  average_loss : nan  step_loss : nan  learning_rate : 0.0006627006581127306 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 221, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4335.881
DLL 2022-11-23 15:01:41.553916 - Training Epoch: 0 Training Iteration: 222  average_loss : nan  step_loss : nan  learning_rate : 0.0006656993036245529 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 222, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4822.866
DLL 2022-11-23 15:01:46.376603 - Training Epoch: 0 Training Iteration: 223  average_loss : nan  step_loss : nan  learning_rate : 0.0006686979491363751 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 223, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4493.001
DLL 2022-11-23 15:01:50.870177 - Training Epoch: 0 Training Iteration: 224  average_loss : nan  step_loss : nan  learning_rate : 0.0006716965946481975 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 224, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4449.329
DLL 2022-11-23 15:01:55.319463 - Training Epoch: 0 Training Iteration: 225  average_loss : nan  step_loss : nan  learning_rate : 0.0006746952401600198 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 225, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4487.934
DLL 2022-11-23 15:01:59.807080 - Training Epoch: 0 Training Iteration: 226  average_loss : nan  step_loss : nan  learning_rate : 0.000677693885671842 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 226, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4261.317
DLL 2022-11-23 15:02:04.068562 - Training Epoch: 0 Training Iteration: 227  average_loss : nan  step_loss : nan  learning_rate : 0.0006806925311836643 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 227, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4402.531
DLL 2022-11-23 15:02:08.471217 - Training Epoch: 0 Training Iteration: 228  average_loss : nan  step_loss : nan  learning_rate : 0.0006836911766954866 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 228, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4485.960
DLL 2022-11-23 15:02:12.964003 - Training Epoch: 0 Training Iteration: 229  average_loss : nan  step_loss : nan  learning_rate : 0.0006866898222073091 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 229, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4547.634
DLL 2022-11-23 15:02:17.511586 - Training Epoch: 0 Training Iteration: 230  average_loss : nan  step_loss : nan  learning_rate : 0.0006896884677191314 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 230, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4302.889
DLL 2022-11-23 15:02:21.807659 - Training Epoch: 0 Training Iteration: 231  average_loss : nan  step_loss : nan  learning_rate : 0.0006926871132309536 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 231, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4148.168
DLL 2022-11-23 15:02:25.963857 - Training Epoch: 0 Training Iteration: 232  average_loss : nan  step_loss : nan  learning_rate : 0.0006956857587427759 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 232, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4322.027
DLL 2022-11-23 15:02:30.278174 - Training Epoch: 0 Training Iteration: 233  average_loss : nan  step_loss : nan  learning_rate : 0.0006986844042545982 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 233, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4367.942
DLL 2022-11-23 15:02:34.645746 - Training Epoch: 0 Training Iteration: 234  average_loss : nan  step_loss : nan  learning_rate : 0.0007016830497664205 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 234, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4445.662
DLL 2022-11-23 15:02:39.098072 - Training Epoch: 0 Training Iteration: 235  average_loss : nan  step_loss : nan  learning_rate : 0.0007046816952782429 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 235, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4196.281
DLL 2022-11-23 15:02:43.287790 - Training Epoch: 0 Training Iteration: 236  average_loss : nan  step_loss : nan  learning_rate : 0.0007076803407900652 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 236, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4271.043
DLL 2022-11-23 15:02:47.558773 - Training Epoch: 0 Training Iteration: 237  average_loss : nan  step_loss : nan  learning_rate : 0.0007106789863018875 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 237, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4323.760
DLL 2022-11-23 15:02:51.889759 - Training Epoch: 0 Training Iteration: 238  average_loss : nan  step_loss : nan  learning_rate : 0.0007136776318137098 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 238, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4297.337
DLL 2022-11-23 15:02:56.180000 - Training Epoch: 0 Training Iteration: 239  average_loss : nan  step_loss : nan  learning_rate : 0.0007166762773255321 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 239, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4445.438
DLL 2022-11-23 15:03:00.625840 - Training Epoch: 0 Training Iteration: 240  average_loss : nan  step_loss : nan  learning_rate : 0.0007196749228373544 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 240, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4368.156
DLL 2022-11-23 15:03:04.993603 - Training Epoch: 0 Training Iteration: 241  average_loss : nan  step_loss : nan  learning_rate : 0.0007226735683491767 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 241, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4534.012
DLL 2022-11-23 15:03:09.527879 - Training Epoch: 0 Training Iteration: 242  average_loss : nan  step_loss : nan  learning_rate : 0.0007256722138609989 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 242, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4451.841
DLL 2022-11-23 15:03:13.979882 - Training Epoch: 0 Training Iteration: 243  average_loss : nan  step_loss : nan  learning_rate : 0.0007286708593728212 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 243, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4721.486
DLL 2022-11-23 15:03:18.701387 - Training Epoch: 0 Training Iteration: 244  average_loss : nan  step_loss : nan  learning_rate : 0.0007316695048846438 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 244, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4447.998
DLL 2022-11-23 15:03:23.156398 - Training Epoch: 0 Training Iteration: 245  average_loss : nan  step_loss : nan  learning_rate : 0.000734668150396466 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 245, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4396.679
DLL 2022-11-23 15:03:27.546016 - Training Epoch: 0 Training Iteration: 246  average_loss : nan  step_loss : nan  learning_rate : 0.0007376667959082883 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 246, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4451.442
DLL 2022-11-23 15:03:31.997641 - Training Epoch: 0 Training Iteration: 247  average_loss : nan  step_loss : nan  learning_rate : 0.0007406654414201106 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 247, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4360.699
DLL 2022-11-23 15:03:36.357989 - Training Epoch: 0 Training Iteration: 248  average_loss : nan  step_loss : nan  learning_rate : 0.0007436640869319328 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 248, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4483.685
DLL 2022-11-23 15:03:40.841961 - Training Epoch: 0 Training Iteration: 249  average_loss : nan  step_loss : nan  learning_rate : 0.0007466627324437552 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 249, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4182.715
DLL 2022-11-23 15:03:45.024536 - Training Epoch: 0 Training Iteration: 250  average_loss : nan  step_loss : nan  learning_rate : 0.0007496613779555775 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 250, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4162.030
DLL 2022-11-23 15:03:49.186548 - Training Epoch: 0 Training Iteration: 251  average_loss : nan  step_loss : nan  learning_rate : 0.0007526600234673998 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 251, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5038.613
DLL 2022-11-23 15:03:54.225176 - Training Epoch: 0 Training Iteration: 252  average_loss : nan  step_loss : nan  learning_rate : 0.0007556586689792222 
Process done with return code -6
Parent process ID: 91112 node: 172.31.28.108
1 per stage
8 servers!
Config:
ranks: range(0, 1)
train batch size: 1024
partitions: 8
chunk_size: 8
data depth: 1
stage to rank map: 0;1;2;3;4;5;6;7;
World size is 8
/opt/conda/envs/varuna/bin/python -u /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --rank=0 --chunk_size=8 --local_rank=0 --stage_to_rank_map=0;1;2;3;4;5;6;7; --batch-size=1024 --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna --resume_step 155
device: cuda:0 n_gpu: 1, distributed training: True, 16-bits training: True
DLL 2022-11-23 15:09:26.527572 - PARAMETER Config : ["Namespace(input_dir='/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/', config_file='bert_config.json', bert_model='bert-large-uncased', output_dir='s3://spot-checkpoints/bert', init_checkpoint=None, max_seq_length=128, max_predictions_per_seq=20, train_batch_size=1024, learning_rate=0.006, num_train_epochs=3.0, max_steps=7038.0, warmup_proportion=0.2843, local_rank=0, seed=12439, gradient_accumulation_steps=1, fp16=True, amp=False, loss_scale=0.0, log_freq=1.0, checkpoint_activations=False, resume_from_checkpoint=True, resume_step=155, num_steps_per_checkpoint=200, skip_checkpoint=False, phase2=False, allreduce_post_accumulation=False, allreduce_post_accumulation_fp16=False, phase1_end_step=7038, init_loss_scale=1048576, do_train=True, json_summary='/home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json', use_env=False, disable_progress_bar=False, steps_this_run=7038.0, varuna=True, stage_to_rank_map='0;1;2;3;4;5;6;7;', chunk_size=8, batch_size=1024, rank=0, profiling=False, n_gpu=1)"] 
dry run time 0.17444705963134766
SHARED WEIGHTS ARE
[(0, 7)]
this rank  0 is part of pipeline replica  0
128 chunks
Begin to load checkpint from s3://spot-checkpoints/bert/ckpt_155.pt
2022-11-23 15:09:36.521460 resume step from  155
Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.

Defaults for this optimization level are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
2022-11-23 15:09:47.721998 - Finished loading checkpoint, takes 11187.976 secs
DLL 2022-11-23 15:09:47.723129 - PARAMETER SEED : 12439 
DLL 2022-11-23 15:09:47.723251 - PARAMETER train_start : True 
DLL 2022-11-23 15:09:47.723304 - PARAMETER batch_size_per_gpu : 1024 
DLL 2022-11-23 15:09:47.723378 - PARAMETER learning_rate : 0.006 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  524288.0
Finished iteration 155, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 15528.945
DLL 2022-11-23 15:10:03.287838 - Training Epoch: 0 Training Iteration: 156  average_loss : nan  step_loss : nan  learning_rate : 0.0004677886998442803 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  262144.0
Finished iteration 156, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 7014.118
DLL 2022-11-23 15:10:10.301513 - Training Epoch: 0 Training Iteration: 157  average_loss : nan  step_loss : nan  learning_rate : 0.0004707873453561027 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  131072.0
Finished iteration 157, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 7142.676
DLL 2022-11-23 15:10:17.452284 - Training Epoch: 0 Training Iteration: 158  average_loss : nan  step_loss : nan  learning_rate : 0.00047378599086792493 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  65536.0
Finished iteration 158, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 7155.636
DLL 2022-11-23 15:10:24.600342 - Training Epoch: 0 Training Iteration: 159  average_loss : nan  step_loss : nan  learning_rate : 0.0004767846363797473 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  32768.0
Finished iteration 159, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 7412.139
DLL 2022-11-23 15:10:32.011863 - Training Epoch: 0 Training Iteration: 160  average_loss : nan  step_loss : nan  learning_rate : 0.0004797832818915696 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  16384.0
Finished iteration 160, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6989.354
DLL 2022-11-23 15:10:39.001355 - Training Epoch: 0 Training Iteration: 161  average_loss : nan  step_loss : nan  learning_rate : 0.00048278192740339187 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  8192.0
Finished iteration 161, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 7417.226
DLL 2022-11-23 15:10:46.418502 - Training Epoch: 0 Training Iteration: 162  average_loss : nan  step_loss : nan  learning_rate : 0.00048578057291521424 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  4096.0
Finished iteration 162, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 7201.054
DLL 2022-11-23 15:10:53.619556 - Training Epoch: 0 Training Iteration: 163  average_loss : nan  step_loss : nan  learning_rate : 0.0004887792184270365 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  2048.0
Finished iteration 163, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 7095.294
DLL 2022-11-23 15:11:00.715077 - Training Epoch: 0 Training Iteration: 164  average_loss : nan  step_loss : nan  learning_rate : 0.0004917778639388588 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1024.0
Finished iteration 164, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 7128.380
DLL 2022-11-23 15:11:07.843279 - Training Epoch: 0 Training Iteration: 165  average_loss : nan  step_loss : nan  learning_rate : 0.0004947765094506812 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  512.0
Finished iteration 165, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 7275.545
DLL 2022-11-23 15:11:15.118905 - Training Epoch: 0 Training Iteration: 166  average_loss : nan  step_loss : nan  learning_rate : 0.0004977751549625034 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  256.0
Finished iteration 166, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 7180.401
DLL 2022-11-23 15:11:22.299207 - Training Epoch: 0 Training Iteration: 167  average_loss : nan  step_loss : nan  learning_rate : 0.0005007738004743258 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  128.0
Finished iteration 167, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 7135.654
DLL 2022-11-23 15:11:29.440286 - Training Epoch: 0 Training Iteration: 168  average_loss : nan  step_loss : nan  learning_rate : 0.0005037724459861481 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  64.0
Finished iteration 168, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 7317.408
DLL 2022-11-23 15:11:36.752507 - Training Epoch: 0 Training Iteration: 169  average_loss : nan  step_loss : nan  learning_rate : 0.0005067710914979704 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  32.0
Finished iteration 169, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 7000.103
DLL 2022-11-23 15:11:43.752658 - Training Epoch: 0 Training Iteration: 170  average_loss : nan  step_loss : nan  learning_rate : 0.0005097697370097927 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  16.0
Finished iteration 170, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 7237.575
DLL 2022-11-23 15:11:50.989938 - Training Epoch: 0 Training Iteration: 171  average_loss : nan  step_loss : nan  learning_rate : 0.0005127683825216149 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  8.0
Finished iteration 171, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 7323.585
DLL 2022-11-23 15:11:58.313837 - Training Epoch: 0 Training Iteration: 172  average_loss : nan  step_loss : nan  learning_rate : 0.0005157670280334373 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  4.0
Finished iteration 172, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6973.065
DLL 2022-11-23 15:12:05.286914 - Training Epoch: 0 Training Iteration: 173  average_loss : nan  step_loss : nan  learning_rate : 0.0005187656735452596 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  2.0
Finished iteration 173, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 7225.507
DLL 2022-11-23 15:12:12.512574 - Training Epoch: 0 Training Iteration: 174  average_loss : nan  step_loss : nan  learning_rate : 0.0005217643190570819 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 174, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 7037.267
DLL 2022-11-23 15:12:19.549630 - Training Epoch: 0 Training Iteration: 175  average_loss : nan  step_loss : nan  learning_rate : 0.0005247629645689043 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 175, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 7141.706
DLL 2022-11-23 15:12:26.691639 - Training Epoch: 0 Training Iteration: 176  average_loss : nan  step_loss : nan  learning_rate : 0.0005277616100807266 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 176, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 7588.251
DLL 2022-11-23 15:12:34.279566 - Training Epoch: 0 Training Iteration: 177  average_loss : nan  step_loss : nan  learning_rate : 0.0005307602555925489 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 177, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 7120.685
DLL 2022-11-23 15:12:41.400636 - Training Epoch: 0 Training Iteration: 178  average_loss : nan  step_loss : nan  learning_rate : 0.0005337589011043712 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 178, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 7120.306
DLL 2022-11-23 15:12:48.520994 - Training Epoch: 0 Training Iteration: 179  average_loss : nan  step_loss : nan  learning_rate : 0.0005367575466161935 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 179, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 7157.728
DLL 2022-11-23 15:12:55.683927 - Training Epoch: 0 Training Iteration: 180  average_loss : nan  step_loss : nan  learning_rate : 0.0005397561921280158 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 180, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 7103.763
DLL 2022-11-23 15:13:02.782372 - Training Epoch: 0 Training Iteration: 181  average_loss : nan  step_loss : nan  learning_rate : 0.0005427548376398381 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 181, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 7059.325
DLL 2022-11-23 15:13:09.851075 - Training Epoch: 0 Training Iteration: 182  average_loss : nan  step_loss : nan  learning_rate : 0.0005457534831516603 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 182, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 6822.696
DLL 2022-11-23 15:13:16.664498 - Training Epoch: 0 Training Iteration: 183  average_loss : nan  step_loss : nan  learning_rate : 0.0005487521286634827 
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 0 signal handler called with signal 10
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 183, CKPT_AND_STOP: True, flag: tensor([8], dtype=torch.int32), speed: 7195.784
DLL 2022-11-23 15:13:23.860337 - Training Epoch: 0 Training Iteration: 184  average_loss : nan  step_loss : nan  learning_rate : 0.0005517507741753051 
2022-11-23 15:13:23.860460 Begin to save checkpont to s3://spot-checkpoints/bert and exit
DLL 2022-11-23 15:13:23.860494 - PARAMETER checkpoint_step : 184 
Opt ckpt time 10.12083101272583
Process done with return code 0
Parent process ID: 92057 node: 172.31.28.108
1 per stage
8 servers!
Config:
ranks: range(0, 1)
train batch size: 1024
partitions: 8
chunk_size: 8
data depth: 1
stage to rank map: 0;1;2;3;4;5;6;7;
World size is 8
/opt/conda/envs/varuna/bin/python -u /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --rank=0 --chunk_size=8 --local_rank=0 --stage_to_rank_map=0;1;2;3;4;5;6;7; --batch-size=1024 --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna --resume_step 184
device: cuda:0 n_gpu: 1, distributed training: True, 16-bits training: True
DLL 2022-11-23 15:13:43.193230 - PARAMETER Config : ["Namespace(input_dir='/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/', config_file='bert_config.json', bert_model='bert-large-uncased', output_dir='s3://spot-checkpoints/bert', init_checkpoint=None, max_seq_length=128, max_predictions_per_seq=20, train_batch_size=1024, learning_rate=0.006, num_train_epochs=3.0, max_steps=7038.0, warmup_proportion=0.2843, local_rank=0, seed=12439, gradient_accumulation_steps=1, fp16=True, amp=False, loss_scale=0.0, log_freq=1.0, checkpoint_activations=False, resume_from_checkpoint=True, resume_step=184, num_steps_per_checkpoint=200, skip_checkpoint=False, phase2=False, allreduce_post_accumulation=False, allreduce_post_accumulation_fp16=False, phase1_end_step=7038, init_loss_scale=1048576, do_train=True, json_summary='/home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json', use_env=False, disable_progress_bar=False, steps_this_run=7038.0, varuna=True, stage_to_rank_map='0;1;2;3;4;5;6;7;', chunk_size=8, batch_size=1024, rank=0, profiling=False, n_gpu=1)"] 
dry run time 0.009726524353027344
SHARED WEIGHTS ARE
[(0, 7)]
this rank  0 is part of pipeline replica  0
128 chunks
Begin to load checkpint from s3://spot-checkpoints/bert/ckpt_184.pt
2022-11-23 15:13:53.005998 resume step from  184
Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.

Defaults for this optimization level are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
2022-11-23 15:14:01.589066 - Finished loading checkpoint, takes 8570.948 secs
DLL 2022-11-23 15:14:01.590136 - PARAMETER SEED : 12439 
DLL 2022-11-23 15:14:01.590262 - PARAMETER train_start : True 
DLL 2022-11-23 15:14:01.590350 - PARAMETER batch_size_per_gpu : 1024 
DLL 2022-11-23 15:14:01.590438 - PARAMETER learning_rate : 0.006 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  524288.0
Finished iteration 184, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 15635.568
DLL 2022-11-23 15:14:17.261347 - Training Epoch: 0 Training Iteration: 185  average_loss : nan  step_loss : nan  learning_rate : 0.0005547494196871273 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  262144.0
Finished iteration 185, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 7286.244
DLL 2022-11-23 15:14:24.547047 - Training Epoch: 0 Training Iteration: 186  average_loss : nan  step_loss : nan  learning_rate : 0.0005577480651989497 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  131072.0
Finished iteration 186, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 7610.650
DLL 2022-11-23 15:14:32.158114 - Training Epoch: 0 Training Iteration: 187  average_loss : nan  step_loss : nan  learning_rate : 0.000560746710710772 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  65536.0
Finished iteration 187, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 7542.657
DLL 2022-11-23 15:14:39.700695 - Training Epoch: 0 Training Iteration: 188  average_loss : nan  step_loss : nan  learning_rate : 0.0005637453562225942 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  32768.0
Finished iteration 188, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 7447.030
DLL 2022-11-23 15:14:47.148159 - Training Epoch: 0 Training Iteration: 189  average_loss : nan  step_loss : nan  learning_rate : 0.0005667440017344166 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  16384.0
Finished iteration 189, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 7620.700
DLL 2022-11-23 15:14:54.768178 - Training Epoch: 0 Training Iteration: 190  average_loss : nan  step_loss : nan  learning_rate : 0.0005697426472462388 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  8192.0
Finished iteration 190, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 7718.240
DLL 2022-11-23 15:15:02.492329 - Training Epoch: 0 Training Iteration: 191  average_loss : nan  step_loss : nan  learning_rate : 0.0005727412927580613 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  4096.0
Finished iteration 191, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 7506.201
DLL 2022-11-23 15:15:09.992905 - Training Epoch: 0 Training Iteration: 192  average_loss : nan  step_loss : nan  learning_rate : 0.0005757399382698836 
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 0 signal handler called with signal 10
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  2048.0
Finished iteration 192, CKPT_AND_STOP: True, flag: tensor([1], dtype=torch.int32), speed: 7504.369
DLL 2022-11-23 15:15:17.503032 - Training Epoch: 0 Training Iteration: 193  average_loss : nan  step_loss : nan  learning_rate : 0.0005787385837817058 
2022-11-23 15:15:17.503160 Begin to save checkpont to s3://spot-checkpoints/bert and exit
DLL 2022-11-23 15:15:17.503189 - PARAMETER checkpoint_step : 193 
Opt ckpt time 10.378859043121338
Process done with return code 0
Parent process ID: 92932 node: 172.31.28.108
2 per stage
16 servers!
Config:
ranks: range(0, 1)
train batch size: 1024
partitions: 8
chunk_size: 8
data depth: 2
stage to rank map: 0,8;1,9;2,10;3,11;4,12;5,13;6,14;7,15;
World size is 16
/opt/conda/envs/varuna/bin/python -u /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --rank=0 --chunk_size=8 --local_rank=0 --stage_to_rank_map=0,8;1,9;2,10;3,11;4,12;5,13;6,14;7,15; --batch-size=512 --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna --resume_step 193
device: cuda:0 n_gpu: 1, distributed training: True, 16-bits training: True
DLL 2022-11-23 15:15:37.463316 - PARAMETER Config : ["Namespace(input_dir='/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/', config_file='bert_config.json', bert_model='bert-large-uncased', output_dir='s3://spot-checkpoints/bert', init_checkpoint=None, max_seq_length=128, max_predictions_per_seq=20, train_batch_size=512, learning_rate=0.006, num_train_epochs=3.0, max_steps=7038.0, warmup_proportion=0.2843, local_rank=0, seed=12439, gradient_accumulation_steps=1, fp16=True, amp=False, loss_scale=0.0, log_freq=1.0, checkpoint_activations=False, resume_from_checkpoint=True, resume_step=193, num_steps_per_checkpoint=200, skip_checkpoint=False, phase2=False, allreduce_post_accumulation=False, allreduce_post_accumulation_fp16=False, phase1_end_step=7038, init_loss_scale=1048576, do_train=True, json_summary='/home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json', use_env=False, disable_progress_bar=False, steps_this_run=7038.0, varuna=True, stage_to_rank_map='0,8;1,9;2,10;3,11;4,12;5,13;6,14;7,15;', chunk_size=8, batch_size=512, rank=0, profiling=False, n_gpu=1)"] 
dry run time 0.7342381477355957
SHARED WEIGHTS ARE
[(0, 7)]
this rank  0 is part of pipeline replica  0
64 chunks
Begin to load checkpint from s3://spot-checkpoints/bert/ckpt_193.pt
2022-11-23 15:15:48.803626 resume step from  193
Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.

Defaults for this optimization level are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
2022-11-23 15:15:57.058580 - Finished loading checkpoint, takes 8242.370 secs
DLL 2022-11-23 15:15:57.059465 - PARAMETER SEED : 12439 
DLL 2022-11-23 15:15:57.059618 - PARAMETER train_start : True 
DLL 2022-11-23 15:15:57.059670 - PARAMETER batch_size_per_gpu : 512 
DLL 2022-11-23 15:15:57.059705 - PARAMETER learning_rate : 0.006 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  524288.0
Finished iteration 193, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 14039.196
DLL 2022-11-23 15:16:11.134211 - Training Epoch: 0 Training Iteration: 194  average_loss : nan  step_loss : nan  learning_rate : 0.0005817372292935281 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  262144.0
Finished iteration 194, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5453.886
DLL 2022-11-23 15:16:16.588024 - Training Epoch: 0 Training Iteration: 195  average_loss : nan  step_loss : nan  learning_rate : 0.0005847358748053504 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  131072.0
Finished iteration 195, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5179.356
DLL 2022-11-23 15:16:21.767109 - Training Epoch: 0 Training Iteration: 196  average_loss : nan  step_loss : nan  learning_rate : 0.0005877345203171727 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  65536.0
Finished iteration 196, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5350.312
DLL 2022-11-23 15:16:27.122973 - Training Epoch: 0 Training Iteration: 197  average_loss : nan  step_loss : nan  learning_rate : 0.000590733165828995 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  32768.0
Finished iteration 197, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5424.090
DLL 2022-11-23 15:16:32.541445 - Training Epoch: 0 Training Iteration: 198  average_loss : nan  step_loss : nan  learning_rate : 0.0005937318113408173 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  16384.0
Finished iteration 198, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4096.899
DLL 2022-11-23 15:16:36.638350 - Training Epoch: 0 Training Iteration: 199  average_loss : nan  step_loss : nan  learning_rate : 0.0005967304568526397 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  8192.0
Finished iteration 199, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4213.021
DLL 2022-11-23 15:16:40.859575 - Training Epoch: 0 Training Iteration: 200  average_loss : nan  step_loss : nan  learning_rate : 0.000599729102364462 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  4096.0
Finished iteration 200, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4345.814
DLL 2022-11-23 15:16:45.197527 - Training Epoch: 0 Training Iteration: 201  average_loss : nan  step_loss : nan  learning_rate : 0.0006027277478762843 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  2048.0
Finished iteration 201, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4333.037
DLL 2022-11-23 15:16:49.530354 - Training Epoch: 0 Training Iteration: 202  average_loss : nan  step_loss : nan  learning_rate : 0.0006057263933881066 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1024.0
Finished iteration 202, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4285.140
DLL 2022-11-23 15:16:53.815728 - Training Epoch: 0 Training Iteration: 203  average_loss : nan  step_loss : nan  learning_rate : 0.0006087250388999289 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  512.0
Finished iteration 203, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4342.964
DLL 2022-11-23 15:16:58.158612 - Training Epoch: 0 Training Iteration: 204  average_loss : nan  step_loss : nan  learning_rate : 0.0006117236844117512 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  256.0
Finished iteration 204, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4092.391
DLL 2022-11-23 15:17:02.258334 - Training Epoch: 0 Training Iteration: 205  average_loss : nan  step_loss : nan  learning_rate : 0.0006147223299235735 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  128.0
Finished iteration 205, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4243.696
DLL 2022-11-23 15:17:06.494899 - Training Epoch: 0 Training Iteration: 206  average_loss : nan  step_loss : nan  learning_rate : 0.000617720975435396 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  64.0
Finished iteration 206, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4083.654
DLL 2022-11-23 15:17:10.578555 - Training Epoch: 0 Training Iteration: 207  average_loss : nan  step_loss : nan  learning_rate : 0.0006207196209472182 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  32.0
Finished iteration 207, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4277.242
DLL 2022-11-23 15:17:14.855701 - Training Epoch: 0 Training Iteration: 208  average_loss : nan  step_loss : nan  learning_rate : 0.0006237182664590405 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  16.0
Finished iteration 208, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4171.813
DLL 2022-11-23 15:17:19.027304 - Training Epoch: 0 Training Iteration: 209  average_loss : nan  step_loss : nan  learning_rate : 0.0006267169119708628 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  8.0
Finished iteration 209, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4515.036
DLL 2022-11-23 15:17:23.547899 - Training Epoch: 0 Training Iteration: 210  average_loss : nan  step_loss : nan  learning_rate : 0.000629715557482685 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  4.0
Finished iteration 210, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4278.364
DLL 2022-11-23 15:17:27.821314 - Training Epoch: 0 Training Iteration: 211  average_loss : nan  step_loss : nan  learning_rate : 0.0006327142029945074 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  2.0
Finished iteration 211, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4187.890
DLL 2022-11-23 15:17:32.009037 - Training Epoch: 0 Training Iteration: 212  average_loss : nan  step_loss : nan  learning_rate : 0.0006357128485063296 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 212, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4287.390
DLL 2022-11-23 15:17:36.301767 - Training Epoch: 0 Training Iteration: 213  average_loss : nan  step_loss : nan  learning_rate : 0.000638711494018152 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 213, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4111.433
DLL 2022-11-23 15:17:40.407874 - Training Epoch: 0 Training Iteration: 214  average_loss : nan  step_loss : nan  learning_rate : 0.0006417101395299744 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 214, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4099.624
DLL 2022-11-23 15:17:44.507560 - Training Epoch: 0 Training Iteration: 215  average_loss : nan  step_loss : nan  learning_rate : 0.0006447087850417966 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 215, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4262.917
DLL 2022-11-23 15:17:48.776402 - Training Epoch: 0 Training Iteration: 216  average_loss : nan  step_loss : nan  learning_rate : 0.000647707430553619 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 216, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4108.396
DLL 2022-11-23 15:17:52.878847 - Training Epoch: 0 Training Iteration: 217  average_loss : nan  step_loss : nan  learning_rate : 0.0006507060760654413 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 217, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4234.434
DLL 2022-11-23 15:17:57.113353 - Training Epoch: 0 Training Iteration: 218  average_loss : nan  step_loss : nan  learning_rate : 0.0006537047215772636 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 218, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4261.994
DLL 2022-11-23 15:18:01.375456 - Training Epoch: 0 Training Iteration: 219  average_loss : nan  step_loss : nan  learning_rate : 0.0006567033670890859 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 219, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4113.942
DLL 2022-11-23 15:18:05.494780 - Training Epoch: 0 Training Iteration: 220  average_loss : nan  step_loss : nan  learning_rate : 0.0006597020126009082 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 220, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4239.353
DLL 2022-11-23 15:18:09.728813 - Training Epoch: 0 Training Iteration: 221  average_loss : nan  step_loss : nan  learning_rate : 0.0006627006581127306 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 221, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4463.709
DLL 2022-11-23 15:18:14.192414 - Training Epoch: 0 Training Iteration: 222  average_loss : nan  step_loss : nan  learning_rate : 0.0006656993036245529 
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 0 signal handler called with signal 10
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 222, CKPT_AND_STOP: True, flag: tensor([2], dtype=torch.int32), speed: 4176.416
DLL 2022-11-23 15:18:18.368812 - Training Epoch: 0 Training Iteration: 223  average_loss : nan  step_loss : nan  learning_rate : 0.0006686979491363751 
2022-11-23 15:18:18.368968 Begin to save checkpont to s3://spot-checkpoints/bert and exit
DLL 2022-11-23 15:18:18.368986 - PARAMETER checkpoint_step : 223 
Opt ckpt time 6.086358308792114
Process done with return code 0
Parent process ID: 93901 node: 172.31.28.108
2 per stage
16 servers!
Config:
ranks: range(0, 1)
train batch size: 1024
partitions: 8
chunk_size: 8
data depth: 2
stage to rank map: 0,8;1,9;2,10;3,11;4,12;5,13;6,14;7,15;
World size is 16
/opt/conda/envs/varuna/bin/python -u /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --rank=0 --chunk_size=8 --local_rank=0 --stage_to_rank_map=0,8;1,9;2,10;3,11;4,12;5,13;6,14;7,15; --batch-size=512 --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna --resume_step 223
device: cuda:0 n_gpu: 1, distributed training: True, 16-bits training: True
DLL 2022-11-23 15:18:36.890921 - PARAMETER Config : ["Namespace(input_dir='/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/', config_file='bert_config.json', bert_model='bert-large-uncased', output_dir='s3://spot-checkpoints/bert', init_checkpoint=None, max_seq_length=128, max_predictions_per_seq=20, train_batch_size=512, learning_rate=0.006, num_train_epochs=3.0, max_steps=7038.0, warmup_proportion=0.2843, local_rank=0, seed=12439, gradient_accumulation_steps=1, fp16=True, amp=False, loss_scale=0.0, log_freq=1.0, checkpoint_activations=False, resume_from_checkpoint=True, resume_step=223, num_steps_per_checkpoint=200, skip_checkpoint=False, phase2=False, allreduce_post_accumulation=False, allreduce_post_accumulation_fp16=False, phase1_end_step=7038, init_loss_scale=1048576, do_train=True, json_summary='/home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json', use_env=False, disable_progress_bar=False, steps_this_run=7038.0, varuna=True, stage_to_rank_map='0,8;1,9;2,10;3,11;4,12;5,13;6,14;7,15;', chunk_size=8, batch_size=512, rank=0, profiling=False, n_gpu=1)"] 
dry run time 0.003645658493041992
SHARED WEIGHTS ARE
[(0, 7)]
this rank  0 is part of pipeline replica  0
64 chunks
Begin to load checkpint from s3://spot-checkpoints/bert/ckpt_223.pt
2022-11-23 15:18:46.898653 resume step from  223
Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.

Defaults for this optimization level are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
2022-11-23 15:19:01.902593 - Finished loading checkpoint, takes 14991.952 secs
DLL 2022-11-23 15:19:01.903609 - PARAMETER SEED : 12439 
DLL 2022-11-23 15:19:01.903739 - PARAMETER train_start : True 
DLL 2022-11-23 15:19:01.903811 - PARAMETER batch_size_per_gpu : 512 
DLL 2022-11-23 15:19:01.903859 - PARAMETER learning_rate : 0.006 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  524288.0
Finished iteration 223, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 12698.545
DLL 2022-11-23 15:19:14.638443 - Training Epoch: 0 Training Iteration: 224  average_loss : nan  step_loss : nan  learning_rate : 0.0006716965946481975 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  262144.0
Finished iteration 224, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5327.984
DLL 2022-11-23 15:19:19.965923 - Training Epoch: 0 Training Iteration: 225  average_loss : nan  step_loss : nan  learning_rate : 0.0006746952401600198 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  131072.0
Finished iteration 225, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5298.540
DLL 2022-11-23 15:19:25.264325 - Training Epoch: 0 Training Iteration: 226  average_loss : nan  step_loss : nan  learning_rate : 0.000677693885671842 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  65536.0
Finished iteration 226, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5192.698
DLL 2022-11-23 15:19:30.457371 - Training Epoch: 0 Training Iteration: 227  average_loss : nan  step_loss : nan  learning_rate : 0.0006806925311836643 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  32768.0
Finished iteration 227, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5259.004
DLL 2022-11-23 15:19:35.723715 - Training Epoch: 0 Training Iteration: 228  average_loss : nan  step_loss : nan  learning_rate : 0.0006836911766954866 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  16384.0
Finished iteration 228, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4405.832
DLL 2022-11-23 15:19:40.122188 - Training Epoch: 0 Training Iteration: 229  average_loss : nan  step_loss : nan  learning_rate : 0.0006866898222073091 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  8192.0
Finished iteration 229, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4337.820
DLL 2022-11-23 15:19:44.460085 - Training Epoch: 0 Training Iteration: 230  average_loss : nan  step_loss : nan  learning_rate : 0.0006896884677191314 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  4096.0
Finished iteration 230, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4175.000
DLL 2022-11-23 15:19:48.634855 - Training Epoch: 0 Training Iteration: 231  average_loss : nan  step_loss : nan  learning_rate : 0.0006926871132309536 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  2048.0
Finished iteration 231, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4237.051
DLL 2022-11-23 15:19:52.877256 - Training Epoch: 0 Training Iteration: 232  average_loss : nan  step_loss : nan  learning_rate : 0.0006956857587427759 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1024.0
Finished iteration 232, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4241.755
DLL 2022-11-23 15:19:57.113841 - Training Epoch: 0 Training Iteration: 233  average_loss : nan  step_loss : nan  learning_rate : 0.0006986844042545982 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  512.0
Finished iteration 233, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4238.012
DLL 2022-11-23 15:20:01.359752 - Training Epoch: 0 Training Iteration: 234  average_loss : nan  step_loss : nan  learning_rate : 0.0007016830497664205 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  256.0
Finished iteration 234, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4259.442
DLL 2022-11-23 15:20:05.611515 - Training Epoch: 0 Training Iteration: 235  average_loss : nan  step_loss : nan  learning_rate : 0.0007046816952782429 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  128.0
Finished iteration 235, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4114.042
DLL 2022-11-23 15:20:09.730706 - Training Epoch: 0 Training Iteration: 236  average_loss : nan  step_loss : nan  learning_rate : 0.0007076803407900652 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  64.0
Finished iteration 236, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4348.405
DLL 2022-11-23 15:20:14.079107 - Training Epoch: 0 Training Iteration: 237  average_loss : nan  step_loss : nan  learning_rate : 0.0007106789863018875 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  32.0
Finished iteration 237, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4166.945
DLL 2022-11-23 15:20:18.240840 - Training Epoch: 0 Training Iteration: 238  average_loss : nan  step_loss : nan  learning_rate : 0.0007136776318137098 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  16.0
Finished iteration 238, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4235.090
DLL 2022-11-23 15:20:22.475773 - Training Epoch: 0 Training Iteration: 239  average_loss : nan  step_loss : nan  learning_rate : 0.0007166762773255321 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  8.0
Finished iteration 239, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4216.223
DLL 2022-11-23 15:20:26.697269 - Training Epoch: 0 Training Iteration: 240  average_loss : nan  step_loss : nan  learning_rate : 0.0007196749228373544 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  4.0
Finished iteration 240, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4248.928
DLL 2022-11-23 15:20:30.941104 - Training Epoch: 0 Training Iteration: 241  average_loss : nan  step_loss : nan  learning_rate : 0.0007226735683491767 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  2.0
Finished iteration 241, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4055.960
DLL 2022-11-23 15:20:34.997033 - Training Epoch: 0 Training Iteration: 242  average_loss : nan  step_loss : nan  learning_rate : 0.0007256722138609989 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 242, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4242.953
DLL 2022-11-23 15:20:39.247238 - Training Epoch: 0 Training Iteration: 243  average_loss : nan  step_loss : nan  learning_rate : 0.0007286708593728212 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 243, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4368.804
DLL 2022-11-23 15:20:43.612742 - Training Epoch: 0 Training Iteration: 244  average_loss : nan  step_loss : nan  learning_rate : 0.0007316695048846438 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 244, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4183.369
DLL 2022-11-23 15:20:47.798160 - Training Epoch: 0 Training Iteration: 245  average_loss : nan  step_loss : nan  learning_rate : 0.000734668150396466 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 245, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4188.397
DLL 2022-11-23 15:20:51.981498 - Training Epoch: 0 Training Iteration: 246  average_loss : nan  step_loss : nan  learning_rate : 0.0007376667959082883 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 246, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4344.644
DLL 2022-11-23 15:20:56.325732 - Training Epoch: 0 Training Iteration: 247  average_loss : nan  step_loss : nan  learning_rate : 0.0007406654414201106 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 247, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4196.556
DLL 2022-11-23 15:21:00.522109 - Training Epoch: 0 Training Iteration: 248  average_loss : nan  step_loss : nan  learning_rate : 0.0007436640869319328 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 248, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4311.638
DLL 2022-11-23 15:21:04.833847 - Training Epoch: 0 Training Iteration: 249  average_loss : nan  step_loss : nan  learning_rate : 0.0007466627324437552 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 249, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4207.930
DLL 2022-11-23 15:21:09.041740 - Training Epoch: 0 Training Iteration: 250  average_loss : nan  step_loss : nan  learning_rate : 0.0007496613779555775 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 250, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4192.729
DLL 2022-11-23 15:21:13.234578 - Training Epoch: 0 Training Iteration: 251  average_loss : nan  step_loss : nan  learning_rate : 0.0007526600234673998 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 251, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4251.301
DLL 2022-11-23 15:21:17.486023 - Training Epoch: 0 Training Iteration: 252  average_loss : nan  step_loss : nan  learning_rate : 0.0007556586689792222 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 252, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4205.585
DLL 2022-11-23 15:21:21.691675 - Training Epoch: 0 Training Iteration: 253  average_loss : nan  step_loss : nan  learning_rate : 0.0007586573144910444 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 253, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4278.308
DLL 2022-11-23 15:21:25.969778 - Training Epoch: 0 Training Iteration: 254  average_loss : nan  step_loss : nan  learning_rate : 0.0007616559600028668 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 254, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4095.487
DLL 2022-11-23 15:21:30.069511 - Training Epoch: 0 Training Iteration: 255  average_loss : nan  step_loss : nan  learning_rate : 0.0007646546055146891 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 255, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4134.597
DLL 2022-11-23 15:21:34.199951 - Training Epoch: 0 Training Iteration: 256  average_loss : nan  step_loss : nan  learning_rate : 0.0007676532510265113 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 256, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4100.624
DLL 2022-11-23 15:21:38.300727 - Training Epoch: 0 Training Iteration: 257  average_loss : nan  step_loss : nan  learning_rate : 0.0007706518965383336 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 257, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4120.570
DLL 2022-11-23 15:21:42.421044 - Training Epoch: 0 Training Iteration: 258  average_loss : nan  step_loss : nan  learning_rate : 0.0007736505420501559 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 258, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4332.262
DLL 2022-11-23 15:21:46.753570 - Training Epoch: 0 Training Iteration: 259  average_loss : nan  step_loss : nan  learning_rate : 0.0007766491875619783 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 259, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4347.534
DLL 2022-11-23 15:21:51.107804 - Training Epoch: 0 Training Iteration: 260  average_loss : nan  step_loss : nan  learning_rate : 0.0007796478330738007 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 260, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4188.318
DLL 2022-11-23 15:21:55.289498 - Training Epoch: 0 Training Iteration: 261  average_loss : nan  step_loss : nan  learning_rate : 0.0007826464785856229 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 261, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4383.849
DLL 2022-11-23 15:21:59.680087 - Training Epoch: 0 Training Iteration: 262  average_loss : nan  step_loss : nan  learning_rate : 0.0007856451240974452 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 262, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4245.159
DLL 2022-11-23 15:22:03.918265 - Training Epoch: 0 Training Iteration: 263  average_loss : nan  step_loss : nan  learning_rate : 0.0007886437696092675 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 263, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4308.598
DLL 2022-11-23 15:22:08.227149 - Training Epoch: 0 Training Iteration: 264  average_loss : nan  step_loss : nan  learning_rate : 0.0007916424151210898 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 264, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4283.586
DLL 2022-11-23 15:22:12.510929 - Training Epoch: 0 Training Iteration: 265  average_loss : nan  step_loss : nan  learning_rate : 0.0007946410606329121 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 265, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4126.149
DLL 2022-11-23 15:22:16.637150 - Training Epoch: 0 Training Iteration: 266  average_loss : nan  step_loss : nan  learning_rate : 0.0007976397061447345 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 266, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4343.314
DLL 2022-11-23 15:22:20.986816 - Training Epoch: 0 Training Iteration: 267  average_loss : nan  step_loss : nan  learning_rate : 0.0008006383516565567 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 267, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4179.482
DLL 2022-11-23 15:22:25.160080 - Training Epoch: 0 Training Iteration: 268  average_loss : nan  step_loss : nan  learning_rate : 0.000803636997168379 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 268, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4345.868
DLL 2022-11-23 15:22:29.512403 - Training Epoch: 0 Training Iteration: 269  average_loss : nan  step_loss : nan  learning_rate : 0.0008066356426802014 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 269, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4262.124
DLL 2022-11-23 15:22:33.767904 - Training Epoch: 0 Training Iteration: 270  average_loss : nan  step_loss : nan  learning_rate : 0.0008096342881920237 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 270, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4274.862
DLL 2022-11-23 15:22:38.042806 - Training Epoch: 0 Training Iteration: 271  average_loss : nan  step_loss : nan  learning_rate : 0.000812632933703846 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 271, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4369.975
DLL 2022-11-23 15:22:42.422716 - Training Epoch: 0 Training Iteration: 272  average_loss : nan  step_loss : nan  learning_rate : 0.0008156315792156683 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 272, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4221.332
DLL 2022-11-23 15:22:46.634123 - Training Epoch: 0 Training Iteration: 273  average_loss : nan  step_loss : nan  learning_rate : 0.0008186302247274905 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 273, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4205.226
DLL 2022-11-23 15:22:50.839643 - Training Epoch: 0 Training Iteration: 274  average_loss : nan  step_loss : nan  learning_rate : 0.000821628870239313 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 274, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4270.794
DLL 2022-11-23 15:22:55.110256 - Training Epoch: 0 Training Iteration: 275  average_loss : nan  step_loss : nan  learning_rate : 0.0008246275157511352 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 275, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4193.729
DLL 2022-11-23 15:22:59.303900 - Training Epoch: 0 Training Iteration: 276  average_loss : nan  step_loss : nan  learning_rate : 0.0008276261612629576 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 276, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4221.961
DLL 2022-11-23 15:23:03.526032 - Training Epoch: 0 Training Iteration: 277  average_loss : nan  step_loss : nan  learning_rate : 0.0008306248067747799 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 277, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4142.715
DLL 2022-11-23 15:23:07.668770 - Training Epoch: 0 Training Iteration: 278  average_loss : nan  step_loss : nan  learning_rate : 0.0008336234522866021 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 278, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4085.472
DLL 2022-11-23 15:23:11.754125 - Training Epoch: 0 Training Iteration: 279  average_loss : nan  step_loss : nan  learning_rate : 0.0008366220977984245 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 279, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4244.485
DLL 2022-11-23 15:23:15.998628 - Training Epoch: 0 Training Iteration: 280  average_loss : nan  step_loss : nan  learning_rate : 0.0008396207433102468 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 280, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4147.893
DLL 2022-11-23 15:23:20.146779 - Training Epoch: 0 Training Iteration: 281  average_loss : nan  step_loss : nan  learning_rate : 0.000842619388822069 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 281, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4250.245
DLL 2022-11-23 15:23:24.406741 - Training Epoch: 0 Training Iteration: 282  average_loss : nan  step_loss : nan  learning_rate : 0.0008456180343338914 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 282, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4384.688
DLL 2022-11-23 15:23:28.781535 - Training Epoch: 0 Training Iteration: 283  average_loss : nan  step_loss : nan  learning_rate : 0.0008486166798457137 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 283, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4166.918
DLL 2022-11-23 15:23:32.948738 - Training Epoch: 0 Training Iteration: 284  average_loss : nan  step_loss : nan  learning_rate : 0.0008516153253575361 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 284, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4171.223
DLL 2022-11-23 15:23:37.119948 - Training Epoch: 0 Training Iteration: 285  average_loss : nan  step_loss : nan  learning_rate : 0.0008546139708693584 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 285, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5243.872
DLL 2022-11-23 15:23:42.363980 - Training Epoch: 0 Training Iteration: 286  average_loss : nan  step_loss : nan  learning_rate : 0.0008576126163811806 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 286, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4374.367
DLL 2022-11-23 15:23:46.738203 - Training Epoch: 0 Training Iteration: 287  average_loss : nan  step_loss : nan  learning_rate : 0.000860611261893003 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 287, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4255.860
DLL 2022-11-23 15:23:50.994071 - Training Epoch: 0 Training Iteration: 288  average_loss : nan  step_loss : nan  learning_rate : 0.0008636099074048253 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 288, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4330.111
DLL 2022-11-23 15:23:55.333859 - Training Epoch: 0 Training Iteration: 289  average_loss : nan  step_loss : nan  learning_rate : 0.0008666085529166475 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 289, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4147.977
DLL 2022-11-23 15:23:59.481689 - Training Epoch: 0 Training Iteration: 290  average_loss : nan  step_loss : nan  learning_rate : 0.0008696071984284699 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 290, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4301.203
DLL 2022-11-23 15:24:03.780450 - Training Epoch: 0 Training Iteration: 291  average_loss : nan  step_loss : nan  learning_rate : 0.0008726058439402921 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 291, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4249.009
DLL 2022-11-23 15:24:08.029400 - Training Epoch: 0 Training Iteration: 292  average_loss : nan  step_loss : nan  learning_rate : 0.0008756044894521145 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 292, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4123.968
DLL 2022-11-23 15:24:12.146516 - Training Epoch: 0 Training Iteration: 293  average_loss : nan  step_loss : nan  learning_rate : 0.0008786031349639369 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 293, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4357.189
DLL 2022-11-23 15:24:16.503769 - Training Epoch: 0 Training Iteration: 294  average_loss : nan  step_loss : nan  learning_rate : 0.0008816017804757592 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 294, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4157.249
DLL 2022-11-23 15:24:20.667902 - Training Epoch: 0 Training Iteration: 295  average_loss : nan  step_loss : nan  learning_rate : 0.0008846004259875814 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 295, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4343.661
DLL 2022-11-23 15:24:25.011632 - Training Epoch: 0 Training Iteration: 296  average_loss : nan  step_loss : nan  learning_rate : 0.0008875990714994038 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 296, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4134.057
DLL 2022-11-23 15:24:29.138798 - Training Epoch: 0 Training Iteration: 297  average_loss : nan  step_loss : nan  learning_rate : 0.0008905977170112259 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 297, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4328.118
DLL 2022-11-23 15:24:33.466921 - Training Epoch: 0 Training Iteration: 298  average_loss : nan  step_loss : nan  learning_rate : 0.0008935963625230486 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 298, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4153.255
DLL 2022-11-23 15:24:37.620278 - Training Epoch: 0 Training Iteration: 299  average_loss : nan  step_loss : nan  learning_rate : 0.0008965950080348708 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 299, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4266.898
DLL 2022-11-23 15:24:41.887050 - Training Epoch: 0 Training Iteration: 300  average_loss : nan  step_loss : nan  learning_rate : 0.0008995936535466931 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 300, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4239.553
DLL 2022-11-23 15:24:46.134389 - Training Epoch: 0 Training Iteration: 301  average_loss : nan  step_loss : nan  learning_rate : 0.0009025922990585153 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 301, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4372.777
DLL 2022-11-23 15:24:50.499374 - Training Epoch: 0 Training Iteration: 302  average_loss : nan  step_loss : nan  learning_rate : 0.0009055909445703376 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 302, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4460.253
DLL 2022-11-23 15:24:54.968433 - Training Epoch: 0 Training Iteration: 303  average_loss : nan  step_loss : nan  learning_rate : 0.00090858959008216 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 303, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4602.221
DLL 2022-11-23 15:24:59.562049 - Training Epoch: 0 Training Iteration: 304  average_loss : nan  step_loss : nan  learning_rate : 0.0009115882355939822 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 304, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4630.713
DLL 2022-11-23 15:25:04.199914 - Training Epoch: 0 Training Iteration: 305  average_loss : nan  step_loss : nan  learning_rate : 0.0009145868811058045 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 305, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4160.723
DLL 2022-11-23 15:25:08.353474 - Training Epoch: 0 Training Iteration: 306  average_loss : nan  step_loss : nan  learning_rate : 0.0009175855266176267 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 306, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4254.542
DLL 2022-11-23 15:25:12.614882 - Training Epoch: 0 Training Iteration: 307  average_loss : nan  step_loss : nan  learning_rate : 0.0009205841721294492 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 307, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4266.896
DLL 2022-11-23 15:25:16.874783 - Training Epoch: 0 Training Iteration: 308  average_loss : nan  step_loss : nan  learning_rate : 0.0009235828176412715 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 308, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4191.667
DLL 2022-11-23 15:25:21.066721 - Training Epoch: 0 Training Iteration: 309  average_loss : nan  step_loss : nan  learning_rate : 0.0009265814631530939 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 309, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4176.822
DLL 2022-11-23 15:25:25.243382 - Training Epoch: 0 Training Iteration: 310  average_loss : nan  step_loss : nan  learning_rate : 0.0009295801086649161 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 310, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4127.983
DLL 2022-11-23 15:25:29.371629 - Training Epoch: 0 Training Iteration: 311  average_loss : nan  step_loss : nan  learning_rate : 0.0009325787541767384 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 311, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4168.518
DLL 2022-11-23 15:25:33.540182 - Training Epoch: 0 Training Iteration: 312  average_loss : nan  step_loss : nan  learning_rate : 0.0009355773996885606 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 312, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4260.176
DLL 2022-11-23 15:25:37.807335 - Training Epoch: 0 Training Iteration: 313  average_loss : nan  step_loss : nan  learning_rate : 0.0009385760452003831 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 313, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4082.130
DLL 2022-11-23 15:25:41.882282 - Training Epoch: 0 Training Iteration: 314  average_loss : nan  step_loss : nan  learning_rate : 0.0009415746907122053 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 314, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4467.774
DLL 2022-11-23 15:25:46.350867 - Training Epoch: 0 Training Iteration: 315  average_loss : nan  step_loss : nan  learning_rate : 0.0009445733362240278 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 315, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4243.671
DLL 2022-11-23 15:25:50.599236 - Training Epoch: 0 Training Iteration: 316  average_loss : nan  step_loss : nan  learning_rate : 0.0009475719817358499 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 316, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4202.608
DLL 2022-11-23 15:25:54.796636 - Training Epoch: 0 Training Iteration: 317  average_loss : nan  step_loss : nan  learning_rate : 0.0009505706272476723 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 317, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4159.651
DLL 2022-11-23 15:25:58.956382 - Training Epoch: 0 Training Iteration: 318  average_loss : nan  step_loss : nan  learning_rate : 0.0009535692727594946 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 318, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4160.447
DLL 2022-11-23 15:26:03.116705 - Training Epoch: 0 Training Iteration: 319  average_loss : nan  step_loss : nan  learning_rate : 0.0009565679182713168 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 319, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4157.416
DLL 2022-11-23 15:26:07.279215 - Training Epoch: 0 Training Iteration: 320  average_loss : nan  step_loss : nan  learning_rate : 0.0009595665637831392 
Process done with return code 1
Parent process ID: 96833 node: 172.31.28.108
1 per stage
8 servers!
Config:
ranks: range(0, 1)
train batch size: 1024
partitions: 8
chunk_size: 8
data depth: 1
stage to rank map: 0;1;2;3;4;5;6;7;
World size is 8
/opt/conda/envs/varuna/bin/python -u /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --rank=0 --chunk_size=8 --local_rank=0 --stage_to_rank_map=0;1;2;3;4;5;6;7; --batch-size=1024 --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna --resume_step 223
Signal handler called with signal 10


 STOPPING VARUNA !!



Process done with return code 1
Parent process ID: 97400 node: 172.31.28.108
2 per stage
16 servers!
Config:
ranks: range(0, 1)
train batch size: 1024
partitions: 8
chunk_size: 8
data depth: 2
stage to rank map: 0,8;1,9;2,10;3,11;4,12;5,13;6,14;7,15;
World size is 16
/opt/conda/envs/varuna/bin/python -u /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/run_pretraining.py --rank=0 --chunk_size=8 --local_rank=0 --stage_to_rank_map=0,8;1,9;2,10;3,11;4,12;5,13;6,14;7,15; --batch-size=512 --input_dir=/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/ --output_dir=s3://spot-checkpoints/bert --config_file=bert_config.json --bert_model=bert-large-uncased --train_batch_size=1024 --max_seq_length=128 --max_predictions_per_seq=20 --max_steps=7038 --warmup_proportion=0.2843 --num_steps_per_checkpoint=200 --learning_rate=6e-3 --seed=12439 --fp16 --gradient_accumulation_steps=128 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --do_train --json-summary /home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json --varuna --resume_step 223
device: cuda:0 n_gpu: 1, distributed training: True, 16-bits training: True
DLL 2022-11-23 15:26:34.203799 - PARAMETER Config : ["Namespace(input_dir='/hdf5_lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5/wikicorpus_en/', config_file='bert_config.json', bert_model='bert-large-uncased', output_dir='s3://spot-checkpoints/bert', init_checkpoint=None, max_seq_length=128, max_predictions_per_seq=20, train_batch_size=512, learning_rate=0.006, num_train_epochs=3.0, max_steps=7038.0, warmup_proportion=0.2843, local_rank=0, seed=12439, gradient_accumulation_steps=1, fp16=True, amp=False, loss_scale=0.0, log_freq=1.0, checkpoint_activations=False, resume_from_checkpoint=True, resume_step=223, num_steps_per_checkpoint=200, skip_checkpoint=False, phase2=False, allreduce_post_accumulation=False, allreduce_post_accumulation_fp16=False, phase1_end_step=7038, init_loss_scale=1048576, do_train=True, json_summary='/home/ubuntu/varuna_examples/DeepLearningExamples/PyTorch/LanguageModeling/BERT/results/dllogger.json', use_env=False, disable_progress_bar=False, steps_this_run=7038.0, varuna=True, stage_to_rank_map='0,8;1,9;2,10;3,11;4,12;5,13;6,14;7,15;', chunk_size=8, batch_size=512, rank=0, profiling=False, n_gpu=1)"] 
dry run time 0.0039010047912597656
SHARED WEIGHTS ARE
[(0, 7)]
this rank  0 is part of pipeline replica  0
64 chunks
Begin to load checkpint from s3://spot-checkpoints/bert/ckpt_223.pt
2022-11-23 15:26:44.334983 resume step from  223
Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.

Defaults for this optimization level are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
2022-11-23 15:27:00.644881 - Finished loading checkpoint, takes 16298.154 secs
DLL 2022-11-23 15:27:00.645755 - PARAMETER SEED : 12439 
DLL 2022-11-23 15:27:00.645876 - PARAMETER train_start : True 
DLL 2022-11-23 15:27:00.645948 - PARAMETER batch_size_per_gpu : 512 
DLL 2022-11-23 15:27:00.646029 - PARAMETER learning_rate : 0.006 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  524288.0
Finished iteration 223, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 12597.703
DLL 2022-11-23 15:27:13.281105 - Training Epoch: 0 Training Iteration: 224  average_loss : nan  step_loss : nan  learning_rate : 0.0006716965946481975 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  262144.0
Finished iteration 224, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5307.408
DLL 2022-11-23 15:27:18.588718 - Training Epoch: 0 Training Iteration: 225  average_loss : nan  step_loss : nan  learning_rate : 0.0006746952401600198 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  131072.0
Finished iteration 225, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5295.264
DLL 2022-11-23 15:27:23.883819 - Training Epoch: 0 Training Iteration: 226  average_loss : nan  step_loss : nan  learning_rate : 0.000677693885671842 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  65536.0
Finished iteration 226, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5232.599
DLL 2022-11-23 15:27:29.121682 - Training Epoch: 0 Training Iteration: 227  average_loss : nan  step_loss : nan  learning_rate : 0.0006806925311836643 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  32768.0
Finished iteration 227, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 5248.683
DLL 2022-11-23 15:27:34.365196 - Training Epoch: 0 Training Iteration: 228  average_loss : nan  step_loss : nan  learning_rate : 0.0006836911766954866 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  16384.0
Finished iteration 228, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4204.421
DLL 2022-11-23 15:27:38.569466 - Training Epoch: 0 Training Iteration: 229  average_loss : nan  step_loss : nan  learning_rate : 0.0006866898222073091 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  8192.0
Finished iteration 229, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4267.236
DLL 2022-11-23 15:27:42.836773 - Training Epoch: 0 Training Iteration: 230  average_loss : nan  step_loss : nan  learning_rate : 0.0006896884677191314 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  4096.0
Finished iteration 230, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4335.246
DLL 2022-11-23 15:27:47.172108 - Training Epoch: 0 Training Iteration: 231  average_loss : nan  step_loss : nan  learning_rate : 0.0006926871132309536 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  2048.0
Finished iteration 231, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4194.197
DLL 2022-11-23 15:27:51.365944 - Training Epoch: 0 Training Iteration: 232  average_loss : nan  step_loss : nan  learning_rate : 0.0006956857587427759 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1024.0
Finished iteration 232, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4416.724
DLL 2022-11-23 15:27:55.783044 - Training Epoch: 0 Training Iteration: 233  average_loss : nan  step_loss : nan  learning_rate : 0.0006986844042545982 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  512.0
Finished iteration 233, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4281.655
DLL 2022-11-23 15:28:00.074144 - Training Epoch: 0 Training Iteration: 234  average_loss : nan  step_loss : nan  learning_rate : 0.0007016830497664205 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  256.0
Finished iteration 234, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4484.506
DLL 2022-11-23 15:28:04.549107 - Training Epoch: 0 Training Iteration: 235  average_loss : nan  step_loss : nan  learning_rate : 0.0007046816952782429 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  128.0
Finished iteration 235, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4308.110
DLL 2022-11-23 15:28:08.857322 - Training Epoch: 0 Training Iteration: 236  average_loss : nan  step_loss : nan  learning_rate : 0.0007076803407900652 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  64.0
Finished iteration 236, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4184.474
DLL 2022-11-23 15:28:13.041822 - Training Epoch: 0 Training Iteration: 237  average_loss : nan  step_loss : nan  learning_rate : 0.0007106789863018875 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  32.0
Finished iteration 237, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4227.918
DLL 2022-11-23 15:28:17.270071 - Training Epoch: 0 Training Iteration: 238  average_loss : nan  step_loss : nan  learning_rate : 0.0007136776318137098 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  16.0
Finished iteration 238, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4193.200
DLL 2022-11-23 15:28:21.472365 - Training Epoch: 0 Training Iteration: 239  average_loss : nan  step_loss : nan  learning_rate : 0.0007166762773255321 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  8.0
Finished iteration 239, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4277.406
DLL 2022-11-23 15:28:25.740524 - Training Epoch: 0 Training Iteration: 240  average_loss : nan  step_loss : nan  learning_rate : 0.0007196749228373544 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  4.0
Finished iteration 240, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4162.278
DLL 2022-11-23 15:28:29.912161 - Training Epoch: 0 Training Iteration: 241  average_loss : nan  step_loss : nan  learning_rate : 0.0007226735683491767 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  2.0
Finished iteration 241, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4248.728
DLL 2022-11-23 15:28:34.151259 - Training Epoch: 0 Training Iteration: 242  average_loss : nan  step_loss : nan  learning_rate : 0.0007256722138609989 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 242, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4257.399
DLL 2022-11-23 15:28:38.409589 - Training Epoch: 0 Training Iteration: 243  average_loss : nan  step_loss : nan  learning_rate : 0.0007286708593728212 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 243, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4241.846
DLL 2022-11-23 15:28:42.650812 - Training Epoch: 0 Training Iteration: 244  average_loss : nan  step_loss : nan  learning_rate : 0.0007316695048846438 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 244, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4158.807
DLL 2022-11-23 15:28:46.809729 - Training Epoch: 0 Training Iteration: 245  average_loss : nan  step_loss : nan  learning_rate : 0.000734668150396466 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 245, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4165.655
DLL 2022-11-23 15:28:50.975041 - Training Epoch: 0 Training Iteration: 246  average_loss : nan  step_loss : nan  learning_rate : 0.0007376667959082883 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 246, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4037.594
DLL 2022-11-23 15:28:55.013154 - Training Epoch: 0 Training Iteration: 247  average_loss : nan  step_loss : nan  learning_rate : 0.0007406654414201106 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 247, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4312.622
DLL 2022-11-23 15:28:59.325871 - Training Epoch: 0 Training Iteration: 248  average_loss : nan  step_loss : nan  learning_rate : 0.0007436640869319328 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 248, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4285.359
DLL 2022-11-23 15:29:03.611045 - Training Epoch: 0 Training Iteration: 249  average_loss : nan  step_loss : nan  learning_rate : 0.0007466627324437552 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 249, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4303.130
DLL 2022-11-23 15:29:07.925860 - Training Epoch: 0 Training Iteration: 250  average_loss : nan  step_loss : nan  learning_rate : 0.0007496613779555775 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 250, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4138.322
DLL 2022-11-23 15:29:12.052555 - Training Epoch: 0 Training Iteration: 251  average_loss : nan  step_loss : nan  learning_rate : 0.0007526600234673998 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 251, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4137.626
DLL 2022-11-23 15:29:16.190120 - Training Epoch: 0 Training Iteration: 252  average_loss : nan  step_loss : nan  learning_rate : 0.0007556586689792222 
0 Overflow !!
0 : update_scale(): _has_overflow, dynamic. _loss_scale =  1.0
Finished iteration 252, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 4069.206
DLL 2022-11-23 15:29:20.268959 - Training Epoch: 0 Training Iteration: 253  average_loss : nan  step_loss : nan  learning_rate : 0.0007586573144910444 
