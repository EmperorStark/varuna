Parent process ID: 25468 node: 172.31.16.5
32 cutpoints
Stages 1
Micro-bs 32 Max mem: 8675329024.0
Predicted microbatch size for 1: 32
comm size 0
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 1 4 0 222679.87060546875 0
End of simulation:  Mini-batch time (usec) = 1777661
Min send: 10000000, max send 0
Min long send: 10000000, max long send 0
Min fwd: 10000000, max fwd 0; min bwd 10000000, max bwd 0
Min long fwd: 201398, max long fwd 203682; min long bwd 184795, max long bwd 189299
Time taken by simulation: 43 microseconds

Stages 2
Micro-bs 32 Max mem: 5306506956.799999
Predicted microbatch size for 2: 32
comm size 6422528
WARNING: no send time found, 2 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 2 8 0 42864.17007446289 339993.4039718803
End of simulation:  Mini-batch time (usec) = 2926179
Min send: 10000000, max send 0
Min long send: 340325, max long send 360040
Min fwd: 54106, max fwd 61226; min bwd 79729, max bwd 84071
Min long fwd: 142875, max long fwd 147087; min long bwd 100210, max long bwd 105674
Time taken by simulation: 162 microseconds

Stages 4
Micro-bs 32 Max mem: 3266000179.2
Predicted microbatch size for 4: 32
comm size 12845056
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 16 0 5012.969017028809 632152.0801385244
End of simulation:  Mini-batch time (usec) = 8186112
Min send: 10000000, max send 0
Min long send: 632289, max long send 656857
Min fwd: 22997, max fwd 85414; min bwd 32345, max bwd 55249
Min long fwd: 59874, max long fwd 66218; min long bwd 45265, max long bwd 54005
Time taken by simulation: 714 microseconds

Stages 8
Micro-bs 32 Max mem: 1980926361.6
Predicted microbatch size for 8: 32
comm size 12845056
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 32 0 1084.3276977539062 632152.0801385244
End of simulation:  Mini-batch time (usec) = 17887923
Min send: 10000000, max send 0
Min long send: 632168, max long send 660373
Min fwd: 5425, max fwd 48670; min bwd 12684, max bwd 35373
Min long fwd: 26803, max long fwd 34176; min long bwd 16127, max long bwd 25418
Time taken by simulation: 3231 microseconds

Stages 16
Micro-bs 32 Max mem: 1128991948.8
Predicted microbatch size for 16: 32
comm size 25690112
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 64 0 0 1028093.6227904424
End of simulation:  Mini-batch time (usec) = 61731430
Min send: 10000000, max send 0
Min long send: 1028093, max long send 1062462
Min fwd: 56, max fwd 33543; min bwd 2591, max bwd 20855
Min long fwd: 1672, max long fwd 12532; min long bwd 2017, max long bwd 11294
Time taken by simulation: 14112 microseconds

{1: 1.777661, 2: 2.926179, 4: 8.186112, 8: 17.887923, 16: 61.73143}
{1: 32, 2: 32, 4: 32, 8: 32, 16: 32}
best config is: 2 32
expected time is 2.926179
9 per stage
18 servers!
Config:
ranks: range(6, 7)
train batch size: 2048
partitions: 2
chunk_size: 32
data depth: 9
stage to rank map: 0,2,4,6,8,10,12,14,16;1,3,5,7,9,11,13,15,17;
World size is 18
/opt/conda/envs/varuna/bin/python -u main.py --rank=6 --chunk_size=32 --local_rank=0 --stage_to_rank_map=0,2,4,6,8,10,12,14,16;1,3,5,7,9,11,13,15,17; --batch-size=224 data -a resnet152 --varuna --lr 0.001 --epochs 1000 --resume s3://spot-checkpoints/resnet
=> creating model 'resnet152'
Files already downloaded and verified
Num cutpoints is 31
dry run time 0.8935050964355469
SHARED WEIGHTS ARE
None
this rank  6 is part of pipeline replica  3
7 chunks
6 Overflow !!
6 : update_scale(): _has_overflow, dynamic. _loss_scale =  524288.0
[2022-11-30 14:37:45.047987] Finished iteration 1, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 7802.082
6 Overflow !!
6 : update_scale(): _has_overflow, dynamic. _loss_scale =  262144.0
[2022-11-30 14:37:47.011791] Finished iteration 2, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1963.655
6 Overflow !!
6 : update_scale(): _has_overflow, dynamic. _loss_scale =  131072.0
[2022-11-30 14:37:48.031691] Finished iteration 3, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1019.798
6 Overflow !!
6 : update_scale(): _has_overflow, dynamic. _loss_scale =  65536.0
[2022-11-30 14:37:49.950719] Finished iteration 4, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1919.028
6 Overflow !!
6 : update_scale(): _has_overflow, dynamic. _loss_scale =  32768.0
[2022-11-30 14:37:51.973245] Finished iteration 5, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2022.536
6 Overflow !!
6 : update_scale(): _has_overflow, dynamic. _loss_scale =  16384.0
[2022-11-30 14:37:52.959849] Finished iteration 6, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 986.495
6 Overflow !!
6 : update_scale(): _has_overflow, dynamic. _loss_scale =  8192.0
[2022-11-30 14:37:53.853245] Finished iteration 7, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 893.362
6 Overflow !!
6 : update_scale(): _has_overflow, dynamic. _loss_scale =  4096.0
[2022-11-30 14:37:54.752530] Finished iteration 8, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 899.261
6 Overflow !!
6 : update_scale(): _has_overflow, dynamic. _loss_scale =  2048.0
[2022-11-30 14:37:55.749245] Finished iteration 9, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 996.674
6 Overflow !!
6 : update_scale(): _has_overflow, dynamic. _loss_scale =  1024.0
[2022-11-30 14:37:37.223135] Epoch: [0][ 10/224]	Time  0.980 ( 1.948)	Data  0.004 ( 0.341)	Loss 6.9464e+00 (7.0792e+00)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
[2022-11-30 14:37:56.732793] Finished iteration 10, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 983.522
[2022-11-30 14:37:57.714478] Finished iteration 11, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 981.671
[2022-11-30 14:37:58.690127] Finished iteration 12, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 975.591
[2022-11-30 14:37:59.607590] Finished iteration 13, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 917.447
[2022-11-30 14:38:00.635143] Finished iteration 14, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1027.513
[2022-11-30 14:38:01.619824] Finished iteration 15, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 984.639
[2022-11-30 14:38:02.618992] Finished iteration 16, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 999.117
[2022-11-30 14:38:03.505649] Finished iteration 17, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 886.623
[2022-11-30 14:38:04.500719] Finished iteration 18, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 995.030
[2022-11-30 14:38:05.424466] Finished iteration 19, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 923.705
[2022-11-30 14:37:37.223135] Epoch: [0][ 20/224]	Time  1.004 ( 1.459)	Data  0.008 ( 0.175)	Loss 4.7567e+00 (6.0971e+00)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
[2022-11-30 14:38:06.428643] Finished iteration 20, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1004.138
[2022-11-30 14:38:07.366724] Finished iteration 21, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 938.063
[2022-11-30 14:38:08.359752] Finished iteration 22, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 992.985
[2022-11-30 14:38:09.342818] Finished iteration 23, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 983.024
[2022-11-30 14:38:10.305043] Finished iteration 24, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 962.214
[2022-11-30 14:38:11.303159] Finished iteration 25, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 998.053
[2022-11-30 14:38:12.212288] Finished iteration 26, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 909.107
[2022-11-30 14:38:13.184495] Finished iteration 27, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 972.172
[2022-11-30 14:38:14.117362] Finished iteration 28, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 932.813
[2022-11-30 14:38:15.087779] Finished iteration 29, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 970.380
[2022-11-30 14:37:37.223135] Epoch: [0][ 30/224]	Time  0.992 ( 1.294)	Data  0.007 ( 0.119)	Loss 4.6953e+00 (5.6484e+00)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
[2022-11-30 14:38:16.079186] Finished iteration 30, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 991.362
[2022-11-30 14:38:17.026970] Finished iteration 31, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 947.763
[2022-11-30 14:38:18.007155] Finished iteration 32, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 980.148
[2022-11-30 14:38:18.941557] Finished iteration 33, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 934.356
[2022-11-30 14:38:19.954741] Finished iteration 34, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1013.149
[2022-11-30 14:38:20.952838] Finished iteration 35, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 998.095
[2022-11-30 14:38:21.948383] Finished iteration 36, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 995.478
[2022-11-30 14:38:22.927739] Finished iteration 37, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 979.290
[2022-11-30 14:38:23.980490] Finished iteration 38, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1052.716
[2022-11-30 14:38:24.958269] Finished iteration 39, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 977.777
[2022-11-30 14:37:37.223135] Epoch: [0][ 40/224]	Time  1.000 ( 1.218)	Data  0.007 ( 0.091)	Loss 4.6429e+00 (5.4045e+00)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
[2022-11-30 14:38:25.959437] Finished iteration 40, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1001.104
[2022-11-30 14:38:26.870995] Finished iteration 41, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 911.540
[2022-11-30 14:38:27.791203] Finished iteration 42, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 920.153
[2022-11-30 14:38:28.669426] Finished iteration 43, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 878.181
[2022-11-30 14:38:29.697448] Finished iteration 44, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1027.982
[2022-11-30 14:38:30.693504] Finished iteration 45, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 996.018
[2022-11-30 14:38:31.687941] Finished iteration 46, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 994.445
[2022-11-30 14:38:32.635404] Finished iteration 47, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 947.407
[2022-11-30 14:38:33.629322] Finished iteration 48, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 993.859
[2022-11-30 14:38:34.534805] Finished iteration 49, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 905.472
[2022-11-30 14:37:37.223135] Epoch: [0][ 50/224]	Time  1.019 ( 1.166)	Data  0.010 ( 0.074)	Loss 4.6797e+00 (5.2551e+00)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
[2022-11-30 14:38:35.548409] Finished iteration 50, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1013.521
[2022-11-30 14:38:36.558555] Finished iteration 51, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1010.164
[2022-11-30 14:38:37.537684] Finished iteration 52, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 979.058
[2022-11-30 14:38:38.532779] Finished iteration 53, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 995.054
[2022-11-30 14:38:39.552580] Finished iteration 54, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1019.763
[2022-11-30 14:38:40.547129] Finished iteration 55, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 994.514
[2022-11-30 14:38:41.500188] Finished iteration 56, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 953.022
[2022-11-30 14:38:42.432868] Finished iteration 57, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 932.643
[2022-11-30 14:38:43.419361] Finished iteration 58, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 986.436
[2022-11-30 14:38:44.335857] Finished iteration 59, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 916.464
[2022-11-30 14:37:37.223135] Epoch: [0][ 60/224]	Time  0.986 ( 1.134)	Data  0.015 ( 0.063)	Loss 4.6417e+00 (5.1539e+00)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
[2022-11-30 14:38:45.311728] Finished iteration 60, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 975.826
[2022-11-30 14:38:46.301634] Finished iteration 61, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 989.904
[2022-11-30 14:38:47.232070] Finished iteration 62, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 930.388
[2022-11-30 14:38:48.191559] Finished iteration 63, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 959.437
[2022-11-30 14:38:49.185079] Finished iteration 64, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 993.551
[2022-11-30 14:38:50.108415] Finished iteration 65, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 923.232
[2022-11-30 14:38:51.118916] Finished iteration 66, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1010.464
[2022-11-30 14:38:52.045756] Finished iteration 67, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 926.806
[2022-11-30 14:38:53.036013] Finished iteration 68, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 990.218
[2022-11-30 14:38:54.007075] Finished iteration 69, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 971.054
[2022-11-30 14:37:37.223135] Epoch: [0][ 70/224]	Time  0.901 ( 1.109)	Data  0.006 ( 0.055)	Loss 4.6535e+00 (5.0806e+00)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
[2022-11-30 14:38:54.910085] Finished iteration 70, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 902.926
[2022-11-30 14:38:55.892792] Finished iteration 71, CKPT_AND_STOP: False, flag: tensor([1], dtype=torch.int32), speed: 982.754
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 6 signal handler called with signal 10
Opt ckpt time 5.221433401107788
Process done with return code 0
Parent process ID: 26031 node: 172.31.16.5
32 cutpoints
Stages 1
Micro-bs 32 Max mem: 8675329024.0
Predicted microbatch size for 1: 32
comm size 0
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 1 4 0 217441.22314453125 0
End of simulation:  Mini-batch time (usec) = 1772423
Min send: 10000000, max send 0
Min long send: 10000000, max long send 0
Min fwd: 10000000, max fwd 0; min bwd 10000000, max bwd 0
Min long fwd: 201398, max long fwd 203682; min long bwd 184795, max long bwd 189299
Time taken by simulation: 44 microseconds

Stages 2
Micro-bs 32 Max mem: 5306506956.799999
Predicted microbatch size for 2: 32
comm size 6422528
WARNING: no send time found, 2 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 2 8 0 42123.68392944336 339993.4039718803
End of simulation:  Mini-batch time (usec) = 2925438
Min send: 10000000, max send 0
Min long send: 340325, max long send 360040
Min fwd: 54106, max fwd 61226; min bwd 79729, max bwd 84071
Min long fwd: 142875, max long fwd 147087; min long bwd 100210, max long bwd 105674
Time taken by simulation: 162 microseconds

Stages 4
Micro-bs 32 Max mem: 3266000179.2
Predicted microbatch size for 4: 32
comm size 12845056
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 16 0 5012.969017028809 632152.0801385244
End of simulation:  Mini-batch time (usec) = 8186112
Min send: 10000000, max send 0
Min long send: 632289, max long send 656857
Min fwd: 22997, max fwd 85414; min bwd 32345, max bwd 55249
Min long fwd: 59874, max long fwd 66218; min long bwd 45265, max long bwd 54005
Time taken by simulation: 713 microseconds

Stages 8
Micro-bs 32 Max mem: 1980926361.6
Predicted microbatch size for 8: 32
comm size 12845056
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 32 0 1084.3276977539062 632152.0801385244
End of simulation:  Mini-batch time (usec) = 17887923
Min send: 10000000, max send 0
Min long send: 632168, max long send 660373
Min fwd: 5425, max fwd 48670; min bwd 12684, max bwd 35373
Min long fwd: 26803, max long fwd 34176; min long bwd 16127, max long bwd 25418
Time taken by simulation: 3216 microseconds

Stages 16
Micro-bs 32 Max mem: 1128991948.8
Predicted microbatch size for 16: 32
comm size 25690112
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 64 0 0 1028093.6227904424
End of simulation:  Mini-batch time (usec) = 61731430
Min send: 10000000, max send 0
Min long send: 1028093, max long send 1062462
Min fwd: 56, max fwd 33543; min bwd 2591, max bwd 20855
Min long fwd: 1672, max long fwd 12532; min long bwd 2017, max long bwd 11294
Time taken by simulation: 14120 microseconds

{1: 1.772423, 2: 2.925438, 4: 8.186112, 8: 17.887923, 16: 61.73143}
{1: 32, 2: 32, 4: 32, 8: 32, 16: 32}
best config is: 2 32
expected time is 2.925438
8 per stage
16 servers!
Config:
ranks: range(6, 7)
train batch size: 2048
partitions: 2
chunk_size: 32
data depth: 8
stage to rank map: 0,2,4,6,8,10,12,14;1,3,5,7,9,11,13,15;
World size is 16
/opt/conda/envs/varuna/bin/python -u main.py --rank=6 --chunk_size=32 --local_rank=0 --stage_to_rank_map=0,2,4,6,8,10,12,14;1,3,5,7,9,11,13,15; --batch-size=256 data -a resnet152 --varuna --lr 0.001 --epochs 1000 --resume s3://spot-checkpoints/resnet --resume_step 71
=> creating model 'resnet152'
Files already downloaded and verified
Num cutpoints is 31
dry run time 1.018031358718872
SHARED WEIGHTS ARE
None
this rank  6 is part of pipeline replica  3
8 chunks
6 Overflow !!
6 : update_scale(): _has_overflow, dynamic. _loss_scale =  524288.0
[2022-11-30 14:41:05.885086] Finished iteration 72, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 8493.313
6 Overflow !!
6 : update_scale(): _has_overflow, dynamic. _loss_scale =  262144.0
[2022-11-30 14:41:06.956165] Finished iteration 73, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1070.847
6 Overflow !!
6 : update_scale(): _has_overflow, dynamic. _loss_scale =  131072.0
[2022-11-30 14:41:08.126769] Finished iteration 74, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1170.576
6 Overflow !!
6 : update_scale(): _has_overflow, dynamic. _loss_scale =  65536.0
[2022-11-30 14:41:10.242518] Finished iteration 75, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2115.779
6 Overflow !!
6 : update_scale(): _has_overflow, dynamic. _loss_scale =  32768.0
[2022-11-30 14:41:11.938051] Finished iteration 76, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1695.455
[2022-11-30 14:41:12.994580] Finished iteration 77, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1056.476
[2022-11-30 14:41:14.087396] Finished iteration 78, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1092.784
[2022-11-30 14:41:15.157427] Finished iteration 79, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1069.998
[2022-11-30 14:40:57.386625] Epoch: [0][ 80/196]	Time  1.078 ( 2.093)	Data  0.008 ( 0.253)	Loss 4.6284e+00 (4.6646e+00)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
[2022-11-30 14:41:16.242312] Finished iteration 80, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1084.847
[2022-11-30 14:41:17.525963] Finished iteration 81, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1283.740
[2022-11-30 14:41:18.549260] Finished iteration 82, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1023.144
[2022-11-30 14:41:19.721058] Finished iteration 83, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1171.815
[2022-11-30 14:41:20.804824] Finished iteration 84, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1083.680
[2022-11-30 14:41:21.803002] Finished iteration 85, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 998.143
[2022-11-30 14:41:22.890781] Finished iteration 86, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1087.738
[2022-11-30 14:41:23.946423] Finished iteration 87, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1055.649
[2022-11-30 14:41:24.982381] Finished iteration 88, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1035.962
[2022-11-30 14:41:26.030967] Finished iteration 89, CKPT_AND_STOP: False, flag: tensor([1], dtype=torch.int32), speed: 1048.494
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 6 signal handler called with signal 10
Opt ckpt time 9.276981353759766
Process done with return code 0
Parent process ID: 29460 node: 172.31.22.229
32 cutpoints
Stages 1
Micro-bs 32 Max mem: 8675329024.0
Predicted microbatch size for 1: 32
comm size 0
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 1 4 0 211804.62646484375 0
End of simulation:  Mini-batch time (usec) = 1766786
Min send: 10000000, max send 0
Min long send: 10000000, max long send 0
Min fwd: 10000000, max fwd 0; min bwd 10000000, max bwd 0
Min long fwd: 201398, max long fwd 203682; min long bwd 184795, max long bwd 189299
Time taken by simulation: 41 microseconds

Stages 2
Micro-bs 32 Max mem: 5306506956.799999
Predicted microbatch size for 2: 32
comm size 6422528
WARNING: no send time found, 2 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 2 8 0 42123.68392944336 339993.4039718803
End of simulation:  Mini-batch time (usec) = 2925438
Min send: 10000000, max send 0
Min long send: 340325, max long send 360040
Min fwd: 54106, max fwd 61226; min bwd 79729, max bwd 84071
Min long fwd: 142875, max long fwd 147087; min long bwd 100210, max long bwd 105674
Time taken by simulation: 158 microseconds

Stages 4
Micro-bs 32 Max mem: 3266000179.2
Predicted microbatch size for 4: 32
comm size 12845056
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 16 0 5012.969017028809 632152.0801385244
End of simulation:  Mini-batch time (usec) = 8186112
Min send: 10000000, max send 0
Min long send: 632289, max long send 656857
Min fwd: 22997, max fwd 85414; min bwd 32345, max bwd 55249
Min long fwd: 59874, max long fwd 66218; min long bwd 45265, max long bwd 54005
Time taken by simulation: 711 microseconds

Stages 8
Micro-bs 32 Max mem: 1980926361.6
Predicted microbatch size for 8: 32
comm size 12845056
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 32 0 1084.3276977539062 632152.0801385244
End of simulation:  Mini-batch time (usec) = 17887923
Min send: 10000000, max send 0
Min long send: 632168, max long send 660373
Min fwd: 5425, max fwd 48670; min bwd 12684, max bwd 35373
Min long fwd: 26803, max long fwd 34176; min long bwd 16127, max long bwd 25418
Time taken by simulation: 3219 microseconds

Stages 16
Micro-bs 32 Max mem: 1128991948.8
Predicted microbatch size for 16: 32
comm size 25690112
WARNING: no send time found, 16 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 16 64 0 0 1028093.6227904424
End of simulation:  Mini-batch time (usec) = 61731430
Min send: 10000000, max send 0
Min long send: 1028093, max long send 1062462
Min fwd: 56, max fwd 33543; min bwd 2591, max bwd 20855
Min long fwd: 1672, max long fwd 12532; min long bwd 2017, max long bwd 11294
Time taken by simulation: 14204 microseconds

{1: 1.766786, 2: 2.925438, 4: 8.186112, 8: 17.887923, 16: 61.73143}
{1: 32, 2: 32, 4: 32, 8: 32, 16: 32}
best config is: 2 32
expected time is 2.925438
8 per stage
16 servers!
Config:
ranks: range(6, 7)
train batch size: 2048
partitions: 2
chunk_size: 32
data depth: 8
stage to rank map: 0,2,4,6,8,10,12,14;1,3,5,7,9,11,13,15;
World size is 16
/opt/conda/envs/varuna/bin/python -u main.py --rank=6 --chunk_size=32 --local_rank=0 --stage_to_rank_map=0,2,4,6,8,10,12,14;1,3,5,7,9,11,13,15; --batch-size=256 data -a resnet152 --varuna --lr 0.001 --epochs 1000 --resume s3://spot-checkpoints/resnet --resume_step 89
=> creating model 'resnet152'
Files already downloaded and verified
Num cutpoints is 31
dry run time 0.8685953617095947
SHARED WEIGHTS ARE
None
this rank  6 is part of pipeline replica  3
8 chunks
Signal handler called with signal 10


 STOPPING VARUNA !!



Rank 6 signal handler called with signal 10
6 Overflow !!
6 : update_scale(): _has_overflow, dynamic. _loss_scale =  524288.0
[2022-11-30 14:43:21.889441] Epoch: [0][ 90/196]	Time  8.331 ( 8.331)	Data  1.512 ( 1.512)	Loss 4.6304e+00 (4.6304e+00)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
[2022-11-30 14:43:30.229858] Finished iteration 90, CKPT_AND_STOP: True, flag: tensor([8], dtype=torch.int32), speed: 8336.474
Opt ckpt time 4.027307033538818
Process done with return code 0
Parent process ID: 31842 node: 172.31.22.165
32 cutpoints
Stages 1
Micro-bs 32 Max mem: 8675329024.0
Predicted microbatch size for 1: 32
comm size 0
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 1 5 0 226787.1551513672 0
End of simulation:  Mini-batch time (usec) = 2165215
Min send: 10000000, max send 0
Min long send: 10000000, max long send 0
Min fwd: 10000000, max fwd 0; min bwd 10000000, max bwd 0
Min long fwd: 200267, max long fwd 203682; min long bwd 183179, max long bwd 189299
Time taken by simulation: 43 microseconds

Stages 2
Micro-bs 32 Max mem: 5306506956.799999
Predicted microbatch size for 2: 32
comm size 6422528
WARNING: no send time found, 2 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 2 10 0 41642.83752441406 339993.4039718803
End of simulation:  Mini-batch time (usec) = 3406748
Min send: 10000000, max send 0
Min long send: 340325, max long send 360040
Min fwd: 52710, max fwd 61918; min bwd 78306, max bwd 84606
Min long fwd: 142036, max long fwd 146873; min long bwd 101940, max long bwd 106151
Time taken by simulation: 192 microseconds

Stages 4
Micro-bs 32 Max mem: 3266000179.2
Predicted microbatch size for 4: 32
comm size 12845056
WARNING: no send time found, 4 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 4 22 0 4118.363380432129 632152.0801385244
End of simulation:  Mini-batch time (usec) = 10201214
Min send: 10000000, max send 0
Min long send: 632152, max long send 656857
Min fwd: 22752, max fwd 85634; min bwd 31589, max bwd 57169
Min long fwd: 59306, max long fwd 67128; min long bwd 46619, max long bwd 54005
Time taken by simulation: 1083 microseconds

Stages 8
Micro-bs 32 Max mem: 1980926361.6
Predicted microbatch size for 8: 32
comm size 12845056
WARNING: no send time found, 8 partitions
GPUS_PER_VM=1 /home/ubuntu/varuna/tools/simulator/simulate-varuna 8 64 0 0 632152.0801385244
End of simulation:  Mini-batch time (usec) = 28149140
Min send: 10000000, max send 0
Min long send: 632152, max long send 667010
Min fwd: 4835, max fwd 48670; min bwd 11023, max bwd 35714
Min long fwd: 24181, max long fwd 33731; min long bwd 12455, max long bwd 24170
Time taken by simulation: 6688 microseconds

can't have 16 stages!
{1: 2.165215, 2: 3.406748, 4: 10.201214, 8: 28.14914}
{1: 32, 2: 32, 4: 32, 8: 32}
best config is: 2 32
expected time is 3.406748
7 per stage
14 servers!
Config:
ranks: range(6, 7)
train batch size: 2048
partitions: 2
chunk_size: 32
data depth: 7
stage to rank map: 0,2,4,6,8,10,12;1,3,5,7,9,11,13;
World size is 14
/opt/conda/envs/varuna/bin/python -u main.py --rank=6 --chunk_size=32 --local_rank=0 --stage_to_rank_map=0,2,4,6,8,10,12;1,3,5,7,9,11,13; --batch-size=288 data -a resnet152 --varuna --lr 0.001 --epochs 1000 --resume s3://spot-checkpoints/resnet --resume_step 90
=> creating model 'resnet152'
Files already downloaded and verified
Num cutpoints is 31
dry run time 0.851306676864624
SHARED WEIGHTS ARE
None
this rank  6 is part of pipeline replica  3
9 chunks
6 Overflow !!
6 : update_scale(): _has_overflow, dynamic. _loss_scale =  524288.0
[2022-11-30 14:45:20.865617] Finished iteration 91, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 9471.878
6 Overflow !!
6 : update_scale(): _has_overflow, dynamic. _loss_scale =  262144.0
[2022-11-30 14:45:23.004060] Finished iteration 92, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2138.184
6 Overflow !!
6 : update_scale(): _has_overflow, dynamic. _loss_scale =  131072.0
[2022-11-30 14:45:25.116486] Finished iteration 93, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2112.397
6 Overflow !!
6 : update_scale(): _has_overflow, dynamic. _loss_scale =  65536.0
[2022-11-30 14:45:27.259931] Finished iteration 94, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2143.428
[2022-11-30 14:45:29.383702] Finished iteration 95, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 2123.718
[2022-11-30 14:45:30.515380] Finished iteration 96, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1131.629
[2022-11-30 14:45:31.657466] Finished iteration 97, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1142.040
[2022-11-30 14:45:32.799825] Finished iteration 98, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1142.431
[2022-11-30 14:45:33.991546] Finished iteration 99, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1191.577
[2022-11-30 14:45:11.389859] Epoch: [0][100/174]	Time  1.144 ( 2.374)	Data  0.005 ( 0.652)	Loss 4.6480e+00 (4.6297e+00)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
[2022-11-30 14:45:35.135588] Finished iteration 100, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1143.989
6 Overflow !!
6 : update_scale(): _has_overflow, dynamic. _loss_scale =  32768.0
[2022-11-30 14:45:36.277411] Finished iteration 101, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1141.805
[2022-11-30 14:45:37.348731] Finished iteration 102, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1071.290
[2022-11-30 14:45:38.478711] Finished iteration 103, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1129.969
[2022-11-30 14:45:39.637875] Finished iteration 104, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1159.126
[2022-11-30 14:45:40.781439] Finished iteration 105, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1143.529
[2022-11-30 14:45:41.912939] Finished iteration 106, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1131.418
[2022-11-30 14:45:43.094048] Finished iteration 107, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1181.079
[2022-11-30 14:45:44.186872] Finished iteration 108, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1092.778
[2022-11-30 14:45:45.344661] Finished iteration 109, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1157.752
[2022-11-30 14:45:11.389859] Epoch: [0][110/174]	Time  1.084 ( 1.752)	Data  0.004 ( 0.328)	Loss 4.6163e+00 (4.6308e+00)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
[2022-11-30 14:45:46.429634] Finished iteration 110, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1084.930
[2022-11-30 14:45:47.575670] Finished iteration 111, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1146.016
[2022-11-30 14:45:48.733680] Finished iteration 112, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1157.975
[2022-11-30 14:45:49.862014] Finished iteration 113, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1128.318
[2022-11-30 14:45:51.034422] Finished iteration 114, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1172.432
[2022-11-30 14:45:52.185664] Finished iteration 115, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1151.147
[2022-11-30 14:45:53.324408] Finished iteration 116, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1138.666
[2022-11-30 14:45:54.471242] Finished iteration 117, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1146.865
[2022-11-30 14:45:55.607884] Finished iteration 118, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1136.512
[2022-11-30 14:45:56.765470] Finished iteration 119, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1157.574
[2022-11-30 14:45:11.389859] Epoch: [0][120/174]	Time  1.122 ( 1.550)	Data  0.004 ( 0.220)	Loss 4.6363e+00 (4.6284e+00)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
[2022-11-30 14:45:57.887133] Finished iteration 120, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1121.723
[2022-11-30 14:45:59.042396] Finished iteration 121, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1155.160
[2022-11-30 14:46:00.184621] Finished iteration 122, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1142.164
[2022-11-30 14:46:01.324148] Finished iteration 123, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1139.454
[2022-11-30 14:46:02.473652] Finished iteration 124, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1149.484
[2022-11-30 14:46:03.597369] Finished iteration 125, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1123.676
[2022-11-30 14:46:04.691451] Finished iteration 126, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1094.061
[2022-11-30 14:46:05.833672] Finished iteration 127, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1142.175
[2022-11-30 14:46:06.965543] Finished iteration 128, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1131.828
[2022-11-30 14:46:08.116181] Finished iteration 129, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1150.629
[2022-11-30 14:45:11.389859] Epoch: [0][130/174]	Time  1.148 ( 1.447)	Data  0.005 ( 0.166)	Loss 4.6207e+00 (4.6273e+00)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
[2022-11-30 14:46:09.263605] Finished iteration 130, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1147.314
[2022-11-30 14:46:10.422621] Finished iteration 131, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1159.004
[2022-11-30 14:46:11.550388] Finished iteration 132, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1127.748
[2022-11-30 14:46:12.816956] Finished iteration 133, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1266.513
[2022-11-30 14:46:13.949804] Finished iteration 134, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1132.834
[2022-11-30 14:46:15.077804] Finished iteration 135, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1127.930
[2022-11-30 14:46:16.201640] Finished iteration 136, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1123.802
[2022-11-30 14:46:17.320320] Finished iteration 137, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1118.644
[2022-11-30 14:46:18.435204] Finished iteration 138, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1114.919
[2022-11-30 14:46:19.579754] Finished iteration 139, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1144.475
[2022-11-30 14:45:11.389859] Epoch: [0][140/174]	Time  1.172 ( 1.387)	Data  0.005 ( 0.134)	Loss 4.6267e+00 (4.6273e+00)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
[2022-11-30 14:46:20.751593] Finished iteration 140, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1171.746
[2022-11-30 14:46:21.886797] Finished iteration 141, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1135.191
[2022-11-30 14:46:23.046774] Finished iteration 142, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1159.938
[2022-11-30 14:46:24.233126] Finished iteration 143, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1186.319
[2022-11-30 14:46:25.330616] Finished iteration 144, CKPT_AND_STOP: False, flag: tensor([0], dtype=torch.int32), speed: 1097.482
